{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13199625",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13199625",
    "key": "ARROW-3842",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343858",
                "id": "12343858",
                "description": "",
                "name": "0.12.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-01-20"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=romainfrancois",
            "name": "romainfrancois",
            "key": "romainfrancois",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=romainfrancois&avatarId=35092",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=romainfrancois&avatarId=35092",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=romainfrancois&avatarId=35092",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=romainfrancois&avatarId=35092"
            },
            "displayName": "Romain Francois",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333008",
                "id": "12333008",
                "name": "R"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=romainfrancois",
            "name": "romainfrancois",
            "key": "romainfrancois",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=romainfrancois&avatarId=35092",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=romainfrancois&avatarId=35092",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=romainfrancois&avatarId=35092",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=romainfrancois&avatarId=35092"
            },
            "displayName": "Romain Francois",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=romainfrancois",
            "name": "romainfrancois",
            "key": "romainfrancois",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=romainfrancois&avatarId=35092",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=romainfrancois&avatarId=35092",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=romainfrancois&avatarId=35092",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=romainfrancois&avatarId=35092"
            },
            "displayName": "Romain Francois",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 1800,
            "total": 1800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 1800,
            "total": 1800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3842/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 3,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13199625/worklog/170238",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "romainfrancois opened a new pull request #3043: ARROW-3842: [R] RecordBatchStreamWriter api\nURL: https://github.com/apache/arrow/pull/3043\n \n \n   This ended up being more than anticipated. In this PR, trying to get closer to the pyarrow api.\r\n   \r\n   -  Using active bindings instead of methods for things that are exposed as properties in python\r\n   -  Using a factory function with the same name as the class name, e.g.. `arrow::RecordBatchFileWriter` gets a `RecordBatchFileWriter` function ....\r\n   \u001c\r\n    \u001cThis is fairly benign even though it's a big pr, it's mostly mechanical. \r\n   \r\n   @javierluraschi this probably affects code that e.g. uses `$schema()` and now should use `$schema` etc ...\r\n   \r\n   - `read_record_batch` now always need a `schema`\r\n   - `write_table` and `write_record_batch` are gone, and replaced with `write_arrow` which uses either the streaming format or the binary file format depending on the `stream` parameter: \r\n   \r\n       - `arrow::ipc::RecordBatchStreamWriter` : streaming format\r\n       - `arrow::ipc::RecordBatchFileWriter` : binary file format\r\n       - `character` : file format\r\n       - `fs_path` : file format\r\n       -  `raw` : streaming format\r\n   \r\n       it's always possible to construct a RecordBatchStreamWriter or a RecordBatchFileWriter from an InputStream of your choice if these defaults don't work, but I believe they make sense.  \r\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-28T14:52:38.885+0000",
                    "updated": "2018-11-28T14:52:38.885+0000",
                    "started": "2018-11-28T14:52:38.884+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "170238",
                    "issueId": "13199625"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13199625/worklog/171713",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm closed pull request #3043: ARROW-3842: [R] RecordBatchStreamWriter api\nURL: https://github.com/apache/arrow/pull/3043\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/r/.gitignore b/r/.gitignore\nindex 85c986810b..0f405f5713 100644\n--- a/r/.gitignore\n+++ b/r/.gitignore\n@@ -1,3 +1,6 @@\n+Meta\n+doc\n+inst/doc\n *.o\n *.o-*\n *.d\ndiff --git a/r/DESCRIPTION b/r/DESCRIPTION\nindex 0250023e8f..5f93c83f23 100644\n--- a/r/DESCRIPTION\n+++ b/r/DESCRIPTION\n@@ -61,6 +61,9 @@ Collate:\n     'memory_pool.R'\n     'message.R'\n     'on_exit.R'\n+    'read_record_batch.R'\n+    'read_table.R'\n     'reexports-bit64.R'\n     'reexports-tibble.R'\n+    'write_arrow.R'\n     'zzz.R'\ndiff --git a/r/NAMESPACE b/r/NAMESPACE\nindex 490d2118c5..10677b43f8 100644\n--- a/r/NAMESPACE\n+++ b/r/NAMESPACE\n@@ -6,57 +6,57 @@ S3method(\"==\",\"arrow::DataType\")\n S3method(\"==\",\"arrow::Field\")\n S3method(\"==\",\"arrow::RecordBatch\")\n S3method(\"==\",\"arrow::ipc::Message\")\n+S3method(BufferReader,\"arrow::Buffer\")\n+S3method(BufferReader,default)\n+S3method(FixedSizeBufferWriter,\"arrow::Buffer\")\n+S3method(FixedSizeBufferWriter,default)\n+S3method(MessageReader,\"arrow::io::InputStream\")\n+S3method(MessageReader,default)\n+S3method(RecordBatchFileReader,\"arrow::io::RandomAccessFile\")\n+S3method(RecordBatchFileReader,character)\n+S3method(RecordBatchFileReader,fs_path)\n+S3method(RecordBatchFileWriter,\"arrow::io::OutputStream\")\n+S3method(RecordBatchFileWriter,character)\n+S3method(RecordBatchFileWriter,fs_path)\n+S3method(RecordBatchStreamReader,\"arrow::io::InputStream\")\n+S3method(RecordBatchStreamReader,raw)\n+S3method(RecordBatchStreamWriter,\"arrow::io::OutputStream\")\n+S3method(RecordBatchStreamWriter,character)\n+S3method(RecordBatchStreamWriter,fs_path)\n S3method(as_tibble,\"arrow::RecordBatch\")\n S3method(as_tibble,\"arrow::Table\")\n+S3method(buffer,complex)\n S3method(buffer,default)\n S3method(buffer,integer)\n S3method(buffer,numeric)\n S3method(buffer,raw)\n-S3method(buffer_reader,\"arrow::Buffer\")\n-S3method(buffer_reader,default)\n S3method(feather_table_reader,\"arrow::io::RandomAccessFile\")\n S3method(feather_table_reader,\"arrow::ipc::feather::TableReader\")\n S3method(feather_table_reader,character)\n S3method(feather_table_reader,default)\n S3method(feather_table_reader,fs_path)\n S3method(feather_table_writer,\"arrow::io::OutputStream\")\n-S3method(fixed_size_buffer_writer,\"arrow::Buffer\")\n-S3method(fixed_size_buffer_writer,default)\n S3method(length,\"arrow::Array\")\n-S3method(message_reader,\"arrow::io::InputStream\")\n-S3method(message_reader,default)\n-S3method(message_reader,raw)\n S3method(names,\"arrow::RecordBatch\")\n S3method(print,\"arrow-enum\")\n S3method(read_message,\"arrow::io::InputStream\")\n-S3method(read_message,default)\n-S3method(read_record_batch,\"arrow::io::BufferReader\")\n-S3method(read_record_batch,\"arrow::io::RandomAccessFile\")\n+S3method(read_message,\"arrow::ipc::MessageReader\")\n+S3method(read_record_batch,\"arrow::Buffer\")\n+S3method(read_record_batch,\"arrow::io::InputStream\")\n S3method(read_record_batch,\"arrow::ipc::Message\")\n-S3method(read_record_batch,\"arrow::ipc::RecordBatchFileReader\")\n-S3method(read_record_batch,\"arrow::ipc::RecordBatchStreamReader\")\n-S3method(read_record_batch,character)\n-S3method(read_record_batch,fs_path)\n S3method(read_record_batch,raw)\n S3method(read_schema,\"arrow::Buffer\")\n S3method(read_schema,\"arrow::io::InputStream\")\n-S3method(read_schema,default)\n S3method(read_schema,raw)\n-S3method(read_table,\"arrow::io::BufferReader\")\n-S3method(read_table,\"arrow::io::RandomAccessFile\")\n S3method(read_table,\"arrow::ipc::RecordBatchFileReader\")\n S3method(read_table,\"arrow::ipc::RecordBatchStreamReader\")\n S3method(read_table,character)\n S3method(read_table,fs_path)\n S3method(read_table,raw)\n-S3method(record_batch_file_reader,\"arrow::io::RandomAccessFile\")\n-S3method(record_batch_file_reader,character)\n-S3method(record_batch_file_reader,fs_path)\n-S3method(record_batch_stream_reader,\"arrow::io::InputStream\")\n-S3method(record_batch_stream_reader,raw)\n-S3method(write_arrow,\"arrow::RecordBatch\")\n-S3method(write_arrow,\"arrow::Table\")\n-S3method(write_arrow,data.frame)\n+S3method(write_arrow,\"arrow::ipc::RecordBatchWriter\")\n+S3method(write_arrow,character)\n+S3method(write_arrow,fs_path)\n+S3method(write_arrow,raw)\n S3method(write_feather,\"arrow::RecordBatch\")\n S3method(write_feather,data.frame)\n S3method(write_feather,default)\n@@ -64,19 +64,20 @@ S3method(write_feather_RecordBatch,\"arrow::io::OutputStream\")\n S3method(write_feather_RecordBatch,character)\n S3method(write_feather_RecordBatch,default)\n S3method(write_feather_RecordBatch,fs_path)\n-S3method(write_record_batch,\"arrow::io::OutputStream\")\n-S3method(write_record_batch,\"arrow::ipc::RecordBatchWriter\")\n-S3method(write_record_batch,character)\n-S3method(write_record_batch,fs_path)\n-S3method(write_record_batch,raw)\n-S3method(write_table,\"arrow::io::OutputStream\")\n-S3method(write_table,\"arrow::ipc::RecordBatchWriter\")\n-S3method(write_table,character)\n-S3method(write_table,fs_path)\n-S3method(write_table,raw)\n+export(BufferOutputStream)\n+export(BufferReader)\n export(DateUnit)\n export(FileMode)\n+export(FileOutputStream)\n+export(FixedSizeBufferWriter)\n+export(MessageReader)\n export(MessageType)\n+export(MockOutputStream)\n+export(ReadableFile)\n+export(RecordBatchFileReader)\n+export(RecordBatchFileWriter)\n+export(RecordBatchStreamReader)\n+export(RecordBatchStreamWriter)\n export(StatusCode)\n export(TimeUnit)\n export(Type)\n@@ -84,20 +85,16 @@ export(array)\n export(as_tibble)\n export(boolean)\n export(buffer)\n-export(buffer_output_stream)\n-export(buffer_reader)\n export(cast_options)\n export(chunked_array)\n export(date32)\n export(date64)\n export(decimal)\n+export(default_memory_pool)\n export(dictionary)\n export(feather_table_reader)\n export(feather_table_writer)\n export(field)\n-export(file_open)\n-export(file_output_stream)\n-export(fixed_size_buffer_writer)\n export(float16)\n export(float32)\n export(float64)\n@@ -106,10 +103,8 @@ export(int32)\n export(int64)\n export(int8)\n export(list_of)\n-export(message_reader)\n export(mmap_create)\n export(mmap_open)\n-export(mock_output_stream)\n export(null)\n export(print.integer64)\n export(read_arrow)\n@@ -119,10 +114,6 @@ export(read_record_batch)\n export(read_schema)\n export(read_table)\n export(record_batch)\n-export(record_batch_file_reader)\n-export(record_batch_file_writer)\n-export(record_batch_stream_reader)\n-export(record_batch_stream_writer)\n export(schema)\n export(str.integer64)\n export(struct)\n@@ -138,8 +129,6 @@ export(utf8)\n export(write_arrow)\n export(write_feather)\n export(write_feather_RecordBatch)\n-export(write_record_batch)\n-export(write_table)\n importFrom(R6,R6Class)\n importFrom(Rcpp,sourceCpp)\n importFrom(assertthat,assert_that)\ndiff --git a/r/R/ArrayData.R b/r/R/ArrayData.R\nindex 47b858d589..765971b405 100644\n--- a/r/R/ArrayData.R\n+++ b/r/R/ArrayData.R\n@@ -17,6 +17,30 @@\n \n #' @include R6.R\n \n+#' @title class arrow::ArrayData\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Usage:\n+#'\n+#' ```\n+#' data <- array(...)$data()\n+#'\n+#' data$type()\n+#' data$length()\n+#' data$null_count()\n+#' data$offset()\n+#' data$buffers()\n+#' ```\n+#'\n+#' @section Methods:\n+#'\n+#' ...\n+#'\n+#' @rdname arrow__ArrayData\n+#' @name arrow__ArrayData\n `arrow::ArrayData` <- R6Class(\"arrow::ArrayData\",\n   inherit = `arrow::Object`,\n   active = list(\ndiff --git a/r/R/ChunkedArray.R b/r/R/ChunkedArray.R\nindex 338438f578..46e4076629 100644\n--- a/r/R/ChunkedArray.R\n+++ b/r/R/ChunkedArray.R\n@@ -17,14 +17,22 @@\n \n #' @include R6.R\n \n+#' @title class arrow::ChunkedArray\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__ChunkedArray\n+#' @name arrow__ChunkedArray\n `arrow::ChunkedArray` <- R6Class(\"arrow::ChunkedArray\", inherit = `arrow::Object`,\n   public = list(\n     length = function() ChunkedArray__length(self),\n-    null_count = function() ChunkedArray__null_count(self),\n-    num_chunks = function() ChunkedArray__num_chunks(self),\n     chunk = function(i) shared_ptr(`arrow::Array`, ChunkedArray__chunk(self, i)),\n-    chunks = function() purrr::map(ChunkedArray__chunks(self), shared_ptr, class = `arrow::Array`),\n-    type = function() `arrow::DataType`$dispatch(ChunkedArray__type(self)),\n     as_vector = function() ChunkedArray__as_vector(self),\n     Slice = function(offset, length = NULL){\n       if (is.null(length)) {\n@@ -38,10 +46,16 @@\n       assert_that(inherits(options, \"arrow::compute::CastOptions\"))\n       shared_ptr(`arrow::ChunkedArray`, ChunkedArray__cast(self, target_type, options))\n     }\n+  ),\n+  active = list(\n+    null_count = function() ChunkedArray__null_count(self),\n+    num_chunks = function() ChunkedArray__num_chunks(self),\n+    chunks = function() map(ChunkedArray__chunks(self), shared_ptr, class = `arrow::Array`),\n+    type = function() `arrow::DataType`$dispatch(ChunkedArray__type(self))\n   )\n )\n \n-#' create an arrow::Array from an R vector\n+#' create an [arrow::ChunkedArray][arrow__ChunkedArray] from various R vectors\n #'\n #' @param \\dots Vectors to coerce\n #' @param type currently ignored\ndiff --git a/r/R/Column.R b/r/R/Column.R\nindex bf3fe0a0e1..fb8af1ea31 100644\n--- a/r/R/Column.R\n+++ b/r/R/Column.R\n@@ -17,11 +17,26 @@\n \n #' @include R6.R\n \n+#' @title class arrow::Column\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__Column\n+#' @name arrow__Column\n `arrow::Column` <- R6Class(\"arrow::Column\", inherit = `arrow::Object`,\n   public = list(\n     length = function() Column__length(self),\n-    null_count = function() Column__null_count(self),\n-    type = function() `arrow::DataType`$dispatch(Column__type(self)),\n     data = function() shared_ptr(`arrow::ChunkedArray`, Column__data(self))\n+  ),\n+\n+  active = list(\n+    null_count = function() Column__null_count(self),\n+    type = function() `arrow::DataType`$dispatch(Column__type(self))\n   )\n )\ndiff --git a/r/R/Field.R b/r/R/Field.R\nindex 79c0f33be6..4f5636fbff 100644\n--- a/r/R/Field.R\n+++ b/r/R/Field.R\n@@ -17,20 +17,35 @@\n \n #' @include R6.R\n \n+#' @title class arrow::Field\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__Field\n+#' @name arrow__Field\n `arrow::Field` <- R6Class(\"arrow::Field\", inherit = `arrow::Object`,\n   public = list(\n     ToString = function() {\n       Field__ToString(self)\n     },\n+    Equals = function(other) {\n+      inherits(other, \"arrow::Field\") && Field__Equals(self, other)\n+    }\n+  ),\n+\n+  active = list(\n     name = function() {\n       Field__name(self)\n     },\n     nullable = function() {\n       Field__nullable(self)\n     },\n-    Equals = function(other) {\n-      inherits(other, \"arrow::Field\") && Field__Equals(self, other)\n-    },\n     type = function() {\n       `arrow::DataType`$dispatch(Field__type(self))\n     }\ndiff --git a/r/R/R6.R b/r/R/R6.R\nindex 1caa885d90..69d58e0c13 100644\n--- a/r/R/R6.R\n+++ b/r/R/R6.R\n@@ -54,15 +54,24 @@ unique_ptr <- function(class, xp) {\n   !(lhs == rhs)\n }\n \n+#' @title class arrow::DataType\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__DataType\n+#' @name arrow__DataType\n `arrow::DataType` <- R6Class(\"arrow::DataType\",\n   inherit = `arrow::Object`,\n   public = list(\n     ToString = function() {\n       DataType__ToString(self)\n     },\n-    name = function() {\n-      DataType__name(self)\n-    },\n     Equals = function(other) {\n       assert_that(inherits(other, \"arrow::DataType\"))\n       DataType__Equals(self, other)\n@@ -73,11 +82,9 @@ unique_ptr <- function(class, xp) {\n     children = function() {\n       map(DataType__children_pointer(self), shared_ptr, class= `arrow::Field`)\n     },\n-    id = function(){\n-      DataType__id(self)\n-    },\n+\n     ..dispatch = function(){\n-      switch(names(Type)[self$id()+1],\n+      switch(names(Type)[self$id + 1],\n         \"NA\" = null(),\n         BOOL = boolean(),\n         UINT8 = uint8(),\n@@ -107,6 +114,15 @@ unique_ptr <- function(class, xp) {\n         MAP = stop(\"Type MAP not implemented yet\")\n       )\n     }\n+  ),\n+\n+  active = list(\n+    id = function(){\n+      DataType__id(self)\n+    },\n+    name = function() {\n+      DataType__name(self)\n+    }\n   )\n )\n \n@@ -116,9 +132,21 @@ unique_ptr <- function(class, xp) {\n \n #----- metadata\n \n+#' @title class arrow::FixedWidthType\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__FixedWidthType\n+#' @name arrow__FixedWidthType\n `arrow::FixedWidthType` <- R6Class(\"arrow::FixedWidthType\",\n   inherit = `arrow::DataType`,\n-  public = list(\n+  active = list(\n     bit_width = function() FixedWidthType__bit_width(self)\n   )\n )\ndiff --git a/r/R/RcppExports.R b/r/R/RcppExports.R\nindex 324510cf1b..ccf854927b 100644\n--- a/r/R/RcppExports.R\n+++ b/r/R/RcppExports.R\n@@ -629,6 +629,10 @@ RecordBatch__schema <- function(x) {\n     .Call(`_arrow_RecordBatch__schema`, x)\n }\n \n+RecordBatch__columns <- function(batch) {\n+    .Call(`_arrow_RecordBatch__columns`, batch)\n+}\n+\n RecordBatch__column <- function(batch, i) {\n     .Call(`_arrow_RecordBatch__column`, batch, i)\n }\n@@ -665,6 +669,14 @@ RecordBatch__Slice2 <- function(self, offset, length) {\n     .Call(`_arrow_RecordBatch__Slice2`, self, offset, length)\n }\n \n+ipc___SerializeRecordBatch__Raw <- function(batch) {\n+    .Call(`_arrow_ipc___SerializeRecordBatch__Raw`, batch)\n+}\n+\n+ipc___ReadRecordBatch__InputStream__Schema <- function(stream, schema) {\n+    .Call(`_arrow_ipc___ReadRecordBatch__InputStream__Schema`, stream, schema)\n+}\n+\n RecordBatchReader__schema <- function(reader) {\n     .Call(`_arrow_RecordBatchReader__schema`, reader)\n }\n@@ -677,6 +689,10 @@ ipc___RecordBatchStreamReader__Open <- function(stream) {\n     .Call(`_arrow_ipc___RecordBatchStreamReader__Open`, stream)\n }\n \n+ipc___RecordBatchStreamReader__batches <- function(reader) {\n+    .Call(`_arrow_ipc___RecordBatchStreamReader__batches`, reader)\n+}\n+\n ipc___RecordBatchFileReader__schema <- function(reader) {\n     .Call(`_arrow_ipc___RecordBatchFileReader__schema`, reader)\n }\n@@ -701,16 +717,12 @@ Table__from_RecordBatchStreamReader <- function(reader) {\n     .Call(`_arrow_Table__from_RecordBatchStreamReader`, reader)\n }\n \n-ipc___RecordBatchFileWriter__Open <- function(stream, schema) {\n-    .Call(`_arrow_ipc___RecordBatchFileWriter__Open`, stream, schema)\n-}\n-\n-ipc___RecordBatchStreamWriter__Open <- function(stream, schema) {\n-    .Call(`_arrow_ipc___RecordBatchStreamWriter__Open`, stream, schema)\n+ipc___RecordBatchFileReader__batches <- function(reader) {\n+    .Call(`_arrow_ipc___RecordBatchFileReader__batches`, reader)\n }\n \n-ipc___RecordBatchWriter__WriteRecordBatch <- function(batch_writer, batch, allow_64bit) {\n-    invisible(.Call(`_arrow_ipc___RecordBatchWriter__WriteRecordBatch`, batch_writer, batch, allow_64bit))\n+ipc___RecordBatchWriter__WriteRecordBatch <- function(batch_writer, batch) {\n+    invisible(.Call(`_arrow_ipc___RecordBatchWriter__WriteRecordBatch`, batch_writer, batch))\n }\n \n ipc___RecordBatchWriter__WriteTable <- function(batch_writer, table) {\n@@ -721,6 +733,14 @@ ipc___RecordBatchWriter__Close <- function(batch_writer) {\n     invisible(.Call(`_arrow_ipc___RecordBatchWriter__Close`, batch_writer))\n }\n \n+ipc___RecordBatchFileWriter__Open <- function(stream, schema) {\n+    .Call(`_arrow_ipc___RecordBatchFileWriter__Open`, stream, schema)\n+}\n+\n+ipc___RecordBatchStreamWriter__Open <- function(stream, schema) {\n+    .Call(`_arrow_ipc___RecordBatchStreamWriter__Open`, stream, schema)\n+}\n+\n Table__from_dataframe <- function(tbl) {\n     .Call(`_arrow_Table__from_dataframe`, tbl)\n }\n@@ -745,3 +765,7 @@ Table__column <- function(table, i) {\n     .Call(`_arrow_Table__column`, table, i)\n }\n \n+Table__columns <- function(table) {\n+    .Call(`_arrow_Table__columns`, table)\n+}\n+\ndiff --git a/r/R/RecordBatch.R b/r/R/RecordBatch.R\nindex c606d12143..fed10abee7 100644\n--- a/r/R/RecordBatch.R\n+++ b/r/R/RecordBatch.R\n@@ -17,11 +17,20 @@\n \n #' @include R6.R\n \n+#' @title class arrow::RecordBatch\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__RecordBatch\n+#' @name arrow__RecordBatch\n `arrow::RecordBatch` <- R6Class(\"arrow::RecordBatch\", inherit = `arrow::Object`,\n   public = list(\n-    num_columns = function() RecordBatch__num_columns(self),\n-    num_rows = function() RecordBatch__num_rows(self),\n-    schema = function() shared_ptr(`arrow::Schema`, RecordBatch__schema(self)),\n     column = function(i) shared_ptr(`arrow::Array`, RecordBatch__column(self, i)),\n     column_name = function(i) RecordBatch__column_name(self, i),\n     names = function() RecordBatch__names(self),\n@@ -29,9 +38,11 @@\n       assert_that(inherits(other, \"arrow::RecordBatch\"))\n       RecordBatch__Equals(self, other)\n     },\n+\n     RemoveColumn = function(i){\n       shared_ptr(`arrow::RecordBatch`, RecordBatch__RemoveColumn(self, i))\n     },\n+\n     Slice = function(offset, length = NULL) {\n       if (is.null(length)) {\n         shared_ptr(`arrow::RecordBatch`, RecordBatch__Slice1(self, offset))\n@@ -40,14 +51,21 @@\n       }\n     },\n \n-    serialize = function(output_stream, ...) write_record_batch(self, output_stream, ...),\n+    serialize = function() ipc___SerializeRecordBatch__Raw(self),\n \n     cast = function(target_schema, safe = TRUE, options = cast_options(safe)) {\n       assert_that(inherits(target_schema, \"arrow::Schema\"))\n       assert_that(inherits(options, \"arrow::compute::CastOptions\"))\n-      assert_that(identical(self$schema()$names, target_schema$names), msg = \"incompatible schemas\")\n+      assert_that(identical(self$schema$names, target_schema$names), msg = \"incompatible schemas\")\n       shared_ptr(`arrow::RecordBatch`, RecordBatch__cast(self, target_schema, options))\n     }\n+  ),\n+\n+  active = list(\n+    num_columns = function() RecordBatch__num_columns(self),\n+    num_rows = function() RecordBatch__num_rows(self),\n+    schema = function() shared_ptr(`arrow::Schema`, RecordBatch__schema(self)),\n+    columns = function() map(RecordBatch__columns(self), shared_ptr, `arrow::Array`)\n   )\n )\n \n@@ -66,10 +84,11 @@\n   RecordBatch__to_dataframe(x)\n }\n \n-#' Create an arrow::RecordBatch from a data frame\n+#' Create an [arrow::RecordBatch][arrow__RecordBatch] from a data frame\n #'\n #' @param .data a data frame\n #'\n+#' @return a [arrow::RecordBatch][arrow__RecordBatch]\n #' @export\n record_batch <- function(.data){\n   shared_ptr(`arrow::RecordBatch`, RecordBatch__from_dataframe(.data))\ndiff --git a/r/R/RecordBatchReader.R b/r/R/RecordBatchReader.R\nindex 3503753842..222f05586c 100644\n--- a/r/R/RecordBatchReader.R\n+++ b/r/R/RecordBatchReader.R\n@@ -17,6 +17,18 @@\n \n #' @include R6.R\n \n+#' @title class arrow::RecordBatchReader\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__RecordBatchReader\n+#' @name arrow__RecordBatchReader\n `arrow::RecordBatchReader` <- R6Class(\"arrow::RecordBatchReader\", inherit = `arrow::Object`,\n   public = list(\n     schema = function() shared_ptr(`arrow::Schema`, RecordBatchReader__schema(self)),\n@@ -26,170 +38,87 @@\n   )\n )\n \n-`arrow::ipc::RecordBatchStreamReader` <- R6Class(\"arrow::ipc::RecordBatchStreamReader\", inherit = `arrow::RecordBatchReader`)\n+#' @title class arrow::ipc::RecordBatchStreamReader\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__ipc__RecordBatchStreamReader\n+#' @name arrow__ipc__RecordBatchStreamReader\n+`arrow::ipc::RecordBatchStreamReader` <- R6Class(\"arrow::ipc::RecordBatchStreamReader\", inherit = `arrow::RecordBatchReader`,\n+  public = list(\n+    batches = function() map(ipc___RecordBatchStreamReader__batches(self), shared_ptr, class = `arrow::RecordBatch`)\n+  )\n+)\n \n+#' @title class arrow::ipc::RecordBatchFileReader\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__ipc__RecordBatchFileReader\n+#' @name arrow__ipc__RecordBatchFileReader\n `arrow::ipc::RecordBatchFileReader` <- R6Class(\"arrow::ipc::RecordBatchFileReader\", inherit = `arrow::Object`,\n   public = list(\n     schema = function() shared_ptr(`arrow::Schema`, ipc___RecordBatchFileReader__schema(self)),\n     num_record_batches = function() ipc___RecordBatchFileReader__num_record_batches(self),\n-    ReadRecordBatch = function(i) shared_ptr(`arrow::RecordBatch`, ipc___RecordBatchFileReader__ReadRecordBatch(self, i))\n+    ReadRecordBatch = function(i) shared_ptr(`arrow::RecordBatch`, ipc___RecordBatchFileReader__ReadRecordBatch(self, i)),\n+\n+    batches = function() map(ipc___RecordBatchFileReader__batches(self), shared_ptr, class = `arrow::RecordBatch`)\n   )\n )\n \n-\n-#' Create a `arrow::ipc::RecordBatchStreamReader` from an input stream\n+#' Create a [arrow::ipc::RecordBatchStreamReader][arrow__ipc__RecordBatchStreamReader] from an input stream\n+#'\n+#' @param stream input stream, an [arrow::io::InputStream][arrow__io__InputStream] or a raw vector\n #'\n-#' @param stream input stream\n #' @export\n-record_batch_stream_reader <- function(stream){\n-  UseMethod(\"record_batch_stream_reader\")\n+RecordBatchStreamReader <- function(stream){\n+  UseMethod(\"RecordBatchStreamReader\")\n }\n \n #' @export\n-`record_batch_stream_reader.arrow::io::InputStream` <- function(stream) {\n+`RecordBatchStreamReader.arrow::io::InputStream` <- function(stream) {\n   shared_ptr(`arrow::ipc::RecordBatchStreamReader`, ipc___RecordBatchStreamReader__Open(stream))\n }\n \n #' @export\n-`record_batch_stream_reader.raw` <- function(stream) {\n-  record_batch_stream_reader(buffer_reader(stream))\n+`RecordBatchStreamReader.raw` <- function(stream) {\n+  RecordBatchStreamReader(BufferReader(stream))\n }\n \n \n-#' Create an `arrow::ipc::RecordBatchFileReader` from a file\n+#' Create an [arrow::ipc::RecordBatchFileReader][arrow__ipc__RecordBatchFileReader] from a file\n #'\n-#' @param file The file to read from\n+#' @param file The file to read from. A file path, or an [arrow::io::RandomAccessFile][arrow__ipc__RecordBatchFileReader]\n #'\n #' @export\n-record_batch_file_reader <- function(file) {\n-  UseMethod(\"record_batch_file_reader\")\n+RecordBatchFileReader <- function(file) {\n+  UseMethod(\"RecordBatchFileReader\")\n }\n \n #' @export\n-`record_batch_file_reader.arrow::io::RandomAccessFile` <- function(file) {\n+`RecordBatchFileReader.arrow::io::RandomAccessFile` <- function(file) {\n   shared_ptr(`arrow::ipc::RecordBatchFileReader`, ipc___RecordBatchFileReader__Open(file))\n }\n \n #' @export\n-`record_batch_file_reader.character` <- function(file) {\n+`RecordBatchFileReader.character` <- function(file) {\n   assert_that(length(file) == 1L)\n-  record_batch_file_reader(fs::path_abs(file))\n-}\n-\n-#' @export\n-`record_batch_file_reader.fs_path` <- function(file) {\n-  record_batch_file_reader(file_open(file))\n-}\n-\n-#-------- read_record_batch\n-\n-#' Read a single record batch from a stream\n-#'\n-#' @param stream input stream\n-#' @param ... additional parameters\n-#'\n-#' @details `stream` can be a `arrow::io::RandomAccessFile` stream as created by [file_open()] or [mmap_open()] or a path.\n-#'\n-#' @export\n-read_record_batch <- function(stream, ...){\n-  UseMethod(\"read_record_batch\")\n-}\n-\n-#' @export\n-read_record_batch.character <- function(stream, ...){\n-  assert_that(length(stream) == 1L)\n-  read_record_batch(fs::path_abs(stream))\n-}\n-\n-#' @export\n-read_record_batch.fs_path <- function(stream, ...){\n-  stream <- close_on_exit(file_open(stream))\n-  read_record_batch(stream)\n-}\n-\n-#' @export\n-`read_record_batch.arrow::io::RandomAccessFile` <- function(stream, ...){\n-  reader <- record_batch_file_reader(stream)\n-  reader$ReadRecordBatch(0)\n-}\n-\n-#' @export\n-`read_record_batch.arrow::io::BufferReader` <- function(stream, ...){\n-  reader <- record_batch_stream_reader(stream)\n-  reader$ReadNext()\n-}\n-\n-#' @export\n-read_record_batch.raw <- function(stream, ...){\n-  stream <- close_on_exit(buffer_reader(stream))\n-  read_record_batch(stream)\n-}\n-\n-#' @export\n-`read_record_batch.arrow::ipc::RecordBatchStreamReader` <- function(stream, ...) {\n-  stream$ReadNext()\n-}\n-\n-#' @export\n-`read_record_batch.arrow::ipc::RecordBatchFileReader` <- function(stream, i = 0, ...) {\n-  stream$ReadRecordBatch(i)\n-}\n-\n-#' @export\n-`read_record_batch.arrow::ipc::Message` <- function(stream, schema, ...) {\n-  assert_that(inherits(schema, \"arrow::Schema\"))\n-  shared_ptr(`arrow::RecordBatch`, ipc___ReadRecordBatch__Message__Schema(stream, schema))\n-}\n-\n-\n-#--------- read_table\n-\n-#' Read an arrow::Table from a stream\n-#'\n-#' @param stream stream. Either a stream created by [file_open()] or [mmap_open()] or a file path.\n-#'\n-#' @export\n-read_table <- function(stream){\n-  UseMethod(\"read_table\")\n+  RecordBatchFileReader(fs::path_abs(file))\n }\n \n #' @export\n-read_table.character <- function(stream){\n-  assert_that(length(stream) == 1L)\n-  read_table(fs::path_abs(stream))\n+`RecordBatchFileReader.fs_path` <- function(file) {\n+  RecordBatchFileReader(ReadableFile(file))\n }\n-\n-#' @export\n-read_table.fs_path <- function(stream) {\n-  stream <- close_on_exit(file_open(stream))\n-  read_table(stream)\n-}\n-\n-#' @export\n-`read_table.arrow::io::RandomAccessFile` <- function(stream) {\n-  reader <- record_batch_file_reader(stream)\n-  read_table(reader)\n-}\n-\n-#' @export\n-`read_table.arrow::ipc::RecordBatchFileReader` <- function(stream) {\n-  shared_ptr(`arrow::Table`, Table__from_RecordBatchFileReader(stream))\n-}\n-\n-#' @export\n-`read_table.arrow::ipc::RecordBatchStreamReader` <- function(stream) {\n-  shared_ptr(`arrow::Table`, Table__from_RecordBatchStreamReader(stream))\n-}\n-\n-#' @export\n-`read_table.arrow::io::BufferReader` <- function(stream) {\n-  reader <- record_batch_stream_reader(stream)\n-  read_table(reader)\n-}\n-\n-#' @export\n-`read_table.raw` <- function(stream) {\n-  stream <- close_on_exit(buffer_reader(stream))\n-  read_table(stream)\n-}\n-\ndiff --git a/r/R/RecordBatchWriter.R b/r/R/RecordBatchWriter.R\nindex 515b6986b9..77305114d3 100644\n--- a/r/R/RecordBatchWriter.R\n+++ b/r/R/RecordBatchWriter.R\n@@ -17,175 +17,174 @@\n \n #' @include R6.R\n \n+#' @title class arrow::ipc::RecordBatchWriter\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' - `$write_batch(batch)`: Write record batch to stream\n+#' - `$write_table(table)`: write Table to stream\n+#' - `$close()`: close stream\n+#'\n+#' @section Derived classes:\n+#'\n+#' - [arrow::ipc::RecordBatchStreamWriter][arrow__ipc__RecordBatchStreamWriter] implements the streaming binary format\n+#' - [arrow::ipc::RecordBatchFileWriter][arrow__ipc__RecordBatchFileWriter] implements the binary file format\n+#'\n+#' @rdname arrow__ipc__RecordBatchWriter\n+#' @name arrow__ipc__RecordBatchWriter\n `arrow::ipc::RecordBatchWriter` <- R6Class(\"arrow::ipc::RecordBatchWriter\", inherit = `arrow::Object`,\n   public = list(\n-    WriteRecordBatch = function(batch, allow_64bit) ipc___RecordBatchWriter__WriteRecordBatch(self, batch, allow_64bit),\n-    WriteTable = function(table) ipc___RecordBatchWriter__WriteTable(self, table),\n-    Close = function() ipc___RecordBatchWriter__Close(self)\n+    write_batch = function(batch) ipc___RecordBatchWriter__WriteRecordBatch(self, batch),\n+    write_table = function(table) ipc___RecordBatchWriter__WriteTable(self, table),\n+\n+    write = function(x) {\n+      if (inherits(x, \"arrow::RecordBatch\")) {\n+        self$write_batch(x)\n+      } else if(inherits(x, \"arrow::Table\")) {\n+        self$write_table(x)\n+      } else if (inherits(x, \"data.frame\")) {\n+        self$write_table(table(x))\n+      } else {\n+        abort(\"unexpected type for RecordBatchWriter$write(), must be an arrow::RecordBatch or an arrow::Table\")\n+      }\n+    },\n+\n+    close = function() ipc___RecordBatchWriter__Close(self)\n   )\n )\n \n-`arrow::ipc::RecordBatchStreamWriter` <- R6Class(\"arrow::ipc::RecordBatchStreamWriter\", inherit = `arrow::ipc::RecordBatchWriter`)\n-`arrow::ipc::RecordBatchFileWriter` <- R6Class(\"arrow::ipc::RecordBatchFileWriter\", inherit = `arrow::ipc::RecordBatchStreamWriter`)\n-\n-#' Create a record batch file writer from a stream\n+#' @title class arrow::ipc::RecordBatchStreamWriter\n #'\n-#' @param stream a stream\n-#' @param schema the schema of the batches\n+#' Writer for the Arrow streaming binary format\n #'\n-#' @return an `arrow::ipc::RecordBatchWriter` object\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n #'\n-#' @export\n-record_batch_file_writer <- function(stream, schema) {\n-  assert_that(\n-    inherits(stream, \"arrow::io::OutputStream\"),\n-    inherits(schema, \"arrow::Schema\")\n-  )\n-  shared_ptr(`arrow::ipc::RecordBatchFileWriter`, ipc___RecordBatchFileWriter__Open(stream, schema))\n-}\n-\n-#' Create a record batch stream writer\n+#' @section usage:\n #'\n-#' @param stream a stream\n-#' @param schema a schema\n+#' ```\n+#' writer <- RecordBatchStreamWriter(sink, schema)\n #'\n-#' @export\n-record_batch_stream_writer <- function(stream, schema) {\n-  assert_that(\n-    inherits(stream, \"arrow::io::OutputStream\"),\n-    inherits(schema, \"arrow::Schema\")\n-  )\n-  shared_ptr(`arrow::ipc::RecordBatchStreamWriter`, ipc___RecordBatchStreamWriter__Open(stream, schema))\n-}\n-\n-#-------- write_record_batch\n-\n-#' write a record batch\n+#' writer$write_batch(batch)\n+#' writer$write_table(table)\n+#' writer$close()\n+#' ```\n #'\n-#' @param x a `arrow::RecordBatch`\n-#' @param stream where to stream the record batch\n-#' @param ... extra parameters\n+#' @section Factory:\n #'\n-#' @export\n-write_record_batch <- function(x, stream, ...){\n-  UseMethod(\"write_record_batch\", stream)\n-}\n-\n-#' @export\n-`write_record_batch.arrow::io::OutputStream` <- function(x, stream, ...) {\n-  stream_writer <- close_on_exit(record_batch_stream_writer(stream, x$schema()))\n-  write_record_batch(x, stream_writer)\n-}\n-\n-#' @export\n-`write_record_batch.arrow::ipc::RecordBatchWriter` <- function(x, stream, allow_64bit = TRUE, ...){\n-  stream$WriteRecordBatch(x, allow_64bit)\n-}\n-\n-#' @export\n-`write_record_batch.character` <- function(x, stream, ...) {\n-  assert_that(length(stream) == 1L)\n-  write_record_batch(x, fs::path_abs(stream), ...)\n-}\n-\n-#' @export\n-`write_record_batch.fs_path` <- function(x, stream, ...) {\n-  assert_that(length(stream) == 1L)\n-  file_stream <- close_on_exit(file_output_stream(stream))\n-  file_writer <- close_on_exit(record_batch_file_writer(file_stream, x$schema()))\n-  write_record_batch(x, file_writer, ...)\n-}\n-\n-#' @export\n-`write_record_batch.raw` <- function(x, stream, ...) {\n-  # how many bytes do we need\n-  mock <- mock_output_stream()\n-  write_record_batch(x, mock)\n-  n <- mock$GetExtentBytesWritten()\n-\n-  bytes <- raw(n)\n-  buffer <- buffer(bytes)\n-  buffer_writer <- fixed_size_buffer_writer(buffer)\n-  write_record_batch(x, buffer_writer)\n-\n-  bytes\n-}\n-\n-#-------- stream Table\n-\n-#' write an arrow::Table\n+#' The [RecordBatchStreamWriter()] function creates a record batch stream writer.\n #'\n-#' @param x an `arrow::Table`\n-#' @param stream where to stream the record batch\n-#' @param ... extra parameters\n+#' @section Methods:\n+#' inherited from [arrow::ipc::RecordBatchWriter][arrow__ipc__RecordBatchWriter]\n #'\n-#' @export\n-write_table <- function(x, stream, ...) {\n-  UseMethod(\"write_table\", stream)\n-}\n+#' - `$write_batch(batch)`: Write record batch to stream\n+#' - `$write_table(table)`: write Table to stream\n+#' - `$close()`: close stream\n+#'\n+#' @rdname arrow__ipc__RecordBatchStreamWriter\n+#' @name arrow__ipc__RecordBatchStreamWriter\n+`arrow::ipc::RecordBatchStreamWriter` <- R6Class(\"arrow::ipc::RecordBatchStreamWriter\", inherit = `arrow::ipc::RecordBatchWriter`)\n \n+#' Writer for the Arrow streaming binary format\n+#'\n+#' @param sink Where to write. Can either be:\n+#'\n+#' - A string, meant as a file path, passed to [fs::path_abs()]\n+#' - a [file path][fs::path_abs()]\n+#' - [arrow::io::OutputStream][arrow__io__OutputStream]\n+#'\n+#' @param schema The [arrow::Schema][arrow__Schema] for data to be written.\n+#'\n+#' @return a [arrow::ipc::RecordBatchStreamWriter][arrow__ipc__RecordBatchStreamWriter]\n+#'\n #' @export\n-`write_table.arrow::io::OutputStream` <- function(x, stream, ...) {\n-  stream_writer <- close_on_exit(record_batch_stream_writer(stream, x$schema()))\n-  write_table(x, stream_writer)\n+RecordBatchStreamWriter <- function(sink, schema) {\n+  UseMethod(\"RecordBatchStreamWriter\")\n }\n \n #' @export\n-`write_table.arrow::ipc::RecordBatchWriter` <- function(x, stream, ...){\n-  stream$WriteTable(x)\n+RecordBatchStreamWriter.character <- function(sink, schema){\n+  RecordBatchStreamWriter(fs::path_abs(sink), schema)\n }\n \n #' @export\n-`write_table.character` <- function(x, stream, ...) {\n-  assert_that(length(stream) == 1L)\n-  write_table(x, fs::path_abs(stream), ...)\n+RecordBatchStreamWriter.fs_path <- function(sink, schema){\n+  RecordBatchStreamWriter(FileOutputStream(sink), schema)\n }\n \n #' @export\n-`write_table.fs_path` <- function(x, stream, ...) {\n-  assert_that(length(stream) == 1L)\n-  file_stream <- close_on_exit(file_output_stream(stream))\n-  file_writer <- close_on_exit(record_batch_file_writer(file_stream, x$schema()))\n-  write_table(x, file_writer, ...)\n+`RecordBatchStreamWriter.arrow::io::OutputStream` <- function(sink, schema){\n+  assert_that(inherits(schema, \"arrow::Schema\"))\n+  shared_ptr(`arrow::ipc::RecordBatchStreamWriter`, ipc___RecordBatchStreamWriter__Open(sink, schema))\n }\n \n-#' @export\n-`write_table.raw` <- function(x, stream, ...) {\n-  # how many bytes do we need\n-  mock <- mock_output_stream()\n-  write_table(x, mock)\n-  n <- mock$GetExtentBytesWritten()\n-\n-  bytes <- raw(n)\n-  buffer <- buffer(bytes)\n-  buffer_writer <- fixed_size_buffer_writer(buffer)\n-  write_table(x, buffer_writer)\n-\n-  bytes\n-}\n+#' @title class arrow::ipc::RecordBatchFileWriter\n+#'\n+#' Writer for the Arrow binary file format\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section usage:\n+#'\n+#' ```\n+#' writer <- RecordBatchFileWriter(sink, schema)\n+#'\n+#' writer$write_batch(batch)\n+#' writer$write_table(table)\n+#' writer$close()\n+#' ```\n+#'\n+#' @section Factory:\n+#'\n+#' The [RecordBatchFileWriter()] function creates a record batch stream writer.\n+#'\n+#' @section Methods:\n+#' inherited from [arrow::ipc::RecordBatchWriter][arrow__ipc__RecordBatchWriter]\n+#'\n+#' - `$write_batch(batch)`: Write record batch to stream\n+#' - `$write_table(table)`: write Table to stream\n+#' - `$close()`: close stream\n+#'\n+#' @rdname arrow__ipc__RecordBatchFileWriter\n+#' @name arrow__ipc__RecordBatchFileWriter\n+`arrow::ipc::RecordBatchFileWriter` <- R6Class(\"arrow::ipc::RecordBatchFileWriter\", inherit = `arrow::ipc::RecordBatchStreamWriter`)\n \n-#' Write an object to a stream\n+#' Create a record batch file writer from a stream\n #'\n-#' @param x An object to stream\n-#' @param stream A stream\n-#' @param ... additional parameters\n+#' @param sink Where to write. Can either be:\n+#'\n+#' - character vector of length one\n+#' - a [file path][fs::path_abs()]\n+#' - [arrow::io::OutputStream][arrow__io__OutputStream]\n+#'\n+#' @param schema The [arrow::Schema][arrow__Schema] for data to be written.\n+#'\n+#' @return an `arrow::ipc::RecordBatchWriter` object\n #'\n #' @export\n-write_arrow <- function(x, stream, ...){\n-  UseMethod(\"write_arrow\")\n+RecordBatchFileWriter <- function(sink, schema) {\n+  UseMethod(\"RecordBatchFileWriter\")\n }\n \n #' @export\n-`write_arrow.arrow::RecordBatch` <- function(x, stream, ...) {\n-  write_record_batch(x, stream, ...)\n+RecordBatchFileWriter.character <- function(sink, schema){\n+  RecordBatchFileWriter(fs::path_abs(sink), schema)\n }\n \n #' @export\n-`write_arrow.arrow::Table` <- function(x, stream, ...) {\n-  write_table(x, stream, ...)\n+RecordBatchFileWriter.fs_path <- function(sink, schema){\n+  RecordBatchFileWriter(FileOutputStream(sink), schema)\n }\n \n #' @export\n-`write_arrow.data.frame` <- function(x, stream, ...) {\n-  write_record_batch(record_batch(x), stream, ...)\n+`RecordBatchFileWriter.arrow::io::OutputStream` <- function(sink, schema){\n+  assert_that(inherits(schema, \"arrow::Schema\"))\n+  shared_ptr(`arrow::ipc::RecordBatchFileWriter`, ipc___RecordBatchFileWriter__Open(sink, schema))\n }\ndiff --git a/r/R/Schema.R b/r/R/Schema.R\nindex b158fee169..08047a3b11 100644\n--- a/r/R/Schema.R\n+++ b/r/R/Schema.R\n@@ -17,6 +17,30 @@\n \n #' @include R6.R\n \n+#' @title class arrow::Schema\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Usage:\n+#'\n+#' ```\n+#' s <- schema(...)\n+#'\n+#' s$ToString()\n+#' s$num_fields()\n+#' s$field(i)\n+#' ```\n+#'\n+#' @section Methods:\n+#'\n+#' - `$ToString()`: convert to a string\n+#' - `$num_fields()`: returns the number of fields\n+#' - `$field(i)`: returns the field at index `i` (0-based)\n+#'\n+#' @rdname arrow__Schema\n+#' @name arrow__Schema\n `arrow::Schema` <- R6Class(\"arrow::Schema\",\n   inherit = `arrow::Object`,\n   public = list(\n@@ -29,11 +53,11 @@\n   )\n )\n \n-#' Schema functions\n+#' Schema factory\n #'\n #' @param ... named list of data types\n #'\n-#' @return a Schema\n+#' @return a [schema][arrow__Schema]\n #'\n #' @export\n schema <- function(...){\n@@ -50,11 +74,6 @@ read_schema <- function(stream, ...) {\n   UseMethod(\"read_schema\")\n }\n \n-#' @export\n-read_schema.default <- function(stream, ...) {\n-  stop(\"unsupported\")\n-}\n-\n #' @export\n `read_schema.arrow::io::InputStream` <- function(stream, ...) {\n   shared_ptr(`arrow::Schema`, ipc___ReadSchema_InputStream(stream))\n@@ -62,10 +81,12 @@ read_schema.default <- function(stream, ...) {\n \n #' @export\n `read_schema.arrow::Buffer` <- function(stream, ...) {\n-  read_schema(buffer_reader(stream), ...)\n+  stream <- close_on_exit(BufferReader(stream))\n+  shared_ptr(`arrow::Schema`, ipc___ReadSchema_InputStream(stream))\n }\n \n #' @export\n `read_schema.raw` <- function(stream, ...) {\n-  read_schema(buffer(stream), ...)\n+  stream <- close_on_exit(BufferReader(stream))\n+  shared_ptr(`arrow::Schema`, ipc___ReadSchema_InputStream(stream))\n }\ndiff --git a/r/R/Table.R b/r/R/Table.R\nindex e7d4545c1f..8972634d59 100644\n--- a/r/R/Table.R\n+++ b/r/R/Table.R\n@@ -16,12 +16,21 @@\n # under the License.\n \n #' @include R6.R\n-\n+#'\n+#' @title class arrow::Table\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__Table\n+#' @name arrow__Table\n `arrow::Table` <- R6Class(\"arrow::Table\", inherit = `arrow::Object`,\n   public = list(\n-    num_columns = function() Table__num_columns(self),\n-    num_rows = function() Table__num_rows(self),\n-    schema = function() shared_ptr(`arrow::Schema`, Table__schema(self)),\n     column = function(i) shared_ptr(`arrow::Column`, Table__column(self, i)),\n \n     serialize = function(output_stream, ...) write_table(self, output_stream, ...),\n@@ -29,9 +38,16 @@\n     cast = function(target_schema, safe = TRUE, options = cast_options(safe)) {\n       assert_that(inherits(target_schema, \"arrow::Schema\"))\n       assert_that(inherits(options, \"arrow::compute::CastOptions\"))\n-      assert_that(identical(self$schema()$names, target_schema$names), msg = \"incompatible schemas\")\n+      assert_that(identical(self$schema$names, target_schema$names), msg = \"incompatible schemas\")\n       shared_ptr(`arrow::Table`, Table__cast(self, target_schema, options))\n     }\n+  ),\n+\n+  active = list(\n+    num_columns = function() Table__num_columns(self),\n+    num_rows = function() Table__num_rows(self),\n+    schema = function() shared_ptr(`arrow::Schema`, Table__schema(self)),\n+    columns = function() map(Table__columns(self), shared_ptr, class = `arrow::Column`)\n   )\n )\n \n@@ -48,14 +64,3 @@ table <- function(.data){\n `as_tibble.arrow::Table` <- function(x, ...){\n   Table__to_dataframe(x)\n }\n-\n-#' Read an tibble from an arrow::Table on disk\n-#'\n-#' @param stream input stream\n-#'\n-#' @return a [tibble::tibble]\n-#'\n-#' @export\n-read_arrow <- function(stream){\n-  as_tibble(read_table(stream))\n-}\ndiff --git a/r/R/array.R b/r/R/array.R\nindex 2d434f9a22..63fdb4e0f6 100644\n--- a/r/R/array.R\n+++ b/r/R/array.R\n@@ -17,18 +17,65 @@\n \n #' @include R6.R\n \n+#' @title class arrow::Array\n+#'\n+#' Array base type. Immutable data array with some logical type and some length.\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Usage:\n+#'\n+#' ```\n+#' a <- array(...)\n+#'\n+#' a$IsNull(i)\n+#' a$IsValid(i)\n+#' a$length() or length(a)\n+#' a$offset()\n+#' a$null_count()\n+#' a$type()\n+#' a$type_id()\n+#' a$Equals(b)\n+#' a$ApproxEquals(b)\n+#' a$as_vector()\n+#' a$ToString()\n+#' a$Slice(offset, length = NULL)\n+#' a$RangeEquals(other, start_idx, end_idx, other_start_idx)\n+#'\n+#' print(a)\n+#' a == a\n+#' ```\n+#'\n+#' @section Methods:\n+#'\n+#' - `$IsNull(i)`: Return true if value at index is null. Does not boundscheck\n+#' - `$IsValid(i)`: Return true if value at index is valid. Does not boundscheck\n+#' - `$length()`: Size in the number of elements this array contains\n+#' - `$offset()`: A relative position into another array's data, to enable zero-copy slicing\n+#' - `$null_count()`: The number of null entries in the array\n+#' - `$type()`: logical type of data\n+#' - `$type_id()`: type id\n+#' - `$Equals(other)` : is this array equal to `other`\n+#' - `$ApproxEquals(other)` :\n+#' - `$data()`: return the underlying [arrow::ArrayData][arrow__ArrayData]\n+#' - `$as_vector()`: convert to an R vector\n+#' - `$ToString()`: string representation of the array\n+#' - `$Slice(offset, length = NULL)` : Construct a zero-copy slice of the array with the indicated offset and length. If length is `NULL`, the slice goes until the end of the array.\n+#' - `$RangeEquals(other, start_idx, end_idx, other_start_idx)` :\n+#'\n+#' @rdname arrow__Array\n+#' @name arrow__Array\n `arrow::Array` <- R6Class(\"arrow::Array\",\n   inherit = `arrow::Object`,\n   public = list(\n     IsNull = function(i) Array__IsNull(self, i),\n     IsValid = function(i) Array__IsValid(self, i),\n     length = function() Array__length(self),\n-    offset = function() Array__offset(self),\n-    null_count = function() Array__null_count(self),\n-    type = function() `arrow::DataType`$dispatch(Array__type(self)),\n     type_id = function() Array__type_id(self),\n     Equals = function(other) Array__Equals(self, other),\n-    ApproxEquals = function(othet) Array__ApproxEquals(self, other),\n+    ApproxEquals = function(other) Array__ApproxEquals(self, other),\n     data = function() shared_ptr(`arrow::ArrayData`, Array__data(self)),\n     as_vector = function() Array__as_vector(self),\n     ToString = function() Array__ToString(self),\n@@ -48,6 +95,11 @@\n       assert_that(inherits(options, \"arrow::compute::CastOptions\"))\n       `arrow::Array`$dispatch(Array__cast(self, target_type, options))\n     }\n+  ),\n+  active = list(\n+    null_count = function() Array__null_count(self),\n+    offset = function() Array__offset(self),\n+    type = function() `arrow::DataType`$dispatch(Array__type(self))\n   )\n )\n \n@@ -65,7 +117,7 @@\n #' @export\n `==.arrow::Array` <- function(x, y) x$Equals(y)\n \n-#' create an arrow::Array from an R vector\n+#' create an [arrow::Array][arrow__Array] from an R vector\n #'\n #' @param \\dots Vectors to coerce\n #' @param type currently ignored\ndiff --git a/r/R/buffer.R b/r/R/buffer.R\nindex 9684a97291..2fecd0e4fc 100644\n--- a/r/R/buffer.R\n+++ b/r/R/buffer.R\n@@ -18,21 +18,38 @@\n #' @include R6.R\n #' @include enums.R\n \n+#' @title class arrow::Buffer\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' - `$is_mutable()` :\n+#' - `$ZeroPadding()` :\n+#' - `$size()` :\n+#' - `$capacity()`:\n+#'\n+#' @rdname arrow__Buffer\n+#' @name arrow__Buffer\n `arrow::Buffer` <- R6Class(\"arrow::Buffer\", inherit = `arrow::Object`,\n   public = list(\n+    ZeroPadding = function() Buffer__ZeroPadding(self)\n+  ),\n+\n+  active = list(\n     is_mutable = function() Buffer__is_mutable(self),\n-    ZeroPadding = function() Buffer__ZeroPadding(self),\n     size = function() Buffer__size(self),\n     capacity = function() Buffer__capacity(self)\n   )\n )\n \n-`arrow::MutableBuffer` <- R6Class(\"arrow::Buffer\", inherit = `arrow::Buffer`)\n-\n-#' Create a buffer from an R object\n+#' Create a [arrow::Buffer][arrow__Buffer] from an R object\n #'\n-#' @param x R object\n-#' @return an instance of `arrow::Buffer` that borrows memory from `x`\n+#' @param x R object. Only raw, numeric and integer vectors are currently supported\n+#'\n+#' @return an instance of [arrow::Buffer][arrow__Buffer] that borrows memory from `x`\n #'\n #' @export\n buffer <- function(x){\n@@ -44,7 +61,6 @@ buffer.default <- function(x) {\n   stop(\"cannot convert to Buffer\")\n }\n \n-\n #' @export\n buffer.raw <- function(x) {\n   shared_ptr(`arrow::Buffer`, r___RBuffer__initialize(x))\ndiff --git a/r/R/dictionary.R b/r/R/dictionary.R\nindex d8a71d92a9..3c3758df30 100644\n--- a/r/R/dictionary.R\n+++ b/r/R/dictionary.R\n@@ -17,15 +17,27 @@\n \n #' @include R6.R\n \n+#' @title class arrow::DictionaryType\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__DictionaryType\n+#' @name arrow__DictionaryType\n `arrow::DictionaryType` <- R6Class(\"arrow::DictionaryType\",\n   inherit = `arrow::FixedWidthType`,\n-  public = list(\n+\n+  active = list(\n     index_type = function() `arrow::DataType`$dispatch(DictionaryType__index_type(self)),\n-    name = function() DictionaryType__name(self),\n     dictionary = function() shared_ptr(`arrow::Array`, DictionaryType__dictionary(self)),\n+    name = function() DictionaryType__name(self),\n     ordered = function() DictionaryType__ordered(self)\n   )\n-\n )\n \n #' dictionary type factory\n@@ -34,6 +46,8 @@\n #' @param values values array, typically an arrow array of strings\n #' @param ordered Is this an ordered dictionary\n #'\n+#' @return a [arrow::DictionaryType][arrow__DictionaryType]\n+#'\n #' @export\n dictionary <- function(type, values, ordered = FALSE) {\n   assert_that(\ndiff --git a/r/R/feather.R b/r/R/feather.R\nindex c36c571bd4..bae71d31bc 100644\n--- a/r/R/feather.R\n+++ b/r/R/feather.R\n@@ -100,7 +100,7 @@ write_feather_RecordBatch <- function(data, stream) {\n #' @export\n #' @method write_feather_RecordBatch fs_path\n `write_feather_RecordBatch.fs_path` <- function(data, stream) {\n-  file_stream <- close_on_exit(file_output_stream(stream))\n+  file_stream <- close_on_exit(FileOutputStream(stream))\n   `write_feather_RecordBatch.arrow::io::OutputStream`(data, file_stream)\n }\n \n@@ -133,7 +133,7 @@ feather_table_reader.character <- function(file, mmap = TRUE, ...) {\n \n #' @export\n feather_table_reader.fs_path <- function(file, mmap = TRUE, ...) {\n-  stream <- if(isTRUE(mmap)) mmap_open(file, ...) else file_open(file, ...)\n+  stream <- if(isTRUE(mmap)) mmap_open(file, ...) else ReadableFile(file, ...)\n   feather_table_reader(stream)\n }\n \ndiff --git a/r/R/io.R b/r/R/io.R\nindex d453492741..b772be30ac 100644\n--- a/r/R/io.R\n+++ b/r/R/io.R\n@@ -19,45 +19,151 @@\n #' @include enums.R\n #' @include buffer.R\n \n-`arrow::io::Readable` <- R6Class(\"arrow::io::Readable\", inherit = `arrow::Object`,\n-  public = list(\n-    Read = function(nbytes) shared_ptr(`arrow::Buffer`, io___Readable__Read(self, nbytes))\n-  )\n-)\n-\n-`arrow::io::InputStream` <- R6Class(\"arrow::io::InputStream\", inherit = `arrow::io::Readable`,\n-  public = list(\n-    Close = function() io___InputStream__Close(self)\n-  )\n-)\n+# OutputStream ------------------------------------------------------------\n \n `arrow::io::Writable` <- R6Class(\"arrow::io::Writable\", inherit = `arrow::Object`)\n \n+#' @title OutputStream\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#'  - `arrow::Buffer` `Read`(`int` nbytes):  Read `nbytes` bytes\n+#'  - `void` `close`(): close the stream\n+#'\n+#' @rdname arrow__io__OutputStream\n+#' @name arrow__io__OutputStream\n `arrow::io::OutputStream` <- R6Class(\"arrow::io::OutputStream\", inherit = `arrow::io::Writable`,\n   public = list(\n-    Close = function() io___OutputStream__Close(self)\n+    close = function() io___OutputStream__Close(self)\n   )\n )\n \n+#' @title class arrow::io::FileOutputStream\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__FileOutputStream\n+#' @name arrow__io__FileOutputStream\n `arrow::io::FileOutputStream` <- R6Class(\"arrow::io::FileOutputStream\", inherit = `arrow::io::OutputStream`)\n \n+#' @title class arrow::io::MockOutputStream\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__MockOutputStream\n+#' @name arrow__io__MockOutputStream\n `arrow::io::MockOutputStream` <- R6Class(\"arrow::io::MockOutputStream\", inherit = `arrow::io::OutputStream`,\n   public = list(\n     GetExtentBytesWritten = function() io___MockOutputStream__GetExtentBytesWritten(self)\n   )\n )\n \n+#' @title class arrow::io::BufferOutputStream\n+#'\n+#' @usage NULL\n+#' @docType class\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__BufferOutputStream\n+#' @name arrow__io__BufferOutputStream\n `arrow::io::BufferOutputStream` <- R6Class(\"arrow::io::BufferOutputStream\", inherit = `arrow::io::OutputStream`,\n   public = list(\n     capacity = function() io___BufferOutputStream__capacity(self),\n-    Finish = function() shared_ptr(`arrow::Buffer`, io___BufferOutputStream__Finish(self)),\n+    getvalue = function() shared_ptr(`arrow::Buffer`, io___BufferOutputStream__Finish(self)),\n+\n     Write = function(bytes) io___BufferOutputStream__Write(self, bytes),\n     Tell = function() io___BufferOutputStream__Tell(self)\n   )\n )\n \n+#' @title class arrow::io::FixedSizeBufferWriter\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__FixedSizeBufferWriter\n+#' @name arrow__io__FixedSizeBufferWriter\n `arrow::io::FixedSizeBufferWriter` <- R6Class(\"arrow::io::FixedSizeBufferWriter\", inherit = `arrow::io::OutputStream`)\n \n+\n+# InputStream -------------------------------------------------------------\n+\n+#' @title class arrow::io::Readable\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__Readable\n+#' @name arrow__io__Readable\n+`arrow::io::Readable` <- R6Class(\"arrow::io::Readable\", inherit = `arrow::Object`,\n+  public = list(\n+    Read = function(nbytes) shared_ptr(`arrow::Buffer`, io___Readable__Read(self, nbytes))\n+  )\n+)\n+\n+#' @title class arrow::io::InputStream\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__InputStream\n+#' @name arrow__io__InputStream\n+`arrow::io::InputStream` <- R6Class(\"arrow::io::InputStream\", inherit = `arrow::io::Readable`,\n+  public = list(\n+    close = function() io___InputStream__Close(self)\n+  )\n+)\n+\n+#' @title class arrow::io::RandomAccessFile\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__RandomAccessFile\n+#' @name arrow__io__RandomAccessFile\n `arrow::io::RandomAccessFile` <- R6Class(\"arrow::io::RandomAccessFile\", inherit = `arrow::io::InputStream`,\n   public = list(\n     GetSize = function() io___RandomAccessFile__GetSize(self),\n@@ -67,94 +173,159 @@\n   )\n )\n \n+#' @title class arrow::io::MemoryMappedFile\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @seealso [mmap_open()], [mmap_create()]\n+#'\n+#'\n+#' @rdname arrow__io__MemoryMappedFile\n+#' @name arrow__io__MemoryMappedFile\n `arrow::io::MemoryMappedFile` <- R6Class(\"arrow::io::MemoryMappedFile\", inherit = `arrow::io::RandomAccessFile`,\n   public = list(\n     Resize = function(size) io___MemoryMappedFile__Resize(self, size)\n   )\n )\n \n+#' @title class arrow::io::ReadableFile\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__ReadableFile\n+#' @name arrow__io__ReadableFile\n `arrow::io::ReadableFile` <- R6Class(\"arrow::io::ReadableFile\", inherit = `arrow::io::RandomAccessFile`)\n-`arrow::io::BufferReader` <- R6Class(\"arrow::io::BufferReader\", inherit = `arrow::io::RandomAccessFile`)\n \n+#' @title class arrow::io::BufferReader\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#'  TODO\n+#'\n+#' @rdname arrow__io__BufferReader\n+#' @name arrow__io__BufferReader\n+`arrow::io::BufferReader` <- R6Class(\"arrow::io::BufferReader\", inherit = `arrow::io::RandomAccessFile`)\n \n #' Create a new read/write memory mapped file of a given size\n #'\n #' @param path file path\n #' @param size size in bytes\n-#' @param mode file mode (read/write/readwrite)\n-#' @param buffer an `arrow::Buffer`, typically created by [buffer()]\n-#' @param initial_capacity initial capacity for the buffer output stream\n #'\n-#' @rdname io\n+#' @return a [arrow::io::MemoryMappedFile][arrow__io__MemoryMappedFile]\n+#'\n #' @export\n-mmap_create <- `arrow::io::MemoryMappedFile`$create <- function(path, size) {\n+mmap_create <- function(path, size) {\n   shared_ptr(`arrow::io::MemoryMappedFile`, io___MemoryMappedFile__Create(fs::path_abs(path), size))\n }\n \n-#' @rdname io\n+#' Open a memory mapped file\n+#'\n+#' @param path file path\n+#' @param mode file mode (read/write/readwrite)\n+#'\n #' @export\n-mmap_open <- `arrow::io::MemoryMappedFile`$open <- function(path, mode = c(\"read\", \"write\", \"readwrite\")) {\n+mmap_open <- function(path, mode = c(\"read\", \"write\", \"readwrite\")) {\n   mode <- match(match.arg(mode), c(\"read\", \"write\", \"readwrite\")) - 1L\n   shared_ptr(`arrow::io::MemoryMappedFile`, io___MemoryMappedFile__Open(fs::path_abs(path), mode))\n }\n \n-#' @rdname io\n+#' open a [arrow::io::ReadableFile][arrow__io__ReadableFile]\n+#'\n+#' @param path file path\n+#'\n+#' @return a [arrow::io::ReadableFile][arrow__io__ReadableFile]\n+#'\n #' @export\n-file_open <- `arrow::io::ReadableFile`$open <- function(path) {\n+ReadableFile <- function(path) {\n   shared_ptr(`arrow::io::ReadableFile`, io___ReadableFile__Open(fs::path_abs(path)))\n }\n \n-#' @rdname io\n+#' Open a [arrow::io::FileOutputStream][arrow__io__FileOutputStream]\n+#'\n+#' @param path file path\n+#'\n+#' @return a [arrow::io::FileOutputStream][arrow__io__FileOutputStream]\n+#'\n #' @export\n-file_output_stream <- function(path) {\n+FileOutputStream <- function(path) {\n   shared_ptr(`arrow::io::FileOutputStream`, io___FileOutputStream__Open(path))\n }\n \n-#' @rdname io\n+#' Open a [arrow::io::MockOutputStream][arrow__io__MockOutputStream]\n+#'\n+#' @return a [arrow::io::MockOutputStream][arrow__io__MockOutputStream]\n+#'\n #' @export\n-mock_output_stream <- function() {\n+MockOutputStream <- function() {\n   shared_ptr(`arrow::io::MockOutputStream`, io___MockOutputStream__initialize())\n }\n \n-#' @rdname io\n+#' Open a [arrow::io::BufferOutputStream][arrow__io__BufferOutputStream]\n+#'\n+#' @param initial_capacity initial capacity\n+#'\n+#' @return a [arrow::io::BufferOutputStream][arrow__io__BufferOutputStream]\n+#'\n #' @export\n-buffer_output_stream <- function(initial_capacity = 0L) {\n+BufferOutputStream <- function(initial_capacity = 0L) {\n   shared_ptr(`arrow::io::BufferOutputStream`, io___BufferOutputStream__Create(initial_capacity))\n }\n \n-#' @rdname io\n+#' Open a [arrow::io::FixedSizeBufferWriter][arrow__io__FixedSizeBufferWriter]\n+#'\n+#' @param buffer [arrow::Buffer][arrow__Buffer] or something [buffer()] can handle\n+#'\n+#' @return a [arrow::io::BufferOutputStream][arrow__io__BufferOutputStream]\n+#'\n #' @export\n-fixed_size_buffer_writer <- function(buffer){\n-  UseMethod(\"fixed_size_buffer_writer\")\n+FixedSizeBufferWriter <- function(buffer){\n+  UseMethod(\"FixedSizeBufferWriter\")\n }\n \n #' @export\n-fixed_size_buffer_writer.default <- function(buffer){\n-  fixed_size_buffer_writer(buffer(buffer))\n+FixedSizeBufferWriter.default <- function(buffer){\n+  FixedSizeBufferWriter(buffer(buffer))\n }\n \n #' @export\n-`fixed_size_buffer_writer.arrow::Buffer` <- function(buffer){\n-  assert_that(buffer$is_mutable())\n+`FixedSizeBufferWriter.arrow::Buffer` <- function(buffer){\n+  assert_that(buffer$is_mutable)\n   shared_ptr(`arrow::io::FixedSizeBufferWriter`, io___FixedSizeBufferWriter__initialize(buffer))\n }\n \n-#' Create a `arrow::BufferReader`\n+#' Create a [arrow::io::BufferReader][arrow__io__BufferReader]\n #'\n #' @param x R object to treat as a buffer or a buffer created by [buffer()]\n #'\n #' @export\n-buffer_reader <- function(x) {\n-  UseMethod(\"buffer_reader\")\n+BufferReader <- function(x) {\n+  UseMethod(\"BufferReader\")\n }\n \n #' @export\n-`buffer_reader.arrow::Buffer` <- function(x) {\n-  shared_ptr(`arrow::io::BufferReader`, io___BufferReader__initialize(x))\n+BufferReader.default <- function(x) {\n+  BufferReader(buffer(x))\n }\n \n #' @export\n-buffer_reader.default <- function(x) {\n-  buffer_reader(buffer(x))\n+`BufferReader.arrow::Buffer` <- function(x) {\n+  shared_ptr(`arrow::io::BufferReader`, io___BufferReader__initialize(x))\n }\n-\ndiff --git a/r/R/memory_pool.R b/r/R/memory_pool.R\nindex 49f65d2a1f..88c2c7bc19 100644\n--- a/r/R/memory_pool.R\n+++ b/r/R/memory_pool.R\n@@ -16,7 +16,19 @@\n # under the License.\n \n #' @include R6.R\n-\n+#'\n+#' @title class arrow::MemoryPool\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow___MemoryPool\n+#' @name arrow__MemoryPool\n `arrow::MemoryPool` <- R6Class(\"arrow::MemoryPool\",\n   inherit = `arrow::Object`,\n   public = list(\n@@ -28,6 +40,10 @@\n   )\n )\n \n+#' default [arrow::MemoryPool][arrow__MemoryPool]\n+#'\n+#' @return the default [arrow::MemoryPool][arrow__MemoryPool]\n+#' @export\n default_memory_pool <- function() {\n   shared_ptr(`arrow::MemoryPool`, MemoryPool__default())\n }\ndiff --git a/r/R/message.R b/r/R/message.R\nindex f31fb9a53b..93c90c0976 100644\n--- a/r/R/message.R\n+++ b/r/R/message.R\n@@ -17,6 +17,18 @@\n \n #' @include R6.R\n \n+#' @title class arrow::ipc::Message\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__ipc__Message\n+#' @name arrow__ipc__Message\n `arrow::ipc::Message` <- R6Class(\"arrow::ipc::Message\", inherit = `arrow::Object`,\n   public = list(\n     Equals = function(other){\n@@ -24,10 +36,10 @@\n       ipc___Message__Equals(self, other)\n     },\n     body_length = function() ipc___Message__body_length(self),\n-    Verify = function() ipc___Message__Verify(self),\n-    type = function() ipc___Message__type(self)\n+    Verify = function() ipc___Message__Verify(self)\n   ),\n   active = list(\n+    type = function() ipc___Message__type(self),\n     metadata = function() shared_ptr(`arrow::Buffer`, ipc___Message__metadata(self)),\n     body = function() shared_ptr(`arrow::Buffer`, ipc___Message__body(self))\n   )\n@@ -36,51 +48,58 @@\n #' @export\n `==.arrow::ipc::Message` <- function(x, y) x$Equals(y)\n \n+#' @title class arrow::ipc::MessageReader\n+#'\n+#' @usage NULL\n+#' @format NULL\n+#' @docType class\n+#'\n+#' @section Methods:\n+#'\n+#' TODO\n+#'\n+#' @rdname arrow__ipc__MessageReader\n+#' @name arrow__ipc__MessageReader\n `arrow::ipc::MessageReader` <- R6Class(\"arrow::ipc::MessageReader\", inherit = `arrow::Object`,\n   public = list(\n     ReadNextMessage = function() unique_ptr(`arrow::ipc::Message`, ipc___MessageReader__ReadNextMessage(self))\n   )\n )\n \n-#' Read a Message from a stream\n+#' Open a MessageReader that reads from a stream\n #'\n #' @param stream an InputStream\n #'\n #' @export\n-read_message <- function(stream) {\n-  UseMethod(\"read_message\")\n+MessageReader <- function(stream) {\n+  UseMethod(\"MessageReader\")\n }\n \n #' @export\n-read_message.default <- function(stream) {\n-  stop(\"unsupported\")\n+MessageReader.default <- function(stream) {\n+  MessageReader(BufferReader(stream))\n }\n \n #' @export\n-`read_message.arrow::io::InputStream` <- function(stream) {\n-  unique_ptr(`arrow::ipc::Message`, ipc___ReadMessage(stream) )\n+`MessageReader.arrow::io::InputStream` <- function(stream) {\n+  unique_ptr(`arrow::ipc::MessageReader`, ipc___MessageReader__Open(stream))\n }\n \n-#' Open a MessageReader that reads from a stream\n+#' Read a Message from a stream\n #'\n #' @param stream an InputStream\n #'\n #' @export\n-message_reader <- function(stream) {\n-  UseMethod(\"message_reader\")\n-}\n-\n-#' @export\n-message_reader.default <- function(stream) {\n-  stop(\"unsupported\")\n+read_message <- function(stream) {\n+  UseMethod(\"read_message\")\n }\n \n #' @export\n-message_reader.raw <- function(stream) {\n-  message_reader(buffer_reader(stream))\n+`read_message.arrow::io::InputStream` <- function(stream) {\n+  unique_ptr(`arrow::ipc::Message`, ipc___ReadMessage(stream) )\n }\n \n #' @export\n-`message_reader.arrow::io::InputStream` <- function(stream) {\n-  unique_ptr(`arrow::ipc::MessageReader`, ipc___MessageReader__Open(stream))\n+`read_message.arrow::ipc::MessageReader` <- function(stream) {\n+  stream$ReadNextMessage()\n }\ndiff --git a/r/R/on_exit.R b/r/R/on_exit.R\nindex 9387169b8b..52b017404d 100644\n--- a/r/R/on_exit.R\n+++ b/r/R/on_exit.R\n@@ -17,7 +17,7 @@\n \n #' @importFrom withr defer_parent\n close_on_exit <- function(x, ...){\n-  defer_parent(x$Close(), ...)\n+  defer_parent(x$close(), ...)\n   x\n }\n \ndiff --git a/r/R/read_record_batch.R b/r/R/read_record_batch.R\nnew file mode 100644\nindex 0000000000..967ac5b765\n--- /dev/null\n+++ b/r/R/read_record_batch.R\n@@ -0,0 +1,52 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+#' read [arrow::RecordBatch][arrow__RecordBatch] as encapsulated IPC message, given a known [arrow::Schema][arrow__Schema]\n+#'\n+#' @param obj a [arrow::ipc::Message][arrow__ipc__Message], a [arrow::io::InputStream][arrow__io__InputStream], a [arrow::Buffer][arrow__Buffer], or a raw vector\n+#' @param schema a [arrow::Schema][arrow__Schema]\n+#'\n+#' @return a [arrow::RecordBatch][arrow__RecordBatch]\n+#'\n+#' @export\n+read_record_batch <- function(obj, schema){\n+  UseMethod(\"read_record_batch\")\n+}\n+\n+#' @export\n+`read_record_batch.arrow::ipc::Message` <- function(obj, schema) {\n+  assert_that(inherits(schema, \"arrow::Schema\"))\n+  shared_ptr(`arrow::RecordBatch`, ipc___ReadRecordBatch__Message__Schema(obj, schema))\n+}\n+\n+#' @export\n+`read_record_batch.arrow::io::InputStream` <- function(obj, schema) {\n+  assert_that(inherits(schema, \"arrow::Schema\"))\n+  shared_ptr(`arrow::RecordBatch`, ipc___ReadRecordBatch__InputStream__Schema(obj, schema))\n+}\n+\n+#' @export\n+read_record_batch.raw <- function(obj, schema){\n+  stream <- close_on_exit(BufferReader(obj))\n+  read_record_batch(stream, schema)\n+}\n+\n+#' @export\n+`read_record_batch.arrow::Buffer` <- function(obj, schema){\n+  stream <- close_on_exit(BufferReader(obj))\n+  read_record_batch(stream, schema)\n+}\ndiff --git a/r/R/read_table.R b/r/R/read_table.R\nnew file mode 100644\nindex 0000000000..a540a42173\n--- /dev/null\n+++ b/r/R/read_table.R\n@@ -0,0 +1,86 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+#' Read an [arrow::Table][arrow__Table] from a stream\n+#'\n+#' @param stream stream.\n+#'\n+#' - a [arrow::ipc::RecordBatchFileReader][arrow__ipc__RecordBatchFileReader]:\n+#'   read an [arrow::Table][arrow__Table]\n+#'   from all the record batches in the reader\n+#'\n+#' - a [arrow::ipc::RecordBatchStreamReader][arrow__ipc__RecordBatchStreamReader]:\n+#'   read an [arrow::Table][arrow__Table] from the remaining record batches\n+#'   in the reader\n+#'\n+#'  - a string or [file path][fs::path_abs()]: interpret the file as an arrow\n+#'    binary file format, and uses a [arrow::ipc::RecordBatchFileReader][arrow__ipc__RecordBatchFileReader]\n+#'    to process it.\n+#'\n+#'  - a raw vector: read using a [arrow::ipc::RecordBatchStreamReader][arrow__ipc__RecordBatchStreamReader]\n+#'\n+#' @return\n+#'\n+#'  - `read_table` returns an [arrow::Table][arrow__Table]\n+#'  - `read_arrow` returns a [tibble::tibble()]\n+#'\n+#' @details\n+#'\n+#' The methods using [arrow::ipc::RecordBatchFileReader][arrow__ipc__RecordBatchFileReader] and\n+#' [arrow::ipc::RecordBatchStreamReader][arrow__ipc__RecordBatchStreamReader] offer the most\n+#' flexibility. The other methods are for convenience.\n+#'\n+#' @export\n+read_table <- function(stream){\n+  UseMethod(\"read_table\")\n+}\n+\n+#' @export\n+`read_table.arrow::ipc::RecordBatchFileReader` <- function(stream) {\n+  shared_ptr(`arrow::Table`, Table__from_RecordBatchFileReader(stream))\n+}\n+\n+#' @export\n+`read_table.arrow::ipc::RecordBatchStreamReader` <- function(stream) {\n+  shared_ptr(`arrow::Table`, Table__from_RecordBatchStreamReader(stream))\n+}\n+\n+#' @export\n+read_table.character <- function(stream){\n+  assert_that(length(stream) == 1L)\n+  read_table(fs::path_abs(stream))\n+}\n+\n+#' @export\n+read_table.fs_path <- function(stream) {\n+  stream <- close_on_exit(ReadableFile(stream))\n+  batch_reader <- close_on_exit(RecordBatchFileReader(stream))\n+  shared_ptr(`arrow::Table`, Table__from_RecordBatchFileReader(batch_reader))\n+}\n+\n+#' @export\n+`read_table.raw` <- function(stream) {\n+  stream <- close_on_exit(BufferReader(stream))\n+  batch_reader <- close_on_exit(RecordBatchStreamReader(stream))\n+  shared_ptr(`arrow::Table`, Table__from_RecordBatchStreamReader(batch_reader))\n+}\n+\n+#' @rdname read_table\n+#' @export\n+read_arrow <- function(stream){\n+  as_tibble(read_table(stream))\n+}\ndiff --git a/r/R/write_arrow.R b/r/R/write_arrow.R\nnew file mode 100644\nindex 0000000000..5fc684771e\n--- /dev/null\n+++ b/r/R/write_arrow.R\n@@ -0,0 +1,94 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+to_arrow <- function(x) {\n+  UseMethod(\"to_arrow\")\n+}\n+\n+`to_arrow.arrow::RecordBatch` <- function(x) x\n+`to_arrow.arrow::Table` <- function(x) x\n+`to_arrow.data.frame` <- function(x) table(x)\n+\n+#' serialize an [arrow::Table][arrow__Table], an [arrow::RecordBatch][arrow__RecordBatch], or a\n+#'   data frame to either the streaming format or the binary file format\n+#'\n+#' @param x an [arrow::Table][arrow__Table], an [arrow::RecordBatch][arrow__RecordBatch] or a data.frame\n+#'\n+#' @param stream where to serialize to\n+#'\n+#' - A [arrow::ipc::RecordBatchWriter][arrow__ipc__RecordBatchWriter]: the `$write()`\n+#'      of `x` is used. The stream is left open. This uses the streaming format\n+#'      or the binary file format depending on the type of the writer.\n+#'\n+#' - A string or [file path][fs::path_abs()]: `x` is serialized with\n+#'      a [arrow::ipc::RecordBatchFileWriter][arrow__ipc__RecordBatchFileWriter], i.e.\n+#'      using the binary file format.\n+#'\n+#' - A raw vector: typically of length zero (its data is ignored, and only used for\n+#'      dispatch). `x` is serialized using the streaming format, i.e. using the\n+#'      [arrow::ipc::RecordBatchStreamWriter][arrow__ipc__RecordBatchStreamWriter]\n+#'\n+#' @param ... extra parameters, currently ignored\n+#'\n+#' `write_arrow` is a convenience function, the classes [arrow::ipc::RecordBatchFileWriter][arrow__ipc__RecordBatchFileWriter]\n+#' and [arrow::ipc::RecordBatchStreamWriter][arrow__ipc__RecordBatchStreamWriter] can be used for more flexibility.\n+#'\n+#' @export\n+write_arrow <- function(x, stream, ...) {\n+  UseMethod(\"write_arrow\", stream)\n+}\n+\n+#' @export\n+`write_arrow.arrow::ipc::RecordBatchWriter` <- function(x, stream, ...){\n+  stream$write(x)\n+}\n+\n+#' @export\n+`write_arrow.character` <- function(x, stream, ...) {\n+  write_arrow(x, fs::path_abs(stream), ...)\n+}\n+\n+#' @export\n+`write_arrow.fs_path` <- function(x, stream, ...) {\n+  assert_that(length(stream) == 1L)\n+  x <- to_arrow(x)\n+  file_stream <- close_on_exit(FileOutputStream(stream))\n+  file_writer <- close_on_exit(RecordBatchFileWriter(file_stream, x$schema))\n+  write_arrow(x, file_writer, ...)\n+}\n+\n+#' @export\n+`write_arrow.raw` <- function(x, stream, ...) {\n+  x <- to_arrow(x)\n+  schema <- x$schema\n+\n+  # how many bytes do we need\n+  mock_stream <- MockOutputStream()\n+  writer <- RecordBatchStreamWriter(mock_stream, schema)\n+  writer$write(x)\n+  writer$close()\n+  n <- mock_stream$GetExtentBytesWritten()\n+\n+  # now that we know the size, stream in a buffer backed by an R raw vector\n+  bytes <- raw(n)\n+  buffer_writer <- FixedSizeBufferWriter(buffer(bytes))\n+  writer <- RecordBatchStreamWriter(buffer_writer, schema)\n+  writer$write(x)\n+  writer$close()\n+\n+  bytes\n+}\ndiff --git a/r/README.Rmd b/r/README.Rmd\nindex 204a9f9d56..2c51d01c0f 100644\n--- a/r/README.Rmd\n+++ b/r/README.Rmd\n@@ -46,9 +46,9 @@ tf <- tempfile()\n \n # write arrow::Table to file\n (tib <- tibble(x = 1:10, y = rnorm(10)))\n-arrow::write_arrow(tib, tf)\n+# arrow::write_arrow(tib, tf)\n \n-# read it back with pyarrow\n-pa <- import(\"pyarrow\")\n-as_tibble(pa$open_file(tf)$read_pandas())\n+# # read it back with pyarrow\n+# pa <- import(\"pyarrow\")\n+# as_tibble(pa$open_file(tf)$read_pandas())\n ```\ndiff --git a/r/configure b/r/configure\nindex 69f04632a2..28f6a73ac7 100755\n--- a/r/configure\n+++ b/r/configure\n@@ -91,7 +91,7 @@ if [ $? -ne 0 ]; then\n fi\n \n # Write to Makevars\n-sed -e \"s|@cflags@|$PKG_CFLAGS|\" -e \"s|@libs@|$PKG_LIBS|\" src/Makevars.in > src/Makevars\n+sed -e \"s|@cflags@|$PKG_CFLAGS|\" -e \"s|@libs@|$PKG_LIBS|\" -e \"s|@visibility@|$C_VISIBILITY|\" src/Makevars.in > src/Makevars\n \n # Success\n exit 0\ndiff --git a/r/data-raw/test.R b/r/data-raw/test.R\ndeleted file mode 100644\nindex 516af58616..0000000000\n--- a/r/data-raw/test.R\n+++ /dev/null\n@@ -1,85 +0,0 @@\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#   http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-library(tidyverse)\n-library(arrow)\n-\n-# meta data\n-(t1 <- int32())\n-(t2 <- utf8())\n-(t5 <- timestamp(unit = TimeUnit$MILLI))\n-\n-# lists\n-list_of(t1)\n-\n-# shema\n-schema(x = int32(), y = float64())\n-\n-# :scream_cat:\n-#\n-# pa.schema(\n-#   [\n-#      pa.field('x', pa.int32()),\n-#      pa.field('y', pa.float64())\n-#   ]\n-# )\n-#\n-\n-schema(x = int32(), y = list_of(float64()))\n-\n-#------- arrays\n-\n-# arr = pa.array([1, 2, 3])\n-arr <- array(1:3, 5:80)\n-arr\n-arr$as_vector()\n-\n-#------- read_arrow / stream\n-tbl <- tibble(x=1:10, y=rnorm(10))\n-write_arrow(tbl, \"/tmp/test.arrow\")\n-readr::write_rds(tbl, \"/tmp/test.rds\")\n-fs::file_info(c(\"/tmp/test.arrow\", \"/tmp/test.rds\"))\n-\n-(data <- read_arrow(\"/tmp/test.arrow\"))\n-\n-# tibble <-> arrow::RecordBatch\n-(batch <- record_batch(tbl))\n-batch$num_columns()\n-batch$num_rows()\n-write_arrow(batch, \"/tmp/test\")\n-readBin(\"/tmp/test\", what = raw(), n = 1000)\n-batch$schema()\n-all.equal(tbl, data)\n-\n-batch <- read_record_batch(\"/tmp/test\")\n-batch$schema()\n-batch$column(0)\n-batch$column(0)$as_vector()\n-\n-as_tibble(batch)\n-\n-# tibble <-> arrow::Table\n-tab <- arrow::table(tbl)\n-tab\n-tab$schema()\n-tab$num_columns()\n-tab$num_rows()\n-\n-# read_arrow, stream\n-tbl <- tibble(x = rnorm(20), y = seq_len(20))\n-write_arrow(tbl, tf)\n-\ndiff --git a/r/man/BufferOutputStream.Rd b/r/man/BufferOutputStream.Rd\nnew file mode 100644\nindex 0000000000..1776f99593\n--- /dev/null\n+++ b/r/man/BufferOutputStream.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\name{BufferOutputStream}\n+\\alias{BufferOutputStream}\n+\\title{Open a \\link[=arrow__io__BufferOutputStream]{arrow::io::BufferOutputStream}}\n+\\usage{\n+BufferOutputStream(initial_capacity = 0L)\n+}\n+\\arguments{\n+\\item{initial_capacity}{initial capacity}\n+}\n+\\value{\n+a \\link[=arrow__io__BufferOutputStream]{arrow::io::BufferOutputStream}\n+}\n+\\description{\n+Open a \\link[=arrow__io__BufferOutputStream]{arrow::io::BufferOutputStream}\n+}\ndiff --git a/r/man/buffer_reader.Rd b/r/man/BufferReader.Rd\nsimilarity index 52%\nrename from r/man/buffer_reader.Rd\nrename to r/man/BufferReader.Rd\nindex 3b814fb00b..ea5dd790cd 100644\n--- a/r/man/buffer_reader.Rd\n+++ b/r/man/BufferReader.Rd\n@@ -1,14 +1,14 @@\n % Generated by roxygen2: do not edit by hand\n % Please edit documentation in R/io.R\n-\\name{buffer_reader}\n-\\alias{buffer_reader}\n-\\title{Create a \\code{arrow::BufferReader}}\n+\\name{BufferReader}\n+\\alias{BufferReader}\n+\\title{Create a \\link[=arrow__io__BufferReader]{arrow::io::BufferReader}}\n \\usage{\n-buffer_reader(x)\n+BufferReader(x)\n }\n \\arguments{\n \\item{x}{R object to treat as a buffer or a buffer created by \\code{\\link[=buffer]{buffer()}}}\n }\n \\description{\n-Create a \\code{arrow::BufferReader}\n+Create a \\link[=arrow__io__BufferReader]{arrow::io::BufferReader}\n }\ndiff --git a/r/man/FileOutputStream.Rd b/r/man/FileOutputStream.Rd\nnew file mode 100644\nindex 0000000000..4155d349d1\n--- /dev/null\n+++ b/r/man/FileOutputStream.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\name{FileOutputStream}\n+\\alias{FileOutputStream}\n+\\title{Open a \\link[=arrow__io__FileOutputStream]{arrow::io::FileOutputStream}}\n+\\usage{\n+FileOutputStream(path)\n+}\n+\\arguments{\n+\\item{path}{file path}\n+}\n+\\value{\n+a \\link[=arrow__io__FileOutputStream]{arrow::io::FileOutputStream}\n+}\n+\\description{\n+Open a \\link[=arrow__io__FileOutputStream]{arrow::io::FileOutputStream}\n+}\ndiff --git a/r/man/FixedSizeBufferWriter.Rd b/r/man/FixedSizeBufferWriter.Rd\nnew file mode 100644\nindex 0000000000..553d61b76e\n--- /dev/null\n+++ b/r/man/FixedSizeBufferWriter.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\name{FixedSizeBufferWriter}\n+\\alias{FixedSizeBufferWriter}\n+\\title{Open a \\link[=arrow__io__FixedSizeBufferWriter]{arrow::io::FixedSizeBufferWriter}}\n+\\usage{\n+FixedSizeBufferWriter(buffer)\n+}\n+\\arguments{\n+\\item{buffer}{\\link[=arrow__Buffer]{arrow::Buffer} or something \\code{\\link[=buffer]{buffer()}} can handle}\n+}\n+\\value{\n+a \\link[=arrow__io__BufferOutputStream]{arrow::io::BufferOutputStream}\n+}\n+\\description{\n+Open a \\link[=arrow__io__FixedSizeBufferWriter]{arrow::io::FixedSizeBufferWriter}\n+}\ndiff --git a/r/man/message_reader.Rd b/r/man/MessageReader.Rd\nsimilarity index 79%\nrename from r/man/message_reader.Rd\nrename to r/man/MessageReader.Rd\nindex 0d8b1e7ff6..01589f5d07 100644\n--- a/r/man/message_reader.Rd\n+++ b/r/man/MessageReader.Rd\n@@ -1,10 +1,10 @@\n % Generated by roxygen2: do not edit by hand\n % Please edit documentation in R/message.R\n-\\name{message_reader}\n-\\alias{message_reader}\n+\\name{MessageReader}\n+\\alias{MessageReader}\n \\title{Open a MessageReader that reads from a stream}\n \\usage{\n-message_reader(stream)\n+MessageReader(stream)\n }\n \\arguments{\n \\item{stream}{an InputStream}\ndiff --git a/r/man/MockOutputStream.Rd b/r/man/MockOutputStream.Rd\nnew file mode 100644\nindex 0000000000..2e3c0b6d3e\n--- /dev/null\n+++ b/r/man/MockOutputStream.Rd\n@@ -0,0 +1,14 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\name{MockOutputStream}\n+\\alias{MockOutputStream}\n+\\title{Open a \\link[=arrow__io__MockOutputStream]{arrow::io::MockOutputStream}}\n+\\usage{\n+MockOutputStream()\n+}\n+\\value{\n+a \\link[=arrow__io__MockOutputStream]{arrow::io::MockOutputStream}\n+}\n+\\description{\n+Open a \\link[=arrow__io__MockOutputStream]{arrow::io::MockOutputStream}\n+}\ndiff --git a/r/man/ReadableFile.Rd b/r/man/ReadableFile.Rd\nnew file mode 100644\nindex 0000000000..11535321bf\n--- /dev/null\n+++ b/r/man/ReadableFile.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\name{ReadableFile}\n+\\alias{ReadableFile}\n+\\title{open a \\link[=arrow__io__ReadableFile]{arrow::io::ReadableFile}}\n+\\usage{\n+ReadableFile(path)\n+}\n+\\arguments{\n+\\item{path}{file path}\n+}\n+\\value{\n+a \\link[=arrow__io__ReadableFile]{arrow::io::ReadableFile}\n+}\n+\\description{\n+open a \\link[=arrow__io__ReadableFile]{arrow::io::ReadableFile}\n+}\ndiff --git a/r/man/RecordBatchFileReader.Rd b/r/man/RecordBatchFileReader.Rd\nnew file mode 100644\nindex 0000000000..3ea04817e0\n--- /dev/null\n+++ b/r/man/RecordBatchFileReader.Rd\n@@ -0,0 +1,14 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchReader.R\n+\\name{RecordBatchFileReader}\n+\\alias{RecordBatchFileReader}\n+\\title{Create an \\link[=arrow__ipc__RecordBatchFileReader]{arrow::ipc::RecordBatchFileReader} from a file}\n+\\usage{\n+RecordBatchFileReader(file)\n+}\n+\\arguments{\n+\\item{file}{The file to read from. A file path, or an \\link[=arrow__ipc__RecordBatchFileReader]{arrow::io::RandomAccessFile}}\n+}\n+\\description{\n+Create an \\link[=arrow__ipc__RecordBatchFileReader]{arrow::ipc::RecordBatchFileReader} from a file\n+}\ndiff --git a/r/man/RecordBatchFileWriter.Rd b/r/man/RecordBatchFileWriter.Rd\nnew file mode 100644\nindex 0000000000..90858304b0\n--- /dev/null\n+++ b/r/man/RecordBatchFileWriter.Rd\n@@ -0,0 +1,24 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchWriter.R\n+\\name{RecordBatchFileWriter}\n+\\alias{RecordBatchFileWriter}\n+\\title{Create a record batch file writer from a stream}\n+\\usage{\n+RecordBatchFileWriter(sink, schema)\n+}\n+\\arguments{\n+\\item{sink}{Where to write. Can either be:\n+\\itemize{\n+\\item character vector of length one\n+\\item a \\link[fs:path_abs]{file path}\n+\\item \\link[=arrow__io__OutputStream]{arrow::io::OutputStream}\n+}}\n+\n+\\item{schema}{The \\link[=arrow__Schema]{arrow::Schema} for data to be written.}\n+}\n+\\value{\n+an \\code{arrow::ipc::RecordBatchWriter} object\n+}\n+\\description{\n+Create a record batch file writer from a stream\n+}\ndiff --git a/r/man/RecordBatchStreamReader.Rd b/r/man/RecordBatchStreamReader.Rd\nnew file mode 100644\nindex 0000000000..4bd0e8ccdc\n--- /dev/null\n+++ b/r/man/RecordBatchStreamReader.Rd\n@@ -0,0 +1,14 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchReader.R\n+\\name{RecordBatchStreamReader}\n+\\alias{RecordBatchStreamReader}\n+\\title{Create a \\link[=arrow__ipc__RecordBatchStreamReader]{arrow::ipc::RecordBatchStreamReader} from an input stream}\n+\\usage{\n+RecordBatchStreamReader(stream)\n+}\n+\\arguments{\n+\\item{stream}{input stream, an \\link[=arrow__io__InputStream]{arrow::io::InputStream} or a raw vector}\n+}\n+\\description{\n+Create a \\link[=arrow__ipc__RecordBatchStreamReader]{arrow::ipc::RecordBatchStreamReader} from an input stream\n+}\ndiff --git a/r/man/RecordBatchStreamWriter.Rd b/r/man/RecordBatchStreamWriter.Rd\nnew file mode 100644\nindex 0000000000..b9183a8071\n--- /dev/null\n+++ b/r/man/RecordBatchStreamWriter.Rd\n@@ -0,0 +1,24 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchWriter.R\n+\\name{RecordBatchStreamWriter}\n+\\alias{RecordBatchStreamWriter}\n+\\title{Writer for the Arrow streaming binary format}\n+\\usage{\n+RecordBatchStreamWriter(sink, schema)\n+}\n+\\arguments{\n+\\item{sink}{Where to write. Can either be:\n+\\itemize{\n+\\item A string, meant as a file path, passed to \\code{\\link[fs:path_abs]{fs::path_abs()}}\n+\\item a \\link[fs:path_abs]{file path}\n+\\item \\link[=arrow__io__OutputStream]{arrow::io::OutputStream}\n+}}\n+\n+\\item{schema}{The \\link[=arrow__Schema]{arrow::Schema} for data to be written.}\n+}\n+\\value{\n+a \\link[=arrow__ipc__RecordBatchStreamWriter]{arrow::ipc::RecordBatchStreamWriter}\n+}\n+\\description{\n+Writer for the Arrow streaming binary format\n+}\ndiff --git a/r/man/array.Rd b/r/man/array.Rd\nindex 38bd773be9..ccdba181db 100644\n--- a/r/man/array.Rd\n+++ b/r/man/array.Rd\n@@ -2,7 +2,7 @@\n % Please edit documentation in R/array.R\n \\name{array}\n \\alias{array}\n-\\title{create an arrow::Array from an R vector}\n+\\title{create an \\link[=arrow__Array]{arrow::Array} from an R vector}\n \\usage{\n array(..., type)\n }\n@@ -12,5 +12,5 @@ array(..., type)\n \\item{type}{currently ignored}\n }\n \\description{\n-create an arrow::Array from an R vector\n+create an \\link[=arrow__Array]{arrow::Array} from an R vector\n }\ndiff --git a/r/man/arrow__Array.Rd b/r/man/arrow__Array.Rd\nnew file mode 100644\nindex 0000000000..b11373d26b\n--- /dev/null\n+++ b/r/man/arrow__Array.Rd\n@@ -0,0 +1,57 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/array.R\n+\\docType{class}\n+\\name{arrow__Array}\n+\\alias{arrow__Array}\n+\\alias{arrow::Array}\n+\\title{class arrow::Array\n+\n+Array base type. Immutable data array with some logical type and some length.}\n+\\description{\n+class arrow::Array\n+\n+Array base type. Immutable data array with some logical type and some length.\n+}\n+\\section{Usage}{\n+\\preformatted{a <- array(...)\n+\n+a$IsNull(i)\n+a$IsValid(i)\n+a$length() or length(a)\n+a$offset()\n+a$null_count()\n+a$type()\n+a$type_id()\n+a$Equals(b)\n+a$ApproxEquals(b)\n+a$as_vector()\n+a$ToString()\n+a$Slice(offset, length = NULL)\n+a$RangeEquals(other, start_idx, end_idx, other_start_idx)\n+\n+print(a)\n+a == a\n+}\n+}\n+\n+\\section{Methods}{\n+\n+\\itemize{\n+\\item \\code{$IsNull(i)}: Return true if value at index is null. Does not boundscheck\n+\\item \\code{$IsValid(i)}: Return true if value at index is valid. Does not boundscheck\n+\\item \\code{$length()}: Size in the number of elements this array contains\n+\\item \\code{$offset()}: A relative position into another array's data, to enable zero-copy slicing\n+\\item \\code{$null_count()}: The number of null entries in the array\n+\\item \\code{$type()}: logical type of data\n+\\item \\code{$type_id()}: type id\n+\\item \\code{$Equals(other)} : is this array equal to \\code{other}\n+\\item \\code{$ApproxEquals(other)} :\n+\\item \\code{$data()}: return the underlying \\link[=arrow__ArrayData]{arrow::ArrayData}\n+\\item \\code{$as_vector()}: convert to an R vector\n+\\item \\code{$ToString()}: string representation of the array\n+\\item \\code{$Slice(offset, length = NULL)} : Construct a zero-copy slice of the array with the indicated offset and length. If length is \\code{NULL}, the slice goes until the end of the array.\n+\\item \\code{$RangeEquals(other, start_idx, end_idx, other_start_idx)} :\n+}\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ArrayData.Rd b/r/man/arrow__ArrayData.Rd\nnew file mode 100644\nindex 0000000000..bdf996605c\n--- /dev/null\n+++ b/r/man/arrow__ArrayData.Rd\n@@ -0,0 +1,28 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/ArrayData.R\n+\\docType{class}\n+\\name{arrow__ArrayData}\n+\\alias{arrow__ArrayData}\n+\\alias{arrow::ArrayData}\n+\\title{class arrow::ArrayData}\n+\\description{\n+class arrow::ArrayData\n+}\n+\\section{Usage}{\n+\\preformatted{data <- array(...)$data()\n+\n+data$type()\n+data$length()\n+data$null_count()\n+data$offset()\n+data$buffers()\n+}\n+}\n+\n+\\section{Methods}{\n+\n+\n+...\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__Buffer.Rd b/r/man/arrow__Buffer.Rd\nnew file mode 100644\nindex 0000000000..135da7a20e\n--- /dev/null\n+++ b/r/man/arrow__Buffer.Rd\n@@ -0,0 +1,21 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/buffer.R\n+\\docType{class}\n+\\name{arrow__Buffer}\n+\\alias{arrow__Buffer}\n+\\alias{arrow::Buffer}\n+\\title{class arrow::Buffer}\n+\\description{\n+class arrow::Buffer\n+}\n+\\section{Methods}{\n+\n+\\itemize{\n+\\item \\code{$is_mutable()} :\n+\\item \\code{$ZeroPadding()} :\n+\\item \\code{$size()} :\n+\\item \\code{$capacity()}:\n+}\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ChunkedArray.Rd b/r/man/arrow__ChunkedArray.Rd\nnew file mode 100644\nindex 0000000000..a87bf1c0dc\n--- /dev/null\n+++ b/r/man/arrow__ChunkedArray.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/ChunkedArray.R\n+\\docType{class}\n+\\name{arrow__ChunkedArray}\n+\\alias{arrow__ChunkedArray}\n+\\alias{arrow::ChunkedArray}\n+\\title{class arrow::ChunkedArray}\n+\\description{\n+class arrow::ChunkedArray\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__Column.Rd b/r/man/arrow__Column.Rd\nnew file mode 100644\nindex 0000000000..6a0ee6a40a\n--- /dev/null\n+++ b/r/man/arrow__Column.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/Column.R\n+\\docType{class}\n+\\name{arrow__Column}\n+\\alias{arrow__Column}\n+\\alias{arrow::Column}\n+\\title{class arrow::Column}\n+\\description{\n+class arrow::Column\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__DataType.Rd b/r/man/arrow__DataType.Rd\nnew file mode 100644\nindex 0000000000..53bd6327d9\n--- /dev/null\n+++ b/r/man/arrow__DataType.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/R6.R\n+\\docType{class}\n+\\name{arrow__DataType}\n+\\alias{arrow__DataType}\n+\\alias{arrow::DataType}\n+\\title{class arrow::DataType}\n+\\description{\n+class arrow::DataType\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__DictionaryType.Rd b/r/man/arrow__DictionaryType.Rd\nnew file mode 100644\nindex 0000000000..ba462ee011\n--- /dev/null\n+++ b/r/man/arrow__DictionaryType.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/dictionary.R\n+\\docType{class}\n+\\name{arrow__DictionaryType}\n+\\alias{arrow__DictionaryType}\n+\\alias{arrow::DictionaryType}\n+\\title{class arrow::DictionaryType}\n+\\description{\n+class arrow::DictionaryType\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__Field.Rd b/r/man/arrow__Field.Rd\nnew file mode 100644\nindex 0000000000..893a65aa08\n--- /dev/null\n+++ b/r/man/arrow__Field.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/Field.R\n+\\docType{class}\n+\\name{arrow__Field}\n+\\alias{arrow__Field}\n+\\alias{arrow::Field}\n+\\title{class arrow::Field}\n+\\description{\n+class arrow::Field\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__FixedWidthType.Rd b/r/man/arrow__FixedWidthType.Rd\nnew file mode 100644\nindex 0000000000..610a400342\n--- /dev/null\n+++ b/r/man/arrow__FixedWidthType.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/R6.R\n+\\docType{class}\n+\\name{arrow__FixedWidthType}\n+\\alias{arrow__FixedWidthType}\n+\\alias{arrow::FixedWidthType}\n+\\title{class arrow::FixedWidthType}\n+\\description{\n+class arrow::FixedWidthType\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__RecordBatch.Rd b/r/man/arrow__RecordBatch.Rd\nnew file mode 100644\nindex 0000000000..40ba6323ee\n--- /dev/null\n+++ b/r/man/arrow__RecordBatch.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatch.R\n+\\docType{class}\n+\\name{arrow__RecordBatch}\n+\\alias{arrow__RecordBatch}\n+\\alias{arrow::RecordBatch}\n+\\title{class arrow::RecordBatch}\n+\\description{\n+class arrow::RecordBatch\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__RecordBatchReader.Rd b/r/man/arrow__RecordBatchReader.Rd\nnew file mode 100644\nindex 0000000000..b3ccd3f174\n--- /dev/null\n+++ b/r/man/arrow__RecordBatchReader.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchReader.R\n+\\docType{class}\n+\\name{arrow__RecordBatchReader}\n+\\alias{arrow__RecordBatchReader}\n+\\alias{arrow::RecordBatchReader}\n+\\title{class arrow::RecordBatchReader}\n+\\description{\n+class arrow::RecordBatchReader\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__Schema.Rd b/r/man/arrow__Schema.Rd\nnew file mode 100644\nindex 0000000000..b657ff2c4a\n--- /dev/null\n+++ b/r/man/arrow__Schema.Rd\n@@ -0,0 +1,29 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/Schema.R\n+\\docType{class}\n+\\name{arrow__Schema}\n+\\alias{arrow__Schema}\n+\\alias{arrow::Schema}\n+\\title{class arrow::Schema}\n+\\description{\n+class arrow::Schema\n+}\n+\\section{Usage}{\n+\\preformatted{s <- schema(...)\n+\n+s$ToString()\n+s$num_fields()\n+s$field(i)\n+}\n+}\n+\n+\\section{Methods}{\n+\n+\\itemize{\n+\\item \\code{$ToString()}: convert to a string\n+\\item \\code{$num_fields()}: returns the number of fields\n+\\item \\code{$field(i)}: returns the field at index \\code{i} (0-based)\n+}\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__Table.Rd b/r/man/arrow__Table.Rd\nnew file mode 100644\nindex 0000000000..139db980ac\n--- /dev/null\n+++ b/r/man/arrow__Table.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/Table.R\n+\\docType{class}\n+\\name{arrow__Table}\n+\\alias{arrow__Table}\n+\\alias{arrow::Table}\n+\\title{class arrow::Table}\n+\\description{\n+class arrow::Table\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow___MemoryPool.Rd b/r/man/arrow___MemoryPool.Rd\nnew file mode 100644\nindex 0000000000..9189e8be4a\n--- /dev/null\n+++ b/r/man/arrow___MemoryPool.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/memory_pool.R\n+\\docType{class}\n+\\name{arrow__MemoryPool}\n+\\alias{arrow__MemoryPool}\n+\\alias{arrow::MemoryPool}\n+\\title{class arrow::MemoryPool}\n+\\description{\n+class arrow::MemoryPool\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__BufferOutputStream.Rd b/r/man/arrow__io__BufferOutputStream.Rd\nnew file mode 100644\nindex 0000000000..e90d1cc0ed\n--- /dev/null\n+++ b/r/man/arrow__io__BufferOutputStream.Rd\n@@ -0,0 +1,18 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__BufferOutputStream}\n+\\alias{arrow__io__BufferOutputStream}\n+\\alias{arrow::io::BufferOutputStream}\n+\\title{class arrow::io::BufferOutputStream}\n+\\format{An object of class \\code{R6ClassGenerator} of length 24.}\n+\\description{\n+class arrow::io::BufferOutputStream\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__BufferReader.Rd b/r/man/arrow__io__BufferReader.Rd\nnew file mode 100644\nindex 0000000000..609fec5b6d\n--- /dev/null\n+++ b/r/man/arrow__io__BufferReader.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__BufferReader}\n+\\alias{arrow__io__BufferReader}\n+\\alias{arrow::io::BufferReader}\n+\\title{class arrow::io::BufferReader}\n+\\description{\n+class arrow::io::BufferReader\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__FileOutputStream.Rd b/r/man/arrow__io__FileOutputStream.Rd\nnew file mode 100644\nindex 0000000000..92eaac13c9\n--- /dev/null\n+++ b/r/man/arrow__io__FileOutputStream.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__FileOutputStream}\n+\\alias{arrow__io__FileOutputStream}\n+\\alias{arrow::io::FileOutputStream}\n+\\title{class arrow::io::FileOutputStream}\n+\\description{\n+class arrow::io::FileOutputStream\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__FixedSizeBufferWriter.Rd b/r/man/arrow__io__FixedSizeBufferWriter.Rd\nnew file mode 100644\nindex 0000000000..39d8bb69c2\n--- /dev/null\n+++ b/r/man/arrow__io__FixedSizeBufferWriter.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__FixedSizeBufferWriter}\n+\\alias{arrow__io__FixedSizeBufferWriter}\n+\\alias{arrow::io::FixedSizeBufferWriter}\n+\\title{class arrow::io::FixedSizeBufferWriter}\n+\\description{\n+class arrow::io::FixedSizeBufferWriter\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__InputStream.Rd b/r/man/arrow__io__InputStream.Rd\nnew file mode 100644\nindex 0000000000..37f83308b6\n--- /dev/null\n+++ b/r/man/arrow__io__InputStream.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__InputStream}\n+\\alias{arrow__io__InputStream}\n+\\alias{arrow::io::InputStream}\n+\\title{class arrow::io::InputStream}\n+\\description{\n+class arrow::io::InputStream\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__MemoryMappedFile.Rd b/r/man/arrow__io__MemoryMappedFile.Rd\nnew file mode 100644\nindex 0000000000..409bb17302\n--- /dev/null\n+++ b/r/man/arrow__io__MemoryMappedFile.Rd\n@@ -0,0 +1,20 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__MemoryMappedFile}\n+\\alias{arrow__io__MemoryMappedFile}\n+\\alias{arrow::io::MemoryMappedFile}\n+\\title{class arrow::io::MemoryMappedFile}\n+\\description{\n+class arrow::io::MemoryMappedFile\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\seealso{\n+\\code{\\link[=mmap_open]{mmap_open()}}, \\code{\\link[=mmap_create]{mmap_create()}}\n+}\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__MockOutputStream.Rd b/r/man/arrow__io__MockOutputStream.Rd\nnew file mode 100644\nindex 0000000000..f0b2c06d7a\n--- /dev/null\n+++ b/r/man/arrow__io__MockOutputStream.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__MockOutputStream}\n+\\alias{arrow__io__MockOutputStream}\n+\\alias{arrow::io::MockOutputStream}\n+\\title{class arrow::io::MockOutputStream}\n+\\description{\n+class arrow::io::MockOutputStream\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__OutputStream.Rd b/r/man/arrow__io__OutputStream.Rd\nnew file mode 100644\nindex 0000000000..c41b815c02\n--- /dev/null\n+++ b/r/man/arrow__io__OutputStream.Rd\n@@ -0,0 +1,19 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__OutputStream}\n+\\alias{arrow__io__OutputStream}\n+\\alias{arrow::io::OutputStream}\n+\\title{OutputStream}\n+\\description{\n+OutputStream\n+}\n+\\section{Methods}{\n+\n+\\itemize{\n+\\item \\code{arrow::Buffer} \\code{Read}(\\code{int} nbytes):  Read \\code{nbytes} bytes\n+\\item \\code{void} \\code{close}(): close the stream\n+}\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__RandomAccessFile.Rd b/r/man/arrow__io__RandomAccessFile.Rd\nnew file mode 100644\nindex 0000000000..f8cb86abda\n--- /dev/null\n+++ b/r/man/arrow__io__RandomAccessFile.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__RandomAccessFile}\n+\\alias{arrow__io__RandomAccessFile}\n+\\alias{arrow::io::RandomAccessFile}\n+\\title{class arrow::io::RandomAccessFile}\n+\\description{\n+class arrow::io::RandomAccessFile\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__Readable.Rd b/r/man/arrow__io__Readable.Rd\nnew file mode 100644\nindex 0000000000..b0b30a4230\n--- /dev/null\n+++ b/r/man/arrow__io__Readable.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__Readable}\n+\\alias{arrow__io__Readable}\n+\\alias{arrow::io::Readable}\n+\\title{class arrow::io::Readable}\n+\\description{\n+class arrow::io::Readable\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__io__ReadableFile.Rd b/r/man/arrow__io__ReadableFile.Rd\nnew file mode 100644\nindex 0000000000..440149fbbb\n--- /dev/null\n+++ b/r/man/arrow__io__ReadableFile.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\docType{class}\n+\\name{arrow__io__ReadableFile}\n+\\alias{arrow__io__ReadableFile}\n+\\alias{arrow::io::ReadableFile}\n+\\title{class arrow::io::ReadableFile}\n+\\description{\n+class arrow::io::ReadableFile\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ipc__Message.Rd b/r/man/arrow__ipc__Message.Rd\nnew file mode 100644\nindex 0000000000..d3811f8f4c\n--- /dev/null\n+++ b/r/man/arrow__ipc__Message.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/message.R\n+\\docType{class}\n+\\name{arrow__ipc__Message}\n+\\alias{arrow__ipc__Message}\n+\\alias{arrow::ipc::Message}\n+\\title{class arrow::ipc::Message}\n+\\description{\n+class arrow::ipc::Message\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ipc__MessageReader.Rd b/r/man/arrow__ipc__MessageReader.Rd\nnew file mode 100644\nindex 0000000000..883e9e0618\n--- /dev/null\n+++ b/r/man/arrow__ipc__MessageReader.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/message.R\n+\\docType{class}\n+\\name{arrow__ipc__MessageReader}\n+\\alias{arrow__ipc__MessageReader}\n+\\alias{arrow::ipc::MessageReader}\n+\\title{class arrow::ipc::MessageReader}\n+\\description{\n+class arrow::ipc::MessageReader\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ipc__RecordBatchFileReader.Rd b/r/man/arrow__ipc__RecordBatchFileReader.Rd\nnew file mode 100644\nindex 0000000000..675f636b36\n--- /dev/null\n+++ b/r/man/arrow__ipc__RecordBatchFileReader.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchReader.R\n+\\docType{class}\n+\\name{arrow__ipc__RecordBatchFileReader}\n+\\alias{arrow__ipc__RecordBatchFileReader}\n+\\alias{arrow::ipc::RecordBatchFileReader}\n+\\title{class arrow::ipc::RecordBatchFileReader}\n+\\description{\n+class arrow::ipc::RecordBatchFileReader\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ipc__RecordBatchFileWriter.Rd b/r/man/arrow__ipc__RecordBatchFileWriter.Rd\nnew file mode 100644\nindex 0000000000..a80b55941f\n--- /dev/null\n+++ b/r/man/arrow__ipc__RecordBatchFileWriter.Rd\n@@ -0,0 +1,40 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchWriter.R\n+\\docType{class}\n+\\name{arrow__ipc__RecordBatchFileWriter}\n+\\alias{arrow__ipc__RecordBatchFileWriter}\n+\\alias{arrow::ipc::RecordBatchFileWriter}\n+\\title{class arrow::ipc::RecordBatchFileWriter\n+\n+Writer for the Arrow binary file format}\n+\\description{\n+class arrow::ipc::RecordBatchFileWriter\n+\n+Writer for the Arrow binary file format\n+}\n+\\section{usage}{\n+\\preformatted{writer <- RecordBatchFileWriter(sink, schema)\n+\n+writer$write_batch(batch)\n+writer$write_table(table)\n+writer$close()\n+}\n+}\n+\n+\\section{Factory}{\n+\n+\n+The \\code{\\link[=RecordBatchFileWriter]{RecordBatchFileWriter()}} function creates a record batch stream writer.\n+}\n+\n+\\section{Methods}{\n+\n+inherited from \\link[=arrow__ipc__RecordBatchWriter]{arrow::ipc::RecordBatchWriter}\n+\\itemize{\n+\\item \\code{$write_batch(batch)}: Write record batch to stream\n+\\item \\code{$write_table(table)}: write Table to stream\n+\\item \\code{$close()}: close stream\n+}\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ipc__RecordBatchStreamReader.Rd b/r/man/arrow__ipc__RecordBatchStreamReader.Rd\nnew file mode 100644\nindex 0000000000..49f57cce05\n--- /dev/null\n+++ b/r/man/arrow__ipc__RecordBatchStreamReader.Rd\n@@ -0,0 +1,17 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchReader.R\n+\\docType{class}\n+\\name{arrow__ipc__RecordBatchStreamReader}\n+\\alias{arrow__ipc__RecordBatchStreamReader}\n+\\alias{arrow::ipc::RecordBatchStreamReader}\n+\\title{class arrow::ipc::RecordBatchStreamReader}\n+\\description{\n+class arrow::ipc::RecordBatchStreamReader\n+}\n+\\section{Methods}{\n+\n+\n+TODO\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ipc__RecordBatchStreamWriter.Rd b/r/man/arrow__ipc__RecordBatchStreamWriter.Rd\nnew file mode 100644\nindex 0000000000..3d2030287d\n--- /dev/null\n+++ b/r/man/arrow__ipc__RecordBatchStreamWriter.Rd\n@@ -0,0 +1,40 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchWriter.R\n+\\docType{class}\n+\\name{arrow__ipc__RecordBatchStreamWriter}\n+\\alias{arrow__ipc__RecordBatchStreamWriter}\n+\\alias{arrow::ipc::RecordBatchStreamWriter}\n+\\title{class arrow::ipc::RecordBatchStreamWriter\n+\n+Writer for the Arrow streaming binary format}\n+\\description{\n+class arrow::ipc::RecordBatchStreamWriter\n+\n+Writer for the Arrow streaming binary format\n+}\n+\\section{usage}{\n+\\preformatted{writer <- RecordBatchStreamWriter(sink, schema)\n+\n+writer$write_batch(batch)\n+writer$write_table(table)\n+writer$close()\n+}\n+}\n+\n+\\section{Factory}{\n+\n+\n+The \\code{\\link[=RecordBatchStreamWriter]{RecordBatchStreamWriter()}} function creates a record batch stream writer.\n+}\n+\n+\\section{Methods}{\n+\n+inherited from \\link[=arrow__ipc__RecordBatchWriter]{arrow::ipc::RecordBatchWriter}\n+\\itemize{\n+\\item \\code{$write_batch(batch)}: Write record batch to stream\n+\\item \\code{$write_table(table)}: write Table to stream\n+\\item \\code{$close()}: close stream\n+}\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/arrow__ipc__RecordBatchWriter.Rd b/r/man/arrow__ipc__RecordBatchWriter.Rd\nnew file mode 100644\nindex 0000000000..08593df852\n--- /dev/null\n+++ b/r/man/arrow__ipc__RecordBatchWriter.Rd\n@@ -0,0 +1,28 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/RecordBatchWriter.R\n+\\docType{class}\n+\\name{arrow__ipc__RecordBatchWriter}\n+\\alias{arrow__ipc__RecordBatchWriter}\n+\\alias{arrow::ipc::RecordBatchWriter}\n+\\title{class arrow::ipc::RecordBatchWriter}\n+\\description{\n+class arrow::ipc::RecordBatchWriter\n+}\n+\\section{Methods}{\n+\n+\\itemize{\n+\\item \\code{$write_batch(batch)}: Write record batch to stream\n+\\item \\code{$write_table(table)}: write Table to stream\n+\\item \\code{$close()}: close stream\n+}\n+}\n+\n+\\section{Derived classes}{\n+\n+\\itemize{\n+\\item \\link[=arrow__ipc__RecordBatchStreamWriter]{arrow::ipc::RecordBatchStreamWriter} implements the streaming binary format\n+\\item \\link[=arrow__ipc__RecordBatchFileWriter]{arrow::ipc::RecordBatchFileWriter} implements the binary file format\n+}\n+}\n+\n+\\keyword{datasets}\ndiff --git a/r/man/buffer.Rd b/r/man/buffer.Rd\nindex 4d4e97e47d..60fd25d4bf 100644\n--- a/r/man/buffer.Rd\n+++ b/r/man/buffer.Rd\n@@ -2,16 +2,16 @@\n % Please edit documentation in R/buffer.R\n \\name{buffer}\n \\alias{buffer}\n-\\title{Create a buffer from an R object}\n+\\title{Create a \\link[=arrow__Buffer]{arrow::Buffer} from an R object}\n \\usage{\n buffer(x)\n }\n \\arguments{\n-\\item{x}{R object}\n+\\item{x}{R object. Only raw, numeric and integer vectors are currently supported}\n }\n \\value{\n-an instance of \\code{arrow::Buffer} that borrows memory from \\code{x}\n+an instance of \\link[=arrow__Buffer]{arrow::Buffer} that borrows memory from \\code{x}\n }\n \\description{\n-Create a buffer from an R object\n+Create a \\link[=arrow__Buffer]{arrow::Buffer} from an R object\n }\ndiff --git a/r/man/chunked_array.Rd b/r/man/chunked_array.Rd\nindex 1f4fb83614..c6973be721 100644\n--- a/r/man/chunked_array.Rd\n+++ b/r/man/chunked_array.Rd\n@@ -2,7 +2,7 @@\n % Please edit documentation in R/ChunkedArray.R\n \\name{chunked_array}\n \\alias{chunked_array}\n-\\title{create an arrow::Array from an R vector}\n+\\title{create an \\link[=arrow__ChunkedArray]{arrow::ChunkedArray} from various R vectors}\n \\usage{\n chunked_array(..., type)\n }\n@@ -12,5 +12,5 @@ chunked_array(..., type)\n \\item{type}{currently ignored}\n }\n \\description{\n-create an arrow::Array from an R vector\n+create an \\link[=arrow__ChunkedArray]{arrow::ChunkedArray} from various R vectors\n }\ndiff --git a/r/man/default_memory_pool.Rd b/r/man/default_memory_pool.Rd\nnew file mode 100644\nindex 0000000000..1725ff0e10\n--- /dev/null\n+++ b/r/man/default_memory_pool.Rd\n@@ -0,0 +1,14 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/memory_pool.R\n+\\name{default_memory_pool}\n+\\alias{default_memory_pool}\n+\\title{default \\link[=arrow__MemoryPool]{arrow::MemoryPool}}\n+\\usage{\n+default_memory_pool()\n+}\n+\\value{\n+the default \\link[=arrow__MemoryPool]{arrow::MemoryPool}\n+}\n+\\description{\n+default \\link[=arrow__MemoryPool]{arrow::MemoryPool}\n+}\ndiff --git a/r/man/dictionary.Rd b/r/man/dictionary.Rd\nindex 2a7989648b..340283ec4d 100644\n--- a/r/man/dictionary.Rd\n+++ b/r/man/dictionary.Rd\n@@ -13,6 +13,9 @@ dictionary(type, values, ordered = FALSE)\n \n \\item{ordered}{Is this an ordered dictionary}\n }\n+\\value{\n+a \\link[=arrow__DictionaryType]{arrow::DictionaryType}\n+}\n \\description{\n dictionary type factory\n }\ndiff --git a/r/man/field.Rd b/r/man/field.Rd\nindex e7af66db29..5cbd803387 100644\n--- a/r/man/field.Rd\n+++ b/r/man/field.Rd\n@@ -2,7 +2,7 @@\n % Please edit documentation in R/Field.R\n \\name{field}\n \\alias{field}\n-\\title{Factor for a \\code{arrow::Field}}\n+\\title{Factory for a \\code{arrow::Field}}\n \\usage{\n field(name, type, metadata)\n }\n@@ -14,7 +14,7 @@ field(name, type, metadata)\n \\item{metadata}{currently ignored}\n }\n \\description{\n-Factor for a \\code{arrow::Field}\n+Factory for a \\code{arrow::Field}\n }\n \\examples{\n field(\"x\", int32())\ndiff --git a/r/man/io.Rd b/r/man/io.Rd\ndeleted file mode 100644\nindex 74817bf88a..0000000000\n--- a/r/man/io.Rd\n+++ /dev/null\n@@ -1,40 +0,0 @@\n-% Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/io.R\n-\\name{mmap_create}\n-\\alias{mmap_create}\n-\\alias{mmap_open}\n-\\alias{file_open}\n-\\alias{file_output_stream}\n-\\alias{mock_output_stream}\n-\\alias{buffer_output_stream}\n-\\alias{fixed_size_buffer_writer}\n-\\title{Create a new read/write memory mapped file of a given size}\n-\\usage{\n-mmap_create(path, size)\n-\n-mmap_open(path, mode = c(\"read\", \"write\", \"readwrite\"))\n-\n-file_open(path)\n-\n-file_output_stream(path)\n-\n-mock_output_stream()\n-\n-buffer_output_stream(initial_capacity = 0L)\n-\n-fixed_size_buffer_writer(buffer)\n-}\n-\\arguments{\n-\\item{path}{file path}\n-\n-\\item{size}{size in bytes}\n-\n-\\item{mode}{file mode (read/write/readwrite)}\n-\n-\\item{initial_capacity}{initial capacity for the buffer output stream}\n-\n-\\item{buffer}{an \\code{arrow::Buffer}, typically created by \\code{\\link[=buffer]{buffer()}}}\n-}\n-\\description{\n-Create a new read/write memory mapped file of a given size\n-}\ndiff --git a/r/man/mmap_create.Rd b/r/man/mmap_create.Rd\nnew file mode 100644\nindex 0000000000..050ae18c76\n--- /dev/null\n+++ b/r/man/mmap_create.Rd\n@@ -0,0 +1,19 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\name{mmap_create}\n+\\alias{mmap_create}\n+\\title{Create a new read/write memory mapped file of a given size}\n+\\usage{\n+mmap_create(path, size)\n+}\n+\\arguments{\n+\\item{path}{file path}\n+\n+\\item{size}{size in bytes}\n+}\n+\\value{\n+a \\link[=arrow__io__MemoryMappedFile]{arrow::io::MemoryMappedFile}\n+}\n+\\description{\n+Create a new read/write memory mapped file of a given size\n+}\ndiff --git a/r/man/mmap_open.Rd b/r/man/mmap_open.Rd\nnew file mode 100644\nindex 0000000000..d0047a72c3\n--- /dev/null\n+++ b/r/man/mmap_open.Rd\n@@ -0,0 +1,16 @@\n+% Generated by roxygen2: do not edit by hand\n+% Please edit documentation in R/io.R\n+\\name{mmap_open}\n+\\alias{mmap_open}\n+\\title{Open a memory mapped file}\n+\\usage{\n+mmap_open(path, mode = c(\"read\", \"write\", \"readwrite\"))\n+}\n+\\arguments{\n+\\item{path}{file path}\n+\n+\\item{mode}{file mode (read/write/readwrite)}\n+}\n+\\description{\n+Open a memory mapped file\n+}\ndiff --git a/r/man/read_arrow.Rd b/r/man/read_arrow.Rd\ndeleted file mode 100644\nindex 362ee7adc1..0000000000\n--- a/r/man/read_arrow.Rd\n+++ /dev/null\n@@ -1,17 +0,0 @@\n-% Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/Table.R\n-\\name{read_arrow}\n-\\alias{read_arrow}\n-\\title{Read an tibble from an arrow::Table on disk}\n-\\usage{\n-read_arrow(stream)\n-}\n-\\arguments{\n-\\item{stream}{input stream}\n-}\n-\\value{\n-a \\link[tibble:tibble]{tibble::tibble}\n-}\n-\\description{\n-Read an tibble from an arrow::Table on disk\n-}\ndiff --git a/r/man/read_record_batch.Rd b/r/man/read_record_batch.Rd\nindex 4ca048f28e..fef12cbac4 100644\n--- a/r/man/read_record_batch.Rd\n+++ b/r/man/read_record_batch.Rd\n@@ -1,19 +1,19 @@\n % Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchReader.R\n+% Please edit documentation in R/read_record_batch.R\n \\name{read_record_batch}\n \\alias{read_record_batch}\n-\\title{Read a single record batch from a stream}\n+\\title{read \\link[=arrow__RecordBatch]{arrow::RecordBatch} as encapsulated IPC message, given a known \\link[=arrow__Schema]{arrow::Schema}}\n \\usage{\n-read_record_batch(stream, ...)\n+read_record_batch(obj, schema)\n }\n \\arguments{\n-\\item{stream}{input stream}\n+\\item{obj}{a \\link[=arrow__ipc__Message]{arrow::ipc::Message}, a \\link[=arrow__io__InputStream]{arrow::io::InputStream}, a \\link[=arrow__Buffer]{arrow::Buffer}, or a raw vector}\n \n-\\item{...}{additional parameters}\n+\\item{schema}{a \\link[=arrow__Schema]{arrow::Schema}}\n }\n-\\description{\n-Read a single record batch from a stream\n+\\value{\n+a \\link[=arrow__RecordBatch]{arrow::RecordBatch}\n }\n-\\details{\n-\\code{stream} can be a \\code{arrow::io::RandomAccessFile} stream as created by \\code{\\link[=file_open]{file_open()}} or \\code{\\link[=mmap_open]{mmap_open()}} or a path.\n+\\description{\n+read \\link[=arrow__RecordBatch]{arrow::RecordBatch} as encapsulated IPC message, given a known \\link[=arrow__Schema]{arrow::Schema}\n }\ndiff --git a/r/man/read_table.Rd b/r/man/read_table.Rd\nindex f851057e8a..3231b26da2 100644\n--- a/r/man/read_table.Rd\n+++ b/r/man/read_table.Rd\n@@ -1,14 +1,40 @@\n % Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchReader.R\n+% Please edit documentation in R/read_table.R\n \\name{read_table}\n \\alias{read_table}\n-\\title{Read an arrow::Table from a stream}\n+\\alias{read_arrow}\n+\\title{Read an \\link[=arrow__Table]{arrow::Table} from a stream}\n \\usage{\n read_table(stream)\n+\n+read_arrow(stream)\n }\n \\arguments{\n-\\item{stream}{stream. Either a stream created by \\code{\\link[=file_open]{file_open()}} or \\code{\\link[=mmap_open]{mmap_open()}} or a file path.}\n+\\item{stream}{stream.\n+\\itemize{\n+\\item a \\link[=arrow__ipc__RecordBatchFileReader]{arrow::ipc::RecordBatchFileReader}:\n+read an \\link[=arrow__Table]{arrow::Table}\n+from all the record batches in the reader\n+\\item a \\link[=arrow__ipc__RecordBatchStreamReader]{arrow::ipc::RecordBatchStreamReader}:\n+read an \\link[=arrow__Table]{arrow::Table} from the remaining record batches\n+in the reader\n+\\item a string or \\link[fs:path_abs]{file path}: interpret the file as an arrow\n+binary file format, and uses a \\link[=arrow__ipc__RecordBatchFileReader]{arrow::ipc::RecordBatchFileReader}\n+to process it.\n+\\item a raw vector: read using a \\link[=arrow__ipc__RecordBatchStreamReader]{arrow::ipc::RecordBatchStreamReader}\n+}}\n+}\n+\\value{\n+\\itemize{\n+\\item \\code{read_table} returns an \\link[=arrow__Table]{arrow::Table}\n+\\item \\code{read_arrow} returns a \\code{\\link[tibble:tibble]{tibble::tibble()}}\n+}\n }\n \\description{\n-Read an arrow::Table from a stream\n+Read an \\link[=arrow__Table]{arrow::Table} from a stream\n+}\n+\\details{\n+The methods using \\link[=arrow__ipc__RecordBatchFileReader]{arrow::ipc::RecordBatchFileReader} and\n+\\link[=arrow__ipc__RecordBatchStreamReader]{arrow::ipc::RecordBatchStreamReader} offer the most\n+flexibility. The other methods are for convenience.\n }\ndiff --git a/r/man/record_batch.Rd b/r/man/record_batch.Rd\nindex e108d64b46..4567a9ab76 100644\n--- a/r/man/record_batch.Rd\n+++ b/r/man/record_batch.Rd\n@@ -2,13 +2,16 @@\n % Please edit documentation in R/RecordBatch.R\n \\name{record_batch}\n \\alias{record_batch}\n-\\title{Create an arrow::RecordBatch from a data frame}\n+\\title{Create an \\link[=arrow__RecordBatch]{arrow::RecordBatch} from a data frame}\n \\usage{\n record_batch(.data)\n }\n \\arguments{\n \\item{.data}{a data frame}\n }\n+\\value{\n+a \\link[=arrow__RecordBatch]{arrow::RecordBatch}\n+}\n \\description{\n-Create an arrow::RecordBatch from a data frame\n+Create an \\link[=arrow__RecordBatch]{arrow::RecordBatch} from a data frame\n }\ndiff --git a/r/man/record_batch_file_reader.Rd b/r/man/record_batch_file_reader.Rd\ndeleted file mode 100644\nindex b7e211dfbc..0000000000\n--- a/r/man/record_batch_file_reader.Rd\n+++ /dev/null\n@@ -1,14 +0,0 @@\n-% Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchReader.R\n-\\name{record_batch_file_reader}\n-\\alias{record_batch_file_reader}\n-\\title{Create an \\code{arrow::ipc::RecordBatchFileReader} from a file}\n-\\usage{\n-record_batch_file_reader(file)\n-}\n-\\arguments{\n-\\item{file}{The file to read from}\n-}\n-\\description{\n-Create an \\code{arrow::ipc::RecordBatchFileReader} from a file\n-}\ndiff --git a/r/man/record_batch_file_writer.Rd b/r/man/record_batch_file_writer.Rd\ndeleted file mode 100644\nindex b7dcb0c39e..0000000000\n--- a/r/man/record_batch_file_writer.Rd\n+++ /dev/null\n@@ -1,19 +0,0 @@\n-% Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchWriter.R\n-\\name{record_batch_file_writer}\n-\\alias{record_batch_file_writer}\n-\\title{Create a record batch file writer from a stream}\n-\\usage{\n-record_batch_file_writer(stream, schema)\n-}\n-\\arguments{\n-\\item{stream}{a stream}\n-\n-\\item{schema}{the schema of the batches}\n-}\n-\\value{\n-an \\code{arrow::ipc::RecordBatchWriter} object\n-}\n-\\description{\n-Create a record batch file writer from a stream\n-}\ndiff --git a/r/man/record_batch_stream_reader.Rd b/r/man/record_batch_stream_reader.Rd\ndeleted file mode 100644\nindex 018045f6a3..0000000000\n--- a/r/man/record_batch_stream_reader.Rd\n+++ /dev/null\n@@ -1,14 +0,0 @@\n-% Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchReader.R\n-\\name{record_batch_stream_reader}\n-\\alias{record_batch_stream_reader}\n-\\title{Create a \\code{arrow::ipc::RecordBatchStreamReader} from an input stream}\n-\\usage{\n-record_batch_stream_reader(stream)\n-}\n-\\arguments{\n-\\item{stream}{input stream}\n-}\n-\\description{\n-Create a \\code{arrow::ipc::RecordBatchStreamReader} from an input stream\n-}\ndiff --git a/r/man/record_batch_stream_writer.Rd b/r/man/record_batch_stream_writer.Rd\ndeleted file mode 100644\nindex d720d50d3a..0000000000\n--- a/r/man/record_batch_stream_writer.Rd\n+++ /dev/null\n@@ -1,16 +0,0 @@\n-% Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchWriter.R\n-\\name{record_batch_stream_writer}\n-\\alias{record_batch_stream_writer}\n-\\title{Create a record batch stream writer}\n-\\usage{\n-record_batch_stream_writer(stream, schema)\n-}\n-\\arguments{\n-\\item{stream}{a stream}\n-\n-\\item{schema}{a schema}\n-}\n-\\description{\n-Create a record batch stream writer\n-}\ndiff --git a/r/man/schema.Rd b/r/man/schema.Rd\nindex 9b77d47b61..ad3bcb1f4e 100644\n--- a/r/man/schema.Rd\n+++ b/r/man/schema.Rd\n@@ -2,7 +2,7 @@\n % Please edit documentation in R/Schema.R\n \\name{schema}\n \\alias{schema}\n-\\title{Schema functions}\n+\\title{Schema factory}\n \\usage{\n schema(...)\n }\n@@ -10,8 +10,8 @@ schema(...)\n \\item{...}{named list of data types}\n }\n \\value{\n-a Schema\n+a \\link[=arrow__Schema]{schema}\n }\n \\description{\n-Schema functions\n+Schema factory\n }\ndiff --git a/r/man/write_arrow.Rd b/r/man/write_arrow.Rd\nindex 42b39f1d05..4296bcbd89 100644\n--- a/r/man/write_arrow.Rd\n+++ b/r/man/write_arrow.Rd\n@@ -1,18 +1,34 @@\n % Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchWriter.R\n+% Please edit documentation in R/write_arrow.R\n \\name{write_arrow}\n \\alias{write_arrow}\n-\\title{Write an object to a stream}\n+\\title{serialize an \\link[=arrow__Table]{arrow::Table}, an \\link[=arrow__RecordBatch]{arrow::RecordBatch}, or a\n+data frame to either the streaming format or the binary file format}\n \\usage{\n write_arrow(x, stream, ...)\n }\n \\arguments{\n-\\item{x}{An object to stream}\n+\\item{x}{an \\link[=arrow__Table]{arrow::Table}, an \\link[=arrow__RecordBatch]{arrow::RecordBatch} or a data.frame}\n \n-\\item{stream}{A stream}\n+\\item{stream}{where to serialize to\n+\\itemize{\n+\\item A \\link[=arrow__ipc__RecordBatchWriter]{arrow::ipc::RecordBatchWriter}: the \\code{$write()}\n+of \\code{x} is used. The stream is left open. This uses the streaming format\n+or the binary file format depending on the type of the writer.\n+\\item A string or \\link[fs:path_abs]{file path}: \\code{x} is serialized with\n+a \\link[=arrow__ipc__RecordBatchFileWriter]{arrow::ipc::RecordBatchFileWriter}, i.e.\n+using the binary file format.\n+\\item A raw vector: typically of length zero (its data is ignored, and only used for\n+dispatch). \\code{x} is serialized using the streaming format, i.e. using the\n+\\link[=arrow__ipc__RecordBatchStreamWriter]{arrow::ipc::RecordBatchStreamWriter}\n+}}\n \n-\\item{...}{additional parameters}\n+\\item{...}{extra parameters, currently ignored\n+\n+\\code{write_arrow} is a convenience function, the classes \\link[=arrow__ipc__RecordBatchFileWriter]{arrow::ipc::RecordBatchFileWriter}\n+and \\link[=arrow__ipc__RecordBatchStreamWriter]{arrow::ipc::RecordBatchStreamWriter} can be used for more flexibility.}\n }\n \\description{\n-Write an object to a stream\n+serialize an \\link[=arrow__Table]{arrow::Table}, an \\link[=arrow__RecordBatch]{arrow::RecordBatch}, or a\n+data frame to either the streaming format or the binary file format\n }\ndiff --git a/r/man/write_record_batch.Rd b/r/man/write_record_batch.Rd\ndeleted file mode 100644\nindex afc3363f0d..0000000000\n--- a/r/man/write_record_batch.Rd\n+++ /dev/null\n@@ -1,18 +0,0 @@\n-% Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchWriter.R\n-\\name{write_record_batch}\n-\\alias{write_record_batch}\n-\\title{write a record batch}\n-\\usage{\n-write_record_batch(x, stream, ...)\n-}\n-\\arguments{\n-\\item{x}{a \\code{arrow::RecordBatch}}\n-\n-\\item{stream}{where to stream the record batch}\n-\n-\\item{...}{extra parameters}\n-}\n-\\description{\n-write a record batch\n-}\ndiff --git a/r/man/write_table.Rd b/r/man/write_table.Rd\ndeleted file mode 100644\nindex a247870ec0..0000000000\n--- a/r/man/write_table.Rd\n+++ /dev/null\n@@ -1,18 +0,0 @@\n-% Generated by roxygen2: do not edit by hand\n-% Please edit documentation in R/RecordBatchWriter.R\n-\\name{write_table}\n-\\alias{write_table}\n-\\title{write an arrow::Table}\n-\\usage{\n-write_table(x, stream, ...)\n-}\n-\\arguments{\n-\\item{x}{an \\code{arrow::Table}}\n-\n-\\item{stream}{where to stream the record batch}\n-\n-\\item{...}{extra parameters}\n-}\n-\\description{\n-write an arrow::Table\n-}\ndiff --git a/r/src/Makevars.in b/r/src/Makevars.in\nindex 5e285518f2..a0d5fed10b 100644\n--- a/r/src/Makevars.in\n+++ b/r/src/Makevars.in\n@@ -16,7 +16,7 @@\n # under the License.\n \n PKG_CPPFLAGS=@cflags@\n-PKG_CXXFLAGS+=$(C_VISIBILITY)\n+PKG_CXXFLAGS=@visibility@\n CXX_STD=CXX11\n PKG_LIBS=@libs@  -Wl,-rpath,/usr/local/lib\n #CXXFLAGS=\"-D_GLIBCXX_USE_CXX11_ABI=0\"\ndiff --git a/r/src/RcppExports.cpp b/r/src/RcppExports.cpp\nindex 2c549ad1b9..bca4eafdee 100644\n--- a/r/src/RcppExports.cpp\n+++ b/r/src/RcppExports.cpp\n@@ -1753,6 +1753,17 @@ BEGIN_RCPP\n     return rcpp_result_gen;\n END_RCPP\n }\n+// RecordBatch__columns\n+arrow::ArrayVector RecordBatch__columns(const std::shared_ptr<arrow::RecordBatch>& batch);\n+RcppExport SEXP _arrow_RecordBatch__columns(SEXP batchSEXP) {\n+BEGIN_RCPP\n+    Rcpp::RObject rcpp_result_gen;\n+    Rcpp::RNGScope rcpp_rngScope_gen;\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::RecordBatch>& >::type batch(batchSEXP);\n+    rcpp_result_gen = Rcpp::wrap(RecordBatch__columns(batch));\n+    return rcpp_result_gen;\n+END_RCPP\n+}\n // RecordBatch__column\n std::shared_ptr<arrow::Array> RecordBatch__column(const std::shared_ptr<arrow::RecordBatch>& batch, int i);\n RcppExport SEXP _arrow_RecordBatch__column(SEXP batchSEXP, SEXP iSEXP) {\n@@ -1859,6 +1870,29 @@ BEGIN_RCPP\n     return rcpp_result_gen;\n END_RCPP\n }\n+// ipc___SerializeRecordBatch__Raw\n+RawVector ipc___SerializeRecordBatch__Raw(const std::shared_ptr<arrow::RecordBatch>& batch);\n+RcppExport SEXP _arrow_ipc___SerializeRecordBatch__Raw(SEXP batchSEXP) {\n+BEGIN_RCPP\n+    Rcpp::RObject rcpp_result_gen;\n+    Rcpp::RNGScope rcpp_rngScope_gen;\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::RecordBatch>& >::type batch(batchSEXP);\n+    rcpp_result_gen = Rcpp::wrap(ipc___SerializeRecordBatch__Raw(batch));\n+    return rcpp_result_gen;\n+END_RCPP\n+}\n+// ipc___ReadRecordBatch__InputStream__Schema\n+std::shared_ptr<arrow::RecordBatch> ipc___ReadRecordBatch__InputStream__Schema(const std::shared_ptr<arrow::io::InputStream>& stream, const std::shared_ptr<arrow::Schema>& schema);\n+RcppExport SEXP _arrow_ipc___ReadRecordBatch__InputStream__Schema(SEXP streamSEXP, SEXP schemaSEXP) {\n+BEGIN_RCPP\n+    Rcpp::RObject rcpp_result_gen;\n+    Rcpp::RNGScope rcpp_rngScope_gen;\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::io::InputStream>& >::type stream(streamSEXP);\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::Schema>& >::type schema(schemaSEXP);\n+    rcpp_result_gen = Rcpp::wrap(ipc___ReadRecordBatch__InputStream__Schema(stream, schema));\n+    return rcpp_result_gen;\n+END_RCPP\n+}\n // RecordBatchReader__schema\n std::shared_ptr<arrow::Schema> RecordBatchReader__schema(const std::shared_ptr<arrow::RecordBatchReader>& reader);\n RcppExport SEXP _arrow_RecordBatchReader__schema(SEXP readerSEXP) {\n@@ -1892,6 +1926,17 @@ BEGIN_RCPP\n     return rcpp_result_gen;\n END_RCPP\n }\n+// ipc___RecordBatchStreamReader__batches\n+std::vector<std::shared_ptr<arrow::RecordBatch>> ipc___RecordBatchStreamReader__batches(const std::shared_ptr<arrow::ipc::RecordBatchStreamReader>& reader);\n+RcppExport SEXP _arrow_ipc___RecordBatchStreamReader__batches(SEXP readerSEXP) {\n+BEGIN_RCPP\n+    Rcpp::RObject rcpp_result_gen;\n+    Rcpp::RNGScope rcpp_rngScope_gen;\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::ipc::RecordBatchStreamReader>& >::type reader(readerSEXP);\n+    rcpp_result_gen = Rcpp::wrap(ipc___RecordBatchStreamReader__batches(reader));\n+    return rcpp_result_gen;\n+END_RCPP\n+}\n // ipc___RecordBatchFileReader__schema\n std::shared_ptr<arrow::Schema> ipc___RecordBatchFileReader__schema(const std::shared_ptr<arrow::ipc::RecordBatchFileReader>& reader);\n RcppExport SEXP _arrow_ipc___RecordBatchFileReader__schema(SEXP readerSEXP) {\n@@ -1959,39 +2004,25 @@ BEGIN_RCPP\n     return rcpp_result_gen;\n END_RCPP\n }\n-// ipc___RecordBatchFileWriter__Open\n-std::shared_ptr<arrow::ipc::RecordBatchWriter> ipc___RecordBatchFileWriter__Open(const std::shared_ptr<arrow::io::OutputStream>& stream, const std::shared_ptr<arrow::Schema>& schema);\n-RcppExport SEXP _arrow_ipc___RecordBatchFileWriter__Open(SEXP streamSEXP, SEXP schemaSEXP) {\n+// ipc___RecordBatchFileReader__batches\n+std::vector<std::shared_ptr<arrow::RecordBatch>> ipc___RecordBatchFileReader__batches(const std::shared_ptr<arrow::ipc::RecordBatchFileReader>& reader);\n+RcppExport SEXP _arrow_ipc___RecordBatchFileReader__batches(SEXP readerSEXP) {\n BEGIN_RCPP\n     Rcpp::RObject rcpp_result_gen;\n     Rcpp::RNGScope rcpp_rngScope_gen;\n-    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::io::OutputStream>& >::type stream(streamSEXP);\n-    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::Schema>& >::type schema(schemaSEXP);\n-    rcpp_result_gen = Rcpp::wrap(ipc___RecordBatchFileWriter__Open(stream, schema));\n-    return rcpp_result_gen;\n-END_RCPP\n-}\n-// ipc___RecordBatchStreamWriter__Open\n-std::shared_ptr<arrow::ipc::RecordBatchWriter> ipc___RecordBatchStreamWriter__Open(const std::shared_ptr<arrow::io::OutputStream>& stream, const std::shared_ptr<arrow::Schema>& schema);\n-RcppExport SEXP _arrow_ipc___RecordBatchStreamWriter__Open(SEXP streamSEXP, SEXP schemaSEXP) {\n-BEGIN_RCPP\n-    Rcpp::RObject rcpp_result_gen;\n-    Rcpp::RNGScope rcpp_rngScope_gen;\n-    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::io::OutputStream>& >::type stream(streamSEXP);\n-    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::Schema>& >::type schema(schemaSEXP);\n-    rcpp_result_gen = Rcpp::wrap(ipc___RecordBatchStreamWriter__Open(stream, schema));\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::ipc::RecordBatchFileReader>& >::type reader(readerSEXP);\n+    rcpp_result_gen = Rcpp::wrap(ipc___RecordBatchFileReader__batches(reader));\n     return rcpp_result_gen;\n END_RCPP\n }\n // ipc___RecordBatchWriter__WriteRecordBatch\n-void ipc___RecordBatchWriter__WriteRecordBatch(const std::shared_ptr<arrow::ipc::RecordBatchWriter>& batch_writer, const std::shared_ptr<arrow::RecordBatch>& batch, bool allow_64bit);\n-RcppExport SEXP _arrow_ipc___RecordBatchWriter__WriteRecordBatch(SEXP batch_writerSEXP, SEXP batchSEXP, SEXP allow_64bitSEXP) {\n+void ipc___RecordBatchWriter__WriteRecordBatch(const std::shared_ptr<arrow::ipc::RecordBatchWriter>& batch_writer, const std::shared_ptr<arrow::RecordBatch>& batch);\n+RcppExport SEXP _arrow_ipc___RecordBatchWriter__WriteRecordBatch(SEXP batch_writerSEXP, SEXP batchSEXP) {\n BEGIN_RCPP\n     Rcpp::RNGScope rcpp_rngScope_gen;\n     Rcpp::traits::input_parameter< const std::shared_ptr<arrow::ipc::RecordBatchWriter>& >::type batch_writer(batch_writerSEXP);\n     Rcpp::traits::input_parameter< const std::shared_ptr<arrow::RecordBatch>& >::type batch(batchSEXP);\n-    Rcpp::traits::input_parameter< bool >::type allow_64bit(allow_64bitSEXP);\n-    ipc___RecordBatchWriter__WriteRecordBatch(batch_writer, batch, allow_64bit);\n+    ipc___RecordBatchWriter__WriteRecordBatch(batch_writer, batch);\n     return R_NilValue;\n END_RCPP\n }\n@@ -2016,6 +2047,30 @@ BEGIN_RCPP\n     return R_NilValue;\n END_RCPP\n }\n+// ipc___RecordBatchFileWriter__Open\n+std::shared_ptr<arrow::ipc::RecordBatchWriter> ipc___RecordBatchFileWriter__Open(const std::shared_ptr<arrow::io::OutputStream>& stream, const std::shared_ptr<arrow::Schema>& schema);\n+RcppExport SEXP _arrow_ipc___RecordBatchFileWriter__Open(SEXP streamSEXP, SEXP schemaSEXP) {\n+BEGIN_RCPP\n+    Rcpp::RObject rcpp_result_gen;\n+    Rcpp::RNGScope rcpp_rngScope_gen;\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::io::OutputStream>& >::type stream(streamSEXP);\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::Schema>& >::type schema(schemaSEXP);\n+    rcpp_result_gen = Rcpp::wrap(ipc___RecordBatchFileWriter__Open(stream, schema));\n+    return rcpp_result_gen;\n+END_RCPP\n+}\n+// ipc___RecordBatchStreamWriter__Open\n+std::shared_ptr<arrow::ipc::RecordBatchWriter> ipc___RecordBatchStreamWriter__Open(const std::shared_ptr<arrow::io::OutputStream>& stream, const std::shared_ptr<arrow::Schema>& schema);\n+RcppExport SEXP _arrow_ipc___RecordBatchStreamWriter__Open(SEXP streamSEXP, SEXP schemaSEXP) {\n+BEGIN_RCPP\n+    Rcpp::RObject rcpp_result_gen;\n+    Rcpp::RNGScope rcpp_rngScope_gen;\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::io::OutputStream>& >::type stream(streamSEXP);\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::Schema>& >::type schema(schemaSEXP);\n+    rcpp_result_gen = Rcpp::wrap(ipc___RecordBatchStreamWriter__Open(stream, schema));\n+    return rcpp_result_gen;\n+END_RCPP\n+}\n // Table__from_dataframe\n std::shared_ptr<arrow::Table> Table__from_dataframe(DataFrame tbl);\n RcppExport SEXP _arrow_Table__from_dataframe(SEXP tblSEXP) {\n@@ -2083,6 +2138,17 @@ BEGIN_RCPP\n     return rcpp_result_gen;\n END_RCPP\n }\n+// Table__columns\n+std::vector<std::shared_ptr<arrow::Column>> Table__columns(const std::shared_ptr<arrow::Table>& table);\n+RcppExport SEXP _arrow_Table__columns(SEXP tableSEXP) {\n+BEGIN_RCPP\n+    Rcpp::RObject rcpp_result_gen;\n+    Rcpp::RNGScope rcpp_rngScope_gen;\n+    Rcpp::traits::input_parameter< const std::shared_ptr<arrow::Table>& >::type table(tableSEXP);\n+    rcpp_result_gen = Rcpp::wrap(Table__columns(table));\n+    return rcpp_result_gen;\n+END_RCPP\n+}\n \n static const R_CallMethodDef CallEntries[] = {\n     {\"_arrow_Array__from_vector\", (DL_FUNC) &_arrow_Array__from_vector, 1},\n@@ -2242,6 +2308,7 @@ static const R_CallMethodDef CallEntries[] = {\n     {\"_arrow_RecordBatch__num_columns\", (DL_FUNC) &_arrow_RecordBatch__num_columns, 1},\n     {\"_arrow_RecordBatch__num_rows\", (DL_FUNC) &_arrow_RecordBatch__num_rows, 1},\n     {\"_arrow_RecordBatch__schema\", (DL_FUNC) &_arrow_RecordBatch__schema, 1},\n+    {\"_arrow_RecordBatch__columns\", (DL_FUNC) &_arrow_RecordBatch__columns, 1},\n     {\"_arrow_RecordBatch__column\", (DL_FUNC) &_arrow_RecordBatch__column, 2},\n     {\"_arrow_RecordBatch__to_dataframe\", (DL_FUNC) &_arrow_RecordBatch__to_dataframe, 1},\n     {\"_arrow_RecordBatch__from_dataframe\", (DL_FUNC) &_arrow_RecordBatch__from_dataframe, 1},\n@@ -2251,26 +2318,31 @@ static const R_CallMethodDef CallEntries[] = {\n     {\"_arrow_RecordBatch__names\", (DL_FUNC) &_arrow_RecordBatch__names, 1},\n     {\"_arrow_RecordBatch__Slice1\", (DL_FUNC) &_arrow_RecordBatch__Slice1, 2},\n     {\"_arrow_RecordBatch__Slice2\", (DL_FUNC) &_arrow_RecordBatch__Slice2, 3},\n+    {\"_arrow_ipc___SerializeRecordBatch__Raw\", (DL_FUNC) &_arrow_ipc___SerializeRecordBatch__Raw, 1},\n+    {\"_arrow_ipc___ReadRecordBatch__InputStream__Schema\", (DL_FUNC) &_arrow_ipc___ReadRecordBatch__InputStream__Schema, 2},\n     {\"_arrow_RecordBatchReader__schema\", (DL_FUNC) &_arrow_RecordBatchReader__schema, 1},\n     {\"_arrow_RecordBatchReader__ReadNext\", (DL_FUNC) &_arrow_RecordBatchReader__ReadNext, 1},\n     {\"_arrow_ipc___RecordBatchStreamReader__Open\", (DL_FUNC) &_arrow_ipc___RecordBatchStreamReader__Open, 1},\n+    {\"_arrow_ipc___RecordBatchStreamReader__batches\", (DL_FUNC) &_arrow_ipc___RecordBatchStreamReader__batches, 1},\n     {\"_arrow_ipc___RecordBatchFileReader__schema\", (DL_FUNC) &_arrow_ipc___RecordBatchFileReader__schema, 1},\n     {\"_arrow_ipc___RecordBatchFileReader__num_record_batches\", (DL_FUNC) &_arrow_ipc___RecordBatchFileReader__num_record_batches, 1},\n     {\"_arrow_ipc___RecordBatchFileReader__ReadRecordBatch\", (DL_FUNC) &_arrow_ipc___RecordBatchFileReader__ReadRecordBatch, 2},\n     {\"_arrow_ipc___RecordBatchFileReader__Open\", (DL_FUNC) &_arrow_ipc___RecordBatchFileReader__Open, 1},\n     {\"_arrow_Table__from_RecordBatchFileReader\", (DL_FUNC) &_arrow_Table__from_RecordBatchFileReader, 1},\n     {\"_arrow_Table__from_RecordBatchStreamReader\", (DL_FUNC) &_arrow_Table__from_RecordBatchStreamReader, 1},\n-    {\"_arrow_ipc___RecordBatchFileWriter__Open\", (DL_FUNC) &_arrow_ipc___RecordBatchFileWriter__Open, 2},\n-    {\"_arrow_ipc___RecordBatchStreamWriter__Open\", (DL_FUNC) &_arrow_ipc___RecordBatchStreamWriter__Open, 2},\n-    {\"_arrow_ipc___RecordBatchWriter__WriteRecordBatch\", (DL_FUNC) &_arrow_ipc___RecordBatchWriter__WriteRecordBatch, 3},\n+    {\"_arrow_ipc___RecordBatchFileReader__batches\", (DL_FUNC) &_arrow_ipc___RecordBatchFileReader__batches, 1},\n+    {\"_arrow_ipc___RecordBatchWriter__WriteRecordBatch\", (DL_FUNC) &_arrow_ipc___RecordBatchWriter__WriteRecordBatch, 2},\n     {\"_arrow_ipc___RecordBatchWriter__WriteTable\", (DL_FUNC) &_arrow_ipc___RecordBatchWriter__WriteTable, 2},\n     {\"_arrow_ipc___RecordBatchWriter__Close\", (DL_FUNC) &_arrow_ipc___RecordBatchWriter__Close, 1},\n+    {\"_arrow_ipc___RecordBatchFileWriter__Open\", (DL_FUNC) &_arrow_ipc___RecordBatchFileWriter__Open, 2},\n+    {\"_arrow_ipc___RecordBatchStreamWriter__Open\", (DL_FUNC) &_arrow_ipc___RecordBatchStreamWriter__Open, 2},\n     {\"_arrow_Table__from_dataframe\", (DL_FUNC) &_arrow_Table__from_dataframe, 1},\n     {\"_arrow_Table__num_columns\", (DL_FUNC) &_arrow_Table__num_columns, 1},\n     {\"_arrow_Table__num_rows\", (DL_FUNC) &_arrow_Table__num_rows, 1},\n     {\"_arrow_Table__schema\", (DL_FUNC) &_arrow_Table__schema, 1},\n     {\"_arrow_Table__to_dataframe\", (DL_FUNC) &_arrow_Table__to_dataframe, 1},\n     {\"_arrow_Table__column\", (DL_FUNC) &_arrow_Table__column, 2},\n+    {\"_arrow_Table__columns\", (DL_FUNC) &_arrow_Table__columns, 1},\n     {NULL, NULL, 0}\n };\n \ndiff --git a/r/src/arrow_types.h b/r/src/arrow_types.h\nindex 419705f9fc..9ebc558d0d 100644\n--- a/r/src/arrow_types.h\n+++ b/r/src/arrow_types.h\n@@ -152,6 +152,7 @@ using LogicalVector_ = Rcpp::Vector<LGLSXP, Rcpp::NoProtectStorage>;\n using StringVector_ = Rcpp::Vector<STRSXP, Rcpp::NoProtectStorage>;\n using CharacterVector_ = StringVector_;\n using RawVector_ = Rcpp::Vector<RAWSXP, Rcpp::NoProtectStorage>;\n+using List_ = Rcpp::Vector<VECSXP, Rcpp::NoProtectStorage>;\n \n template <int RTYPE>\n inline typename Rcpp::Vector<RTYPE>::stored_type default_value() {\ndiff --git a/r/src/recordbatch.cpp b/r/src/recordbatch.cpp\nindex 829ad45ead..b6bee7ae53 100644\n--- a/r/src/recordbatch.cpp\n+++ b/r/src/recordbatch.cpp\n@@ -40,6 +40,17 @@ std::shared_ptr<arrow::Schema> RecordBatch__schema(\n   return x->schema();\n }\n \n+// [[Rcpp::export]]\n+arrow::ArrayVector RecordBatch__columns(\n+    const std::shared_ptr<arrow::RecordBatch>& batch) {\n+  auto nc = batch->num_columns();\n+  ArrayVector res(nc);\n+  for (int i = 0; i < nc; i++) {\n+    res[i] = batch->column(i);\n+  }\n+  return res;\n+}\n+\n // [[Rcpp::export]]\n std::shared_ptr<arrow::Array> RecordBatch__column(\n     const std::shared_ptr<arrow::RecordBatch>& batch, int i) {\n@@ -120,3 +131,32 @@ std::shared_ptr<arrow::RecordBatch> RecordBatch__Slice2(\n     const std::shared_ptr<arrow::RecordBatch>& self, int offset, int length) {\n   return self->Slice(offset, length);\n }\n+\n+// [[Rcpp::export]]\n+RawVector ipc___SerializeRecordBatch__Raw(\n+    const std::shared_ptr<arrow::RecordBatch>& batch) {\n+  // how many bytes do we need ?\n+  int64_t size;\n+  STOP_IF_NOT_OK(arrow::ipc::GetRecordBatchSize(*batch, &size));\n+\n+  // allocate the result raw vector\n+  RawVector out(no_init(size));\n+\n+  // serialize into the bytes of the raw vector\n+  auto buffer = std::make_shared<arrow::r::RBuffer<RAWSXP, RawVector>>(out);\n+  arrow::io::FixedSizeBufferWriter stream(buffer);\n+  STOP_IF_NOT_OK(\n+      arrow::ipc::SerializeRecordBatch(*batch, arrow::default_memory_pool(), &stream));\n+  STOP_IF_NOT_OK(stream.Close());\n+\n+  return out;\n+}\n+\n+// [[Rcpp::export]]\n+std::shared_ptr<arrow::RecordBatch> ipc___ReadRecordBatch__InputStream__Schema(\n+    const std::shared_ptr<arrow::io::InputStream>& stream,\n+    const std::shared_ptr<arrow::Schema>& schema) {\n+  std::shared_ptr<arrow::RecordBatch> batch;\n+  STOP_IF_NOT_OK(arrow::ipc::ReadRecordBatch(schema, stream.get(), &batch));\n+  return batch;\n+}\ndiff --git a/r/src/recordbatchreader.cpp b/r/src/recordbatchreader.cpp\nindex 65a1c9baf3..f3e90228d3 100644\n--- a/r/src/recordbatchreader.cpp\n+++ b/r/src/recordbatchreader.cpp\n@@ -41,6 +41,22 @@ std::shared_ptr<arrow::RecordBatchReader> ipc___RecordBatchStreamReader__Open(\n   return reader;\n }\n \n+// [[Rcpp::export]]\n+std::vector<std::shared_ptr<arrow::RecordBatch>> ipc___RecordBatchStreamReader__batches(\n+    const std::shared_ptr<arrow::ipc::RecordBatchStreamReader>& reader) {\n+  std::vector<std::shared_ptr<arrow::RecordBatch>> res;\n+\n+  while (true) {\n+    std::shared_ptr<arrow::RecordBatch> batch;\n+    STOP_IF_NOT_OK(reader->ReadNext(&batch));\n+    if (!batch) break;\n+\n+    res.push_back(batch);\n+  }\n+\n+  return res;\n+}\n+\n // -------- RecordBatchFileReader\n \n // [[Rcpp::export]]\n@@ -104,3 +120,16 @@ std::shared_ptr<arrow::Table> Table__from_RecordBatchStreamReader(\n \n   return table;\n }\n+\n+// [[Rcpp::export]]\n+std::vector<std::shared_ptr<arrow::RecordBatch>> ipc___RecordBatchFileReader__batches(\n+    const std::shared_ptr<arrow::ipc::RecordBatchFileReader>& reader) {\n+  auto n = reader->num_record_batches();\n+  std::vector<std::shared_ptr<arrow::RecordBatch>> res(n);\n+\n+  for (int i = 0; i < n; i++) {\n+    STOP_IF_NOT_OK(reader->ReadRecordBatch(i, &res[i]));\n+  }\n+\n+  return res;\n+}\ndiff --git a/r/src/recordbatchwriter.cpp b/r/src/recordbatchwriter.cpp\nindex f86c474fec..d4dd212a9b 100644\n--- a/r/src/recordbatchwriter.cpp\n+++ b/r/src/recordbatchwriter.cpp\n@@ -17,6 +17,26 @@\n \n #include \"arrow_types.h\"\n \n+// [[Rcpp::export]]\n+void ipc___RecordBatchWriter__WriteRecordBatch(\n+    const std::shared_ptr<arrow::ipc::RecordBatchWriter>& batch_writer,\n+    const std::shared_ptr<arrow::RecordBatch>& batch) {\n+  STOP_IF_NOT_OK(batch_writer->WriteRecordBatch(*batch, true));\n+}\n+\n+// [[Rcpp::export]]\n+void ipc___RecordBatchWriter__WriteTable(\n+    const std::shared_ptr<arrow::ipc::RecordBatchWriter>& batch_writer,\n+    const std::shared_ptr<arrow::Table>& table) {\n+  STOP_IF_NOT_OK(batch_writer->WriteTable(*table));\n+}\n+\n+// [[Rcpp::export]]\n+void ipc___RecordBatchWriter__Close(\n+    const std::shared_ptr<arrow::ipc::RecordBatchWriter>& batch_writer) {\n+  STOP_IF_NOT_OK(batch_writer->Close());\n+}\n+\n // [[Rcpp::export]]\n std::shared_ptr<arrow::ipc::RecordBatchWriter> ipc___RecordBatchFileWriter__Open(\n     const std::shared_ptr<arrow::io::OutputStream>& stream,\n@@ -36,23 +56,3 @@ std::shared_ptr<arrow::ipc::RecordBatchWriter> ipc___RecordBatchStreamWriter__Op\n       arrow::ipc::RecordBatchStreamWriter::Open(stream.get(), schema, &stream_writer));\n   return stream_writer;\n }\n-\n-// [[Rcpp::export]]\n-void ipc___RecordBatchWriter__WriteRecordBatch(\n-    const std::shared_ptr<arrow::ipc::RecordBatchWriter>& batch_writer,\n-    const std::shared_ptr<arrow::RecordBatch>& batch, bool allow_64bit) {\n-  STOP_IF_NOT_OK(batch_writer->WriteRecordBatch(*batch, allow_64bit));\n-}\n-\n-// [[Rcpp::export]]\n-void ipc___RecordBatchWriter__WriteTable(\n-    const std::shared_ptr<arrow::ipc::RecordBatchWriter>& batch_writer,\n-    const std::shared_ptr<arrow::Table>& table) {\n-  STOP_IF_NOT_OK(batch_writer->WriteTable(*table));\n-}\n-\n-// [[Rcpp::export]]\n-void ipc___RecordBatchWriter__Close(\n-    const std::shared_ptr<arrow::ipc::RecordBatchWriter>& batch_writer) {\n-  STOP_IF_NOT_OK(batch_writer->Close());\n-}\ndiff --git a/r/src/table.cpp b/r/src/table.cpp\nindex 4bdff167db..f4ebd0466b 100644\n--- a/r/src/table.cpp\n+++ b/r/src/table.cpp\n@@ -67,3 +67,14 @@ std::shared_ptr<arrow::Column> Table__column(const std::shared_ptr<arrow::Table>\n                                              int i) {\n   return table->column(i);\n }\n+\n+// [[Rcpp::export]]\n+std::vector<std::shared_ptr<arrow::Column>> Table__columns(\n+    const std::shared_ptr<arrow::Table>& table) {\n+  auto nc = table->num_columns();\n+  std::vector<std::shared_ptr<arrow::Column>> res(nc);\n+  for (int i = 0; i < nc; i++) {\n+    res[i] = table->column(i);\n+  }\n+  return res;\n+}\ndiff --git a/r/tests/testthat/test-Array.R b/r/tests/testthat/test-Array.R\nindex cbf67e711d..e456fe8865 100644\n--- a/r/tests/testthat/test-Array.R\n+++ b/r/tests/testthat/test-Array.R\n@@ -19,35 +19,35 @@ context(\"arrow::Array\")\n \n test_that(\"Array\", {\n   x <- array(1:10, 1:10, 1:5)\n-  expect_equal(x$type(), int32())\n+  expect_equal(x$type, int32())\n   expect_equal(x$length(), 25L)\n   expect_equal(x$as_vector(), c(1:10, 1:10, 1:5))\n \n   y <- x$Slice(10)\n-  expect_equal(y$type(), int32())\n+  expect_equal(y$type, int32())\n   expect_equal(y$length(), 15L)\n   expect_equal(y$as_vector(), c(1:10, 1:5))\n   expect_true(x$RangeEquals(y, 10, 24, 0))\n \n   z <- x$Slice(10, 5)\n-  expect_equal(z$type(), int32())\n+  expect_equal(z$type, int32())\n   expect_equal(z$length(), 5L)\n   expect_equal(z$as_vector(), c(1:5))\n   expect_true(x$RangeEquals(z, 10, 15, 0))\n \n   x_dbl <- array(c(1,2,3), c(4,5,6))\n-  expect_equal(x_dbl$type(), float64())\n+  expect_equal(x_dbl$type, float64())\n   expect_equal(x_dbl$length(), 6L)\n   expect_equal(x_dbl$as_vector(), as.numeric(1:6))\n \n   y_dbl <- x_dbl$Slice(3)\n-  expect_equal(y_dbl$type(), float64())\n+  expect_equal(y_dbl$type, float64())\n   expect_equal(y_dbl$length(), 3L)\n-  expect_equal(y_dbl$offset(), 3L)\n+  expect_equal(y_dbl$offset, 3L)\n   expect_equal(y_dbl$as_vector(), as.numeric(4:6))\n \n   z_dbl <- x_dbl$Slice(3, 2)\n-  expect_equal(z_dbl$type(), float64())\n+  expect_equal(z_dbl$type, float64())\n   expect_equal(z_dbl$length(), 2L)\n   expect_equal(z_dbl$as_vector(), as.numeric(4:5))\n })\n@@ -138,7 +138,7 @@ test_that(\"Array supports unordered factors (ARROW-3355)\", {\n   f <- factor(c(\"itsy\", \"bitsy\", \"spider\", \"spider\"))\n   arr_fac <- array(f)\n   expect_equal(arr_fac$length(), 4L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_identical(arr_fac$as_vector(), f)\n   expect_true(arr_fac$IsValid(0))\n   expect_true(arr_fac$IsValid(1))\n@@ -147,7 +147,7 @@ test_that(\"Array supports unordered factors (ARROW-3355)\", {\n \n   sl <- arr_fac$Slice(1)\n   expect_equal(sl$length(), 3L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_equal(sl$as_vector(), f[2:4])\n \n   # with NA\n@@ -155,7 +155,7 @@ test_that(\"Array supports unordered factors (ARROW-3355)\", {\n   # TODO: rm the suppressWarnings when https://github.com/r-lib/vctrs/issues/109\n   arr_fac <- suppressWarnings(array(f))\n   expect_equal(arr_fac$length(), 5L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_identical(arr_fac$as_vector(), f)\n   expect_true(arr_fac$IsValid(0))\n   expect_true(arr_fac$IsValid(1))\n@@ -165,7 +165,7 @@ test_that(\"Array supports unordered factors (ARROW-3355)\", {\n \n   sl <- arr_fac$Slice(1)\n   expect_equal(sl$length(), 4L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_equal(sl$as_vector(), f[2:5])\n })\n \n@@ -174,7 +174,7 @@ test_that(\"Array supports ordered factors (ARROW-3355)\", {\n   f <- ordered(c(\"itsy\", \"bitsy\", \"spider\", \"spider\"))\n   arr_fac <- array(f)\n   expect_equal(arr_fac$length(), 4L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_identical(arr_fac$as_vector(), f)\n   expect_true(arr_fac$IsValid(0))\n   expect_true(arr_fac$IsValid(1))\n@@ -183,7 +183,7 @@ test_that(\"Array supports ordered factors (ARROW-3355)\", {\n \n   sl <- arr_fac$Slice(1)\n   expect_equal(sl$length(), 3L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_equal(sl$as_vector(), f[2:4])\n \n   # with NA\n@@ -191,7 +191,7 @@ test_that(\"Array supports ordered factors (ARROW-3355)\", {\n   # TODO: rm the suppressWarnings when https://github.com/r-lib/vctrs/issues/109\n   arr_fac <- suppressWarnings(array(f))\n   expect_equal(arr_fac$length(), 5L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_identical(arr_fac$as_vector(), f)\n   expect_true(arr_fac$IsValid(0))\n   expect_true(arr_fac$IsValid(1))\n@@ -201,27 +201,27 @@ test_that(\"Array supports ordered factors (ARROW-3355)\", {\n \n   sl <- arr_fac$Slice(1)\n   expect_equal(sl$length(), 4L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_equal(sl$as_vector(), f[2:5])\n })\n \n test_that(\"array supports Date (ARROW-3340)\", {\n   d <- Sys.Date() + 1:10\n   a <- array(d)\n-  expect_equal(a$type(), date32())\n+  expect_equal(a$type, date32())\n   expect_equal(a$length(), 10L)\n   expect_equal(a$as_vector(), d)\n \n   d[5] <- NA\n   a <- array(d)\n-  expect_equal(a$type(), date32())\n+  expect_equal(a$type, date32())\n   expect_equal(a$length(), 10L)\n   expect_equal(a$as_vector(), d)\n   expect_true(a$IsNull(4))\n \n   d2 <- d + .5\n   a <- array(d2)\n-  expect_equal(a$type(), date32())\n+  expect_equal(a$type, date32())\n   expect_equal(a$length(), 10L)\n   expect_equal(a$as_vector(), d)\n   expect_true(a$IsNull(4))\n@@ -230,15 +230,15 @@ test_that(\"array supports Date (ARROW-3340)\", {\n test_that(\"array supports POSIXct (ARROW-3340)\", {\n   times <- lubridate::ymd_hms(\"2018-10-07 19:04:05\") + 1:10\n   a <- array(times)\n-  expect_equal(a$type()$name(), \"timestamp\")\n-  expect_equal(a$type()$unit(), unclass(TimeUnit$MICRO))\n+  expect_equal(a$type$name, \"timestamp\")\n+  expect_equal(a$type$unit(), unclass(TimeUnit$MICRO))\n   expect_equal(a$length(), 10L)\n   expect_equal(as.numeric(a$as_vector()), as.numeric(times))\n \n   times[5] <- NA\n   a <- array(times)\n-  expect_equal(a$type()$name(), \"timestamp\")\n-  expect_equal(a$type()$unit(), unclass(TimeUnit$MICRO))\n+  expect_equal(a$type$name, \"timestamp\")\n+  expect_equal(a$type$unit(), unclass(TimeUnit$MICRO))\n   expect_equal(a$length(), 10L)\n   expect_equal(as.numeric(a$as_vector()), as.numeric(times))\n   expect_true(a$IsNull(4))\n@@ -247,13 +247,13 @@ test_that(\"array supports POSIXct (ARROW-3340)\", {\n test_that(\"array supports integer64\", {\n   x <- bit64::as.integer64(1:10)\n   a <- array(x)\n-  expect_equal(a$type(), int64())\n+  expect_equal(a$type, int64())\n   expect_equal(a$length(), 10L)\n   expect_equal(a$as_vector(), x)\n \n   x[4] <- NA\n   a <- array(x)\n-  expect_equal(a$type(), int64())\n+  expect_equal(a$type, int64())\n   expect_equal(a$length(), 10L)\n   expect_equal(a$as_vector(), x)\n   expect_true(a$IsNull(3L))\n@@ -268,12 +268,12 @@ test_that(\"array$as_vector() correctly handles all NA inte64 (ARROW-3795)\", {\n test_that(\"array supports difftime\", {\n   time <- hms::hms(56, 34, 12)\n   a <- array(time, time)\n-  expect_equal(a$type(), time32(unit = TimeUnit$SECOND))\n+  expect_equal(a$type, time32(unit = TimeUnit$SECOND))\n   expect_equal(a$length(), 2L)\n   expect_equal(a$as_vector(), c(time, time))\n \n   a <- array(time, NA)\n-  expect_equal(a$type(), time32(unit = TimeUnit$SECOND))\n+  expect_equal(a$type, time32(unit = TimeUnit$SECOND))\n   expect_equal(a$length(), 2L)\n   expect_true(a$IsNull(1))\n   expect_equal(a$as_vector()[1], time)\n@@ -284,7 +284,7 @@ test_that(\"support for NaN (ARROW-3615)\", {\n   x <- c(1, NA, NaN, -1)\n   y <- array(x)\n   expect_true(y$IsValid(2))\n-  expect_equal(y$null_count(), 1L)\n+  expect_equal(y$null_count, 1L)\n })\n \n test_that(\"array ignores the type argument (ARROW-3784)\", {\n@@ -300,10 +300,10 @@ test_that(\"integer types casts (ARROW-3741)\", {\n   a_int32 <- a$cast(int32())\n   a_int64 <- a$cast(int64())\n \n-  expect_equal(a_int8$type(), int8())\n-  expect_equal(a_int16$type(), int16())\n-  expect_equal(a_int32$type(), int32())\n-  expect_equal(a_int64$type(), int64())\n+  expect_equal(a_int8$type, int8())\n+  expect_equal(a_int16$type, int16())\n+  expect_equal(a_int32$type, int32())\n+  expect_equal(a_int64$type, int64())\n   expect_true(a_int8$IsNull(10L))\n   expect_true(a_int16$IsNull(10L))\n   expect_true(a_int32$IsNull(10L))\n@@ -314,10 +314,10 @@ test_that(\"integer types casts (ARROW-3741)\", {\n   a_uint32 <- a$cast(uint32())\n   a_uint64 <- a$cast(uint64())\n \n-  expect_equal(a_uint8$type(), uint8())\n-  expect_equal(a_uint16$type(), uint16())\n-  expect_equal(a_uint32$type(), uint32())\n-  expect_equal(a_uint64$type(), uint64())\n+  expect_equal(a_uint8$type, uint8())\n+  expect_equal(a_uint16$type, uint16())\n+  expect_equal(a_uint32$type, uint32())\n+  expect_equal(a_uint64$type, uint64())\n   expect_true(a_uint8$IsNull(10L))\n   expect_true(a_uint16$IsNull(10L))\n   expect_true(a_uint32$IsNull(10L))\n@@ -345,8 +345,8 @@ test_that(\"float types casts (ARROW-3741)\", {\n   a_f32 <- a$cast(float32())\n   a_f64 <- a$cast(float64())\n \n-  expect_equal(a_f32$type(), float32())\n-  expect_equal(a_f64$type(), float64())\n+  expect_equal(a_f32$type, float32())\n+  expect_equal(a_f64$type, float64())\n \n   expect_true(a_f32$IsNull(3L))\n   expect_true(a_f64$IsNull(3L))\n@@ -359,5 +359,5 @@ test_that(\"cast to half float works\", {\n   skip(\"until https://issues.apache.org/jira/browse/ARROW-3802\")\n   a <- array(1:4)\n   a_f16 <- a$cast(float16())\n-  expect_equal(a_16$type(), float16())\n+  expect_equal(a_16$type, float16())\n })\ndiff --git a/r/tests/testthat/test-DataType.R b/r/tests/testthat/test-DataType.R\nindex b479e5a3f6..fc9fc896ea 100644\n--- a/r/tests/testthat/test-DataType.R\n+++ b/r/tests/testthat/test-DataType.R\n@@ -19,8 +19,8 @@ context(\"arrow::DataType\")\n \n test_that(\"null type works as expected\",{\n   x <- null()\n-  expect_equal(x$id(), 0L)\n-  expect_equal(x$name(), \"null\")\n+  expect_equal(x$id, 0L)\n+  expect_equal(x$name, \"null\")\n   expect_equal(x$ToString(), \"null\")\n   expect_true(x == x)\n   expect_false(x == int8())\n@@ -30,134 +30,134 @@ test_that(\"null type works as expected\",{\n \n test_that(\"boolean type work as expected\",{\n   x <- boolean()\n-  expect_equal(x$id(), 1L)\n-  expect_equal(x$name(), \"bool\")\n+  expect_equal(x$id, 1L)\n+  expect_equal(x$name, \"bool\")\n   expect_equal(x$ToString(), \"bool\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 1L)\n+  expect_equal(x$bit_width, 1L)\n })\n \n test_that(\"int types works as expected\",{\n   x <- uint8()\n-  expect_equal(x$id(), 2L)\n-  expect_equal(x$name(), \"uint8\")\n+  expect_equal(x$id, 2L)\n+  expect_equal(x$name, \"uint8\")\n   expect_equal(x$ToString(), \"uint8\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 8L)\n+  expect_equal(x$bit_width, 8L)\n \n   x <- int8()\n-  expect_equal(x$id(), 3L)\n-  expect_equal(x$name(), \"int8\")\n+  expect_equal(x$id, 3L)\n+  expect_equal(x$name, \"int8\")\n   expect_equal(x$ToString(), \"int8\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 8L)\n+  expect_equal(x$bit_width, 8L)\n \n   x <- uint16()\n-  expect_equal(x$id(), 4L)\n-  expect_equal(x$name(), \"uint16\")\n+  expect_equal(x$id, 4L)\n+  expect_equal(x$name, \"uint16\")\n   expect_equal(x$ToString(), \"uint16\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 16L)\n+  expect_equal(x$bit_width, 16L)\n \n   x <- int16()\n-  expect_equal(x$id(), 5L)\n-  expect_equal(x$name(), \"int16\")\n+  expect_equal(x$id, 5L)\n+  expect_equal(x$name, \"int16\")\n   expect_equal(x$ToString(), \"int16\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 16L)\n+  expect_equal(x$bit_width, 16L)\n \n   x <- uint32()\n-  expect_equal(x$id(), 6L)\n-  expect_equal(x$name(), \"uint32\")\n+  expect_equal(x$id, 6L)\n+  expect_equal(x$name, \"uint32\")\n   expect_equal(x$ToString(), \"uint32\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 32L)\n+  expect_equal(x$bit_width, 32L)\n \n   x <- int32()\n-  expect_equal(x$id(), 7L)\n-  expect_equal(x$name(), \"int32\")\n+  expect_equal(x$id, 7L)\n+  expect_equal(x$name, \"int32\")\n   expect_equal(x$ToString(), \"int32\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 32L)\n+  expect_equal(x$bit_width, 32L)\n \n   x <- uint64()\n-  expect_equal(x$id(), 8L)\n-  expect_equal(x$name(), \"uint64\")\n+  expect_equal(x$id, 8L)\n+  expect_equal(x$name, \"uint64\")\n   expect_equal(x$ToString(), \"uint64\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n \n   x <- int64()\n-  expect_equal(x$id(), 9L)\n-  expect_equal(x$name(), \"int64\")\n+  expect_equal(x$id, 9L)\n+  expect_equal(x$name, \"int64\")\n   expect_equal(x$ToString(), \"int64\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n })\n \n test_that(\"float types work as expected\",{\n   x <- float16()\n-  expect_equal(x$id(), 10L)\n-  expect_equal(x$name(), \"halffloat\")\n+  expect_equal(x$id, 10L)\n+  expect_equal(x$name, \"halffloat\")\n   expect_equal(x$ToString(), \"halffloat\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 16L)\n+  expect_equal(x$bit_width, 16L)\n \n   x <- float32()\n-  expect_equal(x$id(), 11L)\n-  expect_equal(x$name(), \"float\")\n+  expect_equal(x$id, 11L)\n+  expect_equal(x$name, \"float\")\n   expect_equal(x$ToString(), \"float\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 32L)\n+  expect_equal(x$bit_width, 32L)\n \n   x <- float64()\n-  expect_equal(x$id(), 12L)\n-  expect_equal(x$name(), \"double\")\n+  expect_equal(x$id, 12L)\n+  expect_equal(x$name, \"double\")\n   expect_equal(x$ToString(), \"double\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n })\n \n test_that(\"utf8 type works as expected\",{\n   x <- utf8()\n-  expect_equal(x$id(), 13L)\n-  expect_equal(x$name(), \"utf8\")\n+  expect_equal(x$id, 13L)\n+  expect_equal(x$name, \"utf8\")\n   expect_equal(x$ToString(), \"string\")\n   expect_true(x == x)\n   expect_false(x == null())\n@@ -167,8 +167,8 @@ test_that(\"utf8 type works as expected\",{\n \n test_that(\"date types work as expected\", {\n   x <- date32()\n-  expect_equal(x$id(), 16L)\n-  expect_equal(x$name(), \"date32\")\n+  expect_equal(x$id, 16L)\n+  expect_equal(x$name, \"date32\")\n   expect_equal(x$ToString(), \"date32[day]\")\n   expect_true(x == x)\n   expect_false(x == null())\n@@ -177,8 +177,8 @@ test_that(\"date types work as expected\", {\n   expect_equal(x$unit(), unclass(DateUnit$DAY))\n \n   x <- date64()\n-  expect_equal(x$id(), 17L)\n-  expect_equal(x$name(), \"date64\")\n+  expect_equal(x$id, 17L)\n+  expect_equal(x$name, \"date64\")\n   expect_equal(x$ToString(), \"date64[ms]\")\n   expect_true(x == x)\n   expect_false(x == null())\n@@ -189,106 +189,106 @@ test_that(\"date types work as expected\", {\n \n test_that(\"timestamp type works as expected\", {\n   x <- timestamp(TimeUnit$SECOND)\n-  expect_equal(x$id(), 18L)\n-  expect_equal(x$name(), \"timestamp\")\n+  expect_equal(x$id, 18L)\n+  expect_equal(x$name, \"timestamp\")\n   expect_equal(x$ToString(), \"timestamp[s]\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n   expect_equal(x$timezone(), \"\")\n   expect_equal(x$unit(), unclass(TimeUnit$SECOND))\n \n   x <- timestamp(TimeUnit$MILLI)\n-  expect_equal(x$id(), 18L)\n-  expect_equal(x$name(), \"timestamp\")\n+  expect_equal(x$id, 18L)\n+  expect_equal(x$name, \"timestamp\")\n   expect_equal(x$ToString(), \"timestamp[ms]\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n   expect_equal(x$timezone(), \"\")\n   expect_equal(x$unit(), unclass(TimeUnit$MILLI))\n \n   x <- timestamp(TimeUnit$MICRO)\n-  expect_equal(x$id(), 18L)\n-  expect_equal(x$name(), \"timestamp\")\n+  expect_equal(x$id, 18L)\n+  expect_equal(x$name, \"timestamp\")\n   expect_equal(x$ToString(), \"timestamp[us]\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n   expect_equal(x$timezone(), \"\")\n   expect_equal(x$unit(), unclass(TimeUnit$MICRO))\n \n   x <- timestamp(TimeUnit$NANO)\n-  expect_equal(x$id(), 18L)\n-  expect_equal(x$name(), \"timestamp\")\n+  expect_equal(x$id, 18L)\n+  expect_equal(x$name, \"timestamp\")\n   expect_equal(x$ToString(), \"timestamp[ns]\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n   expect_equal(x$timezone(), \"\")\n   expect_equal(x$unit(), unclass(TimeUnit$NANO))\n })\n \n test_that(\"time32 types work as expected\", {\n   x <- time32(TimeUnit$SECOND)\n-  expect_equal(x$id(), 19L)\n-  expect_equal(x$name(), \"time32\")\n+  expect_equal(x$id, 19L)\n+  expect_equal(x$name, \"time32\")\n   expect_equal(x$ToString(), \"time32[s]\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 32L)\n+  expect_equal(x$bit_width, 32L)\n   expect_equal(x$unit(), unclass(TimeUnit$SECOND))\n \n   x <- time32(TimeUnit$MILLI)\n-  expect_equal(x$id(), 19L)\n-  expect_equal(x$name(), \"time32\")\n+  expect_equal(x$id, 19L)\n+  expect_equal(x$name, \"time32\")\n   expect_equal(x$ToString(), \"time32[ms]\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 32L)\n+  expect_equal(x$bit_width, 32L)\n   expect_equal(x$unit(), unclass(TimeUnit$MILLI))\n })\n \n test_that(\"time64 types work as expected\", {\n   x <- time64(TimeUnit$MICRO)\n-  expect_equal(x$id(), 20L)\n-  expect_equal(x$name(), \"time64\")\n+  expect_equal(x$id, 20L)\n+  expect_equal(x$name, \"time64\")\n   expect_equal(x$ToString(), \"time64[us]\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n   expect_equal(x$unit(), unclass(TimeUnit$MICRO))\n \n   x <- time64(TimeUnit$NANO)\n-  expect_equal(x$id(), 20L)\n-  expect_equal(x$name(), \"time64\")\n+  expect_equal(x$id, 20L)\n+  expect_equal(x$name, \"time64\")\n   expect_equal(x$ToString(), \"time64[ns]\")\n   expect_true(x == x)\n   expect_false(x == null())\n   expect_equal(x$num_children(), 0L)\n   expect_equal(x$children(), list())\n-  expect_equal(x$bit_width(), 64L)\n+  expect_equal(x$bit_width, 64L)\n   expect_equal(x$unit(), unclass(TimeUnit$NANO))\n })\n \n test_that(\"list type works as expected\", {\n   x <- list_of(int32())\n-  expect_equal(x$id(), 23L)\n-  expect_equal(x$name(), \"list\")\n+  expect_equal(x$id, 23L)\n+  expect_equal(x$name, \"list\")\n   expect_equal(x$ToString(), \"list<item: int32>\")\n   expect_true(x == x)\n   expect_false(x == null())\n@@ -301,8 +301,8 @@ test_that(\"list type works as expected\", {\n \n test_that(\"struct type works as expected\", {\n   x <- struct(x = int32(), y = boolean())\n-  expect_equal(x$id(), 24L)\n-  expect_equal(x$name(), \"struct\")\n+  expect_equal(x$id, 24L)\n+  expect_equal(x$name, \"struct\")\n   expect_equal(x$ToString(), \"struct<x: int32, y: bool>\")\n   expect_true(x == x)\n   expect_false(x == null())\n@@ -318,9 +318,9 @@ test_that(\"DictionaryType works as expected (ARROW-3355)\", {\n   expect_equal(d, d)\n   expect_true(d == d)\n   expect_false(d == int32())\n-  expect_equal(d$id(), Type$DICTIONARY)\n-  expect_equal(d$bit_width(), 32L)\n+  expect_equal(d$id, Type$DICTIONARY)\n+  expect_equal(d$bit_width, 32L)\n   expect_equal(d$ToString(), \"dictionary<values=string, indices=int32, ordered=0>\")\n-  expect_equal(d$index_type(), int32())\n-  expect_equal(d$dictionary(), array(c(\"foo\", \"bar\", \"baz\")))\n+  expect_equal(d$index_type, int32())\n+  expect_equal(d$dictionary, array(c(\"foo\", \"bar\", \"baz\")))\n })\ndiff --git a/r/tests/testthat/test-RecordBatch.R b/r/tests/testthat/test-RecordBatch.R\nindex 348327783f..f40bd8387a 100644\n--- a/r/tests/testthat/test-RecordBatch.R\n+++ b/r/tests/testthat/test-RecordBatch.R\n@@ -28,15 +28,15 @@ test_that(\"RecordBatch\", {\n \n   expect_true(batch == batch)\n   expect_equal(\n-    batch$schema(),\n+    batch$schema,\n     schema(\n       int = int32(), dbl = float64(),\n       lgl = boolean(), chr = utf8(),\n       fct = dictionary(int32(), array(letters[1:10]))\n     )\n   )\n-  expect_equal(batch$num_columns(), 5L)\n-  expect_equal(batch$num_rows(), 10L)\n+  expect_equal(batch$num_columns, 5L)\n+  expect_equal(batch$num_rows, 10L)\n   expect_equal(batch$column_name(0), \"int\")\n   expect_equal(batch$column_name(1), \"dbl\")\n   expect_equal(batch$column_name(2), \"lgl\")\n@@ -47,32 +47,32 @@ test_that(\"RecordBatch\", {\n   col_int <- batch$column(0)\n   expect_true(inherits(col_int, 'arrow::Array'))\n   expect_equal(col_int$as_vector(), tbl$int)\n-  expect_equal(col_int$type(), int32())\n+  expect_equal(col_int$type, int32())\n \n   col_dbl <- batch$column(1)\n   expect_true(inherits(col_dbl, 'arrow::Array'))\n   expect_equal(col_dbl$as_vector(), tbl$dbl)\n-  expect_equal(col_dbl$type(), float64())\n+  expect_equal(col_dbl$type, float64())\n \n   col_lgl <- batch$column(2)\n   expect_true(inherits(col_dbl, 'arrow::Array'))\n   expect_equal(col_lgl$as_vector(), tbl$lgl)\n-  expect_equal(col_lgl$type(), boolean())\n+  expect_equal(col_lgl$type, boolean())\n \n   col_chr <- batch$column(3)\n   expect_true(inherits(col_chr, 'arrow::Array'))\n   expect_equal(col_chr$as_vector(), tbl$chr)\n-  expect_equal(col_chr$type(), utf8())\n+  expect_equal(col_chr$type, utf8())\n \n   col_fct <- batch$column(4)\n   expect_true(inherits(col_fct, 'arrow::Array'))\n   expect_equal(col_fct$as_vector(), tbl$fct)\n-  expect_equal(col_fct$type(), dictionary(int32(), array(letters[1:10])))\n+  expect_equal(col_fct$type, dictionary(int32(), array(letters[1:10])))\n \n \n   batch2 <- batch$RemoveColumn(0)\n   expect_equal(\n-    batch2$schema(),\n+    batch2$schema,\n     schema(dbl = float64(), lgl = boolean(), chr = utf8(), fct = dictionary(int32(), array(letters[1:10])))\n   )\n   expect_equal(batch2$column(0), batch$column(1))\n@@ -95,10 +95,10 @@ test_that(\"RecordBatch with 0 rows are supported\", {\n   )\n \n   batch <- record_batch(tbl)\n-  expect_equal(batch$num_columns(), 5L)\n-  expect_equal(batch$num_rows(), 0L)\n+  expect_equal(batch$num_columns, 5L)\n+  expect_equal(batch$num_rows, 0L)\n   expect_equal(\n-    batch$schema(),\n+    batch$schema,\n     schema(\n       int = int32(),\n       dbl = float64(),\n@@ -107,67 +107,6 @@ test_that(\"RecordBatch with 0 rows are supported\", {\n       fct = dictionary(int32(), array(c(\"a\", \"b\")))\n     )\n   )\n-\n-  tf <- local_tempfile()\n-  write_record_batch(batch, tf)\n-  res <- read_record_batch(tf)\n-  expect_equal(res, batch)\n-})\n-\n-test_that(\"read_record_batch handles various streams (ARROW-3450, ARROW-3505)\", {\n-  tbl <- tibble::tibble(\n-    int = 1:10, dbl = as.numeric(1:10),\n-    lgl = sample(c(TRUE, FALSE, NA), 10, replace = TRUE),\n-    chr = letters[1:10]\n-  )\n-  batch <- record_batch(tbl)\n-  tf <- local_tempfile()\n-  write_record_batch(batch, tf)\n-\n-  bytes <- write_record_batch(batch, raw())\n-  buf_reader <- buffer_reader(bytes)\n-\n-  batch1 <- read_record_batch(tf)\n-  batch2 <- read_record_batch(fs::path_abs(tf))\n-\n-  readable_file <- close_on_exit(file_open(tf))\n-  batch3 <- read_record_batch(readable_file)\n-\n-  mmap_file <- close_on_exit(mmap_open(tf))\n-  batch4 <- read_record_batch(mmap_file)\n-  batch5 <- read_record_batch(bytes)\n-  batch6 <- read_record_batch(buf_reader)\n-\n-  stream_reader <- record_batch_stream_reader(bytes)\n-  batch7 <- read_record_batch(stream_reader)\n-  expect_null(read_record_batch(stream_reader))\n-\n-  file_reader <- record_batch_file_reader(tf)\n-  batch8 <- read_record_batch(file_reader)\n-  expect_null(read_record_batch(file_reader, i = 2))\n-\n-  expect_equal(batch, batch1)\n-  expect_equal(batch, batch2)\n-  expect_equal(batch, batch3)\n-  expect_equal(batch, batch4)\n-  expect_equal(batch, batch5)\n-  expect_equal(batch, batch6)\n-  expect_equal(batch, batch7)\n-  expect_equal(batch, batch8)\n-})\n-\n-test_that(\"read_record_batch can handle Message, Schema parameters (ARROW-3499)\", {\n-  batch <- record_batch(tibble::tibble(x = 1:10))\n-  stream <- buffer_reader(write_record_batch(batch, raw()))\n-\n-  # schema\n-  message <- read_message(stream)\n-\n-  # batch\n-  message <- read_message(stream)\n-  schema <- batch$schema()\n-  batch2 <- read_record_batch(message, schema)\n-  expect_equal(batch, batch2)\n })\n \n test_that(\"RecordBatch cast (ARROW-3741)\", {\n@@ -178,7 +117,7 @@ test_that(\"RecordBatch cast (ARROW-3741)\", {\n \n   s2 <- schema(x = int16(), y = int64())\n   batch2 <- batch$cast(s2)\n-  expect_equal(batch2$schema(), s2)\n-  expect_equal(batch2$column(0L)$type(), int16())\n-  expect_equal(batch2$column(1L)$type(), int64())\n+  expect_equal(batch2$schema, s2)\n+  expect_equal(batch2$column(0L)$type, int16())\n+  expect_equal(batch2$column(1L)$type, int64())\n })\ndiff --git a/r/tests/testthat/test-Table.R b/r/tests/testthat/test-Table.R\nindex d5db9de240..ec1be9b234 100644\n--- a/r/tests/testthat/test-Table.R\n+++ b/r/tests/testthat/test-Table.R\n@@ -24,29 +24,28 @@ test_that(\"read_table handles various input streams (ARROW-3450, ARROW-3505)\", {\n     chr = letters[1:10]\n   )\n   tab <- arrow::table(tbl)\n+\n   tf <- local_tempfile()\n-  write_table(tab, tf)\n+  write_arrow(tab, tf)\n \n-  bytes <- write_table(tab, raw())\n-  buf_reader <- buffer_reader(bytes)\n+  bytes <- write_arrow(tab, raw())\n \n   tab1 <- read_table(tf)\n   tab2 <- read_table(fs::path_abs(tf))\n \n-  readable_file <- close_on_exit(file_open(tf))\n-  tab3 <- read_table(readable_file)\n+  readable_file <- close_on_exit(ReadableFile(tf))\n+  tab3 <- read_table(close_on_exit(RecordBatchFileReader(readable_file)))\n \n   mmap_file <- close_on_exit(mmap_open(tf))\n-  tab4 <- read_table(mmap_file)\n+  tab4 <- read_table(close_on_exit(RecordBatchFileReader(mmap_file)))\n \n   tab5 <- read_table(bytes)\n-  tab6 <- read_table(buf_reader)\n \n-  stream_reader <- record_batch_stream_reader(bytes)\n-  tab7 <- read_table(stream_reader)\n+  stream_reader <- RecordBatchStreamReader(bytes)\n+  tab6 <- read_table(stream_reader)\n \n-  file_reader <- record_batch_file_reader(tf)\n-  tab8 <- read_table(file_reader)\n+  file_reader <- RecordBatchFileReader(tf)\n+  tab7 <- read_table(file_reader)\n \n   expect_equal(tab, tab1)\n   expect_equal(tab, tab2)\n@@ -55,7 +54,6 @@ test_that(\"read_table handles various input streams (ARROW-3450, ARROW-3505)\", {\n   expect_equal(tab, tab5)\n   expect_equal(tab, tab6)\n   expect_equal(tab, tab7)\n-  expect_equal(tab, tab8)\n })\n \n test_that(\"Table cast (ARROW-3741)\", {\n@@ -66,7 +64,7 @@ test_that(\"Table cast (ARROW-3741)\", {\n \n   s2 <- schema(x = int16(), y = int64())\n   tab2 <- tab$cast(s2)\n-  expect_equal(tab2$schema(), s2)\n-  expect_equal(tab2$column(0L)$type(), int16())\n-  expect_equal(tab2$column(1L)$type(), int64())\n+  expect_equal(tab2$schema, s2)\n+  expect_equal(tab2$column(0L)$type, int16())\n+  expect_equal(tab2$column(1L)$type, int64())\n })\ndiff --git a/r/tests/testthat/test-arraydata.R b/r/tests/testthat/test-arraydata.R\nindex 5d8f8f1dca..02ca9b8562 100644\n--- a/r/tests/testthat/test-arraydata.R\n+++ b/r/tests/testthat/test-arraydata.R\n@@ -24,5 +24,5 @@ test_that(\"string vectors with only empty strings and nulls don't allocate a dat\n   buffers <- a$data()$buffers\n   expect_null(buffers[[1]])\n   expect_null(buffers[[3]])\n-  expect_equal(buffers[[2]]$size(), 8L)\n+  expect_equal(buffers[[2]]$size, 8L)\n })\ndiff --git a/r/tests/testthat/test-buffer.R b/r/tests/testthat/test-buffer.R\nindex aa712b0268..26ec8dfde0 100644\n--- a/r/tests/testthat/test-buffer.R\n+++ b/r/tests/testthat/test-buffer.R\n@@ -21,26 +21,26 @@ test_that(\"arrow::Buffer can be created from raw vector\", {\n   vec <- raw(123)\n   buf <- buffer(vec)\n   expect_is(buf, \"arrow::Buffer\")\n-  expect_equal(buf$size(), 123)\n+  expect_equal(buf$size, 123)\n })\n \n test_that(\"arrow::Buffer can be created from integer vector\", {\n   vec <- integer(17)\n   buf <- buffer(vec)\n   expect_is(buf, \"arrow::Buffer\")\n-  expect_equal(buf$size(), 17 * 4)\n+  expect_equal(buf$size, 17 * 4)\n })\n \n test_that(\"arrow::Buffer can be created from numeric vector\", {\n   vec <- numeric(17)\n   buf <- buffer(vec)\n   expect_is(buf, \"arrow::Buffer\")\n-  expect_equal(buf$size(), 17 * 8)\n+  expect_equal(buf$size, 17 * 8)\n })\n \n test_that(\"arrow::Buffer can be created from complex vector\", {\n   vec <- complex(3)\n   buf <- buffer(vec)\n   expect_is(buf, \"arrow::Buffer\")\n-  expect_equal(buf$size(), 3 * 16)\n+  expect_equal(buf$size, 3 * 16)\n })\ndiff --git a/r/tests/testthat/test-bufferreader.R b/r/tests/testthat/test-bufferreader.R\nindex e7680a493f..72d257101f 100644\n--- a/r/tests/testthat/test-bufferreader.R\n+++ b/r/tests/testthat/test-bufferreader.R\n@@ -18,9 +18,9 @@\n context(\"arrow::BufferReader\")\n \n test_that(\"BufferReader can be created from R objects\", {\n-  num <- buffer_reader(numeric(13))\n-  int <- buffer_reader(integer(13))\n-  raw <- buffer_reader(raw(16))\n+  num <- BufferReader(numeric(13))\n+  int <- BufferReader(integer(13))\n+  raw <- BufferReader(raw(16))\n \n   expect_is(num, \"arrow::io::BufferReader\")\n   expect_is(int, \"arrow::io::BufferReader\")\n@@ -33,7 +33,7 @@ test_that(\"BufferReader can be created from R objects\", {\n \n test_that(\"BufferReader can be created from Buffer\", {\n   buf <- buffer(raw(76))\n-  reader <- buffer_reader(buf)\n+  reader <- BufferReader(buf)\n \n   expect_is(reader, \"arrow::io::BufferReader\")\n   expect_equal(reader$GetSize(), 76)\ndiff --git a/r/tests/testthat/test-chunkedarray.R b/r/tests/testthat/test-chunkedarray.R\nindex 8bca620147..11a196d039 100644\n--- a/r/tests/testthat/test-chunkedarray.R\n+++ b/r/tests/testthat/test-chunkedarray.R\n@@ -19,38 +19,38 @@ context(\"arrow::ChunkedArray\")\n \n test_that(\"ChunkedArray\", {\n   x <- chunked_array(1:10, 1:10, 1:5)\n-  expect_equal(x$type(), int32())\n-  expect_equal(x$num_chunks(), 3L)\n+  expect_equal(x$type, int32())\n+  expect_equal(x$num_chunks, 3L)\n   expect_equal(x$length(), 25L)\n   expect_equal(x$as_vector(), c(1:10, 1:10, 1:5))\n \n   y <- x$Slice(8)\n-  expect_equal(y$type(), int32())\n-  expect_equal(y$num_chunks(), 3L)\n+  expect_equal(y$type, int32())\n+  expect_equal(y$num_chunks, 3L)\n   expect_equal(y$length(), 17L)\n   expect_equal(y$as_vector(), c(9:10, 1:10, 1:5))\n \n   z <- x$Slice(8, 5)\n-  expect_equal(z$type(), int32())\n-  expect_equal(z$num_chunks(), 2L)\n+  expect_equal(z$type, int32())\n+  expect_equal(z$num_chunks, 2L)\n   expect_equal(z$length(), 5L)\n   expect_equal(z$as_vector(), c(9:10, 1:3))\n \n   x_dbl <- chunked_array(c(1,2,3), c(4,5,6))\n-  expect_equal(x_dbl$type(), float64())\n-  expect_equal(x_dbl$num_chunks(), 2L)\n+  expect_equal(x_dbl$type, float64())\n+  expect_equal(x_dbl$num_chunks, 2L)\n   expect_equal(x_dbl$length(), 6L)\n   expect_equal(x_dbl$as_vector(), as.numeric(1:6))\n \n   y_dbl <- x_dbl$Slice(2)\n-  expect_equal(y_dbl$type(), float64())\n-  expect_equal(y_dbl$num_chunks(), 2L)\n+  expect_equal(y_dbl$type, float64())\n+  expect_equal(y_dbl$num_chunks, 2L)\n   expect_equal(y_dbl$length(), 4L)\n   expect_equal(y_dbl$as_vector(), as.numeric(3:6))\n \n   z_dbl <- x_dbl$Slice(2, 2)\n-  expect_equal(z_dbl$type(), float64())\n-  expect_equal(z_dbl$num_chunks(), 2L)\n+  expect_equal(z_dbl$type, float64())\n+  expect_equal(z_dbl$num_chunks, 2L)\n   expect_equal(z_dbl$length(), 2L)\n   expect_equal(z_dbl$as_vector(), as.numeric(3:4))\n })\n@@ -58,19 +58,19 @@ test_that(\"ChunkedArray\", {\n test_that(\"ChunkedArray handles !!! splicing\", {\n   data <- list(1, 2, 3)\n   x <- chunked_array(!!!data)\n-  expect_equal(x$type(), float64())\n-  expect_equal(x$num_chunks(), 3L)\n+  expect_equal(x$type, float64())\n+  expect_equal(x$num_chunks, 3L)\n })\n \n test_that(\"ChunkedArray handles NA\", {\n   data <- list(1:10, c(NA, 2:10), c(1:3, NA, 5L))\n   x <- chunked_array(!!!data)\n-  expect_equal(x$type(), int32())\n-  expect_equal(x$num_chunks(), 3L)\n+  expect_equal(x$type, int32())\n+  expect_equal(x$num_chunks, 3L)\n   expect_equal(x$length(), 25L)\n   expect_equal(x$as_vector(), c(1:10, c(NA, 2:10), c(1:3, NA, 5)))\n \n-  chunks <- x$chunks()\n+  chunks <- x$chunks\n   expect_equal(Array__Mask(chunks[[1]]), !is.na(data[[1]]))\n   expect_equal(Array__Mask(chunks[[2]]), !is.na(data[[2]]))\n   expect_equal(Array__Mask(chunks[[3]]), !is.na(data[[3]]))\n@@ -81,10 +81,10 @@ test_that(\"ChunkedArray supports logical vectors (ARROW-3341)\", {\n   data <- purrr::rerun(3, sample(c(TRUE, FALSE, NA), 100, replace = TRUE))\n   arr_lgl <- chunked_array(!!!data)\n   expect_equal(arr_lgl$length(), 300L)\n-  expect_equal(arr_lgl$null_count(), sum(unlist(map(data, is.na))))\n+  expect_equal(arr_lgl$null_count, sum(unlist(map(data, is.na))))\n   expect_identical(arr_lgl$as_vector(), purrr::flatten_lgl(data))\n \n-  chunks <- arr_lgl$chunks()\n+  chunks <- arr_lgl$chunks\n   expect_identical(data[[1]], chunks[[1]]$as_vector())\n   expect_identical(data[[2]], chunks[[2]]$as_vector())\n   expect_identical(data[[3]], chunks[[3]]$as_vector())\n@@ -94,10 +94,10 @@ test_that(\"ChunkedArray supports logical vectors (ARROW-3341)\", {\n   data <- purrr::rerun(3, sample(c(TRUE, FALSE), 100, replace = TRUE))\n   arr_lgl <- chunked_array(!!!data)\n   expect_equal(arr_lgl$length(), 300L)\n-  expect_equal(arr_lgl$null_count(), sum(unlist(map(data, is.na))))\n+  expect_equal(arr_lgl$null_count, sum(unlist(map(data, is.na))))\n   expect_identical(arr_lgl$as_vector(), purrr::flatten_lgl(data))\n \n-  chunks <- arr_lgl$chunks()\n+  chunks <- arr_lgl$chunks\n   expect_identical(data[[1]], chunks[[1]]$as_vector())\n   expect_identical(data[[2]], chunks[[2]]$as_vector())\n   expect_identical(data[[3]], chunks[[3]]$as_vector())\n@@ -112,10 +112,10 @@ test_that(\"ChunkedArray supports character vectors (ARROW-3339)\", {\n   )\n   arr_chr <- chunked_array(!!!data)\n   expect_equal(arr_chr$length(), length(unlist(data)))\n-  expect_equal(arr_chr$null_count(), 1L)\n+  expect_equal(arr_chr$null_count, 1L)\n   expect_equal(arr_chr$as_vector(), purrr::flatten_chr(data))\n \n-  chunks <- arr_chr$chunks()\n+  chunks <- arr_chr$chunks\n   expect_equal(data, purrr::map(chunks, ~.$as_vector()))\n })\n \n@@ -123,14 +123,14 @@ test_that(\"ChunkedArray supports factors (ARROW-3716)\", {\n   f <- factor(c(\"itsy\", \"bitsy\", \"spider\", \"spider\"))\n   arr_fac <- chunked_array(f, f, f)\n   expect_equal(arr_fac$length(), 12L)\n-  expect_equal(arr_fac$type()$index_type(), int8())\n+  expect_equal(arr_fac$type$index_type, int8())\n   expect_identical(arr_fac$as_vector(), vctrs::vec_c(f, f, f))\n })\n \n test_that(\"ChunkedArray supports dates (ARROW-3716)\", {\n   d <- Sys.Date() + 1:10\n   a <- chunked_array(d, d)\n-  expect_equal(a$type(), date32())\n+  expect_equal(a$type, date32())\n   expect_equal(a$length(), 20L)\n   expect_equal(a$as_vector(), c(d, d))\n })\n@@ -138,8 +138,8 @@ test_that(\"ChunkedArray supports dates (ARROW-3716)\", {\n test_that(\"ChunkedArray supports POSIXct (ARROW-3716)\", {\n   times <- lubridate::ymd_hms(\"2018-10-07 19:04:05\") + 1:10\n   a <- chunked_array(times, times)\n-  expect_equal(a$type()$name(), \"timestamp\")\n-  expect_equal(a$type()$unit(), unclass(TimeUnit$MICRO))\n+  expect_equal(a$type$name, \"timestamp\")\n+  expect_equal(a$type$unit(), unclass(TimeUnit$MICRO))\n   expect_equal(a$length(), 20L)\n   expect_equal(as.numeric(a$as_vector()), as.numeric(c(times, times)))\n })\n@@ -147,7 +147,7 @@ test_that(\"ChunkedArray supports POSIXct (ARROW-3716)\", {\n test_that(\"ChunkedArray supports integer64 (ARROW-3716)\", {\n   x <- bit64::as.integer64(1:10)\n   a <- chunked_array(x, x)\n-  expect_equal(a$type(), int64())\n+  expect_equal(a$type, int64())\n   expect_equal(a$length(), 20L)\n   expect_equal(a$as_vector(), c(x,x))\n })\n@@ -155,7 +155,7 @@ test_that(\"ChunkedArray supports integer64 (ARROW-3716)\", {\n test_that(\"ChunkedArray supports difftime\", {\n   time <- hms::hms(56, 34, 12)\n   a <- chunked_array(time, time)\n-  expect_equal(a$type(), time32(unit = TimeUnit$SECOND))\n+  expect_equal(a$type, time32(unit = TimeUnit$SECOND))\n   expect_equal(a$length(), 2L)\n   expect_equal(a$as_vector(), c(time, time))\n })\n@@ -177,10 +177,10 @@ test_that(\"integer types casts for ChunkedArray (ARROW-3741)\", {\n   expect_is(a_int16, \"arrow::ChunkedArray\")\n   expect_is(a_int32, \"arrow::ChunkedArray\")\n   expect_is(a_int64, \"arrow::ChunkedArray\")\n-  expect_equal(a_int8$type(), int8())\n-  expect_equal(a_int16$type(), int16())\n-  expect_equal(a_int32$type(), int32())\n-  expect_equal(a_int64$type(), int64())\n+  expect_equal(a_int8$type, int8())\n+  expect_equal(a_int16$type, int16())\n+  expect_equal(a_int32$type, int32())\n+  expect_equal(a_int64$type, int64())\n \n   a_uint8 <- a$cast(uint8())\n   a_uint16 <- a$cast(uint16())\n@@ -192,8 +192,8 @@ test_that(\"integer types casts for ChunkedArray (ARROW-3741)\", {\n   expect_is(a_uint32, \"arrow::ChunkedArray\")\n   expect_is(a_uint64, \"arrow::ChunkedArray\")\n \n-  expect_equal(a_uint8$type(), uint8())\n-  expect_equal(a_uint16$type(), uint16())\n-  expect_equal(a_uint32$type(), uint32())\n-  expect_equal(a_uint64$type(), uint64())\n+  expect_equal(a_uint8$type, uint8())\n+  expect_equal(a_uint16$type, uint16())\n+  expect_equal(a_uint32$type, uint32())\n+  expect_equal(a_uint64$type, uint64())\n })\ndiff --git a/r/tests/testthat/test-feather.R b/r/tests/testthat/test-feather.R\nindex f6d9bee581..715017fb58 100644\n--- a/r/tests/testthat/test-feather.R\n+++ b/r/tests/testthat/test-feather.R\n@@ -29,7 +29,7 @@ test_that(\"feather read/write round trip\", {\n   expect_true(fs::file_exists(tf2))\n \n   tf3 <- local_tempfile()\n-  stream <- close_on_exit(file_output_stream(tf3))\n+  stream <- close_on_exit(FileOutputStream(tf3))\n   write_feather(tib, stream)\n   expect_true(fs::file_exists(tf3))\n \n@@ -47,7 +47,7 @@ test_that(\"feather read/write round trip\", {\n   expect_is(tab4, \"arrow::Table\")\n \n   # reading directly from arrow::io::ReadableFile\n-  tab5 <- read_feather(file_open(tf3))\n+  tab5 <- read_feather(ReadableFile(tf3))\n   expect_is(tab5, \"arrow::Table\")\n \n   expect_equal(tib, as_tibble(tab1))\ndiff --git a/r/tests/testthat/test-field.R b/r/tests/testthat/test-field.R\nindex 08bf4db36a..aaa2875510 100644\n--- a/r/tests/testthat/test-field.R\n+++ b/r/tests/testthat/test-field.R\n@@ -19,8 +19,8 @@ context(\"arrow::Field\")\n \n test_that(\"field() factory\", {\n   x <- field(\"x\", int32())\n-  expect_equal(x$type(), int32())\n-  expect_equal(x$name(), \"x\")\n+  expect_equal(x$type, int32())\n+  expect_equal(x$name, \"x\")\n   expect_true(x == x)\n   expect_false(x == field(\"x\", int64()))\n })\ndiff --git a/r/tests/testthat/test-message.R b/r/tests/testthat/test-message.R\nindex fd05b86056..3fe5829f86 100644\n--- a/r/tests/testthat/test-message.R\n+++ b/r/tests/testthat/test-message.R\n@@ -19,16 +19,12 @@ context(\"arrow::ipc::Message\")\n \n test_that(\"read_message can read from input stream\", {\n   batch <- record_batch(tibble::tibble(x = 1:10))\n-  bytes <- write_record_batch(batch, raw())\n-  stream <- buffer_reader(bytes)\n+  bytes <- batch$serialize()\n+  stream <- BufferReader(bytes)\n \n   message <- read_message(stream)\n-  expect_equal(message$type(), MessageType$SCHEMA)\n-  expect_is(message$body, \"arrow::Buffer\")\n-  expect_is(message$metadata, \"arrow::Buffer\")\n-\n-  message <- read_message(stream)\n-  expect_equal(message$type(), MessageType$RECORD_BATCH)\n+  expect_is(message, \"arrow::ipc::Message\")\n+  expect_equal(message$type, MessageType$RECORD_BATCH)\n   expect_is(message$body, \"arrow::Buffer\")\n   expect_is(message$metadata, \"arrow::Buffer\")\n \ndiff --git a/r/tests/testthat/test-messagereader.R b/r/tests/testthat/test-messagereader.R\nindex 4527a2882f..5ff8277625 100644\n--- a/r/tests/testthat/test-messagereader.R\n+++ b/r/tests/testthat/test-messagereader.R\n@@ -19,16 +19,13 @@ context(\"arrow::ipc::MessageReader\")\n \n test_that(\"MessageReader can be created from raw vectors\", {\n   batch <- record_batch(tibble::tibble(x = 1:10))\n-  bytes <- write_record_batch(batch, raw())\n+  bytes <- batch$serialize()\n \n-  reader <- message_reader(bytes)\n-  message <- reader$ReadNextMessage()\n-  expect_equal(message$type(), MessageType$SCHEMA)\n-  expect_is(message$body, \"arrow::Buffer\")\n-  expect_is(message$metadata, \"arrow::Buffer\")\n+  reader <- MessageReader(bytes)\n \n   message <- reader$ReadNextMessage()\n-  expect_equal(message$type(), MessageType$RECORD_BATCH)\n+  expect_is(message, \"arrow::ipc::Message\")\n+  expect_equal(message$type, MessageType$RECORD_BATCH)\n   expect_is(message$body, \"arrow::Buffer\")\n   expect_is(message$metadata, \"arrow::Buffer\")\n \n@@ -38,17 +35,17 @@ test_that(\"MessageReader can be created from raw vectors\", {\n \n test_that(\"MessageReader can be created from input stream\", {\n   batch <- record_batch(tibble::tibble(x = 1:10))\n-  bytes <- write_record_batch(batch, raw())\n-  stream <- buffer_reader(bytes)\n+  bytes <- batch$serialize()\n \n-  reader <- message_reader(stream)\n-  message <- reader$ReadNextMessage()\n-  expect_equal(message$type(), MessageType$SCHEMA)\n-  expect_is(message$body, \"arrow::Buffer\")\n-  expect_is(message$metadata, \"arrow::Buffer\")\n+  stream <- BufferReader(bytes)\n+  expect_is(stream, \"arrow::io::BufferReader\")\n+\n+  reader <- MessageReader(stream)\n+  expect_is(reader, \"arrow::ipc::MessageReader\")\n \n   message <- reader$ReadNextMessage()\n-  expect_equal(message$type(), MessageType$RECORD_BATCH)\n+  expect_is(message, \"arrow::ipc::Message\")\n+  expect_equal(message$type, MessageType$RECORD_BATCH)\n   expect_is(message$body, \"arrow::Buffer\")\n   expect_is(message$metadata, \"arrow::Buffer\")\n \ndiff --git a/r/tests/testthat/test-read-write.R b/r/tests/testthat/test-read-write.R\nindex 2af718ebe5..ffc14eba72 100644\n--- a/r/tests/testthat/test-read-write.R\n+++ b/r/tests/testthat/test-read-write.R\n@@ -25,24 +25,24 @@ test_that(\"arrow::table round trip\", {\n   )\n \n   tab <- arrow::table(tbl)\n-  expect_equal(tab$num_columns(), 3L)\n-  expect_equal(tab$num_rows(), 10L)\n+  expect_equal(tab$num_columns, 3L)\n+  expect_equal(tab$num_rows, 10L)\n \n   # arrow::Column\n   col_int <- tab$column(0)\n   expect_equal(col_int$length(), 10L)\n-  expect_equal(col_int$null_count(), 0L)\n-  expect_equal(col_int$type(), int32())\n+  expect_equal(col_int$null_count, 0L)\n+  expect_equal(col_int$type, int32())\n \n   # arrow::ChunkedArray\n   chunked_array_int <- col_int$data()\n   expect_equal(chunked_array_int$length(), 10L)\n-  expect_equal(chunked_array_int$null_count(), 0L)\n+  expect_equal(chunked_array_int$null_count, 0L)\n   expect_equal(chunked_array_int$as_vector(), tbl$int)\n \n   # arrow::Array\n-  chunks_int <- chunked_array_int$chunks()\n-  expect_equal(length(chunks_int), chunked_array_int$num_chunks())\n+  chunks_int <- chunked_array_int$chunks\n+  expect_equal(length(chunks_int), chunked_array_int$num_chunks)\n   for( i in seq_along(chunks_int)){\n     expect_equal(chunked_array_int$chunk(i-1L), chunks_int[[i]])\n   }\n@@ -50,18 +50,18 @@ test_that(\"arrow::table round trip\", {\n   # arrow::Column\n   col_dbl <- tab$column(1)\n   expect_equal(col_dbl$length(), 10L)\n-  expect_equal(col_dbl$null_count(), 0L)\n-  expect_equal(col_dbl$type(), float64())\n+  expect_equal(col_dbl$null_count, 0L)\n+  expect_equal(col_dbl$type, float64())\n \n   # arrow::ChunkedArray\n   chunked_array_dbl <- col_dbl$data()\n   expect_equal(chunked_array_dbl$length(), 10L)\n-  expect_equal(chunked_array_dbl$null_count(), 0L)\n+  expect_equal(chunked_array_dbl$null_count, 0L)\n   expect_equal(chunked_array_dbl$as_vector(), tbl$dbl)\n \n   # arrow::Array\n-  chunks_dbl <- chunked_array_dbl$chunks()\n-  expect_equal(length(chunks_dbl), chunked_array_dbl$num_chunks())\n+  chunks_dbl <- chunked_array_dbl$chunks\n+  expect_equal(length(chunks_dbl), chunked_array_dbl$num_chunks)\n   for( i in seq_along(chunks_dbl)){\n     expect_equal(chunked_array_dbl$chunk(i-1L), chunks_dbl[[i]])\n   }\n@@ -69,18 +69,18 @@ test_that(\"arrow::table round trip\", {\n   # arrow::Colmumn\n   col_raw <- tab$column(2)\n   expect_equal(col_raw$length(), 10L)\n-  expect_equal(col_raw$null_count(), 0L)\n-  expect_equal(col_raw$type(), int8())\n+  expect_equal(col_raw$null_count, 0L)\n+  expect_equal(col_raw$type, int8())\n \n   # arrow::ChunkedArray\n   chunked_array_raw <- col_raw$data()\n   expect_equal(chunked_array_raw$length(), 10L)\n-  expect_equal(chunked_array_raw$null_count(), 0L)\n+  expect_equal(chunked_array_raw$null_count, 0L)\n   expect_equal(chunked_array_raw$as_vector(), tbl$raw)\n \n   # arrow::Array\n-  chunks_raw <- chunked_array_raw$chunks()\n-  expect_equal(length(chunks_raw), chunked_array_raw$num_chunks())\n+  chunks_raw <- chunked_array_raw$chunks\n+  expect_equal(length(chunks_raw), chunked_array_raw$num_chunks)\n   for( i in seq_along(chunks_raw)){\n     expect_equal(chunked_array_raw$chunk(i-1L), chunks_raw[[i]])\n   }\n@@ -99,20 +99,20 @@ test_that(\"arrow::table round trip handles NA in integer and numeric\", {\n   )\n \n   tab <- arrow::table(tbl)\n-  expect_equal(tab$num_columns(), 3L)\n-  expect_equal(tab$num_rows(), 10L)\n+  expect_equal(tab$num_columns, 3L)\n+  expect_equal(tab$num_rows, 10L)\n \n   expect_equal(tab$column(0)$length(), 10L)\n   expect_equal(tab$column(1)$length(), 10L)\n   expect_equal(tab$column(2)$length(), 10L)\n \n-  expect_equal(tab$column(0)$null_count(), 1L)\n-  expect_equal(tab$column(1)$null_count(), 2L)\n-  expect_equal(tab$column(2)$null_count(), 0L)\n+  expect_equal(tab$column(0)$null_count, 1L)\n+  expect_equal(tab$column(1)$null_count, 2L)\n+  expect_equal(tab$column(2)$null_count, 0L)\n \n-  expect_equal(tab$column(0)$type(), int32())\n-  expect_equal(tab$column(1)$type(), float64())\n-  expect_equal(tab$column(2)$type(), int8())\n+  expect_equal(tab$column(0)$type, int32())\n+  expect_equal(tab$column(1)$type, float64())\n+  expect_equal(tab$column(2)$type, int8())\n \n   tf <- local_tempfile()\n   write_arrow(tbl, tf)\ndiff --git a/r/tests/testthat/test-read_record_batch.R b/r/tests/testthat/test-read_record_batch.R\nnew file mode 100644\nindex 0000000000..8477b7a4c3\n--- /dev/null\n+++ b/r/tests/testthat/test-read_record_batch.R\n@@ -0,0 +1,73 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+context(\"read_record_batch()\")\n+\n+test_that(\"RecordBatchFileWriter / RecordBatchFileReader roundtrips\", {\n+  tab <- table(tibble::tibble(\n+    int = 1:10, dbl = as.numeric(1:10),\n+    lgl = sample(c(TRUE, FALSE, NA), 10, replace = TRUE),\n+    chr = letters[1:10]\n+  ))\n+  tf <- local_tempfile()\n+\n+  writer <- RecordBatchFileWriter(tf, tab$schema)\n+  expect_is(writer, \"arrow::ipc::RecordBatchFileWriter\")\n+  writer$write_table(tab)\n+  writer$close()\n+  tab2 <- read_table(tf)\n+  expect_equal(tab, tab2)\n+\n+  stream <- FileOutputStream(tf)\n+  writer <- RecordBatchFileWriter(stream, tab$schema)\n+  expect_is(writer, \"arrow::ipc::RecordBatchFileWriter\")\n+  writer$write_table(tab)\n+  writer$close()\n+  tab3 <- read_table(tf)\n+  expect_equal(tab, tab3)\n+})\n+\n+test_that(\"read_record_batch() handles (raw|Buffer|InputStream, Schema) (ARROW-3450, ARROW-3505)\", {\n+  tbl <- tibble::tibble(\n+    int = 1:10, dbl = as.numeric(1:10),\n+    lgl = sample(c(TRUE, FALSE, NA), 10, replace = TRUE),\n+    chr = letters[1:10]\n+  )\n+  batch <- record_batch(tbl)\n+  schema <- batch$schema\n+\n+  raw <- batch$serialize()\n+  batch2 <- read_record_batch(raw, schema)\n+  batch3 <- read_record_batch(buffer(raw), schema)\n+  batch4 <- read_record_batch(close_on_exit(BufferReader(raw)), schema)\n+\n+  expect_equal(batch, batch2)\n+  expect_equal(batch, batch3)\n+  expect_equal(batch, batch4)\n+})\n+\n+test_that(\"read_record_batch() can handle (Message, Schema) parameters (ARROW-3499)\", {\n+  batch <- record_batch(tibble::tibble(x = 1:10))\n+  schema <- batch$schema\n+\n+  raw <- batch$serialize()\n+  stream <- close_on_exit(BufferReader(raw))\n+\n+  message <- read_message(stream)\n+  batch2 <- read_record_batch(message, schema)\n+  expect_equal(batch, batch2)\n+})\ndiff --git a/r/tests/testthat/test-schema.R b/r/tests/testthat/test-schema.R\nindex d40fbfa36b..2f2d3ee84e 100644\n--- a/r/tests/testthat/test-schema.R\n+++ b/r/tests/testthat/test-schema.R\n@@ -17,18 +17,30 @@\n \n context(\"arrow::Schema\")\n \n-test_that(\"reading schema from raw vector\", {\n+test_that(\"reading schema from Buffer\", {\n+  # TODO: this uses the streaming format, i.e. from RecordBatchStreamWriter\n+  #       maybe there is an easier way to serialize a schema\n   batch <- record_batch(tibble::tibble(x = 1:10))\n-  bytes <- write_record_batch(batch, raw())\n-  schema <- read_schema(bytes)\n-  expect_equal(schema, batch$schema())\n-})\n+  expect_is(batch, \"arrow::RecordBatch\")\n \n-test_that(\"reading schema from streams\", {\n-  batch <- record_batch(tibble::tibble(x = 1:10))\n-  bytes <- write_record_batch(batch, raw())\n-  stream <- buffer_reader(bytes)\n+  stream <- BufferOutputStream()\n+  writer <- RecordBatchStreamWriter(stream, batch$schema)\n+  expect_is(writer, \"arrow::ipc::RecordBatchStreamWriter\")\n+  writer$close()\n+\n+  buffer <- stream$getvalue()\n+  expect_is(buffer, \"arrow::Buffer\")\n+\n+  reader <- MessageReader(buffer)\n+  expect_is(reader, \"arrow::ipc::MessageReader\")\n+\n+  message <- reader$ReadNextMessage()\n+  expect_is(message, \"arrow::ipc::Message\")\n+  expect_equal(message$type, MessageType$SCHEMA)\n \n-  schema <- read_schema(stream)\n-  expect_equal(schema, batch$schema())\n+  stream <- BufferReader(buffer)\n+  expect_is(stream, \"arrow::io::BufferReader\")\n+  message <- read_message(stream)\n+  expect_is(message, \"arrow::ipc::Message\")\n+  expect_equal(message$type, MessageType$SCHEMA)\n })\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-03T21:21:44.477+0000",
                    "updated": "2018-12-03T21:21:44.477+0000",
                    "started": "2018-12-03T21:21:44.476+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "171713",
                    "issueId": "13199625"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13199625/worklog/171851",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "romainfrancois commented on issue #3043: ARROW-3842: [R] RecordBatchStreamWriter api\nURL: https://github.com/apache/arrow/pull/3043#issuecomment-444007825\n \n \n   yeah, but I'll be more careful now. Better to have done this now than after a release. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-04T08:07:00.172+0000",
                    "updated": "2018-12-04T08:07:00.172+0000",
                    "started": "2018-12-04T08:07:00.171+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "171851",
                    "issueId": "13199625"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": 1800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@54371398[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@23fc9348[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7ec74706[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@39e6fd45[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5f130819[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@4c683e23[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@8d3bfdf[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@6d16755[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@41c5f456[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@4c51436b[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@59e92079[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@548f1fde[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 1800,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Dec 03 21:21:30 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-12-03T21:21:30.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3842/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2018-11-20T15:33:10.000+0000",
        "updated": "2018-12-04T08:07:00.000+0000",
        "timeoriginalestimate": null,
        "description": "To support the \"Writing and Reading Streams\" section of the vignette, perhaps we should rely more on the RecordBatchStreamWriter class and less the `write_record_batch` function. \r\n\r\nWe should be able to write code resembling the python api : \r\n\r\n{code:r}\r\nbatch <- ... \r\nsink <- buffer_output_stream()\r\nwriter <- record_batch_stream_writer(sink, batch$schema())\r\nwriter$write_batch()\r\nwriter$close()\r\nsink$getvalue()\r\n{code}\r\n\r\nMost of the code is there, but we need to add \r\n\r\n- RecordBatchStreamWriter$write_batch() : write a record batch to the stream. We already have RecordBatchStreamWriter$WriteRecordBatch\r\n- RecordBatchStreamWriter$close() : not sure why it is lower case close() in python but upper case in C++. We already have RecordBatchWriter$Close()\r\n- BufferOutputStream$getvalue() : we already have BufferOutputStream$Finish()\r\n\r\nCurrently the constructor for a BufferOutputStream is buffer_output_stream(), perhaps we can align with python and make it BufferOutputStream, that would not clash with the `arrow::BufferOutputStream` class because of the namespacing. \r\n\r\n\r\n",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "0.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 1800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[R] RecordBatchStreamWriter api",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13199625/comment/16707811",
                    "id": "16707811",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 3043\n[https://github.com/apache/arrow/pull/3043]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-12-03T21:21:30.398+0000",
                    "updated": "2018-12-03T21:21:30.398+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|s00pbc:",
        "customfield_12314139": null
    }
}