{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13104027",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13104027",
    "key": "ARROW-1596",
    "fields": {
        "fixVersions": [],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/2",
            "id": "2",
            "description": "The problem described is an issue which will never be fixed.",
            "name": "Won't Fix"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available",
            "pyarrow-serialization"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": null,
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "name": "Closed",
            "id": "6",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 1200,
            "total": 1200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 1200,
            "total": 1200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1596/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 2,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13104027/worklog/162336",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #1367: WIP ARROW-1596: [Python] Expand NumPy serialization tests by adding test cases from Dask (failing)\nURL: https://github.com/apache/arrow/pull/1367#issuecomment-435692465\n \n \n   Closing as stale for now\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-04T18:12:46.047+0000",
                    "updated": "2018-11-04T18:12:46.047+0000",
                    "started": "2018-11-04T18:12:46.046+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "162336",
                    "issueId": "13104027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13104027/worklog/162337",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm closed pull request #1367: WIP ARROW-1596: [Python] Expand NumPy serialization tests by adding test cases from Dask (failing)\nURL: https://github.com/apache/arrow/pull/1367\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/LICENSE.txt b/LICENSE.txt\nindex 30966d36f3..262e95c629 100644\n--- a/LICENSE.txt\n+++ b/LICENSE.txt\n@@ -460,65 +460,6 @@ SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n \n --------------------------------------------------------------------------------\n \n-This project includes code from the Boost project\n-\n-Boost Software License - Version 1.0 - August 17th, 2003\n-\n-Permission is hereby granted, free of charge, to any person or organization\n-obtaining a copy of the software and accompanying documentation covered by\n-this license (the \"Software\") to use, reproduce, display, distribute,\n-execute, and transmit the Software, and to prepare derivative works of the\n-Software, and to permit third-parties to whom the Software is furnished to\n-do so, all subject to the following:\n-\n-The copyright notices in the Software and this entire statement, including\n-the above license grant, this restriction and the following disclaimer,\n-must be included in all copies of the Software, in whole or in part, and\n-all derivative works of the Software, unless such copies or derivative\n-works are solely in the form of machine-executable object code generated by\n-a source language processor.\n-\n-THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT\n-SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE\n-FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,\n-ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n-DEALINGS IN THE SOFTWARE.\n-\n---------------------------------------------------------------------------------\n-\n-This project includes code from the mapbox/variant project, BSD 3-clause\n-license\n-\n-Copyright (c) MapBox\n-All rights reserved.\n-\n-Redistribution and use in source and binary forms, with or without modification,\n-are permitted provided that the following conditions are met:\n-\n-- Redistributions of source code must retain the above copyright notice, this\n-  list of conditions and the following disclaimer.\n-- Redistributions in binary form must reproduce the above copyright notice, this\n-  list of conditions and the following disclaimer in the documentation and/or\n-  other materials provided with the distribution.\n-- Neither the name \"MapBox\" nor the names of its contributors may be\n-  used to endorse or promote products derived from this software without\n-  specific prior written permission.\n-\n-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n-ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n-WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n-DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n-ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n-(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n-LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n-ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n-SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n-\n---------------------------------------------------------------------------------\n-\n This project includes code from the FlatBuffers project\n \n Copyright 2014 Google Inc.\n@@ -583,3 +524,34 @@ LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE\n OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n --------------------------------------------------------------------------------\n+\n+This project includes code from the Dask project\n+\n+\ufeffCopyright (c) 2015-2017, Anaconda, Inc. and contributors\n+All rights reserved.\n+\n+Redistribution and use in source and binary forms, with or without modification,\n+are permitted provided that the following conditions are met:\n+\n+Redistributions of source code must retain the above copyright notice,\n+this list of conditions and the following disclaimer.\n+\n+Redistributions in binary form must reproduce the above copyright notice,\n+this list of conditions and the following disclaimer in the documentation\n+and/or other materials provided with the distribution.\n+\n+Neither the name of Anaconda nor the names of any contributors\n+may be used to endorse or promote products derived from this software\n+without specific prior written permission.\n+\n+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n+AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n+ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n+LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF\n+THE POSSIBILITY OF SUCH DAMAGE.\ndiff --git a/c_glib/arrow-glib/input-stream.cpp b/c_glib/arrow-glib/input-stream.cpp\nindex a7a894b9d4..94422241b9 100644\n--- a/c_glib/arrow-glib/input-stream.cpp\n+++ b/c_glib/arrow-glib/input-stream.cpp\n@@ -420,7 +420,7 @@ namespace garrow {\n \n     arrow::Status Read(int64_t n_bytes,\n                        int64_t *n_read_bytes,\n-                       uint8_t *out) override {\n+                       void *out) override {\n       GError *error = NULL;\n       *n_read_bytes = g_input_stream_read(input_stream_,\n                                           out,\n@@ -437,7 +437,7 @@ namespace garrow {\n     }\n \n     arrow::Status ReadAt(int64_t position, int64_t n_bytes,\n-\t\t\t int64_t *n_read_bytes, uint8_t* out) override {\n+\t\t\t int64_t *n_read_bytes, void* out) override {\n \treturn arrow::io::RandomAccessFile::ReadAt(\n \t    position, n_bytes, n_read_bytes, out);\n     }\ndiff --git a/c_glib/arrow-glib/output-stream.cpp b/c_glib/arrow-glib/output-stream.cpp\nindex 739992fb62..9939f4f086 100644\n--- a/c_glib/arrow-glib/output-stream.cpp\n+++ b/c_glib/arrow-glib/output-stream.cpp\n@@ -76,7 +76,7 @@ garrow_output_stream_file_interface_init(GArrowFileInterface *iface)\n   iface->get_raw = garrow_output_stream_get_raw_file_interface;\n }\n \n-static std::shared_ptr<arrow::io::Writeable>\n+static std::shared_ptr<arrow::io::Writable>\n garrow_output_stream_get_raw_writeable_interface(GArrowWriteable *writeable)\n {\n   auto output_stream = GARROW_OUTPUT_STREAM(writeable);\n@@ -325,7 +325,7 @@ namespace garrow {\n       return arrow::Status::OK();\n     }\n \n-    arrow::Status Write(const uint8_t *data,\n+    arrow::Status Write(const void *data,\n                         int64_t n_bytes) override {\n       GError *error = NULL;\n       gsize n_written_bytes;\ndiff --git a/c_glib/arrow-glib/writeable.cpp b/c_glib/arrow-glib/writeable.cpp\nindex eb6adfee8c..a16e43ab17 100644\n--- a/c_glib/arrow-glib/writeable.cpp\n+++ b/c_glib/arrow-glib/writeable.cpp\n@@ -88,7 +88,7 @@ garrow_writeable_flush(GArrowWriteable *writeable,\n \n G_END_DECLS\n \n-std::shared_ptr<arrow::io::Writeable>\n+std::shared_ptr<arrow::io::Writable>\n garrow_writeable_get_raw(GArrowWriteable *writeable)\n {\n   auto *iface = GARROW_WRITEABLE_GET_IFACE(writeable);\ndiff --git a/c_glib/arrow-glib/writeable.hpp b/c_glib/arrow-glib/writeable.hpp\nindex 2b398f8b50..806d36fc07 100644\n--- a/c_glib/arrow-glib/writeable.hpp\n+++ b/c_glib/arrow-glib/writeable.hpp\n@@ -26,13 +26,13 @@\n /**\n  * GArrowWriteableInterface:\n  *\n- * It wraps `arrow::io::Writeable`.\n+ * It wraps `arrow::io::Writable`.\n  */\n struct _GArrowWriteableInterface\n {\n   GTypeInterface parent_iface;\n \n-  std::shared_ptr<arrow::io::Writeable> (*get_raw)(GArrowWriteable *file);\n+  std::shared_ptr<arrow::io::Writable> (*get_raw)(GArrowWriteable *file);\n };\n \n-std::shared_ptr<arrow::io::Writeable> garrow_writeable_get_raw(GArrowWriteable *writeable);\n+std::shared_ptr<arrow::io::Writable> garrow_writeable_get_raw(GArrowWriteable *writeable);\ndiff --git a/cpp/src/arrow/gpu/CMakeLists.txt b/cpp/src/arrow/gpu/CMakeLists.txt\nindex 3f3069b919..3ddf2c7974 100644\n--- a/cpp/src/arrow/gpu/CMakeLists.txt\n+++ b/cpp/src/arrow/gpu/CMakeLists.txt\n@@ -54,7 +54,7 @@ configure_file(cuda_version.h.in\n   @ONLY)\n \n install(FILES\n-  \"${CMAKE_CURRENT_SOURCE_DIR}/cuda_version.h\"\n+  \"${CMAKE_CURRENT_BINARY_DIR}/cuda_version.h\"\n   DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/arrow/gpu\")\n \n install(FILES\ndiff --git a/cpp/src/arrow/gpu/cuda_context.cc b/cpp/src/arrow/gpu/cuda_context.cc\nindex fff8ece6c1..2f5ccb0a95 100644\n--- a/cpp/src/arrow/gpu/cuda_context.cc\n+++ b/cpp/src/arrow/gpu/cuda_context.cc\n@@ -69,28 +69,27 @@ class CudaContext::CudaContextImpl {\n     return Status::OK();\n   }\n \n-  Status CopyHostToDevice(uint8_t* dst, const uint8_t* src, int64_t nbytes) {\n+  Status CopyHostToDevice(void* dst, const void* src, int64_t nbytes) {\n     CU_RETURN_NOT_OK(cuCtxSetCurrent(context_));\n-    CU_RETURN_NOT_OK(cuMemcpyHtoD(reinterpret_cast<CUdeviceptr>(dst),\n-                                  reinterpret_cast<const void*>(src),\n+    CU_RETURN_NOT_OK(cuMemcpyHtoD(reinterpret_cast<CUdeviceptr>(dst), src,\n                                   static_cast<size_t>(nbytes)));\n     return Status::OK();\n   }\n \n-  Status CopyDeviceToHost(uint8_t* dst, const uint8_t* src, int64_t nbytes) {\n+  Status CopyDeviceToHost(void* dst, const void* src, int64_t nbytes) {\n     CU_RETURN_NOT_OK(cuCtxSetCurrent(context_));\n     CU_RETURN_NOT_OK(cuMemcpyDtoH(dst, reinterpret_cast<const CUdeviceptr>(src),\n                                   static_cast<size_t>(nbytes)));\n     return Status::OK();\n   }\n \n-  Status Free(uint8_t* device_ptr, int64_t nbytes) {\n+  Status Free(void* device_ptr, int64_t nbytes) {\n     CU_RETURN_NOT_OK(cuMemFree(reinterpret_cast<CUdeviceptr>(device_ptr)));\n     bytes_allocated_ -= nbytes;\n     return Status::OK();\n   }\n \n-  Status ExportIpcBuffer(uint8_t* data, std::unique_ptr<CudaIpcMemHandle>* handle) {\n+  Status ExportIpcBuffer(void* data, std::unique_ptr<CudaIpcMemHandle>* handle) {\n     CU_RETURN_NOT_OK(cuCtxSetCurrent(context_));\n     CUipcMemHandle cu_handle;\n     CU_RETURN_NOT_OK(cuIpcGetMemHandle(&cu_handle, reinterpret_cast<CUdeviceptr>(data)));\n@@ -145,7 +144,7 @@ class CudaDeviceManager::CudaDeviceManagerImpl {\n     return Status::OK();\n   }\n \n-  Status FreeHost(uint8_t* data, int64_t nbytes) {\n+  Status FreeHost(void* data, int64_t nbytes) {\n     CU_RETURN_NOT_OK(cuMemFreeHost(data));\n     host_bytes_allocated_ -= nbytes;\n     return Status::OK();\n@@ -221,7 +220,7 @@ Status CudaDeviceManager::AllocateHost(int64_t nbytes,\n   return Status::OK();\n }\n \n-Status CudaDeviceManager::FreeHost(uint8_t* data, int64_t nbytes) {\n+Status CudaDeviceManager::FreeHost(void* data, int64_t nbytes) {\n   return impl_->FreeHost(data, nbytes);\n }\n \n@@ -241,22 +240,22 @@ Status CudaContext::Allocate(int64_t nbytes, std::shared_ptr<CudaBuffer>* out) {\n   return Status::OK();\n }\n \n-Status CudaContext::ExportIpcBuffer(uint8_t* data,\n+Status CudaContext::ExportIpcBuffer(void* data,\n                                     std::unique_ptr<CudaIpcMemHandle>* handle) {\n   return impl_->ExportIpcBuffer(data, handle);\n }\n \n-Status CudaContext::CopyHostToDevice(uint8_t* dst, const uint8_t* src, int64_t nbytes) {\n+Status CudaContext::CopyHostToDevice(void* dst, const void* src, int64_t nbytes) {\n   return impl_->CopyHostToDevice(dst, src, nbytes);\n }\n \n-Status CudaContext::CopyDeviceToHost(uint8_t* dst, const uint8_t* src, int64_t nbytes) {\n+Status CudaContext::CopyDeviceToHost(void* dst, const void* src, int64_t nbytes) {\n   return impl_->CopyDeviceToHost(dst, src, nbytes);\n }\n \n Status CudaContext::Close() { return impl_->Close(); }\n \n-Status CudaContext::Free(uint8_t* device_ptr, int64_t nbytes) {\n+Status CudaContext::Free(void* device_ptr, int64_t nbytes) {\n   return impl_->Free(device_ptr, nbytes);\n }\n \ndiff --git a/cpp/src/arrow/gpu/cuda_context.h b/cpp/src/arrow/gpu/cuda_context.h\nindex 6471059612..6fc2e0d08a 100644\n--- a/cpp/src/arrow/gpu/cuda_context.h\n+++ b/cpp/src/arrow/gpu/cuda_context.h\n@@ -46,7 +46,7 @@ class ARROW_EXPORT CudaDeviceManager {\n \n   Status AllocateHost(int64_t nbytes, std::shared_ptr<CudaHostBuffer>* buffer);\n \n-  Status FreeHost(uint8_t* data, int64_t nbytes);\n+  Status FreeHost(void* data, int64_t nbytes);\n \n   int num_devices() const;\n \n@@ -88,10 +88,10 @@ class ARROW_EXPORT CudaContext : public std::enable_shared_from_this<CudaContext\n  private:\n   CudaContext();\n \n-  Status ExportIpcBuffer(uint8_t* data, std::unique_ptr<CudaIpcMemHandle>* handle);\n-  Status CopyHostToDevice(uint8_t* dst, const uint8_t* src, int64_t nbytes);\n-  Status CopyDeviceToHost(uint8_t* dst, const uint8_t* src, int64_t nbytes);\n-  Status Free(uint8_t* device_ptr, int64_t nbytes);\n+  Status ExportIpcBuffer(void* data, std::unique_ptr<CudaIpcMemHandle>* handle);\n+  Status CopyHostToDevice(void* dst, const void* src, int64_t nbytes);\n+  Status CopyDeviceToHost(void* dst, const void* src, int64_t nbytes);\n+  Status Free(void* device_ptr, int64_t nbytes);\n \n   class CudaContextImpl;\n   std::unique_ptr<CudaContextImpl> impl_;\ndiff --git a/cpp/src/arrow/gpu/cuda_memory.cc b/cpp/src/arrow/gpu/cuda_memory.cc\nindex 949c1d7a4d..cbf044121a 100644\n--- a/cpp/src/arrow/gpu/cuda_memory.cc\n+++ b/cpp/src/arrow/gpu/cuda_memory.cc\n@@ -101,11 +101,11 @@ CudaBuffer::CudaBuffer(const std::shared_ptr<CudaBuffer>& parent, const int64_t\n       is_ipc_(false) {}\n \n Status CudaBuffer::CopyToHost(const int64_t position, const int64_t nbytes,\n-                              uint8_t* out) const {\n+                              void* out) const {\n   return context_->CopyDeviceToHost(out, data_ + position, nbytes);\n }\n \n-Status CudaBuffer::CopyFromHost(const int64_t position, const uint8_t* data,\n+Status CudaBuffer::CopyFromHost(const int64_t position, const void* data,\n                                 int64_t nbytes) {\n   DCHECK_LE(nbytes, size_ - position) << \"Copy would overflow buffer\";\n   return context_->CopyHostToDevice(mutable_data_ + position, data, nbytes);\n@@ -134,7 +134,7 @@ CudaBufferReader::CudaBufferReader(const std::shared_ptr<CudaBuffer>& buffer)\n \n CudaBufferReader::~CudaBufferReader() {}\n \n-Status CudaBufferReader::Read(int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) {\n+Status CudaBufferReader::Read(int64_t nbytes, int64_t* bytes_read, void* buffer) {\n   nbytes = std::min(nbytes, size_ - position_);\n   *bytes_read = nbytes;\n   RETURN_NOT_OK(context_->CopyDeviceToHost(buffer, data_ + position_, nbytes));\n@@ -190,7 +190,7 @@ class CudaBufferWriter::CudaBufferWriterImpl {\n     return Status::OK();\n   }\n \n-  Status Write(const uint8_t* data, int64_t nbytes) {\n+  Status Write(const void* data, int64_t nbytes) {\n     if (nbytes == 0) {\n       return Status::OK();\n     }\n@@ -214,7 +214,7 @@ class CudaBufferWriter::CudaBufferWriterImpl {\n     return Status::OK();\n   }\n \n-  Status WriteAt(int64_t position, const uint8_t* data, int64_t nbytes) {\n+  Status WriteAt(int64_t position, const void* data, int64_t nbytes) {\n     std::lock_guard<std::mutex> guard(lock_);\n     RETURN_NOT_OK(Seek(position));\n     return Write(data, nbytes);\n@@ -269,11 +269,11 @@ Status CudaBufferWriter::Seek(int64_t position) {\n \n Status CudaBufferWriter::Tell(int64_t* position) const { return impl_->Tell(position); }\n \n-Status CudaBufferWriter::Write(const uint8_t* data, int64_t nbytes) {\n+Status CudaBufferWriter::Write(const void* data, int64_t nbytes) {\n   return impl_->Write(data, nbytes);\n }\n \n-Status CudaBufferWriter::WriteAt(int64_t position, const uint8_t* data, int64_t nbytes) {\n+Status CudaBufferWriter::WriteAt(int64_t position, const void* data, int64_t nbytes) {\n   return impl_->WriteAt(position, data, nbytes);\n }\n \ndiff --git a/cpp/src/arrow/gpu/cuda_memory.h b/cpp/src/arrow/gpu/cuda_memory.h\nindex 9ebd2ccf0c..9376b4b3ff 100644\n--- a/cpp/src/arrow/gpu/cuda_memory.h\n+++ b/cpp/src/arrow/gpu/cuda_memory.h\n@@ -49,14 +49,14 @@ class ARROW_EXPORT CudaBuffer : public Buffer {\n   /// \\brief Copy memory from GPU device to CPU host\n   /// \\param[out] out a pre-allocated output buffer\n   /// \\return Status\n-  Status CopyToHost(const int64_t position, const int64_t nbytes, uint8_t* out) const;\n+  Status CopyToHost(const int64_t position, const int64_t nbytes, void* out) const;\n \n   /// \\brief Copy memory to device at position\n   /// \\param[in] position start position to copy bytes\n   /// \\param[in] data the host data to copy\n   /// \\param[in] nbytes number of bytes to copy\n   /// \\return Status\n-  Status CopyFromHost(const int64_t position, const uint8_t* data, int64_t nbytes);\n+  Status CopyFromHost(const int64_t position, const void* data, int64_t nbytes);\n \n   /// \\brief Expose this device buffer as IPC memory which can be used in other processes\n   /// \\param[out] handle the exported IPC handle\n@@ -130,7 +130,7 @@ class ARROW_EXPORT CudaBufferReader : public io::BufferReader {\n   /// \\param[in] nbytes number of bytes to read\n   /// \\param[out] bytes_read actual number of bytes read\n   /// \\param[out] buffer pre-allocated memory to write into\n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) override;\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* buffer) override;\n \n   /// \\brief Zero-copy read from device memory\n   /// \\param[in] nbytes number of bytes to read\n@@ -158,9 +158,9 @@ class ARROW_EXPORT CudaBufferWriter : public io::WriteableFile {\n \n   Status Seek(int64_t position) override;\n \n-  Status Write(const uint8_t* data, int64_t nbytes) override;\n+  Status Write(const void* data, int64_t nbytes) override;\n \n-  Status WriteAt(int64_t position, const uint8_t* data, int64_t nbytes) override;\n+  Status WriteAt(int64_t position, const void* data, int64_t nbytes) override;\n \n   Status Tell(int64_t* position) const override;\n \ndiff --git a/cpp/src/arrow/io/file.cc b/cpp/src/arrow/io/file.cc\nindex 1ec5e23e58..65a302c8be 100644\n--- a/cpp/src/arrow/io/file.cc\n+++ b/cpp/src/arrow/io/file.cc\n@@ -394,11 +394,11 @@ class OSFile {\n     return Status::OK();\n   }\n \n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* out) {\n-    return FileRead(fd_, out, nbytes, bytes_read);\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* out) {\n+    return FileRead(fd_, reinterpret_cast<uint8_t*>(out), nbytes, bytes_read);\n   }\n \n-  Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read, uint8_t* out) {\n+  Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read, void* out) {\n     std::lock_guard<std::mutex> guard(lock_);\n     RETURN_NOT_OK(Seek(position));\n     return Read(nbytes, bytes_read, out);\n@@ -413,12 +413,12 @@ class OSFile {\n \n   Status Tell(int64_t* pos) const { return FileTell(fd_, pos); }\n \n-  Status Write(const uint8_t* data, int64_t length) {\n+  Status Write(const void* data, int64_t length) {\n     std::lock_guard<std::mutex> guard(lock_);\n     if (length < 0) {\n       return Status::IOError(\"Length must be non-negative\");\n     }\n-    return FileWrite(fd_, data, length);\n+    return FileWrite(fd_, reinterpret_cast<const uint8_t*>(data), length);\n   }\n \n   int fd() const { return fd_; }\n@@ -504,13 +504,13 @@ Status ReadableFile::Close() { return impl_->Close(); }\n \n Status ReadableFile::Tell(int64_t* pos) const { return impl_->Tell(pos); }\n \n-Status ReadableFile::Read(int64_t nbytes, int64_t* bytes_read, uint8_t* out) {\n+Status ReadableFile::Read(int64_t nbytes, int64_t* bytes_read, void* out) {\n   std::lock_guard<std::mutex> guard(impl_->lock());\n   return impl_->Read(nbytes, bytes_read, out);\n }\n \n Status ReadableFile::ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                            uint8_t* out) {\n+                            void* out) {\n   return impl_->ReadAt(position, nbytes, bytes_read, out);\n }\n \n@@ -570,7 +570,7 @@ Status FileOutputStream::Close() { return impl_->Close(); }\n \n Status FileOutputStream::Tell(int64_t* pos) const { return impl_->Tell(pos); }\n \n-Status FileOutputStream::Write(const uint8_t* data, int64_t length) {\n+Status FileOutputStream::Write(const void* data, int64_t length) {\n   return impl_->Write(data, length);\n }\n \n@@ -710,7 +710,7 @@ Status MemoryMappedFile::Close() {\n   return Status::OK();\n }\n \n-Status MemoryMappedFile::Read(int64_t nbytes, int64_t* bytes_read, uint8_t* out) {\n+Status MemoryMappedFile::Read(int64_t nbytes, int64_t* bytes_read, void* out) {\n   nbytes = std::max<int64_t>(\n       0, std::min(nbytes, memory_map_->size() - memory_map_->position()));\n   if (nbytes > 0) {\n@@ -735,7 +735,7 @@ Status MemoryMappedFile::Read(int64_t nbytes, std::shared_ptr<Buffer>* out) {\n }\n \n Status MemoryMappedFile::ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                                uint8_t* out) {\n+                                void* out) {\n   std::lock_guard<std::mutex> guard(memory_map_->lock());\n   RETURN_NOT_OK(Seek(position));\n   return Read(nbytes, bytes_read, out);\n@@ -750,7 +750,7 @@ Status MemoryMappedFile::ReadAt(int64_t position, int64_t nbytes,\n \n bool MemoryMappedFile::supports_zero_copy() const { return true; }\n \n-Status MemoryMappedFile::WriteAt(int64_t position, const uint8_t* data, int64_t nbytes) {\n+Status MemoryMappedFile::WriteAt(int64_t position, const void* data, int64_t nbytes) {\n   std::lock_guard<std::mutex> guard(memory_map_->lock());\n \n   if (!memory_map_->opened() || !memory_map_->writable()) {\n@@ -761,7 +761,7 @@ Status MemoryMappedFile::WriteAt(int64_t position, const uint8_t* data, int64_t\n   return WriteInternal(data, nbytes);\n }\n \n-Status MemoryMappedFile::Write(const uint8_t* data, int64_t nbytes) {\n+Status MemoryMappedFile::Write(const void* data, int64_t nbytes) {\n   std::lock_guard<std::mutex> guard(memory_map_->lock());\n \n   if (!memory_map_->opened() || !memory_map_->writable()) {\n@@ -773,7 +773,7 @@ Status MemoryMappedFile::Write(const uint8_t* data, int64_t nbytes) {\n   return WriteInternal(data, nbytes);\n }\n \n-Status MemoryMappedFile::WriteInternal(const uint8_t* data, int64_t nbytes) {\n+Status MemoryMappedFile::WriteInternal(const void* data, int64_t nbytes) {\n   memcpy(memory_map_->head(), data, static_cast<size_t>(nbytes));\n   memory_map_->advance(nbytes);\n   return Status::OK();\ndiff --git a/cpp/src/arrow/io/file.h b/cpp/src/arrow/io/file.h\nindex 7937fea749..265df4d652 100644\n--- a/cpp/src/arrow/io/file.h\n+++ b/cpp/src/arrow/io/file.h\n@@ -59,7 +59,7 @@ class ARROW_EXPORT FileOutputStream : public OutputStream {\n   Status Tell(int64_t* position) const override;\n \n   // Write bytes to the stream. Thread-safe\n-  Status Write(const uint8_t* data, int64_t nbytes) override;\n+  Status Write(const void* data, int64_t nbytes) override;\n \n   int file_descriptor() const;\n \n@@ -93,12 +93,12 @@ class ARROW_EXPORT ReadableFile : public RandomAccessFile {\n   Status Tell(int64_t* position) const override;\n \n   // Read bytes from the file. Thread-safe\n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) override;\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* buffer) override;\n   Status Read(int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n \n   /// \\brief Thread-safe implementation of ReadAt\n   Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                uint8_t* out) override;\n+                void* out) override;\n \n   /// \\brief Thread-safe implementation of ReadAt\n   Status ReadAt(int64_t position, int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n@@ -141,13 +141,13 @@ class ARROW_EXPORT MemoryMappedFile : public ReadWriteFileInterface {\n   Status Seek(int64_t position) override;\n \n   // Required by RandomAccessFile, copies memory into out. Not thread-safe\n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* out) override;\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* out) override;\n \n   // Zero copy read. Not thread-safe\n   Status Read(int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n \n   Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                uint8_t* out) override;\n+                void* out) override;\n \n   /// Default implementation is thread-safe\n   Status ReadAt(int64_t position, int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n@@ -155,10 +155,10 @@ class ARROW_EXPORT MemoryMappedFile : public ReadWriteFileInterface {\n   bool supports_zero_copy() const override;\n \n   /// Write data at the current position in the file. Thread-safe\n-  Status Write(const uint8_t* data, int64_t nbytes) override;\n+  Status Write(const void* data, int64_t nbytes) override;\n \n   /// Write data at a particular position in the file. Thread-safe\n-  Status WriteAt(int64_t position, const uint8_t* data, int64_t nbytes) override;\n+  Status WriteAt(int64_t position, const void* data, int64_t nbytes) override;\n \n   // @return: the size in bytes of the memory source\n   Status GetSize(int64_t* size) override;\n@@ -168,7 +168,7 @@ class ARROW_EXPORT MemoryMappedFile : public ReadWriteFileInterface {\n  private:\n   MemoryMappedFile();\n \n-  Status WriteInternal(const uint8_t* data, int64_t nbytes);\n+  Status WriteInternal(const void* data, int64_t nbytes);\n \n   class ARROW_NO_EXPORT MemoryMap;\n   std::shared_ptr<MemoryMap> memory_map_;\ndiff --git a/cpp/src/arrow/io/hdfs.cc b/cpp/src/arrow/io/hdfs.cc\nindex 77d1f524aa..6e3e4a7a1c 100644\n--- a/cpp/src/arrow/io/hdfs.cc\n+++ b/cpp/src/arrow/io/hdfs.cc\n@@ -119,7 +119,7 @@ class HdfsReadableFile::HdfsReadableFileImpl : public HdfsAnyFileImpl {\n     return Status::OK();\n   }\n \n-  Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) {\n+  Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read, void* buffer) {\n     tSize ret;\n     if (driver_->HasPread()) {\n       ret = driver_->Pread(fs_, file_, static_cast<tOffset>(position),\n@@ -149,11 +149,11 @@ class HdfsReadableFile::HdfsReadableFileImpl : public HdfsAnyFileImpl {\n     return Status::OK();\n   }\n \n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) {\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* buffer) {\n     int64_t total_bytes = 0;\n     while (total_bytes < nbytes) {\n       tSize ret = driver_->Read(\n-          fs_, file_, reinterpret_cast<void*>(buffer + total_bytes),\n+          fs_, file_, reinterpret_cast<uint8_t*>(buffer) + total_bytes,\n           static_cast<tSize>(std::min<int64_t>(buffer_size_, nbytes - total_bytes)));\n       RETURN_NOT_OK(CheckReadResult(ret));\n       total_bytes += ret;\n@@ -212,7 +212,7 @@ HdfsReadableFile::~HdfsReadableFile() { DCHECK(impl_->Close().ok()); }\n Status HdfsReadableFile::Close() { return impl_->Close(); }\n \n Status HdfsReadableFile::ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                                uint8_t* buffer) {\n+                                void* buffer) {\n   return impl_->ReadAt(position, nbytes, bytes_read, buffer);\n }\n \n@@ -223,7 +223,7 @@ Status HdfsReadableFile::ReadAt(int64_t position, int64_t nbytes,\n \n bool HdfsReadableFile::supports_zero_copy() const { return false; }\n \n-Status HdfsReadableFile::Read(int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) {\n+Status HdfsReadableFile::Read(int64_t nbytes, int64_t* bytes_read, void* buffer) {\n   return impl_->Read(nbytes, bytes_read, buffer);\n }\n \n@@ -261,7 +261,7 @@ class HdfsOutputStream::HdfsOutputStreamImpl : public HdfsAnyFileImpl {\n     return Status::OK();\n   }\n \n-  Status Write(const uint8_t* buffer, int64_t nbytes, int64_t* bytes_written) {\n+  Status Write(const void* buffer, int64_t nbytes, int64_t* bytes_written) {\n     std::lock_guard<std::mutex> guard(lock_);\n     tSize ret = driver_->Write(fs_, file_, reinterpret_cast<const void*>(buffer),\n                                static_cast<tSize>(nbytes));\n@@ -277,12 +277,11 @@ HdfsOutputStream::~HdfsOutputStream() { DCHECK(impl_->Close().ok()); }\n \n Status HdfsOutputStream::Close() { return impl_->Close(); }\n \n-Status HdfsOutputStream::Write(const uint8_t* buffer, int64_t nbytes,\n-                               int64_t* bytes_read) {\n+Status HdfsOutputStream::Write(const void* buffer, int64_t nbytes, int64_t* bytes_read) {\n   return impl_->Write(buffer, nbytes, bytes_read);\n }\n \n-Status HdfsOutputStream::Write(const uint8_t* buffer, int64_t nbytes) {\n+Status HdfsOutputStream::Write(const void* buffer, int64_t nbytes) {\n   int64_t bytes_written_dummy = 0;\n   return Write(buffer, nbytes, &bytes_written_dummy);\n }\ndiff --git a/cpp/src/arrow/io/hdfs.h b/cpp/src/arrow/io/hdfs.h\nindex 0708b11cca..062473b201 100644\n--- a/cpp/src/arrow/io/hdfs.h\n+++ b/cpp/src/arrow/io/hdfs.h\n@@ -182,12 +182,12 @@ class ARROW_EXPORT HdfsReadableFile : public RandomAccessFile {\n \n   // NOTE: If you wish to read a particular range of a file in a multithreaded\n   // context, you may prefer to use ReadAt to avoid locking issues\n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) override;\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* buffer) override;\n \n   Status Read(int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n \n   Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                uint8_t* buffer) override;\n+                void* buffer) override;\n \n   Status ReadAt(int64_t position, int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n \n@@ -217,9 +217,9 @@ class ARROW_EXPORT HdfsOutputStream : public OutputStream {\n \n   Status Close() override;\n \n-  Status Write(const uint8_t* buffer, int64_t nbytes) override;\n+  Status Write(const void* buffer, int64_t nbytes) override;\n \n-  Status Write(const uint8_t* buffer, int64_t nbytes, int64_t* bytes_written);\n+  Status Write(const void* buffer, int64_t nbytes, int64_t* bytes_written);\n \n   Status Flush() override;\n \ndiff --git a/cpp/src/arrow/io/interfaces.cc b/cpp/src/arrow/io/interfaces.cc\nindex 582cc2026d..04560209a6 100644\n--- a/cpp/src/arrow/io/interfaces.cc\n+++ b/cpp/src/arrow/io/interfaces.cc\n@@ -38,7 +38,7 @@ RandomAccessFile::RandomAccessFile()\n     : impl_(new RandomAccessFile::RandomAccessFileImpl()) {}\n \n Status RandomAccessFile::ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                                uint8_t* out) {\n+                                void* out) {\n   std::lock_guard<std::mutex> lock(impl_->lock_);\n   RETURN_NOT_OK(Seek(position));\n   return Read(nbytes, bytes_read, out);\n@@ -51,12 +51,11 @@ Status RandomAccessFile::ReadAt(int64_t position, int64_t nbytes,\n   return Read(nbytes, out);\n }\n \n-Status Writeable::Write(const std::string& data) {\n-  return Write(reinterpret_cast<const uint8_t*>(data.c_str()),\n-               static_cast<int64_t>(data.size()));\n+Status Writable::Write(const std::string& data) {\n+  return Write(data.c_str(), static_cast<int64_t>(data.size()));\n }\n \n-Status Writeable::Flush() { return Status::OK(); }\n+Status Writable::Flush() { return Status::OK(); }\n \n }  // namespace io\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/io/interfaces.h b/cpp/src/arrow/io/interfaces.h\nindex 82af875e7c..09536a44ef 100644\n--- a/cpp/src/arrow/io/interfaces.h\n+++ b/cpp/src/arrow/io/interfaces.h\n@@ -86,11 +86,11 @@ class ARROW_EXPORT Seekable {\n   virtual Status Seek(int64_t position) = 0;\n };\n \n-class ARROW_EXPORT Writeable {\n+class ARROW_EXPORT Writable {\n  public:\n-  virtual ~Writeable() = default;\n+  virtual ~Writable() = default;\n \n-  virtual Status Write(const uint8_t* data, int64_t nbytes) = 0;\n+  virtual Status Write(const void* data, int64_t nbytes) = 0;\n \n   /// \\brief Flush buffered bytes, if any\n   virtual Status Flush();\n@@ -102,13 +102,13 @@ class ARROW_EXPORT Readable {\n  public:\n   virtual ~Readable() = default;\n \n-  virtual Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* out) = 0;\n+  virtual Status Read(int64_t nbytes, int64_t* bytes_read, void* out) = 0;\n \n   // Does not copy if not necessary\n   virtual Status Read(int64_t nbytes, std::shared_ptr<Buffer>* out) = 0;\n };\n \n-class ARROW_EXPORT OutputStream : virtual public FileInterface, public Writeable {\n+class ARROW_EXPORT OutputStream : virtual public FileInterface, public Writable {\n  protected:\n   OutputStream() = default;\n };\n@@ -138,7 +138,7 @@ class ARROW_EXPORT RandomAccessFile : public InputStream, public Seekable {\n   /// \\param[out] out The buffer to read bytes into\n   /// \\return Status\n   virtual Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                        uint8_t* out) = 0;\n+                        void* out) = 0;\n \n   /// \\brief Read nbytes at position, provide default implementations using Read(...), but\n   /// can be overridden. Default implementation is thread-safe.\n@@ -162,7 +162,7 @@ class ARROW_EXPORT RandomAccessFile : public InputStream, public Seekable {\n \n class ARROW_EXPORT WriteableFile : public OutputStream, public Seekable {\n  public:\n-  virtual Status WriteAt(int64_t position, const uint8_t* data, int64_t nbytes) = 0;\n+  virtual Status WriteAt(int64_t position, const void* data, int64_t nbytes) = 0;\n \n  protected:\n   WriteableFile() = default;\ndiff --git a/cpp/src/arrow/io/io-file-test.cc b/cpp/src/arrow/io/io-file-test.cc\nindex ee3beabd9a..e70431e695 100644\n--- a/cpp/src/arrow/io/io-file-test.cc\n+++ b/cpp/src/arrow/io/io-file-test.cc\n@@ -135,7 +135,7 @@ TEST_F(TestFileOutputStream, Close) {\n   OpenFile();\n \n   const char* data = \"testdata\";\n-  ASSERT_OK(file_->Write(reinterpret_cast<const uint8_t*>(data), strlen(data)));\n+  ASSERT_OK(file_->Write(data, strlen(data)));\n \n   int fd = file_->file_descriptor();\n   ASSERT_OK(file_->Close());\n@@ -158,7 +158,7 @@ TEST_F(TestFileOutputStream, InvalidWrites) {\n \n   const char* data = \"\";\n \n-  ASSERT_RAISES(IOError, file_->Write(reinterpret_cast<const uint8_t*>(data), -1));\n+  ASSERT_RAISES(IOError, file_->Write(data, -1));\n }\n \n TEST_F(TestFileOutputStream, Tell) {\n@@ -170,7 +170,7 @@ TEST_F(TestFileOutputStream, Tell) {\n   ASSERT_EQ(0, position);\n \n   const char* data = \"testdata\";\n-  ASSERT_OK(file_->Write(reinterpret_cast<const uint8_t*>(data), 8));\n+  ASSERT_OK(file_->Write(data, 8));\n   ASSERT_OK(file_->Tell(&position));\n   ASSERT_EQ(8, position);\n }\n@@ -179,7 +179,7 @@ TEST_F(TestFileOutputStream, TruncatesNewFile) {\n   ASSERT_OK(FileOutputStream::Open(path_, &file_));\n \n   const char* data = \"testdata\";\n-  ASSERT_OK(file_->Write(reinterpret_cast<const uint8_t*>(data), strlen(data)));\n+  ASSERT_OK(file_->Write(data, strlen(data)));\n   ASSERT_OK(file_->Close());\n \n   ASSERT_OK(FileOutputStream::Open(path_, &file_));\n@@ -583,8 +583,7 @@ TEST_F(TestMemoryMappedFile, ThreadSafety) {\n \n   std::shared_ptr<MemoryMappedFile> file;\n   ASSERT_OK(MemoryMappedFile::Open(path, FileMode::READWRITE, &file));\n-  ASSERT_OK(file->Write(reinterpret_cast<const uint8_t*>(data.c_str()),\n-                        static_cast<int64_t>(data.size())));\n+  ASSERT_OK(file->Write(data.c_str(), static_cast<int64_t>(data.size())));\n \n   std::atomic<int> correct_count(0);\n   constexpr int niter = 10000;\ndiff --git a/cpp/src/arrow/io/io-memory-test.cc b/cpp/src/arrow/io/io-memory-test.cc\nindex 117972f1cf..8c2e8c3b0b 100644\n--- a/cpp/src/arrow/io/io-memory-test.cc\n+++ b/cpp/src/arrow/io/io-memory-test.cc\n@@ -93,7 +93,7 @@ TEST(TestFixedSizeBufferWriter, Basics) {\n \n   std::string data = \"data123456\";\n   auto nbytes = static_cast<int64_t>(data.size());\n-  ASSERT_OK(writer.Write(reinterpret_cast<const uint8_t*>(data.c_str()), nbytes));\n+  ASSERT_OK(writer.Write(data.c_str(), nbytes));\n \n   ASSERT_OK(writer.Tell(&position));\n   ASSERT_EQ(nbytes, position);\ndiff --git a/cpp/src/arrow/io/memory.cc b/cpp/src/arrow/io/memory.cc\nindex d9c84b495d..ecdf26f0a9 100644\n--- a/cpp/src/arrow/io/memory.cc\n+++ b/cpp/src/arrow/io/memory.cc\n@@ -79,7 +79,7 @@ Status BufferOutputStream::Tell(int64_t* position) const {\n   return Status::OK();\n }\n \n-Status BufferOutputStream::Write(const uint8_t* data, int64_t nbytes) {\n+Status BufferOutputStream::Write(const void* data, int64_t nbytes) {\n   if (ARROW_PREDICT_FALSE(!is_open_)) {\n     return Status::IOError(\"OutputStream is closed\");\n   }\n@@ -116,7 +116,7 @@ Status MockOutputStream::Tell(int64_t* position) const {\n   return Status::OK();\n }\n \n-Status MockOutputStream::Write(const uint8_t* data, int64_t nbytes) {\n+Status MockOutputStream::Write(const void* data, int64_t nbytes) {\n   extent_bytes_written_ += nbytes;\n   return Status::OK();\n }\n@@ -162,9 +162,10 @@ class FixedSizeBufferWriter::FixedSizeBufferWriterImpl {\n     return Status::OK();\n   }\n \n-  Status Write(const uint8_t* data, int64_t nbytes) {\n+  Status Write(const void* data, int64_t nbytes) {\n     if (nbytes > memcopy_threshold_ && memcopy_num_threads_ > 1) {\n-      internal::parallel_memcopy(mutable_data_ + position_, data, nbytes,\n+      internal::parallel_memcopy(mutable_data_ + position_,\n+                                 reinterpret_cast<const uint8_t*>(data), nbytes,\n                                  memcopy_blocksize_, memcopy_num_threads_);\n     } else {\n       memcpy(mutable_data_ + position_, data, nbytes);\n@@ -173,7 +174,7 @@ class FixedSizeBufferWriter::FixedSizeBufferWriterImpl {\n     return Status::OK();\n   }\n \n-  Status WriteAt(int64_t position, const uint8_t* data, int64_t nbytes) {\n+  Status WriteAt(int64_t position, const void* data, int64_t nbytes) {\n     std::lock_guard<std::mutex> guard(lock_);\n     RETURN_NOT_OK(Seek(position));\n     return Write(data, nbytes);\n@@ -210,11 +211,11 @@ Status FixedSizeBufferWriter::Tell(int64_t* position) const {\n   return impl_->Tell(position);\n }\n \n-Status FixedSizeBufferWriter::Write(const uint8_t* data, int64_t nbytes) {\n+Status FixedSizeBufferWriter::Write(const void* data, int64_t nbytes) {\n   return impl_->Write(data, nbytes);\n }\n \n-Status FixedSizeBufferWriter::WriteAt(int64_t position, const uint8_t* data,\n+Status FixedSizeBufferWriter::WriteAt(int64_t position, const void* data,\n                                       int64_t nbytes) {\n   return impl_->WriteAt(position, data, nbytes);\n }\n@@ -240,6 +241,9 @@ BufferReader::BufferReader(const std::shared_ptr<Buffer>& buffer)\n BufferReader::BufferReader(const uint8_t* data, int64_t size)\n     : buffer_(nullptr), data_(data), size_(size), position_(0) {}\n \n+BufferReader::BufferReader(const Buffer& buffer)\n+    : BufferReader(buffer.data(), buffer.size()) {}\n+\n Status BufferReader::Close() {\n   // no-op\n   return Status::OK();\n@@ -252,7 +256,7 @@ Status BufferReader::Tell(int64_t* position) const {\n \n bool BufferReader::supports_zero_copy() const { return true; }\n \n-Status BufferReader::Read(int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) {\n+Status BufferReader::Read(int64_t nbytes, int64_t* bytes_read, void* buffer) {\n   memcpy(buffer, data_ + position_, nbytes);\n   *bytes_read = std::min(nbytes, size_ - position_);\n   position_ += *bytes_read;\n@@ -273,7 +277,7 @@ Status BufferReader::Read(int64_t nbytes, std::shared_ptr<Buffer>* out) {\n }\n \n Status BufferReader::ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                            uint8_t* out) {\n+                            void* out) {\n   return RandomAccessFile::ReadAt(position, nbytes, bytes_read, out);\n }\n \ndiff --git a/cpp/src/arrow/io/memory.h b/cpp/src/arrow/io/memory.h\nindex 3aec91f723..cf370b3b63 100644\n--- a/cpp/src/arrow/io/memory.h\n+++ b/cpp/src/arrow/io/memory.h\n@@ -48,7 +48,7 @@ class ARROW_EXPORT BufferOutputStream : public OutputStream {\n   // Implement the OutputStream interface\n   Status Close() override;\n   Status Tell(int64_t* position) const override;\n-  Status Write(const uint8_t* data, int64_t nbytes) override;\n+  Status Write(const void* data, int64_t nbytes) override;\n \n   /// Close the stream and return the buffer\n   Status Finish(std::shared_ptr<Buffer>* result);\n@@ -72,7 +72,7 @@ class ARROW_EXPORT MockOutputStream : public OutputStream {\n   // Implement the OutputStream interface\n   Status Close() override;\n   Status Tell(int64_t* position) const override;\n-  Status Write(const uint8_t* data, int64_t nbytes) override;\n+  Status Write(const void* data, int64_t nbytes) override;\n \n   int64_t GetExtentBytesWritten() const { return extent_bytes_written_; }\n \n@@ -90,8 +90,8 @@ class ARROW_EXPORT FixedSizeBufferWriter : public WriteableFile {\n   Status Close() override;\n   Status Seek(int64_t position) override;\n   Status Tell(int64_t* position) const override;\n-  Status Write(const uint8_t* data, int64_t nbytes) override;\n-  Status WriteAt(int64_t position, const uint8_t* data, int64_t nbytes) override;\n+  Status Write(const void* data, int64_t nbytes) override;\n+  Status WriteAt(int64_t position, const void* data, int64_t nbytes) override;\n \n   void set_memcopy_threads(int num_threads);\n   void set_memcopy_blocksize(int64_t blocksize);\n@@ -107,16 +107,17 @@ class ARROW_EXPORT FixedSizeBufferWriter : public WriteableFile {\n class ARROW_EXPORT BufferReader : public RandomAccessFile {\n  public:\n   explicit BufferReader(const std::shared_ptr<Buffer>& buffer);\n+  explicit BufferReader(const Buffer& buffer);\n   BufferReader(const uint8_t* data, int64_t size);\n \n   Status Close() override;\n   Status Tell(int64_t* position) const override;\n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* buffer) override;\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* buffer) override;\n \n   // Zero copy read\n   Status Read(int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n   Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                uint8_t* out) override;\n+                void* out) override;\n \n   /// Default implementation is thread-safe\n   Status ReadAt(int64_t position, int64_t nbytes, std::shared_ptr<Buffer>* out) override;\ndiff --git a/cpp/src/arrow/ipc/feather.cc b/cpp/src/arrow/ipc/feather.cc\nindex d339449c08..d3872503ed 100644\n--- a/cpp/src/arrow/ipc/feather.cc\n+++ b/cpp/src/arrow/ipc/feather.cc\n@@ -523,10 +523,8 @@ class TableWriter::TableWriterImpl : public ArrayVisitor {\n     uint32_t buffer_size = static_cast<uint32_t>(bytes_written);\n \n     // Footer: metadata length, magic bytes\n-    RETURN_NOT_OK(\n-        stream_->Write(reinterpret_cast<const uint8_t*>(&buffer_size), sizeof(uint32_t)));\n-    return stream_->Write(reinterpret_cast<const uint8_t*>(kFeatherMagicBytes),\n-                          strlen(kFeatherMagicBytes));\n+    RETURN_NOT_OK(stream_->Write(&buffer_size, sizeof(uint32_t)));\n+    return stream_->Write(kFeatherMagicBytes, strlen(kFeatherMagicBytes));\n   }\n \n   Status LoadArrayMetadata(const Array& values, ArrayMetadata* meta) {\ndiff --git a/cpp/src/arrow/ipc/json-integration-test.cc b/cpp/src/arrow/ipc/json-integration-test.cc\nindex f487487dfd..f362d97015 100644\n--- a/cpp/src/arrow/ipc/json-integration-test.cc\n+++ b/cpp/src/arrow/ipc/json-integration-test.cc\n@@ -119,8 +119,7 @@ static Status ConvertArrowToJson(const std::string& arrow_path,\n \n   std::string result;\n   RETURN_NOT_OK(writer->Finish(&result));\n-  return out_file->Write(reinterpret_cast<const uint8_t*>(result.c_str()),\n-                         static_cast<int64_t>(result.size()));\n+  return out_file->Write(result.c_str(), static_cast<int64_t>(result.size()));\n }\n \n static Status ValidateArrowVsJson(const std::string& arrow_path,\n@@ -250,8 +249,7 @@ class TestJSONIntegration : public ::testing::Test {\n     do {\n       std::shared_ptr<io::FileOutputStream> out;\n       RETURN_NOT_OK(io::FileOutputStream::Open(path, &out));\n-      RETURN_NOT_OK(out->Write(reinterpret_cast<const uint8_t*>(data),\n-                               static_cast<int64_t>(strlen(data))));\n+      RETURN_NOT_OK(out->Write(data, static_cast<int64_t>(strlen(data))));\n     } while (0);\n     return Status::OK();\n   }\ndiff --git a/cpp/src/arrow/ipc/message.cc b/cpp/src/arrow/ipc/message.cc\nindex 21d6a69a28..1835cefde0 100644\n--- a/cpp/src/arrow/ipc/message.cc\n+++ b/cpp/src/arrow/ipc/message.cc\n@@ -236,11 +236,35 @@ Status ReadMessage(io::InputStream* file, std::unique_ptr<Message>* message) {\n // ----------------------------------------------------------------------\n // Implement InputStream message reader\n \n-Status InputStreamMessageReader::ReadNextMessage(std::unique_ptr<Message>* message) {\n-  return ReadMessage(stream_, message);\n+/// \\brief Implementation of MessageReader that reads from InputStream\n+class InputStreamMessageReader : public MessageReader {\n+ public:\n+  explicit InputStreamMessageReader(io::InputStream* stream) : stream_(stream) {}\n+\n+  explicit InputStreamMessageReader(const std::shared_ptr<io::InputStream>& owned_stream)\n+      : InputStreamMessageReader(owned_stream.get()) {\n+    owned_stream_ = owned_stream;\n+  }\n+\n+  ~InputStreamMessageReader() {}\n+\n+  Status ReadNextMessage(std::unique_ptr<Message>* message) {\n+    return ReadMessage(stream_, message);\n+  }\n+\n+ private:\n+  io::InputStream* stream_;\n+  std::shared_ptr<io::InputStream> owned_stream_;\n+};\n+\n+std::unique_ptr<MessageReader> MessageReader::Open(io::InputStream* stream) {\n+  return std::unique_ptr<MessageReader>(new InputStreamMessageReader(stream));\n }\n \n-InputStreamMessageReader::~InputStreamMessageReader() {}\n+std::unique_ptr<MessageReader> MessageReader::Open(\n+    const std::shared_ptr<io::InputStream>& owned_stream) {\n+  return std::unique_ptr<MessageReader>(new InputStreamMessageReader(owned_stream));\n+}\n \n }  // namespace ipc\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/ipc/message.h b/cpp/src/arrow/ipc/message.h\nindex 495474e505..159b39a81f 100644\n--- a/cpp/src/arrow/ipc/message.h\n+++ b/cpp/src/arrow/ipc/message.h\n@@ -144,6 +144,13 @@ class ARROW_EXPORT MessageReader {\n  public:\n   virtual ~MessageReader() = default;\n \n+  /// \\brief Create MessageReader that reads from InputStream\n+  static std::unique_ptr<MessageReader> Open(io::InputStream* stream);\n+\n+  /// \\brief Create MessageReader that reads from owned InputStream\n+  static std::unique_ptr<MessageReader> Open(\n+      const std::shared_ptr<io::InputStream>& owned_stream);\n+\n   /// \\brief Read next Message from the interface\n   ///\n   /// \\param[out] message an arrow::ipc::Message instance\n@@ -151,26 +158,6 @@ class ARROW_EXPORT MessageReader {\n   virtual Status ReadNextMessage(std::unique_ptr<Message>* message) = 0;\n };\n \n-/// \\brief Implementation of MessageReader that reads from InputStream\n-/// \\since 0.5.0\n-class ARROW_EXPORT InputStreamMessageReader : public MessageReader {\n- public:\n-  explicit InputStreamMessageReader(io::InputStream* stream) : stream_(stream) {}\n-\n-  explicit InputStreamMessageReader(const std::shared_ptr<io::InputStream>& owned_stream)\n-      : InputStreamMessageReader(owned_stream.get()) {\n-    owned_stream_ = owned_stream;\n-  }\n-\n-  ~InputStreamMessageReader();\n-\n-  Status ReadNextMessage(std::unique_ptr<Message>* message) override;\n-\n- private:\n-  io::InputStream* stream_;\n-  std::shared_ptr<io::InputStream> owned_stream_;\n-};\n-\n /// \\brief Read encapulated RPC message from position in file\n ///\n /// Read a length-prefixed message flatbuffer starting at the indicated file\ndiff --git a/cpp/src/arrow/ipc/metadata-internal.cc b/cpp/src/arrow/ipc/metadata-internal.cc\nindex 87b4708bf6..05202ea937 100644\n--- a/cpp/src/arrow/ipc/metadata-internal.cc\n+++ b/cpp/src/arrow/ipc/metadata-internal.cc\n@@ -945,8 +945,7 @@ Status WriteMessage(const Buffer& message, io::OutputStream* file,\n \n   // Write the flatbuffer size prefix including padding\n   int32_t flatbuffer_size = padded_message_length - 4;\n-  RETURN_NOT_OK(\n-      file->Write(reinterpret_cast<const uint8_t*>(&flatbuffer_size), sizeof(int32_t)));\n+  RETURN_NOT_OK(file->Write(&flatbuffer_size, sizeof(int32_t)));\n \n   // Write the flatbuffer\n   RETURN_NOT_OK(file->Write(message.data(), message.size()));\ndiff --git a/cpp/src/arrow/ipc/reader.cc b/cpp/src/arrow/ipc/reader.cc\nindex 5960e81883..ae0f8f3980 100644\n--- a/cpp/src/arrow/ipc/reader.cc\n+++ b/cpp/src/arrow/ipc/reader.cc\n@@ -480,14 +480,12 @@ Status RecordBatchStreamReader::Open(std::unique_ptr<MessageReader> message_read\n \n Status RecordBatchStreamReader::Open(io::InputStream* stream,\n                                      std::shared_ptr<RecordBatchReader>* out) {\n-  std::unique_ptr<MessageReader> message_reader(new InputStreamMessageReader(stream));\n-  return Open(std::move(message_reader), out);\n+  return Open(MessageReader::Open(stream), out);\n }\n \n Status RecordBatchStreamReader::Open(const std::shared_ptr<io::InputStream>& stream,\n                                      std::shared_ptr<RecordBatchReader>* out) {\n-  std::unique_ptr<MessageReader> message_reader(new InputStreamMessageReader(stream));\n-  return Open(std::move(message_reader), out);\n+  return Open(MessageReader::Open(stream), out);\n }\n \n std::shared_ptr<Schema> RecordBatchStreamReader::schema() const {\n@@ -717,14 +715,17 @@ Status ReadTensor(int64_t offset, io::RandomAccessFile* file,\n \n   std::unique_ptr<Message> message;\n   RETURN_NOT_OK(ReadContiguousPayload(file, &message));\n+  return ReadTensor(*message, out);\n+}\n \n+Status ReadTensor(const Message& message, std::shared_ptr<Tensor>* out) {\n   std::shared_ptr<DataType> type;\n   std::vector<int64_t> shape;\n   std::vector<int64_t> strides;\n   std::vector<std::string> dim_names;\n-  RETURN_NOT_OK(internal::GetTensorMetadata(*message->metadata(), &type, &shape, &strides,\n+  RETURN_NOT_OK(internal::GetTensorMetadata(*message.metadata(), &type, &shape, &strides,\n                                             &dim_names));\n-  *out = std::make_shared<Tensor>(type, message->body(), shape, strides, dim_names);\n+  *out = std::make_shared<Tensor>(type, message.body(), shape, strides, dim_names);\n   return Status::OK();\n }\n \ndiff --git a/cpp/src/arrow/ipc/reader.h b/cpp/src/arrow/ipc/reader.h\nindex 627f67e251..019c9bc1f3 100644\n--- a/cpp/src/arrow/ipc/reader.h\n+++ b/cpp/src/arrow/ipc/reader.h\n@@ -219,7 +219,7 @@ Status ReadRecordBatch(const Buffer& metadata, const std::shared_ptr<Schema>& sc\n                        int max_recursion_depth, io::RandomAccessFile* file,\n                        std::shared_ptr<RecordBatch>* out);\n \n-/// EXPERIMENTAL: Read arrow::Tensor as encapsulated IPC message in file\n+/// \\brief EXPERIMENTAL: Read arrow::Tensor as encapsulated IPC message in file\n ///\n /// \\param[in] offset the file location of the start of the message\n /// \\param[in] file the file where the batch is located\n@@ -229,6 +229,14 @@ ARROW_EXPORT\n Status ReadTensor(int64_t offset, io::RandomAccessFile* file,\n                   std::shared_ptr<Tensor>* out);\n \n+/// \\brief EXPERIMENTAL: Read arrow::Tensor from IPC message\n+///\n+/// \\param[in] message a Message containing the tensor metadata and body\n+/// \\param[out] out the read tensor\n+/// \\return Status\n+ARROW_EXPORT\n+Status ReadTensor(const Message& message, std::shared_ptr<Tensor>* out);\n+\n }  // namespace ipc\n }  // namespace arrow\n \ndiff --git a/cpp/src/arrow/ipc/writer.cc b/cpp/src/arrow/ipc/writer.cc\nindex fb766a9a75..c6aa770127 100644\n--- a/cpp/src/arrow/ipc/writer.cc\n+++ b/cpp/src/arrow/ipc/writer.cc\n@@ -560,9 +560,18 @@ Status WriteLargeRecordBatch(const RecordBatch& batch, int64_t buffer_start_offs\n                           pool, kMaxNestingDepth, true);\n }\n \n-static Status WriteStridedTensorData(int dim_index, int64_t offset, int elem_size,\n-                                     const Tensor& tensor, uint8_t* scratch_space,\n-                                     io::OutputStream* dst) {\n+namespace {\n+\n+Status WriteTensorHeader(const Tensor& tensor, io::OutputStream* dst,\n+                         int32_t* metadata_length, int64_t* body_length) {\n+  std::shared_ptr<Buffer> metadata;\n+  RETURN_NOT_OK(internal::WriteTensorMessage(tensor, 0, &metadata));\n+  return internal::WriteMessage(*metadata, dst, metadata_length);\n+}\n+\n+Status WriteStridedTensorData(int dim_index, int64_t offset, int elem_size,\n+                              const Tensor& tensor, uint8_t* scratch_space,\n+                              io::OutputStream* dst) {\n   if (dim_index == tensor.ndim() - 1) {\n     const uint8_t* data_ptr = tensor.raw_data() + offset;\n     const int64_t stride = tensor.strides()[dim_index];\n@@ -580,16 +589,37 @@ static Status WriteStridedTensorData(int dim_index, int64_t offset, int elem_siz\n   return Status::OK();\n }\n \n-Status WriteTensorHeader(const Tensor& tensor, io::OutputStream* dst,\n-                         int32_t* metadata_length, int64_t* body_length) {\n-  RETURN_NOT_OK(AlignStreamPosition(dst));\n-  std::shared_ptr<Buffer> metadata;\n-  RETURN_NOT_OK(internal::WriteTensorMessage(tensor, 0, &metadata));\n-  return internal::WriteMessage(*metadata, dst, metadata_length);\n+Status GetContiguousTensor(const Tensor& tensor, MemoryPool* pool,\n+                           std::unique_ptr<Tensor>* out) {\n+  const auto& type = static_cast<const FixedWidthType&>(*tensor.type());\n+  const int elem_size = type.bit_width() / 8;\n+\n+  // TODO(wesm): Do we care enough about this temporary allocation to pass in\n+  // a MemoryPool to this function?\n+  std::shared_ptr<Buffer> scratch_space;\n+  RETURN_NOT_OK(AllocateBuffer(default_memory_pool(),\n+                               tensor.shape()[tensor.ndim() - 1] * elem_size,\n+                               &scratch_space));\n+\n+  std::shared_ptr<ResizableBuffer> contiguous_data;\n+  RETURN_NOT_OK(\n+      AllocateResizableBuffer(pool, tensor.size() * elem_size, &contiguous_data));\n+\n+  io::BufferOutputStream stream(contiguous_data);\n+  RETURN_NOT_OK(WriteStridedTensorData(0, 0, elem_size, tensor,\n+                                       scratch_space->mutable_data(), &stream));\n+\n+  out->reset(new Tensor(tensor.type(), contiguous_data, tensor.shape()));\n+\n+  return Status::OK();\n }\n \n+}  // namespace\n+\n Status WriteTensor(const Tensor& tensor, io::OutputStream* dst, int32_t* metadata_length,\n                    int64_t* body_length) {\n+  RETURN_NOT_OK(AlignStreamPosition(dst));\n+\n   if (tensor.is_contiguous()) {\n     RETURN_NOT_OK(WriteTensorHeader(tensor, dst, metadata_length, body_length));\n     auto data = tensor.data();\n@@ -619,6 +649,22 @@ Status WriteTensor(const Tensor& tensor, io::OutputStream* dst, int32_t* metadat\n   }\n }\n \n+Status GetTensorMessage(const Tensor& tensor, MemoryPool* pool,\n+                        std::unique_ptr<Message>* out) {\n+  const Tensor* tensor_to_write = &tensor;\n+  std::unique_ptr<Tensor> temp_tensor;\n+\n+  if (!tensor.is_contiguous()) {\n+    RETURN_NOT_OK(GetContiguousTensor(tensor, pool, &temp_tensor));\n+    tensor_to_write = temp_tensor.get();\n+  }\n+\n+  std::shared_ptr<Buffer> metadata;\n+  RETURN_NOT_OK(internal::WriteTensorMessage(*tensor_to_write, 0, &metadata));\n+  out->reset(new Message(metadata, tensor_to_write->data()));\n+  return Status::OK();\n+}\n+\n Status WriteDictionary(int64_t dictionary_id, const std::shared_ptr<Array>& dictionary,\n                        int64_t buffer_start_offset, io::OutputStream* dst,\n                        int32_t* metadata_length, int64_t* body_length, MemoryPool* pool) {\n@@ -693,7 +739,7 @@ class StreamBookKeeper {\n   }\n \n   // Write data and update position\n-  Status Write(const uint8_t* data, int64_t nbytes) {\n+  Status Write(const void* data, int64_t nbytes) {\n     RETURN_NOT_OK(sink_->Write(data, nbytes));\n     position_ += nbytes;\n     return Status::OK();\n@@ -782,7 +828,7 @@ class RecordBatchStreamWriter::RecordBatchStreamWriterImpl : public StreamBookKe\n \n     // Write 0 EOS message\n     const int32_t kEos = 0;\n-    return Write(reinterpret_cast<const uint8_t*>(&kEos), sizeof(int32_t));\n+    return Write(&kEos, sizeof(int32_t));\n   }\n \n   Status CheckStarted() {\n@@ -870,8 +916,7 @@ class RecordBatchFileWriter::RecordBatchFileWriterImpl\n \n   Status Start() override {\n     // It is only necessary to align to 8-byte boundary at the start of the file\n-    RETURN_NOT_OK(Write(reinterpret_cast<const uint8_t*>(kArrowMagicBytes),\n-                        strlen(kArrowMagicBytes)));\n+    RETURN_NOT_OK(Write(kArrowMagicBytes, strlen(kArrowMagicBytes)));\n     RETURN_NOT_OK(Align());\n \n     // We write the schema at the start of the file (and the end). This also\n@@ -895,12 +940,10 @@ class RecordBatchFileWriter::RecordBatchFileWriterImpl\n       return Status::Invalid(\"Invalid file footer\");\n     }\n \n-    RETURN_NOT_OK(\n-        Write(reinterpret_cast<const uint8_t*>(&footer_length), sizeof(int32_t)));\n+    RETURN_NOT_OK(Write(&footer_length, sizeof(int32_t)));\n \n     // Write magic bytes to end file\n-    return Write(reinterpret_cast<const uint8_t*>(kArrowMagicBytes),\n-                 strlen(kArrowMagicBytes));\n+    return Write(kArrowMagicBytes, strlen(kArrowMagicBytes));\n   }\n };\n \ndiff --git a/cpp/src/arrow/ipc/writer.h b/cpp/src/arrow/ipc/writer.h\nindex 457dcb4ec6..013783ee0a 100644\n--- a/cpp/src/arrow/ipc/writer.h\n+++ b/cpp/src/arrow/ipc/writer.h\n@@ -245,6 +245,17 @@ Status GetRecordBatchSize(const RecordBatch& batch, int64_t* size);\n ARROW_EXPORT\n Status GetTensorSize(const Tensor& tensor, int64_t* size);\n \n+/// \\brief EXPERIMENTAL: Convert arrow::Tensor to a Message with minimal memory\n+/// allocation\n+///\n+/// \\param[in] tensor the Tensor to write\n+/// \\param[in] pool MemoryPool to allocate space for metadata\n+/// \\param[out] out the resulting Message\n+/// \\return Status\n+ARROW_EXPORT\n+Status GetTensorMessage(const Tensor& tensor, MemoryPool* pool,\n+                        std::unique_ptr<Message>* out);\n+\n /// \\brief EXPERIMENTAL: Write arrow::Tensor as a contiguous message\n ///\n /// \\param[in] tensor the Tensor to write\ndiff --git a/cpp/src/arrow/python/arrow_to_pandas.cc b/cpp/src/arrow/python/arrow_to_pandas.cc\nindex 8814fc190a..096bbd55c6 100644\n--- a/cpp/src/arrow/python/arrow_to_pandas.cc\n+++ b/cpp/src/arrow/python/arrow_to_pandas.cc\n@@ -480,7 +480,7 @@ inline Status ConvertStruct(PandasOptions options, const ChunkedArray& data,\n             Py_INCREF(Py_None);\n             field_value.reset(Py_None);\n           }\n-          // PyDict_SetItemString does not steal the value reference\n+          // PyDict_SetItemString increments reference count\n           auto setitem_result =\n               PyDict_SetItemString(dict_item.obj(), name.c_str(), field_value.obj());\n           RETURN_IF_PYERROR();\ndiff --git a/cpp/src/arrow/python/arrow_to_python.cc b/cpp/src/arrow/python/arrow_to_python.cc\nindex 9686050b96..ce539a597b 100644\n--- a/cpp/src/arrow/python/arrow_to_python.cc\n+++ b/cpp/src/arrow/python/arrow_to_python.cc\n@@ -29,15 +29,17 @@\n \n #include \"arrow/array.h\"\n #include \"arrow/io/interfaces.h\"\n+#include \"arrow/io/memory.h\"\n #include \"arrow/ipc/reader.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/logging.h\"\n+\n #include \"arrow/python/common.h\"\n #include \"arrow/python/helpers.h\"\n #include \"arrow/python/numpy_convert.h\"\n #include \"arrow/python/pyarrow.h\"\n #include \"arrow/python/python_to_arrow.h\"\n #include \"arrow/python/util/datetime.h\"\n-#include \"arrow/table.h\"\n-#include \"arrow/util/logging.h\"\n \n namespace arrow {\n namespace py {\n@@ -286,5 +288,59 @@ Status DeserializeObject(PyObject* context, const SerializedPyObject& obj, PyObj\n                          obj, out);\n }\n \n+Status GetSerializedFromComponents(int num_tensors, int num_buffers, PyObject* data,\n+                                   SerializedPyObject* out) {\n+  PyAcquireGIL gil;\n+  const Py_ssize_t data_length = PyList_Size(data);\n+  RETURN_IF_PYERROR();\n+\n+  const Py_ssize_t expected_data_length = 1 + num_tensors * 2 + num_buffers;\n+  if (data_length != expected_data_length) {\n+    return Status::Invalid(\"Invalid number of buffers in data\");\n+  }\n+\n+  auto GetBuffer = [&data](Py_ssize_t index, std::shared_ptr<Buffer>* out) {\n+    PyObject* py_buf = PyList_GET_ITEM(data, index);\n+    return unwrap_buffer(py_buf, out);\n+  };\n+\n+  Py_ssize_t buffer_index = 0;\n+\n+  // Read the union batch describing object structure\n+  {\n+    std::shared_ptr<Buffer> data_buffer;\n+    RETURN_NOT_OK(GetBuffer(buffer_index++, &data_buffer));\n+    gil.release();\n+    io::BufferReader buf_reader(data_buffer);\n+    std::shared_ptr<RecordBatchReader> reader;\n+    RETURN_NOT_OK(ipc::RecordBatchStreamReader::Open(&buf_reader, &reader));\n+    RETURN_NOT_OK(reader->ReadNext(&out->batch));\n+    gil.acquire();\n+  }\n+\n+  // Zero-copy reconstruct tensors\n+  for (int i = 0; i < num_tensors; ++i) {\n+    std::shared_ptr<Buffer> metadata;\n+    std::shared_ptr<Buffer> body;\n+    std::shared_ptr<Tensor> tensor;\n+    RETURN_NOT_OK(GetBuffer(buffer_index++, &metadata));\n+    RETURN_NOT_OK(GetBuffer(buffer_index++, &body));\n+\n+    ipc::Message message(metadata, body);\n+\n+    RETURN_NOT_OK(ReadTensor(message, &tensor));\n+    out->tensors.emplace_back(std::move(tensor));\n+  }\n+\n+  // Unwrap and append buffers\n+  for (int i = 0; i < num_buffers; ++i) {\n+    std::shared_ptr<Buffer> buffer;\n+    RETURN_NOT_OK(GetBuffer(buffer_index++, &buffer));\n+    out->buffers.emplace_back(std::move(buffer));\n+  }\n+\n+  return Status::OK();\n+}\n+\n }  // namespace py\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/python/arrow_to_python.h b/cpp/src/arrow/python/arrow_to_python.h\nindex 7509f30eb4..9440ffb32a 100644\n--- a/cpp/src/arrow/python/arrow_to_python.h\n+++ b/cpp/src/arrow/python/arrow_to_python.h\n@@ -48,6 +48,19 @@ namespace py {\n ARROW_EXPORT\n Status ReadSerializedObject(io::RandomAccessFile* src, SerializedPyObject* out);\n \n+/// \\brief Reconstruct SerializedPyObject from representation produced by\n+/// SerializedPyObject::GetComponents.\n+///\n+/// \\param[in] num_tensors\n+/// \\param[in] num_buffers\n+/// \\param[in] data a list containing pyarrow.Buffer instances. Must be 1 +\n+/// num_tensors * 2 + num_buffers in length\n+/// \\param[out] out the reconstructed object\n+/// \\return Status\n+ARROW_EXPORT\n+Status GetSerializedFromComponents(int num_tensors, int num_buffers, PyObject* data,\n+                                   SerializedPyObject* out);\n+\n /// \\brief Reconstruct Python object from Arrow-serialized representation\n /// \\param[in] context Serialization context which contains custom serialization\n /// and deserialization callbacks. Can be any Python object with a\ndiff --git a/cpp/src/arrow/python/io.cc b/cpp/src/arrow/python/io.cc\nindex b01358ab00..cc3892928c 100644\n--- a/cpp/src/arrow/python/io.cc\n+++ b/cpp/src/arrow/python/io.cc\n@@ -76,7 +76,7 @@ class PythonFile {\n     return Status::OK();\n   }\n \n-  Status Write(const uint8_t* data, int64_t nbytes) {\n+  Status Write(const void* data, int64_t nbytes) {\n     PyObject* py_data =\n         PyBytes_FromStringAndSize(reinterpret_cast<const char*>(data), nbytes);\n     PY_RETURN_IF_ERROR(StatusCode::IOError);\n@@ -130,7 +130,7 @@ Status PyReadableFile::Tell(int64_t* position) const {\n   return file_->Tell(position);\n }\n \n-Status PyReadableFile::Read(int64_t nbytes, int64_t* bytes_read, uint8_t* out) {\n+Status PyReadableFile::Read(int64_t nbytes, int64_t* bytes_read, void* out) {\n   PyAcquireGIL lock;\n   PyObject* bytes_obj;\n   ARROW_RETURN_NOT_OK(file_->Read(nbytes, &bytes_obj));\n@@ -155,7 +155,7 @@ Status PyReadableFile::Read(int64_t nbytes, std::shared_ptr<Buffer>* out) {\n }\n \n Status PyReadableFile::ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                              uint8_t* out) {\n+                              void* out) {\n   std::lock_guard<std::mutex> guard(file_->lock());\n   RETURN_NOT_OK(Seek(position));\n   return Read(nbytes, bytes_read, out);\n@@ -208,7 +208,7 @@ Status PyOutputStream::Tell(int64_t* position) const {\n   return Status::OK();\n }\n \n-Status PyOutputStream::Write(const uint8_t* data, int64_t nbytes) {\n+Status PyOutputStream::Write(const void* data, int64_t nbytes) {\n   PyAcquireGIL lock;\n   position_ += nbytes;\n   return file_->Write(data, nbytes);\ndiff --git a/cpp/src/arrow/python/io.h b/cpp/src/arrow/python/io.h\nindex bf5db5313a..f550de7b28 100644\n--- a/cpp/src/arrow/python/io.h\n+++ b/cpp/src/arrow/python/io.h\n@@ -41,12 +41,12 @@ class ARROW_EXPORT PyReadableFile : public io::RandomAccessFile {\n \n   Status Close() override;\n \n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* out) override;\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* out) override;\n   Status Read(int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n \n   // Thread-safe version\n   Status ReadAt(int64_t position, int64_t nbytes, int64_t* bytes_read,\n-                uint8_t* out) override;\n+                void* out) override;\n \n   // Thread-safe version\n   Status ReadAt(int64_t position, int64_t nbytes, std::shared_ptr<Buffer>* out) override;\n@@ -70,7 +70,7 @@ class ARROW_EXPORT PyOutputStream : public io::OutputStream {\n \n   Status Close() override;\n   Status Tell(int64_t* position) const override;\n-  Status Write(const uint8_t* data, int64_t nbytes) override;\n+  Status Write(const void* data, int64_t nbytes) override;\n \n  private:\n   std::unique_ptr<PythonFile> file_;\ndiff --git a/cpp/src/arrow/python/python_to_arrow.cc b/cpp/src/arrow/python/python_to_arrow.cc\nindex 72cc5b6e1d..253e9d9a7d 100644\n--- a/cpp/src/arrow/python/python_to_arrow.cc\n+++ b/cpp/src/arrow/python/python_to_arrow.cc\n@@ -31,7 +31,9 @@\n #include \"arrow/array.h\"\n #include \"arrow/builder.h\"\n #include \"arrow/io/interfaces.h\"\n+#include \"arrow/io/memory.h\"\n #include \"arrow/ipc/writer.h\"\n+#include \"arrow/memory_pool.h\"\n #include \"arrow/record_batch.h\"\n #include \"arrow/tensor.h\"\n #include \"arrow/util/logging.h\"\n@@ -710,27 +712,89 @@ Status SerializeObject(PyObject* context, PyObject* sequence, SerializedPyObject\n   return Status::OK();\n }\n \n-Status WriteSerializedObject(const SerializedPyObject& obj, io::OutputStream* dst) {\n-  int32_t num_tensors = static_cast<int32_t>(obj.tensors.size());\n-  int32_t num_buffers = static_cast<int32_t>(obj.buffers.size());\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_tensors), sizeof(int32_t)));\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_buffers), sizeof(int32_t)));\n-  RETURN_NOT_OK(ipc::WriteRecordBatchStream({obj.batch}, dst));\n+Status SerializedPyObject::WriteTo(io::OutputStream* dst) {\n+  int32_t num_tensors = static_cast<int32_t>(this->tensors.size());\n+  int32_t num_buffers = static_cast<int32_t>(this->buffers.size());\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_tensors), sizeof(int32_t)));\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_buffers), sizeof(int32_t)));\n+  RETURN_NOT_OK(ipc::WriteRecordBatchStream({this->batch}, dst));\n \n   int32_t metadata_length;\n   int64_t body_length;\n-  for (const auto& tensor : obj.tensors) {\n+  for (const auto& tensor : this->tensors) {\n     RETURN_NOT_OK(ipc::WriteTensor(*tensor, dst, &metadata_length, &body_length));\n   }\n \n-  for (const auto& buffer : obj.buffers) {\n+  for (const auto& buffer : this->buffers) {\n     int64_t size = buffer->size();\n-    RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&size), sizeof(int64_t)));\n+    RETURN_NOT_OK(dst->Write(reinterpret_cast<const uint8_t*>(&size), sizeof(int64_t)));\n     RETURN_NOT_OK(dst->Write(buffer->data(), size));\n   }\n \n   return Status::OK();\n }\n \n+Status SerializedPyObject::GetComponents(MemoryPool* memory_pool, PyObject** out) {\n+  PyAcquireGIL py_gil;\n+\n+  ScopedRef result(PyDict_New());\n+  PyObject* buffers = PyList_New(0);\n+\n+  // TODO(wesm): Not sure how pedantic we need to be about checking the return\n+  // values of these functions. There are other places where we do not check\n+  // PyDict_SetItem/SetItemString return value, but these failures would be\n+  // quite esoteric\n+  PyDict_SetItemString(result.get(), \"num_tensors\",\n+                       PyLong_FromSize_t(this->tensors.size()));\n+  PyDict_SetItemString(result.get(), \"num_buffers\",\n+                       PyLong_FromSize_t(this->buffers.size()));\n+  PyDict_SetItemString(result.get(), \"data\", buffers);\n+  RETURN_IF_PYERROR();\n+\n+  Py_DECREF(buffers);\n+\n+  auto PushBuffer = [&buffers](const std::shared_ptr<Buffer>& buffer) {\n+    PyObject* wrapped_buffer = wrap_buffer(buffer);\n+    RETURN_IF_PYERROR();\n+    if (PyList_Append(buffers, wrapped_buffer) < 0) {\n+      Py_DECREF(wrapped_buffer);\n+      RETURN_IF_PYERROR();\n+    }\n+    Py_DECREF(wrapped_buffer);\n+    return Status::OK();\n+  };\n+\n+  constexpr int64_t kInitialCapacity = 1024;\n+\n+  // Write the record batch describing the object structure\n+  std::shared_ptr<io::BufferOutputStream> stream;\n+  std::shared_ptr<Buffer> buffer;\n+\n+  py_gil.release();\n+  RETURN_NOT_OK(io::BufferOutputStream::Create(kInitialCapacity, memory_pool, &stream));\n+  RETURN_NOT_OK(ipc::WriteRecordBatchStream({this->batch}, stream.get()));\n+  RETURN_NOT_OK(stream->Finish(&buffer));\n+  py_gil.acquire();\n+\n+  RETURN_NOT_OK(PushBuffer(buffer));\n+\n+  // For each tensor, get a metadata buffer and a buffer for the body\n+  for (const auto& tensor : this->tensors) {\n+    std::unique_ptr<ipc::Message> message;\n+    RETURN_NOT_OK(ipc::GetTensorMessage(*tensor, memory_pool, &message));\n+    RETURN_NOT_OK(PushBuffer(message->metadata()));\n+    RETURN_NOT_OK(PushBuffer(message->body()));\n+  }\n+\n+  for (const auto& buf : this->buffers) {\n+    RETURN_NOT_OK(PushBuffer(buf));\n+  }\n+\n+  *out = result.release();\n+  return Status::OK();\n+}\n+\n }  // namespace py\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/python/python_to_arrow.h b/cpp/src/arrow/python/python_to_arrow.h\nindex c5b6396145..ce7aefa0e2 100644\n--- a/cpp/src/arrow/python/python_to_arrow.h\n+++ b/cpp/src/arrow/python/python_to_arrow.h\n@@ -30,6 +30,7 @@\n \n namespace arrow {\n \n+class MemoryPool;\n class RecordBatch;\n class Tensor;\n \n@@ -45,6 +46,26 @@ struct ARROW_EXPORT SerializedPyObject {\n   std::shared_ptr<RecordBatch> batch;\n   std::vector<std::shared_ptr<Tensor>> tensors;\n   std::vector<std::shared_ptr<Buffer>> buffers;\n+\n+  /// \\brief Write serialized Python object to OutputStream\n+  /// \\param[in,out] dst an OutputStream\n+  /// \\return Status\n+  Status WriteTo(io::OutputStream* dst);\n+\n+  /// \\brief Convert SerializedPyObject to a dict containing the message\n+  /// components as Buffer instances with minimal memory allocation\n+  ///\n+  /// {\n+  ///   'num_tensors': N,\n+  ///   'num_buffers': K,\n+  ///   'data': [Buffer]\n+  /// }\n+  ///\n+  /// Each tensor is written as two buffers, one for the metadata and one for\n+  /// the body. Therefore, the number of buffers in 'data' is 2 * N + K + 1,\n+  /// with the first buffer containing the serialized record batch containing\n+  /// the UnionArray that describes the whole object\n+  Status GetComponents(MemoryPool* pool, PyObject** out);\n };\n \n /// \\brief Serialize Python sequence as a RecordBatch plus\n@@ -62,13 +83,6 @@ struct ARROW_EXPORT SerializedPyObject {\n ARROW_EXPORT\n Status SerializeObject(PyObject* context, PyObject* sequence, SerializedPyObject* out);\n \n-/// \\brief Write serialized Python object to OutputStream\n-/// \\param[in] object a serialized Python object to write out\n-/// \\param[out] dst an OutputStream\n-/// \\return Status\n-ARROW_EXPORT\n-Status WriteSerializedObject(const SerializedPyObject& object, io::OutputStream* dst);\n-\n }  // namespace py\n }  // namespace arrow\n \ndiff --git a/cpp/src/arrow/util/io-util.h b/cpp/src/arrow/util/io-util.h\nindex dbca0d8be3..7e2a94ca82 100644\n--- a/cpp/src/arrow/util/io-util.h\n+++ b/cpp/src/arrow/util/io-util.h\n@@ -40,7 +40,7 @@ class StdoutStream : public OutputStream {\n     return Status::OK();\n   }\n \n-  Status Write(const uint8_t* data, int64_t nbytes) override {\n+  Status Write(const void* data, int64_t nbytes) override {\n     pos_ += nbytes;\n     std::cout.write(reinterpret_cast<const char*>(data), nbytes);\n     return Status::OK();\n@@ -63,7 +63,7 @@ class StdinStream : public InputStream {\n     return Status::OK();\n   }\n \n-  Status Read(int64_t nbytes, int64_t* bytes_read, uint8_t* out) override {\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* out) override {\n     std::cin.read(reinterpret_cast<char*>(out), nbytes);\n     if (std::cin) {\n       *bytes_read = nbytes;\ndiff --git a/python/doc/source/api.rst b/python/doc/source/api.rst\nindex bb2a0420b2..636f41d67b 100644\n--- a/python/doc/source/api.rst\n+++ b/python/doc/source/api.rst\n@@ -245,6 +245,7 @@ Serialization and IPC\n    serialize\n    serialize_to\n    deserialize\n+   deserialize_components\n    deserialize_from\n    read_serialized\n    SerializedPyObject\ndiff --git a/python/pyarrow/__init__.py b/python/pyarrow/__init__.py\nindex 0456a658f1..bd31b21c19 100644\n--- a/python/pyarrow/__init__.py\n+++ b/python/pyarrow/__init__.py\n@@ -101,6 +101,7 @@\n \n # Serialization\n from pyarrow.lib import (deserialize_from, deserialize,\n+                         deserialize_components,\n                          serialize, serialize_to, read_serialized,\n                          SerializedPyObject, SerializationContext,\n                          SerializationCallbackError,\ndiff --git a/python/pyarrow/includes/libarrow.pxd b/python/pyarrow/includes/libarrow.pxd\nindex 14211787c8..91bc96dc63 100644\n--- a/python/pyarrow/includes/libarrow.pxd\n+++ b/python/pyarrow/includes/libarrow.pxd\n@@ -689,11 +689,10 @@ cdef extern from \"arrow/ipc/api.h\" namespace \"arrow::ipc\" nogil:\n     c_string FormatMessageType(MessageType type)\n \n     cdef cppclass CMessageReader\" arrow::ipc::MessageReader\":\n-        CStatus ReadNextMessage(unique_ptr[CMessage]* out)\n+        @staticmethod\n+        unique_ptr[CMessageReader] Open(const shared_ptr[InputStream]& stream)\n \n-    cdef cppclass CInputStreamMessageReader \\\n-            \" arrow::ipc::InputStreamMessageReader\":\n-        CInputStreamMessageReader(const shared_ptr[InputStream]& stream)\n+        CStatus ReadNextMessage(unique_ptr[CMessage]* out)\n \n     cdef cppclass CRecordBatchWriter\" arrow::ipc::RecordBatchWriter\":\n         CStatus Close()\n@@ -915,12 +914,12 @@ cdef extern from \"arrow/python/api.h\" namespace 'arrow::py' nogil:\n         shared_ptr[CRecordBatch] batch\n         vector[shared_ptr[CTensor]] tensors\n \n+        CStatus WriteTo(OutputStream* dst)\n+        CStatus GetComponents(CMemoryPool* pool, PyObject** dst)\n+\n     CStatus SerializeObject(object context, object sequence,\n                             CSerializedPyObject* out)\n \n-    CStatus WriteSerializedObject(const CSerializedPyObject& obj,\n-                                  OutputStream* dst)\n-\n     CStatus DeserializeObject(object context,\n                               const CSerializedPyObject& obj,\n                               PyObject* base, PyObject** out)\n@@ -928,6 +927,10 @@ cdef extern from \"arrow/python/api.h\" namespace 'arrow::py' nogil:\n     CStatus ReadSerializedObject(RandomAccessFile* src,\n                                  CSerializedPyObject* out)\n \n+    CStatus GetSerializedFromComponents(int num_tensors, int num_buffers,\n+                                        object buffers,\n+                                        CSerializedPyObject* out)\n+\n \n cdef extern from 'arrow/python/init.h':\n     int arrow_init_numpy() except -1\ndiff --git a/python/pyarrow/ipc.pxi b/python/pyarrow/ipc.pxi\nindex e5639137dd..7534b0d0e8 100644\n--- a/python/pyarrow/ipc.pxi\n+++ b/python/pyarrow/ipc.pxi\n@@ -125,9 +125,11 @@ cdef class MessageReader:\n     def open_stream(source):\n         cdef MessageReader result = MessageReader()\n         cdef shared_ptr[InputStream] in_stream\n+        cdef unique_ptr[CMessageReader] reader\n         get_input_stream(source, &in_stream)\n         with nogil:\n-            result.reader.reset(new CInputStreamMessageReader(in_stream))\n+            reader = CMessageReader.Open(in_stream)\n+            result.reader.reset(reader.release())\n \n         return result\n \ndiff --git a/python/pyarrow/serialization.pxi b/python/pyarrow/serialization.pxi\nindex 3ee5c7d4e2..bb266b2f92 100644\n--- a/python/pyarrow/serialization.pxi\n+++ b/python/pyarrow/serialization.pxi\n@@ -155,7 +155,7 @@ cdef class SerializedPyObject:\n         def __get__(self):\n             cdef CMockOutputStream mock_stream\n             with nogil:\n-                check_status(WriteSerializedObject(self.data, &mock_stream))\n+                check_status(self.data.WriteTo(&mock_stream))\n \n             return mock_stream.GetExtentBytesWritten()\n \n@@ -169,7 +169,7 @@ cdef class SerializedPyObject:\n \n     cdef _write_to(self, OutputStream* stream):\n         with nogil:\n-            check_status(WriteSerializedObject(self.data, stream))\n+            check_status(self.data.WriteTo(stream))\n \n     def deserialize(self, SerializationContext context=None):\n         \"\"\"\n@@ -199,6 +199,46 @@ cdef class SerializedPyObject:\n         self.write_to(sink)\n         return output\n \n+    @staticmethod\n+    def from_components(components):\n+        \"\"\"\n+        Reconstruct SerializedPyObject from output of\n+        SerializedPyObject.to_components\n+        \"\"\"\n+        cdef:\n+            int num_tensors = components['num_tensors']\n+            int num_buffers = components['num_buffers']\n+            list buffers = components['data']\n+            SerializedPyObject result = SerializedPyObject()\n+\n+        with nogil:\n+            check_status(GetSerializedFromComponents(num_tensors, num_buffers,\n+                                                     buffers, &result.data))\n+\n+        return result\n+\n+    def to_components(self, memory_pool=None):\n+        \"\"\"\n+        Return the decomposed dict representation of the serialized object\n+        containing a collection of Buffer objects which maximize opportunities\n+        for zero-copy\n+\n+        Parameters\n+        ----------\n+        memory_pool : MemoryPool default None\n+            Pool to use for necessary allocations\n+\n+        Returns\n+\n+        \"\"\"\n+        cdef PyObject* result\n+        cdef CMemoryPool* c_pool = maybe_unbox_memory_pool(memory_pool)\n+\n+        with nogil:\n+            check_status(self.data.GetComponents(c_pool, &result))\n+\n+        return PyObject_to_object(result)\n+\n \n def serialize(object value, SerializationContext context=None):\n     \"\"\"EXPERIMENTAL: Serialize a Python sequence\n@@ -291,6 +331,24 @@ def deserialize_from(source, object base, SerializationContext context=None):\n     return serialized.deserialize(context)\n \n \n+def deserialize_components(components, SerializationContext context=None):\n+    \"\"\"\n+    Reconstruct Python object from output of SerializedPyObject.to_components\n+\n+    Parameters\n+    ----------\n+    components : dict\n+        Output of SerializedPyObject.to_components\n+    context : SerializationContext, default None\n+\n+    Returns\n+    -------\n+    object : the Python object that was originally serialized\n+    \"\"\"\n+    serialized = SerializedPyObject.from_components(components)\n+    return serialized.deserialize(context)\n+\n+\n def deserialize(obj, SerializationContext context=None):\n     \"\"\"\n     EXPERIMENTAL: Deserialize Python object from Buffer or other Python object\ndiff --git a/python/pyarrow/tests/test_serialization.py b/python/pyarrow/tests/test_serialization.py\nindex ed4fd9ae59..3e1d151129 100644\n--- a/python/pyarrow/tests/test_serialization.py\n+++ b/python/pyarrow/tests/test_serialization.py\n@@ -116,6 +116,48 @@ def assert_equal(obj1, obj2):\n     np.random.normal(size=[45, 22]).T]\n \n \n+# Serialization test cases from dask/distributed\n+DASK_TEST_CASES = [\n+    np.random.random((5, 5)),\n+    np.random.random((5, 5))[::2, :],\n+    np.random.random((5, 5))[:, ::2],\n+    np.asfortranarray(np.random.random((5, 5))),\n+    np.asfortranarray(np.random.random((5, 5)))[::2, :],\n+    np.asfortranarray(np.random.random((5, 5)))[:, ::2],\n+    np.random.random(5).astype('f4'),\n+    np.random.random(5).astype('>i8'),\n+    np.random.random(5).astype('<i8'),\n+    np.arange(5).astype('M8[us]'),\n+    np.arange(5).astype('M8[ms]'),\n+    np.arange(5).astype('m8'),\n+    np.arange(5).astype('m8[s]'),\n+    np.arange(5).astype('c16'),\n+    np.arange(5).astype('c8'),\n+    np.array([True, False, True]),\n+    np.ones(shape=5, dtype=[('a', 'i4'), ('b', 'M8[us]')]),\n+    np.array(['abc'], dtype='S3'),\n+    np.array(['abc'], dtype='U3'),\n+    np.array(['abc'], dtype=object),\n+    np.ones(shape=(5,), dtype=('f8', 32)),\n+    np.ones(shape=(5,), dtype=[('x', 'f8', 32)]),\n+    np.ones(shape=(5,), dtype=np.dtype([('a', 'i1'), ('b', 'f8')],\n+                                       align=False)),\n+    np.ones(shape=(5,), dtype=np.dtype([('a', 'i1'), ('b', 'f8')],\n+                                       align=True)),\n+    np.ones(shape=(5,), dtype=np.dtype([('a', 'm8[us]')], align=False)),\n+    # this dtype fails unpickling\n+    np.ones(shape=(5,), dtype=np.dtype([('a', 'm8')], align=False)),\n+    np.array([(1, 'abc')], dtype=[('x', 'i4'), ('s', object)]),\n+    np.zeros(5000, dtype=[('x%d' % i, '<f8') for i in range(4)]),\n+    np.zeros(5000, dtype='S32'),\n+    np.zeros((1, 1000, 1000)),\n+    np.arange(12)[::2],  # non-contiguous array\n+    np.ones(shape=(5, 6)).astype(dtype=[('total', '<f8'), ('n', '<f8')])\n+]\n+\n+PRIMITIVE_OBJECTS += DASK_TEST_CASES\n+\n+\n if sys.version_info >= (3, 0):\n     PRIMITIVE_OBJECTS += [0, np.array([[\"hi\", u\"hi\"], [1.3, 1]])]\n else:\n@@ -219,6 +261,17 @@ def serialization_roundtrip(value, f):\n     result = pa.deserialize_from(f, None, serialization_context)\n     assert_equal(value, result)\n \n+    _check_component_roundtrip(value)\n+\n+\n+def _check_component_roundtrip(value):\n+    # Test to/from components\n+    serialized = pa.serialize(value)\n+    components = serialized.to_components()\n+    from_comp = pa.SerializedPyObject.from_components(components)\n+    recons = from_comp.deserialize()\n+    assert_equal(value, recons)\n+\n \n @pytest.yield_fixture(scope='session')\n def large_memory_map(tmpdir_factory, size=100*1024*1024):\n@@ -485,3 +538,25 @@ def test_serialize_subclasses():\n     deserialized = serialized.deserialize()\n     assert type(deserialized).__name__ == SerializableClass.__name__\n     assert deserialized.value == 3\n+\n+\n+def test_serialize_to_components_invalid_cases():\n+    buf = pa.frombuffer(b'hello')\n+\n+    components = {\n+        'num_tensors': 0,\n+        'num_buffers': 1,\n+        'data': [buf]\n+    }\n+\n+    with pytest.raises(pa.ArrowException):\n+        pa.deserialize_components(components)\n+\n+    components = {\n+        'num_tensors': 1,\n+        'num_buffers': 0,\n+        'data': [buf, buf]\n+    }\n+\n+    with pytest.raises(pa.ArrowException):\n+        pa.deserialize_components(components)\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-04T18:12:46.825+0000",
                    "updated": "2018-11-04T18:12:46.825+0000",
                    "started": "2018-11-04T18:12:46.824+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "162337",
                    "issueId": "13104027"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 1200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@4678d242[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@69dd2e7d[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7947fcb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@73a1782[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@a0b557a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@7f3de0e8[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5bf3b2e3[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@ca23818[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5c520c73[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@4c788db1[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@ada5a77[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@1725c1cc[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 1200,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Feb 17 16:04:57 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-02-17T16:04:57.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1596/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2017-09-21T17:22:04.000+0000",
        "updated": "2021-02-17T16:04:57.000+0000",
        "timeoriginalestimate": null,
        "description": "see https://github.com/dask/distributed/blob/master/distributed/protocol/tests/test_numpy.py#L30-L65 for inspiration",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "20m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 1200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Expand serialization test suite for NumPy arrays",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13104027/comment/16267610",
                    "id": "16267610",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm opened a new pull request #1367: WIP ARROW-1596: [Python] Expand NumPy serialization tests by adding test cases from Dask (failing)\nURL: https://github.com/apache/arrow/pull/1367\n \n \n   We aren't able to serialize a lot of these. Related to ARROW-1854 we should think about what to do\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T21:36:43.194+0000",
                    "updated": "2017-11-27T21:36:43.194+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13104027/comment/17285933",
                    "id": "17285933",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "PyArrow serialization is deprecated, closing as won't fix.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2021-02-17T16:04:57.327+0000",
                    "updated": "2021-02-17T16:04:57.327+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|i3kdcn:",
        "customfield_12314139": null
    }
}