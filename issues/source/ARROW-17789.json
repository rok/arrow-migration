{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13482472",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472",
    "key": "ARROW-17789",
    "fields": {
        "parent": {
            "id": "13476618",
            "key": "ARROW-17404",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/13476618",
            "fields": {
                "summary": "[Java] Consolidate JNI compilation #2",
                "status": {
                    "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                    "description": "The issue is open and ready for the assignee to start work on it.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                    "name": "Open",
                    "id": "1",
                    "statusCategory": {
                        "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                        "id": 2,
                        "key": "new",
                        "colorName": "blue-gray",
                        "name": "To Do"
                    }
                },
                "priority": {
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                    "name": "Major",
                    "id": "3"
                },
                "issuetype": {
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                    "id": "1",
                    "description": "A problem which impairs or prevents the functions of the product.",
                    "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                    "name": "Bug",
                    "subtask": false,
                    "avatarId": 21133
                }
            }
        },
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351947",
                "id": "12351947",
                "description": "",
                "name": "10.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-10-26"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=dsusanibara",
            "name": "dsusanibara",
            "key": "dsusanibara",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "David Dali Susanibar Arce",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12332532",
                "id": "12332532",
                "name": "Documentation"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328933",
                "id": "12328933",
                "name": "Java"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=dsusanibara",
            "name": "dsusanibara",
            "key": "dsusanibara",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "David Dali Susanibar Arce",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=dsusanibara",
            "name": "dsusanibara",
            "key": "dsusanibara",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "David Dali Susanibar Arce",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 9000,
            "total": 9000,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 9000,
            "total": 9000,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-17789/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 15,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816087",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#issuecomment-1275950564\n\n   https://issues.apache.org/jira/browse/ARROW-17789\n\n\n",
                    "created": "2022-10-12T10:35:09.257+0000",
                    "updated": "2022-10-12T10:35:09.257+0000",
                    "started": "2022-10-12T10:35:09.256+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816087",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816198",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lwhite1 commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993530932\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -228,3 +249,50 @@ native objects after using. For example:\n     AutoCloseables.close(factory, dataset, scanner);\n \n If user forgets to close them then native object leakage might be caused.\n+\n+Development Guidelines\n+======================\n+\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n+\n+    .. code-block::\n+\n+       # Let configure ScanOptions as:\n+       ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+\n+       $ parquet-tools meta data4_3rg_gzip.parquet\n+       file schema: schema\n+       age:         OPTIONAL INT64 R:0 D:1\n+       name:        OPTIONAL BINARY L:STRING R:0 D:1\n+       row group 1: RC:4 TS:182 OFFSET:4\n+       row group 2: RC:4 TS:190 OFFSET:420\n+       row group 3: RC:3 TS:179 OFFSET:838\n+\n+    In this case, we are configuring ScanOptions batchSize argument equals to\n+    32768 rows, it's greater than 04 rows used on the file, then 04 rows is\n+    used on the program execution instead of 32768 rows requested.\n+\n+* Arrow Java Dataset offer native functionalities consuming native artifacts such as:\n\nReview Comment:\n   I don't understand what this section is telling me. It's a pretty big context switch to go from configuring scan options to building jars. Maybe additional description would be helpful\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,49 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n+- Apache ORC (`.orc`)\n+- Apache Parquet (`.parquet`)\n+- Comma-Separated Values (`.csv`)\n+\n Below shows a simplest example of using Dataset to query a Parquet file in Java:\n \n .. code-block:: Java\n \n     // read data from file /opt/example.parquet\n     String uri = \"file:/opt/example.parquet\";\n-    BufferAllocator allocator = new RootAllocator(Long.MAX_VALUE);\n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100)));\n-    List<ArrowRecordBatch> batches = StreamSupport.stream(\n-        scanner.scan().spliterator(), false)\n-            .flatMap(t -> stream(t.execute()))\n-            .collect(Collectors.toList());\n-\n-    // do something with read record batches, for example:\n-    analyzeArrowData(batches);\n-\n-    // finished the analysis of the data, close all resources:\n-    AutoCloseables.close(batches);\n-    AutoCloseables.close(factory, dataset, scanner);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n+        DatasetFactory datasetFactory = new FileSystemDatasetFactory(\n+                allocator, NativeMemoryPool.getDefault(),\n+                FileFormat.PARQUET, uri);\n+        Dataset dataset = datasetFactory.finish();\n+        Scanner scanner = dataset.newScan(options);\n\nReview Comment:\n   The variable `options` doesn't seem to be declared or initialized anywhere\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,49 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n+- Apache ORC (`.orc`)\n+- Apache Parquet (`.parquet`)\n+- Comma-Separated Values (`.csv`)\n+\n Below shows a simplest example of using Dataset to query a Parquet file in Java:\n \n .. code-block:: Java\n \n     // read data from file /opt/example.parquet\n     String uri = \"file:/opt/example.parquet\";\n-    BufferAllocator allocator = new RootAllocator(Long.MAX_VALUE);\n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100)));\n-    List<ArrowRecordBatch> batches = StreamSupport.stream(\n-        scanner.scan().spliterator(), false)\n-            .flatMap(t -> stream(t.execute()))\n-            .collect(Collectors.toList());\n-\n-    // do something with read record batches, for example:\n-    analyzeArrowData(batches);\n-\n-    // finished the analysis of the data, close all resources:\n-    AutoCloseables.close(batches);\n-    AutoCloseables.close(factory, dataset, scanner);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n+        DatasetFactory datasetFactory = new FileSystemDatasetFactory(\n+                allocator, NativeMemoryPool.getDefault(),\n+                FileFormat.PARQUET, uri);\n+        Dataset dataset = datasetFactory.finish();\n+        Scanner scanner = dataset.newScan(options);\n\nReview Comment:\n   I see you discuss options below. Maybe add a comment here to that effect if you're not going to initialize it. \n\n\n\n",
                    "created": "2022-10-12T14:23:39.581+0000",
                    "updated": "2022-10-12T14:23:39.581+0000",
                    "started": "2022-10-12T14:23:39.581+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816198",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816205",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "davisusanibar commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993552058\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -228,3 +249,50 @@ native objects after using. For example:\n     AutoCloseables.close(factory, dataset, scanner);\n \n If user forgets to close them then native object leakage might be caused.\n+\n+Development Guidelines\n+======================\n+\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n+\n+    .. code-block::\n+\n+       # Let configure ScanOptions as:\n+       ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+\n+       $ parquet-tools meta data4_3rg_gzip.parquet\n+       file schema: schema\n+       age:         OPTIONAL INT64 R:0 D:1\n+       name:        OPTIONAL BINARY L:STRING R:0 D:1\n+       row group 1: RC:4 TS:182 OFFSET:4\n+       row group 2: RC:4 TS:190 OFFSET:420\n+       row group 3: RC:3 TS:179 OFFSET:838\n+\n+    In this case, we are configuring ScanOptions batchSize argument equals to\n+    32768 rows, it's greater than 04 rows used on the file, then 04 rows is\n+    used on the program execution instead of 32768 rows requested.\n+\n+* Arrow Java Dataset offer native functionalities consuming native artifacts such as:\n\nReview Comment:\n   Yes, this is more low level detail, let me delete that part because that ares JNI libs running under the hood.\n\n\n\n",
                    "created": "2022-10-12T14:38:10.664+0000",
                    "updated": "2022-10-12T14:38:10.664+0000",
                    "started": "2022-10-12T14:38:10.663+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816205",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816208",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "davisusanibar commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993556131\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,49 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n+- Apache ORC (`.orc`)\n+- Apache Parquet (`.parquet`)\n+- Comma-Separated Values (`.csv`)\n+\n Below shows a simplest example of using Dataset to query a Parquet file in Java:\n \n .. code-block:: Java\n \n     // read data from file /opt/example.parquet\n     String uri = \"file:/opt/example.parquet\";\n-    BufferAllocator allocator = new RootAllocator(Long.MAX_VALUE);\n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100)));\n-    List<ArrowRecordBatch> batches = StreamSupport.stream(\n-        scanner.scan().spliterator(), false)\n-            .flatMap(t -> stream(t.execute()))\n-            .collect(Collectors.toList());\n-\n-    // do something with read record batches, for example:\n-    analyzeArrowData(batches);\n-\n-    // finished the analysis of the data, close all resources:\n-    AutoCloseables.close(batches);\n-    AutoCloseables.close(factory, dataset, scanner);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n+        DatasetFactory datasetFactory = new FileSystemDatasetFactory(\n+                allocator, NativeMemoryPool.getDefault(),\n+                FileFormat.PARQUET, uri);\n+        Dataset dataset = datasetFactory.finish();\n+        Scanner scanner = dataset.newScan(options);\n\nReview Comment:\n   Thanks to catch that, I just added that `options` part\n\n\n\n",
                    "created": "2022-10-12T14:40:55.934+0000",
                    "updated": "2022-10-12T14:40:55.934+0000",
                    "started": "2022-10-12T14:40:55.934+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816208",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816334",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993805820\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,50 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n+- Apache ORC (`.orc`)\n+- Apache Parquet (`.parquet`)\n+- Comma-Separated Values (`.csv`)\n+\n Below shows a simplest example of using Dataset to query a Parquet file in Java:\n \n .. code-block:: Java\n \n     // read data from file /opt/example.parquet\n     String uri = \"file:/opt/example.parquet\";\n-    BufferAllocator allocator = new RootAllocator(Long.MAX_VALUE);\n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100)));\n-    List<ArrowRecordBatch> batches = StreamSupport.stream(\n-        scanner.scan().spliterator(), false)\n-            .flatMap(t -> stream(t.execute()))\n-            .collect(Collectors.toList());\n-\n-    // do something with read record batches, for example:\n-    analyzeArrowData(batches);\n-\n-    // finished the analysis of the data, close all resources:\n-    AutoCloseables.close(batches);\n-    AutoCloseables.close(factory, dataset, scanner);\n+    ScanOptions options = new ScanOptions(/*batchSize*/ 5);\n\nReview Comment:\n   For the first example, can we use realistic-ish parameters? A batch size of 5 is far too small.\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,50 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n\nReview Comment:\n   reST uses double backticks.\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -65,6 +84,9 @@ Below shows a simplest example of using Dataset to query a Parquet file in Java:\n     aware container ``VectorSchemaRoot`` by which user could be able to access\n     decoded data conveniently in Java.\n \n+    The ``ScanOptions`` `batchSize` argument takes effect only if it is set to a value\n\nReview Comment:\n   reST uses double backticks.\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -228,3 +250,25 @@ native objects after using. For example:\n     AutoCloseables.close(factory, dataset, scanner);\n \n If user forgets to close them then native object leakage might be caused.\n+\n+Development Guidelines\n+======================\n+\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n+\n+    .. code-block::\n+\n+       # Let configure ScanOptions as:\n+       ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+\n+       $ parquet-tools meta data4_3rg_gzip.parquet\n+       file schema: schema\n+       age:         OPTIONAL INT64 R:0 D:1\n+       name:        OPTIONAL BINARY L:STRING R:0 D:1\n+       row group 1: RC:4 TS:182 OFFSET:4\n+       row group 2: RC:4 TS:190 OFFSET:420\n+       row group 3: RC:3 TS:179 OFFSET:838\n+\n+    In this case, we are configuring ScanOptions batchSize argument equals to\n\nReview Comment:\n   This is a pretty confusing way to think about it. The batch size parameter controls the _maximum_ batch size only. If the underlying file has smaller batches, those will not be consolidated. \n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,50 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n+- Apache ORC (`.orc`)\n+- Apache Parquet (`.parquet`)\n+- Comma-Separated Values (`.csv`)\n+\n Below shows a simplest example of using Dataset to query a Parquet file in Java:\n \n .. code-block:: Java\n \n     // read data from file /opt/example.parquet\n     String uri = \"file:/opt/example.parquet\";\n-    BufferAllocator allocator = new RootAllocator(Long.MAX_VALUE);\n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100)));\n-    List<ArrowRecordBatch> batches = StreamSupport.stream(\n-        scanner.scan().spliterator(), false)\n-            .flatMap(t -> stream(t.execute()))\n-            .collect(Collectors.toList());\n-\n-    // do something with read record batches, for example:\n-    analyzeArrowData(batches);\n-\n-    // finished the analysis of the data, close all resources:\n-    AutoCloseables.close(batches);\n-    AutoCloseables.close(factory, dataset, scanner);\n+    ScanOptions options = new ScanOptions(/*batchSize*/ 5);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n\nReview Comment:\n   The allocator should be within a try-with-resources block (ideally everything should be)\n\n\n\n",
                    "created": "2022-10-12T19:06:32.669+0000",
                    "updated": "2022-10-12T19:06:32.669+0000",
                    "started": "2022-10-12T19:06:32.669+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816334",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816342",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "davisusanibar commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993825842\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -228,3 +250,25 @@ native objects after using. For example:\n     AutoCloseables.close(factory, dataset, scanner);\n \n If user forgets to close them then native object leakage might be caused.\n+\n+Development Guidelines\n+======================\n+\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n+\n+    .. code-block::\n+\n+       # Let configure ScanOptions as:\n+       ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+\n+       $ parquet-tools meta data4_3rg_gzip.parquet\n+       file schema: schema\n+       age:         OPTIONAL INT64 R:0 D:1\n+       name:        OPTIONAL BINARY L:STRING R:0 D:1\n+       row group 1: RC:4 TS:182 OFFSET:4\n+       row group 2: RC:4 TS:190 OFFSET:420\n+       row group 3: RC:3 TS:179 OFFSET:838\n+\n+    In this case, we are configuring ScanOptions batchSize argument equals to\n\nReview Comment:\n   Please could you help me to understand your point. It is how it is working (i.e. every row group has 4 rows or less, this value are compared with the batchSize internally). You are proposing to change the example? change the paragraph?\n\n\n\n",
                    "created": "2022-10-12T19:32:10.902+0000",
                    "updated": "2022-10-12T19:32:10.902+0000",
                    "started": "2022-10-12T19:32:10.901+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816342",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816344",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993842724\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -228,3 +250,25 @@ native objects after using. For example:\n     AutoCloseables.close(factory, dataset, scanner);\n \n If user forgets to close them then native object leakage might be caused.\n+\n+Development Guidelines\n+======================\n+\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n+\n+    .. code-block::\n+\n+       # Let configure ScanOptions as:\n+       ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+\n+       $ parquet-tools meta data4_3rg_gzip.parquet\n+       file schema: schema\n+       age:         OPTIONAL INT64 R:0 D:1\n+       name:        OPTIONAL BINARY L:STRING R:0 D:1\n+       row group 1: RC:4 TS:182 OFFSET:4\n+       row group 2: RC:4 TS:190 OFFSET:420\n+       row group 3: RC:3 TS:179 OFFSET:838\n+\n+    In this case, we are configuring ScanOptions batchSize argument equals to\n\nReview Comment:\n   32768 isn't a request for rows, it's a limit. Since the file only has 4 rows in in the first row group, the actual batch size will be 4. If the file had more than 32768 rows, then it would get split into blocks of 32768 rows or less.\n\n\n\n",
                    "created": "2022-10-12T19:55:37.992+0000",
                    "updated": "2022-10-12T19:55:37.992+0000",
                    "started": "2022-10-12T19:55:37.992+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816344",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816346",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "davisusanibar commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993848153\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -228,3 +250,25 @@ native objects after using. For example:\n     AutoCloseables.close(factory, dataset, scanner);\n \n If user forgets to close them then native object leakage might be caused.\n+\n+Development Guidelines\n+======================\n+\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n+\n+    .. code-block::\n+\n+       # Let configure ScanOptions as:\n+       ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+\n+       $ parquet-tools meta data4_3rg_gzip.parquet\n+       file schema: schema\n+       age:         OPTIONAL INT64 R:0 D:1\n+       name:        OPTIONAL BINARY L:STRING R:0 D:1\n+       row group 1: RC:4 TS:182 OFFSET:4\n+       row group 2: RC:4 TS:190 OFFSET:420\n+       row group 3: RC:3 TS:179 OFFSET:838\n+\n+    In this case, we are configuring ScanOptions batchSize argument equals to\n\nReview Comment:\n   Thank you for that detail, let me add that detail\n\n\n\n",
                    "created": "2022-10-12T20:03:23.735+0000",
                    "updated": "2022-10-12T20:03:23.735+0000",
                    "started": "2022-10-12T20:03:23.735+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816346",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816351",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "davisusanibar commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993854080\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,50 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n\nReview Comment:\n   Changed\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,50 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n+- Apache ORC (`.orc`)\n+- Apache Parquet (`.parquet`)\n+- Comma-Separated Values (`.csv`)\n+\n Below shows a simplest example of using Dataset to query a Parquet file in Java:\n \n .. code-block:: Java\n \n     // read data from file /opt/example.parquet\n     String uri = \"file:/opt/example.parquet\";\n-    BufferAllocator allocator = new RootAllocator(Long.MAX_VALUE);\n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100)));\n-    List<ArrowRecordBatch> batches = StreamSupport.stream(\n-        scanner.scan().spliterator(), false)\n-            .flatMap(t -> stream(t.execute()))\n-            .collect(Collectors.toList());\n-\n-    // do something with read record batches, for example:\n-    analyzeArrowData(batches);\n-\n-    // finished the analysis of the data, close all resources:\n-    AutoCloseables.close(batches);\n-    AutoCloseables.close(factory, dataset, scanner);\n+    ScanOptions options = new ScanOptions(/*batchSize*/ 5);\n\nReview Comment:\n   Changed\n\n\n\n",
                    "created": "2022-10-12T20:11:45.445+0000",
                    "updated": "2022-10-12T20:11:45.445+0000",
                    "started": "2022-10-12T20:11:45.445+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816351",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816352",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "davisusanibar commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993854275\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -32,31 +32,50 @@ is not designed only for querying files but can be extended to serve all\n possible data sources such as from inter-process communication or from other\n network locations, etc.\n \n+.. contents::\n+\n Getting Started\n ===============\n \n+Currently supported file formats are:\n+\n+- Apache Arrow (`.arrow`)\n+- Apache ORC (`.orc`)\n+- Apache Parquet (`.parquet`)\n+- Comma-Separated Values (`.csv`)\n+\n Below shows a simplest example of using Dataset to query a Parquet file in Java:\n \n .. code-block:: Java\n \n     // read data from file /opt/example.parquet\n     String uri = \"file:/opt/example.parquet\";\n-    BufferAllocator allocator = new RootAllocator(Long.MAX_VALUE);\n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100)));\n-    List<ArrowRecordBatch> batches = StreamSupport.stream(\n-        scanner.scan().spliterator(), false)\n-            .flatMap(t -> stream(t.execute()))\n-            .collect(Collectors.toList());\n-\n-    // do something with read record batches, for example:\n-    analyzeArrowData(batches);\n-\n-    // finished the analysis of the data, close all resources:\n-    AutoCloseables.close(batches);\n-    AutoCloseables.close(factory, dataset, scanner);\n+    ScanOptions options = new ScanOptions(/*batchSize*/ 5);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n\nReview Comment:\n   Changed\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -65,6 +84,9 @@ Below shows a simplest example of using Dataset to query a Parquet file in Java:\n     aware container ``VectorSchemaRoot`` by which user could be able to access\n     decoded data conveniently in Java.\n \n+    The ``ScanOptions`` `batchSize` argument takes effect only if it is set to a value\n\nReview Comment:\n   Changed\n\n\n\n",
                    "created": "2022-10-12T20:11:59.652+0000",
                    "updated": "2022-10-12T20:11:59.652+0000",
                    "started": "2022-10-12T20:11:59.652+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816352",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816353",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "davisusanibar commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993854407\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -228,3 +250,25 @@ native objects after using. For example:\n     AutoCloseables.close(factory, dataset, scanner);\n \n If user forgets to close them then native object leakage might be caused.\n+\n+Development Guidelines\n+======================\n+\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n+\n+    .. code-block::\n+\n+       # Let configure ScanOptions as:\n+       ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+\n+       $ parquet-tools meta data4_3rg_gzip.parquet\n+       file schema: schema\n+       age:         OPTIONAL INT64 R:0 D:1\n+       name:        OPTIONAL BINARY L:STRING R:0 D:1\n+       row group 1: RC:4 TS:182 OFFSET:4\n+       row group 2: RC:4 TS:190 OFFSET:420\n+       row group 3: RC:3 TS:179 OFFSET:838\n+\n+    In this case, we are configuring ScanOptions batchSize argument equals to\n\nReview Comment:\n   Changed\n\n\n\n",
                    "created": "2022-10-12T20:12:14.653+0000",
                    "updated": "2022-10-12T20:12:14.653+0000",
                    "started": "2022-10-12T20:12:14.653+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816353",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816372",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993951264\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -213,18 +235,51 @@ be thrown during scanning.\n Native Object Resource Management\n =================================\n As another result of relying on JNI, all components related to\n-``FileSystemDataset`` should be closed manually to release the corresponding\n-native objects after using. For example:\n+``FileSystemDataset`` should be closed manually or use try-with-resources to\n+release the corresponding native objects after using. For example:\n \n .. code-block:: Java\n \n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100));\n+    String uri = \"file:/opt/example.parquet\";\n+    ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n+        DatasetFactory factory = new FileSystemDatasetFactory(\n+                allocator, NativeMemoryPool.getDefault(),\n+                FileFormat.PARQUET, uri);\n+        Dataset dataset = factory.finish();\n+        Scanner scanner = dataset.newScan(options)\n+    ) {\n+\n+        // do something\n+\n+    } catch (Exception e) {\n+        e.printStackTrace();\n+    }\n \n-    // do something\n+If user forgets to close them then native object leakage might be caused.\n \n-    AutoCloseables.close(factory, dataset, scanner);\n+Development Guidelines\n+======================\n \n-If user forgets to close them then native object leakage might be caused.\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n+\n+    .. code-block::\n+\n+       # Let configure ScanOptions as:\n+       ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+\n+       $ parquet-tools meta data4_3rg_gzip.parquet\n+       file schema: schema\n+       age:         OPTIONAL INT64 R:0 D:1\n+       name:        OPTIONAL BINARY L:STRING R:0 D:1\n+       row group 1: RC:4 TS:182 OFFSET:4\n+       row group 2: RC:4 TS:190 OFFSET:420\n+       row group 3: RC:3 TS:179 OFFSET:838\n+\n+    In this case, we are configuring ScanOptions batchSize argument limit to\n+    32768, it's greater than current 4 rows read on the file, then 4 is\n+    used as a limit on the program execution instead of 32768 limit requested.\n+\n+    In case the file had more than 32768 rows, then it would get split into\n+    blocks of 32768 rows or less.\n\nReview Comment:\n   ```suggestion\r\n       Here, we set the batchSize in ScanOptions to 32768. Because that's greater\r\n       than the number of rows in the next batch, which is 4 rows because the first\r\n       row group has only 4 rows, then the program gets only 4 rows. The scanner\r\n       will not combine smaller batches to reach the limit, but it will split\r\n       large batches to stay under the limit. So in the case the row group had more\r\n       than 32768 rows, it would get split into blocks of 32768 rows or less.\r\n   ```\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -213,18 +235,51 @@ be thrown during scanning.\n Native Object Resource Management\n =================================\n As another result of relying on JNI, all components related to\n-``FileSystemDataset`` should be closed manually to release the corresponding\n-native objects after using. For example:\n+``FileSystemDataset`` should be closed manually or use try-with-resources to\n+release the corresponding native objects after using. For example:\n \n .. code-block:: Java\n \n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100));\n+    String uri = \"file:/opt/example.parquet\";\n+    ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n+        DatasetFactory factory = new FileSystemDatasetFactory(\n+                allocator, NativeMemoryPool.getDefault(),\n+                FileFormat.PARQUET, uri);\n+        Dataset dataset = factory.finish();\n+        Scanner scanner = dataset.newScan(options)\n+    ) {\n+\n+        // do something\n+\n+    } catch (Exception e) {\n+        e.printStackTrace();\n+    }\n \n-    // do something\n+If user forgets to close them then native object leakage might be caused.\n \n-    AutoCloseables.close(factory, dataset, scanner);\n+Development Guidelines\n+======================\n \n-If user forgets to close them then native object leakage might be caused.\n+* Related to the note about ScanOptions batchSize argument: Let's try to read a Parquet file with gzip compression and 3 row groups:\n\nReview Comment:\n   ```suggestion\r\n   * The ``batchSize`` argument of ``ScanOptions`` is a limit on the size of an individual batch.\r\n   \r\n     For example, let's try to read a Parquet file with gzip compression and 3 row groups:\r\n   ```\r\n   \r\n   Can we remove the list from this? It makes the formatting weird and there's only one item here anyways.\n\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -213,18 +235,51 @@ be thrown during scanning.\n Native Object Resource Management\n =================================\n As another result of relying on JNI, all components related to\n-``FileSystemDataset`` should be closed manually to release the corresponding\n-native objects after using. For example:\n+``FileSystemDataset`` should be closed manually or use try-with-resources to\n+release the corresponding native objects after using. For example:\n \n .. code-block:: Java\n \n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100));\n+    String uri = \"file:/opt/example.parquet\";\n+    ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n+        DatasetFactory factory = new FileSystemDatasetFactory(\n+                allocator, NativeMemoryPool.getDefault(),\n+                FileFormat.PARQUET, uri);\n+        Dataset dataset = factory.finish();\n+        Scanner scanner = dataset.newScan(options)\n+    ) {\n+\n+        // do something\n+\n+    } catch (Exception e) {\n+        e.printStackTrace();\n+    }\n \n-    // do something\n+If user forgets to close them then native object leakage might be caused.\n \n-    AutoCloseables.close(factory, dataset, scanner);\n+Development Guidelines\n\nReview Comment:\n   IMO, \"Development Guidelines\" isn't a great name. Maybe this section can be combined with the one above, and renamed \"Usage Notes\" or something similar? And then we can have subheadings for \"Native Object Resource Management\" and \"Batch Sizes\".\n\n\n\n",
                    "created": "2022-10-12T22:38:09.693+0000",
                    "updated": "2022-10-12T22:38:09.693+0000",
                    "started": "2022-10-12T22:38:09.692+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816372",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816378",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "davisusanibar commented on code in PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#discussion_r993988938\n\n\n##########\ndocs/source/java/dataset.rst:\n##########\n@@ -213,18 +235,51 @@ be thrown during scanning.\n Native Object Resource Management\n =================================\n As another result of relying on JNI, all components related to\n-``FileSystemDataset`` should be closed manually to release the corresponding\n-native objects after using. For example:\n+``FileSystemDataset`` should be closed manually or use try-with-resources to\n+release the corresponding native objects after using. For example:\n \n .. code-block:: Java\n \n-    DatasetFactory factory = new FileSystemDatasetFactory(allocator,\n-        NativeMemoryPool.getDefault(), FileFormat.PARQUET, uri);\n-    Dataset dataset = factory.finish();\n-    Scanner scanner = dataset.newScan(new ScanOptions(100));\n+    String uri = \"file:/opt/example.parquet\";\n+    ScanOptions options = new ScanOptions(/*batchSize*/ 32768);\n+    try (\n+        BufferAllocator allocator = new RootAllocator();\n+        DatasetFactory factory = new FileSystemDatasetFactory(\n+                allocator, NativeMemoryPool.getDefault(),\n+                FileFormat.PARQUET, uri);\n+        Dataset dataset = factory.finish();\n+        Scanner scanner = dataset.newScan(options)\n+    ) {\n+\n+        // do something\n+\n+    } catch (Exception e) {\n+        e.printStackTrace();\n+    }\n \n-    // do something\n+If user forgets to close them then native object leakage might be caused.\n \n-    AutoCloseables.close(factory, dataset, scanner);\n+Development Guidelines\n\nReview Comment:\n   Make sense, changed\n\n\n\n",
                    "created": "2022-10-12T23:50:36.170+0000",
                    "updated": "2022-10-12T23:50:36.170+0000",
                    "started": "2022-10-12T23:50:36.169+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816378",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816556",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm merged PR #14382:\nURL: https://github.com/apache/arrow/pull/14382\n\n\n",
                    "created": "2022-10-13T12:08:27.713+0000",
                    "updated": "2022-10-13T12:08:27.713+0000",
                    "started": "2022-10-13T12:08:27.713+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816556",
                    "issueId": "13482472"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/worklog/816900",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "ursabot commented on PR #14382:\nURL: https://github.com/apache/arrow/pull/14382#issuecomment-1278625660\n\n   Benchmark runs are scheduled for baseline = ff0aa08e264ccc83ec84e65c914eb209a71592fb and contender = e8d54ea765ae7ba63b8f42c29ec855d656e85dc8. e8d54ea765ae7ba63b8f42c29ec855d656e85dc8 is a master commit associated with this PR. Results will be available as each benchmark for each run completes.\n   Conbench compare runs links:\n   [Finished :arrow_down:0.0% :arrow_up:0.0%] [ec2-t3-xlarge-us-east-2](https://conbench.ursa.dev/compare/runs/f42efbf67f5d4965aab2ffd8a53d5bfb...efe29c293e094faf99633169074baaff/)\n   [Failed :arrow_down:1.11% :arrow_up:0.0%] [test-mac-arm](https://conbench.ursa.dev/compare/runs/cf9108a811804afd80dfc90c6bd75aff...f2300e1fa56f43b4b107f2cd0f0d9592/)\n   [Failed :arrow_down:0.0% :arrow_up:0.0%] [ursa-i9-9960x](https://conbench.ursa.dev/compare/runs/cf1cd5d0ca09454bb94bbaafd891290a...431b63ccedb04429a5aba261496342ba/)\n   [Finished :arrow_down:0.11% :arrow_up:0.0%] [ursa-thinkcentre-m75q](https://conbench.ursa.dev/compare/runs/a13540e17ca54d8e9ad926a9945639a2...3622ffa2d166429091a6f33ce9137e60/)\n   Buildkite builds:\n   [Finished] [`e8d54ea7` ec2-t3-xlarge-us-east-2](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ec2-t3-xlarge-us-east-2/builds/1685)\n   [Failed] [`e8d54ea7` test-mac-arm](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-test-mac-arm/builds/1704)\n   [Failed] [`e8d54ea7` ursa-i9-9960x](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ursa-i9-9960x/builds/1687)\n   [Finished] [`e8d54ea7` ursa-thinkcentre-m75q](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ursa-thinkcentre-m75q/builds/1698)\n   [Finished] [`ff0aa08e` ec2-t3-xlarge-us-east-2](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ec2-t3-xlarge-us-east-2/builds/1684)\n   [Failed] [`ff0aa08e` test-mac-arm](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-test-mac-arm/builds/1703)\n   [Failed] [`ff0aa08e` ursa-i9-9960x](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ursa-i9-9960x/builds/1686)\n   [Finished] [`ff0aa08e` ursa-thinkcentre-m75q](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ursa-thinkcentre-m75q/builds/1697)\n   Supported benchmarks:\n   ec2-t3-xlarge-us-east-2: Supported benchmark langs: Python, R. Runs only benchmarks with cloud = True\n   test-mac-arm: Supported benchmark langs: C++, Python, R\n   ursa-i9-9960x: Supported benchmark langs: Python, R, JavaScript\n   ursa-thinkcentre-m75q: Supported benchmark langs: C++, Java\n   \n\n\n",
                    "created": "2022-10-14T07:52:20.934+0000",
                    "updated": "2022-10-14T07:52:20.934+0000",
                    "started": "2022-10-14T07:52:20.934+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "816900",
                    "issueId": "13482472"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
            "id": "7",
            "description": "The sub-task of the issue",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
            "name": "Sub-task",
            "subtask": true,
            "avatarId": 21146
        },
        "timespent": 9000,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@763698fd[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7dcf5d3c[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@469f8f80[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@413e1cd2[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@70f6c6f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@63b3fac8[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@59ea9ab1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@6803d5d2[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1493b0a9[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@680a6d49[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@65b85deb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@13e3b9cb[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 9000,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Oct 13 12:08:28 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-10-13T12:08:28.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-17789/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2022-09-21T01:37:50.000+0000",
        "updated": "2022-10-14T07:52:21.000+0000",
        "timeoriginalestimate": null,
        "description": "Update documentation with latest Dataset changes (orc/csv):\r\n * Add info about batch size argument for Parquet / ORC / CSV\r\n * Add latest support for ORC / CSV",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "2.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 9000
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Java][Dataset] Update documentation with latest Dataset changes",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13482472/comment/17617003",
                    "id": "17617003",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 14382\n[https://github.com/apache/arrow/pull/14382]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-10-13T12:08:28.685+0000",
                    "updated": "2022-10-13T12:08:28.685+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z18pvk:",
        "customfield_12314139": null
    }
}