{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13448618",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618",
    "key": "ARROW-16757",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351550",
                "id": "12351550",
                "name": "9.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-08-03"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12641287",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12641287",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13448614",
                    "key": "ARROW-16755",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448614",
                    "fields": {
                        "summary": "[C++] Improve array expression and kernel evaluation performance on small inputs",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12643808",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12643808",
                "type": {
                    "id": "12310051",
                    "name": "Supercedes",
                    "inward": "is superceded by",
                    "outward": "supercedes",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310051"
                },
                "outwardIssue": {
                    "id": "13441213",
                    "key": "ARROW-16288",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441213",
                    "fields": {
                        "summary": "[C++] ValueDescr::SCALAR nearly unused and does not work for projection",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 19800,
            "total": 19800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 19800,
            "total": 19800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16757/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 33,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788047",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm opened a new pull request, #13521:\nURL: https://github.com/apache/arrow/pull/13521\n\n   This was a pretty painful refactoring project, but all for the better long term. \r\n   \r\n   I will do my best to improve the PR summary to explain changes as I go through the PR myself, but the basic summary is that argument shape is no longer part of kernel signatures (or expressions or anything else) ",
                    "created": "2022-07-05T21:10:59.435+0000",
                    "updated": "2022-07-05T21:10:59.435+0000",
                    "started": "2022-07-05T21:10:59.434+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788047",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788048",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1175502364\n\n   https://issues.apache.org/jira/browse/ARROW-16757\n\n\n",
                    "created": "2022-07-05T21:11:19.120+0000",
                    "updated": "2022-07-05T21:11:19.120+0000",
                    "started": "2022-07-05T21:11:19.120+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788048",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788052",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r914208594\n\n\n##########\ncpp/src/arrow/array/data.h:\n##########\n@@ -266,16 +266,19 @@ struct ARROW_EXPORT ArraySpan {\n   int64_t offset = 0;\n   BufferSpan buffers[3];\n \n+  // 16 bytes of scratch space to enable this ArraySpan to be a view onto\n+  // scalar values including binary scalars (where we need to create a buffer\n+  // that looks like two 32-bit or 64-bit offsets)\n+  uint8_t scratch_space[16];\n\nReview Comment:\n   It might make sense to put this \"scratch space\" only in the Scalar values that require it (types that have offsets), then we don't have to carry around an extra 16 bytes with every ArraySpan \n\n\n\n##########\ncpp/src/arrow/compute/exec.cc:\n##########\n@@ -385,13 +387,20 @@ int64_t ExecSpanIterator::GetNextChunkSpan(int64_t iteration_size, ExecSpan* spa\n   return iteration_size;\n }\n \n-bool ExecSpanIterator::Next(ExecSpan* span) {\n-  if (position_ == length_) {\n-    // This also protects from degenerate cases like ChunkedArrays\n-    // without any chunks\n-    return false;\n+void PromoteExecSpanScalars(ExecSpan* span) {\n\nReview Comment:\n   Here is the Scalar -> ArraySpan promotion\n\n\n\n##########\ncpp/src/arrow/compute/exec/test_util.cc:\n##########\n@@ -143,16 +143,25 @@ ExecNode* MakeDummyNode(ExecPlan* plan, std::string label, std::vector<ExecNode*\n   return node;\n }\n \n-ExecBatch ExecBatchFromJSON(const std::vector<ValueDescr>& descrs,\n+ExecBatch ExecBatchFromJSON(const std::vector<TypeHolder>& types,\n                             util::string_view json) {\n   auto fields = ::arrow::internal::MapVector(\n-      [](const ValueDescr& descr) { return field(\"\", descr.type); }, descrs);\n+      [](const TypeHolder& th) { return field(\"\", th.GetSharedPtr()); }, types);\n \n   ExecBatch batch{*RecordBatchFromJSON(schema(std::move(fields)), json)};\n \n+  return batch;\n+}\n+\n+ExecBatch ExecBatchFromJSON(const std::vector<TypeHolder>& types,\n+                            const std::vector<ArgShape>& shapes, util::string_view json) {\n\nReview Comment:\n   This is the only place that `ArgShape` is used now, just for the construction of test data\n\n\n\n##########\ncpp/src/arrow/compute/kernel.h:\n##########\n@@ -555,8 +505,7 @@ struct Kernel {\n /// endeavor to write into pre-allocated memory if they are able, though for\n /// some kernels (e.g. in cases when a builder like StringBuilder) must be\n /// employed this may not be possible.\n-using ArrayKernelExec =\n-    std::function<Status(KernelContext*, const ExecSpan&, ExecResult*)>;\n+typedef Status (*ArrayKernelExec)(KernelContext*, const ExecSpan&, ExecResult*);\n\nReview Comment:\n   Using plain function pointers makes debugging this code much easier (`std::function` adds many levels to gdb stack traces); we should use function pointers for the other kernel APIs in this file, too\n\n\n\n##########\ncpp/src/arrow/compute/kernel.h:\n##########\n@@ -143,10 +143,14 @@ ARROW_EXPORT std::shared_ptr<TypeMatcher> Primitive();\n \n }  // namespace match\n \n-/// \\brief An object used for type- and shape-checking arguments to be passed\n-/// to a kernel and stored in a KernelSignature. Distinguishes between ARRAY\n-/// and SCALAR arguments using ValueDescr::Shape. The type-checking rule can be\n-/// supplied either with an exact DataType instance or a custom TypeMatcher.\n+/// \\brief Shape qualifier for value types. In certain instances\n+/// (e.g. \"map_lookup\" kernel), an argument may only be a scalar, where in\n+/// other kernels arguments can be arrays or scalars\n+enum class ArgShape { ANY, ARRAY, SCALAR };\n\nReview Comment:\n   This is ONLY used in testing. I will update the docstring and move this to the place where it's used\n\n\n\n##########\ncpp/src/arrow/array/builder_nested.h:\n##########\n@@ -304,10 +304,12 @@ class ARROW_EXPORT MapBuilder : public ArrayBuilder {\n       if (!validity || bit_util::GetBit(validity, array.offset + row)) {\n         ARROW_RETURN_NOT_OK(Append());\n         const int64_t slot_length = offsets[row + 1] - offsets[row];\n+        // Add together the inner StructArray offset to the Map/List offset\n+        int64_t key_value_offset = array.child_data[0].offset + offsets[row];\n         ARROW_RETURN_NOT_OK(key_builder_->AppendArraySlice(\n-            array.child_data[0].child_data[0], offsets[row], slot_length));\n+            array.child_data[0].child_data[0], key_value_offset, slot_length));\n         ARROW_RETURN_NOT_OK(item_builder_->AppendArraySlice(\n-            array.child_data[0].child_data[1], offsets[row], slot_length));\n+            array.child_data[0].child_data[1], key_value_offset, slot_length));\n\nReview Comment:\n   This fixes a bug that I introduced in a previous PR\n\n\n\n##########\ncpp/src/arrow/compute/exec.h:\n##########\n@@ -254,19 +253,16 @@ inline bool operator==(const ExecBatch& l, const ExecBatch& r) { return l.Equals\n inline bool operator!=(const ExecBatch& l, const ExecBatch& r) { return !l.Equals(r); }\n \n struct ExecValue {\n-  enum Kind { ARRAY, SCALAR };\n-  Kind kind = ARRAY;\n   ArraySpan array;\n-  const Scalar* scalar;\n+  const Scalar* scalar = NULLPTR;\n\nReview Comment:\n   I applied Antoine's suggested optimization\n\n\n\n##########\ncpp/src/arrow/compute/function_benchmark.cc:\n##########\n@@ -19,6 +19,7 @@\n \n #include \"arrow/array/array_base.h\"\n\nReview Comment:\n   Need to check this benchmark wasn't broken\n\n\n\n##########\ncpp/src/arrow/compute/exec.h:\n##########\n@@ -235,12 +235,11 @@ struct ARROW_EXPORT ExecBatch {\n \n   ExecBatch Slice(int64_t offset, int64_t length) const;\n \n-  /// \\brief A convenience for returning the ValueDescr objects (types and\n-  /// shapes) from the batch.\n-  std::vector<ValueDescr> GetDescriptors() const {\n-    std::vector<ValueDescr> result;\n+  /// \\brief A convenience for returning the types from the batch.\n+  std::vector<TypeHolder> GetTypes() const {\n+    std::vector<TypeHolder> result;\n     for (const auto& value : this->values) {\n-      result.emplace_back(value.descr());\n+      result.emplace_back(value.type());\n\nReview Comment:\n   There are several places where we can probably drop to construct from all `const DataType*` which is less expensive, this is one of them (I need to check that it doesn't cause tests to fail)\n\n\n\n##########\ncpp/src/arrow/compute/exec.h:\n##########\n@@ -324,29 +310,21 @@ struct ExecValue {\n \n struct ARROW_EXPORT ExecResult {\n   // The default value of the variant is ArraySpan\n-  // TODO(wesm): remove Scalar output modality in ARROW-16577\n-  util::Variant<ArraySpan, std::shared_ptr<ArrayData>, std::shared_ptr<Scalar>> value;\n+  util::Variant<ArraySpan, std::shared_ptr<ArrayData>> value;\n\nReview Comment:\n   Kernels can no longer return `shared_ptr<Scalar>`\n\n\n\n##########\ncpp/src/arrow/compute/function_internal.h:\n##########\n@@ -430,6 +434,12 @@ static inline enable_if_same_result<T, std::shared_ptr<DataType>> GenericFromSca\n   return value->type;\n }\n \n+template <typename T>\n+static inline enable_if_same_result<T, TypeHolder> GenericFromScalar(\n+    const std::shared_ptr<Scalar>& value) {\n+  return value->type;\n+}\n+\n\nReview Comment:\n   Aside: I struggled a bit with this reflection stuff\n\n\n\n##########\ncpp/src/arrow/compute/kernels/vector_cumulative_ops_test.cc:\n##########\n@@ -66,21 +66,45 @@ TEST(TestCumulativeSum, AllNulls) {\n   }\n }\n \n-using testing::HasSubstr;\n-\n-TEST(TestCumulativeSum, ScalarNotSupported) {\n-  CumulativeSumOptions options;\n-\n-  EXPECT_RAISES_WITH_MESSAGE_THAT(\n-      NotImplemented, HasSubstr(\"no kernel\"),\n-      CallFunction(\"cumulative_sum\", {std::make_shared<Int64Scalar>(5)}, &options));\n+TEST(TestCumulativeSum, ScalarInput) {\n+  CumulativeSumOptions no_start_no_skip;\n+  CumulativeSumOptions no_start_do_skip(0, true);\n+  CumulativeSumOptions has_start_no_skip(10);\n+  CumulativeSumOptions has_start_do_skip(10, true);\n \n-  EXPECT_RAISES_WITH_MESSAGE_THAT(\n-      NotImplemented, HasSubstr(\"no kernel\"),\n-      CallFunction(\"cumulative_sum_checked\", {std::make_shared<Int64Scalar>(5)},\n-                   &options));\n+  for (auto ty : NumericTypes()) {\n+    CheckVectorUnary(\"cumulative_sum\", ScalarFromJSON(ty, \"10\"),\n+                     ArrayFromJSON(ty, \"[10]\"), &no_start_no_skip);\n+    CheckVectorUnary(\"cumulative_sum_checked\", ScalarFromJSON(ty, \"10\"),\n+                     ArrayFromJSON(ty, \"[10]\"), &no_start_no_skip);\n+\n+    CheckVectorUnary(\"cumulative_sum\", ScalarFromJSON(ty, \"10\"),\n+                     ArrayFromJSON(ty, \"[20]\"), &has_start_no_skip);\n+    CheckVectorUnary(\"cumulative_sum_checked\", ScalarFromJSON(ty, \"10\"),\n+                     ArrayFromJSON(ty, \"[20]\"), &has_start_no_skip);\n+\n+    CheckVectorUnary(\"cumulative_sum\", ScalarFromJSON(ty, \"null\"),\n+                     ArrayFromJSON(ty, \"[null]\"), &no_start_no_skip);\n+    CheckVectorUnary(\"cumulative_sum_checked\", ScalarFromJSON(ty, \"null\"),\n+                     ArrayFromJSON(ty, \"[null]\"), &no_start_no_skip);\n+    CheckVectorUnary(\"cumulative_sum\", ScalarFromJSON(ty, \"null\"),\n+                     ArrayFromJSON(ty, \"[null]\"), &has_start_no_skip);\n+    CheckVectorUnary(\"cumulative_sum_checked\", ScalarFromJSON(ty, \"null\"),\n+                     ArrayFromJSON(ty, \"[null]\"), &has_start_no_skip);\n+\n+    CheckVectorUnary(\"cumulative_sum\", ScalarFromJSON(ty, \"null\"),\n+                     ArrayFromJSON(ty, \"[null]\"), &no_start_do_skip);\n+    CheckVectorUnary(\"cumulative_sum_checked\", ScalarFromJSON(ty, \"null\"),\n+                     ArrayFromJSON(ty, \"[null]\"), &no_start_do_skip);\n+    CheckVectorUnary(\"cumulative_sum\", ScalarFromJSON(ty, \"null\"),\n+                     ArrayFromJSON(ty, \"[null]\"), &has_start_do_skip);\n+    CheckVectorUnary(\"cumulative_sum_checked\", ScalarFromJSON(ty, \"null\"),\n+                     ArrayFromJSON(ty, \"[null]\"), &has_start_do_skip);\n+  }\n\nReview Comment:\n   These tests are restored from having been deleted in one of my recent PRs\n\n\n\n##########\ncpp/src/arrow/scalar.h:\n##########\n@@ -110,7 +108,7 @@ struct ARROW_EXPORT Scalar : public std::enable_shared_from_this<Scalar>,\n   /// \\brief EXPERIMENTAL Enable obtaining shared_ptr<Scalar> from a const\n   /// Scalar& context. Implementation depends on enable_shared_from_this, but\n   /// we may change this in the future\n-  std::shared_ptr<Scalar> Copy() const {\n+  std::shared_ptr<Scalar> GetSharedPtr() const {\n\nReview Comment:\n   Per previous comments\n\n\n\n##########\ncpp/src/arrow/type_fwd.h:\n##########\n@@ -416,43 +416,43 @@ struct Type {\n /// @{\n \n /// \\brief Return a NullType instance\n-std::shared_ptr<DataType> ARROW_EXPORT null();\n+const std::shared_ptr<DataType>& ARROW_EXPORT null();\n\nReview Comment:\n   This way we can do `null().get()` or `int32().get()` to get a pointer without having to copy the shared_ptr every time we call these functions (they return static instances)\n\n\n\n##########\ncpp/src/arrow/scalar.h:\n##########\n@@ -479,37 +481,52 @@ struct ARROW_EXPORT StructScalar : public Scalar {\n \n   Result<std::shared_ptr<Scalar>> field(FieldRef ref) const;\n \n-  StructScalar(ValueType value, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)) {}\n+  StructScalar(ValueType value, std::shared_ptr<DataType> type, bool is_valid = true)\n+      : Scalar(std::move(type), is_valid), value(std::move(value)) {}\n \n   static Result<std::shared_ptr<StructScalar>> Make(ValueType value,\n                                                     std::vector<std::string> field_names);\n-\n-  explicit StructScalar(std::shared_ptr<DataType> type) : Scalar(std::move(type)) {}\n };\n \n struct ARROW_EXPORT UnionScalar : public Scalar {\n-  using Scalar::Scalar;\n-  using ValueType = std::shared_ptr<Scalar>;\n-\n-  ValueType value;\n   int8_t type_code;\n \n-  UnionScalar(int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), false), type_code(type_code) {}\n-\n-  UnionScalar(ValueType value, int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)), type_code(type_code) {}\n+ protected:\n+  UnionScalar(std::shared_ptr<DataType> type, int8_t type_code, bool is_valid)\n+      : Scalar(std::move(type), is_valid), type_code(type_code) {}\n };\n \n struct ARROW_EXPORT SparseUnionScalar : public UnionScalar {\n-  using UnionScalar::UnionScalar;\n   using TypeClass = SparseUnionType;\n+\n+  // Even though only one of the union values is relevant for this scalar, we\n+  // nonetheless construct a vector of scalars, one per union value, to have\n+  // enough data to reconstruct a valid ArraySpan of length 1 from this scalar\n+  using ValueType = std::vector<std::shared_ptr<Scalar>>;\n+  ValueType value;\n\nReview Comment:\n   Note: this change is necessary to establish a 1-1 mapping between SparseUnionScalar and an ArraySpan referencing a single-element slice of a SparseUnionArray. It's annoying but I think it's the simplest thing\n\n\n\n",
                    "created": "2022-07-05T21:33:09.122+0000",
                    "updated": "2022-07-05T21:33:09.122+0000",
                    "started": "2022-07-05T21:33:09.122+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788052",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788054",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1175538170\n\n   @kou if my proposed solution to the SparseUnionScalar issue does not cause too much controversy (maybe wait a day or two for @pitrou or @lidavidm to look), I would appreciate your assistance refactoring the glib bindings to follow\n\n\n",
                    "created": "2022-07-05T21:54:32.207+0000",
                    "updated": "2022-07-05T21:54:32.207+0000",
                    "started": "2022-07-05T21:54:32.207+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788054",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788094",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1175632276\n\n   I was able to fix the R unit tests (it was just error messages that don't have shapes in them anymore), so I'll work on getting the other CI jobs to fail and then I think the glib stuff is that only thing that will need fixing\n\n\n",
                    "created": "2022-07-06T00:35:15.563+0000",
                    "updated": "2022-07-06T00:35:15.563+0000",
                    "started": "2022-07-06T00:35:15.563+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788094",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788118",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1175728038\n\n   @wesm Sure! I'll do it.\n\n\n",
                    "created": "2022-07-06T03:07:15.498+0000",
                    "updated": "2022-07-06T03:07:15.498+0000",
                    "started": "2022-07-06T03:07:15.498+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788118",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788362",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r914967972\n\n\n##########\ncpp/src/arrow/scalar.h:\n##########\n@@ -479,37 +481,52 @@ struct ARROW_EXPORT StructScalar : public Scalar {\n \n   Result<std::shared_ptr<Scalar>> field(FieldRef ref) const;\n \n-  StructScalar(ValueType value, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)) {}\n+  StructScalar(ValueType value, std::shared_ptr<DataType> type, bool is_valid = true)\n+      : Scalar(std::move(type), is_valid), value(std::move(value)) {}\n \n   static Result<std::shared_ptr<StructScalar>> Make(ValueType value,\n                                                     std::vector<std::string> field_names);\n-\n-  explicit StructScalar(std::shared_ptr<DataType> type) : Scalar(std::move(type)) {}\n };\n \n struct ARROW_EXPORT UnionScalar : public Scalar {\n-  using Scalar::Scalar;\n-  using ValueType = std::shared_ptr<Scalar>;\n-\n-  ValueType value;\n   int8_t type_code;\n \n-  UnionScalar(int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), false), type_code(type_code) {}\n-\n-  UnionScalar(ValueType value, int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)), type_code(type_code) {}\n+ protected:\n+  UnionScalar(std::shared_ptr<DataType> type, int8_t type_code, bool is_valid)\n+      : Scalar(std::move(type), is_valid), type_code(type_code) {}\n };\n \n struct ARROW_EXPORT SparseUnionScalar : public UnionScalar {\n-  using UnionScalar::UnionScalar;\n   using TypeClass = SparseUnionType;\n+\n+  // Even though only one of the union values is relevant for this scalar, we\n+  // nonetheless construct a vector of scalars, one per union value, to have\n+  // enough data to reconstruct a valid ArraySpan of length 1 from this scalar\n+  using ValueType = std::vector<std::shared_ptr<Scalar>>;\n+  ValueType value;\n\nReview Comment:\n   This works. I suppose if we really wanted, we could keep a static buffer of zeroes and construct the span from slices of that based on type but that'd be quite a bit of work for one particular case.\n\n\n\n##########\ncpp/src/arrow/type.h:\n##########\n@@ -191,7 +191,7 @@ class ARROW_EXPORT DataType : public std::enable_shared_from_this<DataType>,\n   // \\brief EXPERIMENTAL: Enable retrieving shared_ptr<DataType> from a const\n   // context. Implementation requires enable_shared_from_this but we may fix\n   // this in the future\n-  std::shared_ptr<DataType> Copy() const {\n+  std::shared_ptr<DataType> GetSharedPtr() const {\n\nReview Comment:\n   Should we also remove the \"Implementation requires enable_shared_from_this but we may fix this in the future\" note?\n\n\n\n##########\ncpp/src/arrow/compute/function_internal.h:\n##########\n@@ -430,6 +434,12 @@ static inline enable_if_same_result<T, std::shared_ptr<DataType>> GenericFromSca\n   return value->type;\n }\n \n+template <typename T>\n+static inline enable_if_same_result<T, TypeHolder> GenericFromScalar(\n+    const std::shared_ptr<Scalar>& value) {\n+  return value->type;\n+}\n+\n\nReview Comment:\n   It is rather complicated but it saves us a good amount of boilerplate to implement serialization/ToString/equality for all the options classes. Not sure if there's a better way (more codegen?)\n\n\n\n##########\ncpp/src/arrow/scalar_test.cc:\n##########\n@@ -1370,27 +1373,61 @@ TEST(TestDictionaryScalar, Cast) {\n   }\n }\n \n+const Scalar& GetUnionValue(const Scalar& value) {\n\nReview Comment:\n   Should this just be a getter of (Base)UnionScalar? Though I suppose then you'd have to cast to use it in the tests here\n\n\n\n",
                    "created": "2022-07-06T18:27:50.813+0000",
                    "updated": "2022-07-06T18:27:50.813+0000",
                    "started": "2022-07-06T18:27:50.812+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788362",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788375",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r915183045\n\n\n##########\ncpp/src/arrow/type.h:\n##########\n@@ -191,7 +191,7 @@ class ARROW_EXPORT DataType : public std::enable_shared_from_this<DataType>,\n   // \\brief EXPERIMENTAL: Enable retrieving shared_ptr<DataType> from a const\n   // context. Implementation requires enable_shared_from_this but we may fix\n   // this in the future\n-  std::shared_ptr<DataType> Copy() const {\n+  std::shared_ptr<DataType> GetSharedPtr() const {\n\nReview Comment:\n   will fix\n\n\n\n",
                    "created": "2022-07-06T19:26:17.363+0000",
                    "updated": "2022-07-06T19:26:17.363+0000",
                    "started": "2022-07-06T19:26:17.362+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788375",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788378",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1176596152\n\n   > This works. I suppose if we really wanted, we could keep a static buffer of zeroes and construct the span from slices of that based on type but that'd be quite a bit of work for one particular case.\r\n   \r\n   Re: SparseUnionScalar \u2014 unfortunately we can't use a static buffer of zeros because child array types can have arbitrarily large values (e.g. fixed_size_binary can be arbitrarily large, or fixed_size_list, etc.) \n\n\n",
                    "created": "2022-07-06T19:28:14.383+0000",
                    "updated": "2022-07-06T19:28:14.383+0000",
                    "started": "2022-07-06T19:28:14.383+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788378",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788381",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1176597625\n\n   > 58/70 Test #59: arrow-python-test .........................***Failed    0.22 sec\r\n   > RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf\r\n   \r\n   This is an odd failure in the MinGW 32/64 C++ builds, anyone know what that's about?\n\n\n",
                    "created": "2022-07-06T19:30:04.725+0000",
                    "updated": "2022-07-06T19:30:04.725+0000",
                    "started": "2022-07-06T19:30:04.724+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788381",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788385",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1176610823\n\n   > > 58/70 Test #59: arrow-python-test .........................***Failed    0.22 sec\r\n   > > RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf\r\n   > \r\n   > This is an odd failure in the MinGW 32/64 C++ builds, anyone know what that's about?\r\n   \r\n   @amol- you mentioned you noticed this earlier - did you figure out what happened there?\n\n\n",
                    "created": "2022-07-06T19:35:54.906+0000",
                    "updated": "2022-07-06T19:35:54.906+0000",
                    "started": "2022-07-06T19:35:54.906+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788385",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788443",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1176926571\n\n   I've pushed changes for GLib.\r\n   \r\n   > > 58/70 Test #59: arrow-python-test .........................***Failed    0.22 sec\r\n   > > RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf\r\n   > \r\n   > This is an odd failure in the MinGW 32/64 C++ builds, anyone know what that's about?\r\n   \r\n   I didn't notice it but it's not related to this change.\r\n   \r\n   I think that it's caused by version change of NumPy installed by MSYS2 package manager and ccache.\r\n   MSYS2's NumPy package was updated to 1.23.0-1 from 1.22.4-3 recently. And this was caused from the update. (I think that https://github.com/apache/arrow/runs/7214056952?check_suite_focus=true is the first fail.)\r\n   It seems that ccache still uses build results with NumPy 1.22.4-3.\r\n   \r\n   It seems that we can clear GitHub Actions cache manually by GitHub Actions Cache API: https://docs.github.com/en/rest/actions/cache\r\n   I'll try clearing GitHub Actions cache for MinGW 32/64 C++ builds.\n\n\n",
                    "created": "2022-07-07T01:17:46.769+0000",
                    "updated": "2022-07-07T01:17:46.769+0000",
                    "started": "2022-07-07T01:17:46.768+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788443",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788448",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1176947212\n\n   > I'll try clearing GitHub Actions cache for MinGW 32/64 C++ builds.\r\n   \r\n   I couldn't do this...\r\n   \r\n   ```console\r\n   $ curl --verbose -X DELETE -H \"Authorization: token ...\" -H \"Accept: application/vnd.github.v3+json\" https://api.github.com/repos/apache/arrow/actions/caches/cpp-ccache-mingw64-cfa1684ec4da6404fc0c738c9563a75ca1148a7ca2e6fdfc6995e2833bbd0979\r\n   ...\r\n   {\r\n     \"message\": \"Not Found\",\r\n     \"documentation_url\": \"https://docs.github.com/rest/actions/cache#delete-a-github-actions-cache-for-a-repository-using-a-cache-id\"\r\n   }\r\n   ```\r\n   \r\n   I think that we need to add NumPy version to cache key.\n\n\n",
                    "created": "2022-07-07T01:40:54.908+0000",
                    "updated": "2022-07-07T01:40:54.908+0000",
                    "started": "2022-07-07T01:40:54.907+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788448",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788453",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#issuecomment-1176953630\n\n   > I think that we need to add NumPy version to cache key.\r\n   \r\n   #13534\n\n\n",
                    "created": "2022-07-07T01:54:01.719+0000",
                    "updated": "2022-07-07T01:54:01.719+0000",
                    "started": "2022-07-07T01:54:01.718+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788453",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788639",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r915904390\n\n\n##########\ncpp/src/arrow/array/builder_nested.h:\n##########\n@@ -304,10 +304,12 @@ class ARROW_EXPORT MapBuilder : public ArrayBuilder {\n       if (!validity || bit_util::GetBit(validity, array.offset + row)) {\n         ARROW_RETURN_NOT_OK(Append());\n         const int64_t slot_length = offsets[row + 1] - offsets[row];\n+        // Add together the inner StructArray offset to the Map/List offset\n+        int64_t key_value_offset = array.child_data[0].offset + offsets[row];\n         ARROW_RETURN_NOT_OK(key_builder_->AppendArraySlice(\n-            array.child_data[0].child_data[0], offsets[row], slot_length));\n+            array.child_data[0].child_data[0], key_value_offset, slot_length));\n         ARROW_RETURN_NOT_OK(item_builder_->AppendArraySlice(\n-            array.child_data[0].child_data[1], offsets[row], slot_length));\n+            array.child_data[0].child_data[1], key_value_offset, slot_length));\n\nReview Comment:\n   Is it tested somewhere?\n\n\n\n",
                    "created": "2022-07-07T13:55:20.383+0000",
                    "updated": "2022-07-07T13:55:20.383+0000",
                    "started": "2022-07-07T13:55:20.382+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788639",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788670",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r915974431\n\n\n##########\ncpp/src/arrow/compute/function_benchmark.cc:\n##########\n@@ -85,15 +85,13 @@ void BM_CastDispatchBaseline(benchmark::State& state) {\n                         .ValueOrDie();\n   kernel_context.SetState(cast_state.get());\n \n-  ExecSpan input;\n-  input.length = 1;\n+  ExecSpan input({ExecValue(*int_array->data())}, 1);\n+  ExecResult result;\n+  ASSERT_OK_AND_ASSIGN(std::shared_ptr<Array> result_space,\n+                       MakeArrayOfNull(double_type, 1));\n+  result.array_span()->SetMembers(*result_space->data());\n   for (auto _ : state) {\n-    ExecResult result;\n-    result.value = MakeNullScalar(double_type);\n-    for (const std::shared_ptr<Scalar>& int_scalar : int_scalars) {\n-      input.values = {ExecValue(int_scalar.get())};\n-      ABORT_NOT_OK(exec(&kernel_context, input, &result));\n-    }\n+    ABORT_NOT_OK(exec(&kernel_context, input, &result));\n\nReview Comment:\n   Hmm, the point here was to execute on bunch of different scalars, not a single one. I'm not sure it makes much of a difference in practice, except that `setItemsProcessed` below is now wrong.\n\n\n\n##########\ncpp/src/arrow/compute/kernels/scalar_nested_test.cc:\n##########\n@@ -603,11 +603,17 @@ TEST(MakeStruct, Scalar) {\n   EXPECT_THAT(MakeStructor({i32, f64, str}),\n               ResultWith(Datum(*StructScalar::Make({i32, f64, str}, {\"0\", \"1\", \"2\"}))));\n \n-  // No field names or input values is fine\n-  EXPECT_THAT(MakeStructor({}), ResultWith(Datum(*StructScalar::Make({}, {}))));\n-\n   // Three field names but one input value\n   EXPECT_THAT(MakeStructor({str}, {\"i\", \"f\", \"s\"}), Raises(StatusCode::Invalid));\n+\n+  // ARROW-16757: No input values yields empty struct array of length 1\n+  ScalarVector value;\n+  auto empty_scalar = std::make_shared<StructScalar>(value, struct_({}));\n+  ASSERT_OK_AND_ASSIGN(std::shared_ptr<Array> empty_result,\n+                       MakeArrayFromScalar(*empty_scalar, 0));\n\nReview Comment:\n   If passing length = 0 is deliberate here, then perhaps you can simply use `MakeEmptyArray`?\n\n\n\n##########\ncpp/src/arrow/scalar_test.cc:\n##########\n@@ -1648,17 +1721,20 @@ TEST_F(TestExtensionScalar, ValidateErrors) {\n   AssertValidationFails(uuid_scalar);\n \n   // Null storage scalar\n-  auto null_storage = std::make_shared<FixedSizeBinaryScalar>(storage_type_);\n+  auto null_storage = MakeNullScalar(storage_type_);\n   ExtensionScalar scalar(null_storage, type_);\n   scalar.is_valid = true;\n   AssertValidationFails(scalar);\n+\n+  // If the scalar is null it's okay\n   scalar.is_valid = false;\n-  AssertValidationFails(scalar);\n+  ASSERT_OK(scalar.ValidateFull());\n \n   // Invalid storage scalar (wrong length)\n-  auto invalid_storage = std::make_shared<FixedSizeBinaryScalar>(storage_type_);\n+  std::shared_ptr<Scalar> invalid_storage = MakeNullScalar(storage_type_);\n   invalid_storage->is_valid = true;\n-  invalid_storage->value = std::make_shared<Buffer>(\"123\");\n+  static_cast<FixedSizeBinaryScalar*>(invalid_storage.get())->value =\n\nReview Comment:\n   `checked_cast`\n\n\n\n##########\ncpp/src/arrow/compute/exec.cc:\n##########\n@@ -784,30 +811,28 @@ class ScalarExecutor : public KernelExecutorImpl<ScalarKernel> {\n \n   Datum WrapResults(const std::vector<Datum>& inputs,\n                     const std::vector<Datum>& outputs) override {\n-    if (output_descr_.shape == ValueDescr::SCALAR) {\n-      // TODO(wesm): to remove, see ARROW-16757\n-      DCHECK_EQ(outputs.size(), 1);\n-      // Return as SCALAR\n-      return outputs[0];\n+    // If execution yielded multiple chunks (because large arrays were split\n+    // based on the ExecContext parameters, then the result is a ChunkedArray\n+    if (HaveChunkedArray(inputs) || outputs.size() > 1) {\n+      return ToChunkedArray(outputs, output_type_);\n     } else {\n-      // If execution yielded multiple chunks (because large arrays were split\n-      // based on the ExecContext parameters, then the result is a ChunkedArray\n-      if (HaveChunkedArray(inputs) || outputs.size() > 1) {\n-        return ToChunkedArray(outputs, output_descr_.type);\n-      } else if (outputs.size() == 1) {\n-        // Outputs have just one element\n-        return outputs[0];\n-      } else {\n-        // XXX: In the case where no outputs are omitted, is returning a 0-length\n-        // array always the correct move?\n-        return MakeArrayOfNull(output_descr_.type, /*length=*/0,\n-                               exec_context()->memory_pool())\n-            .ValueOrDie();\n-      }\n+      // Outputs have just one element\n+      return outputs[0];\n     }\n   }\n \n  protected:\n+  Status EmitResult(std::shared_ptr<ArrayData> out, ExecListener* listener) {\n\nReview Comment:\n   `out` could be passed by const-ref here?\n\n\n\n##########\ncpp/src/arrow/compute/exec_test.cc:\n##########\n@@ -1154,8 +1155,9 @@ TEST_F(TestCallScalarFunction, ArgumentValidation) {\n   ASSERT_RAISES(Invalid, CallFunction(\"test_copy\", args));\n \n   // Cannot do scalar\n-  args = {Datum(std::make_shared<Int32Scalar>(5))};\n-  ASSERT_RAISES(NotImplemented, CallFunction(\"test_copy\", args));\n+  Datum d1_scalar(std::make_shared<Int32Scalar>(5));\n+  ASSERT_OK_AND_ASSIGN(auto result, CallFunction(\"test_copy\", {d1}));\n+  ASSERT_OK_AND_ASSIGN(result, CallFunction(\"test_copy\", {d1_scalar}));\n\nReview Comment:\n   We should probably test the result values, to check that the Scalar->ArraySpan->Scalar plumbing works.\n\n\n\n##########\ncpp/src/arrow/compute/kernel.cc:\n##########\n@@ -122,11 +124,11 @@ class TimeUnitMatcher : public TypeMatcher {\n   explicit TimeUnitMatcher(TimeUnit::type accepted_unit)\n       : accepted_unit_(accepted_unit) {}\n \n-  bool Matches(const DataType& type) const override {\n+  bool Matches(const TypeHolder& type) const override {\n\nReview Comment:\n   Same here, and below as well.\n\n\n\n##########\ncpp/src/arrow/compute/kernels/scalar_if_else_test.cc:\n##########\n@@ -1215,19 +1220,28 @@ TYPED_TEST(TestCaseWhenNumeric, FixedSize) {\n \n     // Error cases\n     EXPECT_RAISES_WITH_MESSAGE_THAT(\n-        Invalid, ::testing::HasSubstr(\"cond struct must not be null\"),\n-        CallFunction(\n-            \"case_when\",\n-            {Datum(std::make_shared<StructScalar>(struct_({field(\"\", boolean())}))),\n-             Datum(scalar1)}));\n+        Invalid,\n+        ::testing::HasSubstr(\"cond struct must not be a null scalar or \"\n+                             \"have top-level nulls\"),\n+        CallFunction(\"case_when\",\n+                     {MakeNullScalar(struct_({field(\"\", boolean())})), Datum(scalar1)}));\n     EXPECT_RAISES_WITH_MESSAGE_THAT(\n-        Invalid, ::testing::HasSubstr(\"cond struct must not have top-level nulls\"),\n+        Invalid,\n+        ::testing::HasSubstr(\"cond struct must not be a null scalar or \"\n+                             \"have top-level nulls\"),\n         CallFunction(\"case_when\",\n                      {Datum(*MakeArrayOfNull(struct_({field(\"\", boolean())}), 4)),\n                       Datum(values1)}));\n   }\n }\n \n+template <typename Type>\n+class TestCaseWhenNumeric : public ::testing::Test {};\n+\n+TYPED_TEST_SUITE(TestCaseWhenNumeric, IfElseNumericBasedTypes);\n+\n+TYPED_TEST(TestCaseWhenNumeric, FixedSize) { TestCaseWhenFixedSize<TypeParam>(); }\n\nReview Comment:\n   Hmm, is there any reason for the `TestCaseWhenFixedSize` redirection? It probably makes reading the test a bit more cumbersome.\n\n\n\n##########\ncpp/src/arrow/array/data.cc:\n##########\n@@ -174,27 +175,197 @@ void ArraySpan::SetMembers(const ArrayData& data) {\n   }\n }\n \n+template <typename offset_type>\n+void SetOffsetsForScalar(ArraySpan* span, uint8_t* buffer, int64_t value_size,\n+                         int buffer_index = 1) {\n+  auto offsets = reinterpret_cast<offset_type*>(buffer);\n+  offsets[0] = 0;\n+  offsets[1] = static_cast<offset_type>(value_size);\n+  span->buffers[buffer_index].data = buffer;\n+  span->buffers[buffer_index].size = 2 * sizeof(offset_type);\n+}\n+\n+int GetNumBuffers(const DataType& type) {\n+  switch (type.id()) {\n+    case Type::NA:\n+    case Type::STRUCT:\n+    case Type::FIXED_SIZE_LIST:\n+      return 1;\n+    case Type::BINARY:\n+    case Type::LARGE_BINARY:\n+    case Type::STRING:\n+    case Type::LARGE_STRING:\n+    case Type::DENSE_UNION:\n+      return 3;\n+    case Type::EXTENSION:\n+      // The number of buffers depends on the storage type\n+      return GetNumBuffers(\n+          *internal::checked_cast<const ExtensionType&>(type).storage_type());\n+    default:\n+      // Everything else has 2 buffers\n+      return 2;\n+  }\n+}\n+\n+namespace internal {\n+\n+void FillZeroLengthArray(const DataType* type, ArraySpan* span) {\n+  memset(span->scratch_space, 0x00, 16);\n+\n+  span->type = type;\n+  span->length = 0;\n+  int num_buffers = GetNumBuffers(*type);\n+  for (int i = 0; i < num_buffers; ++i) {\n+    span->buffers[i].data = span->scratch_space;\n+    span->buffers[i].size = 0;\n+  }\n+\n+  for (int i = num_buffers; i < 3; ++i) {\n+    span->ClearBuffer(i);\n+  }\n+\n+  // Fill children\n+  span->child_data.resize(type->num_fields());\n+  for (int i = 0; i < type->num_fields(); ++i) {\n+    FillZeroLengthArray(type->field(i)->type().get(), &span->child_data[i]);\n+  }\n+}\n+\n+}  // namespace internal\n+\n void ArraySpan::FillFromScalar(const Scalar& value) {\n-  static const uint8_t kValidByte = 0x01;\n-  static const uint8_t kNullByte = 0x00;\n+  static uint8_t kTrueBit = 0x01;\n+  static uint8_t kFalseBit = 0x00;\n \n   this->type = value.type.get();\n   this->length = 1;\n \n-  // Populate null count and validity bitmap\n+  Type::type type_id = value.type->id();\n+\n+  // Populate null count and validity bitmap (only for non-union types)\n   this->null_count = value.is_valid ? 0 : 1;\n-  this->buffers[0].data = const_cast<uint8_t*>(value.is_valid ? &kValidByte : &kNullByte);\n-  this->buffers[0].size = 1;\n+  if (!is_union(type_id)) {\n+    this->buffers[0].data = value.is_valid ? &kTrueBit : &kFalseBit;\n+    this->buffers[0].size = 1;\n+  }\n \n-  if (is_primitive(value.type->id())) {\n-    const auto& scalar =\n-        internal::checked_cast<const internal::PrimitiveScalarBase&>(value);\n+  if (type_id == Type::BOOL) {\n+    const auto& scalar = checked_cast<const BooleanScalar&>(value);\n+    this->buffers[1].data = scalar.value ? &kTrueBit : &kFalseBit;\n+    this->buffers[1].size = 1;\n+  } else if (is_primitive(type_id) || is_decimal(type_id) ||\n+             type_id == Type::DICTIONARY) {\n+    const auto& scalar = checked_cast<const internal::PrimitiveScalarBase&>(value);\n     const uint8_t* scalar_data = reinterpret_cast<const uint8_t*>(scalar.view().data());\n     this->buffers[1].data = const_cast<uint8_t*>(scalar_data);\n     this->buffers[1].size = scalar.type->byte_width();\n+    if (type_id == Type::DICTIONARY) {\n+      // Populate dictionary data\n+      const auto& dict_scalar = checked_cast<const DictionaryScalar&>(value);\n+      this->child_data.resize(1);\n+      this->child_data[0].SetMembers(*dict_scalar.value.dictionary->data());\n+    }\n+  } else if (is_base_binary_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = this->scratch_space;\n+    const uint8_t* data_buffer = nullptr;\n+    int64_t data_size = 0;\n+    if (scalar.is_valid) {\n+      data_buffer = scalar.value->data();\n+      data_size = scalar.value->size();\n+    }\n+    if (is_binary_like(type_id)) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, data_size);\n+    } else {\n+      // is_large_binary_like\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, data_size);\n+    }\n+    this->buffers[2].data = const_cast<uint8_t*>(data_buffer);\n+    this->buffers[2].size = data_size;\n+  } else if (type_id == Type::FIXED_SIZE_BINARY) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = const_cast<uint8_t*>(scalar.value->data());\n+    this->buffers[1].size = scalar.value->size();\n+  } else if (is_list_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseListScalar&>(value);\n+\n+    int64_t value_length = 0;\n+    this->child_data.resize(1);\n+    if (scalar.value != nullptr) {\n+      // When the scalar is null, scalar.value can also be null\n+      this->child_data[0].SetMembers(*scalar.value->data());\n+      value_length = scalar.value->length();\n+    } else {\n+      // Even when the value is null, we still must populate the\n+      // child_data to yield a valid array. Tedious\n+      internal::FillZeroLengthArray(this->type->field(0)->type().get(),\n+                                    &this->child_data[0]);\n+    }\n+\n+    if (type_id == Type::LIST || type_id == Type::MAP) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, value_length);\n+    } else if (type_id == Type::LARGE_LIST) {\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, value_length);\n+    } else {\n+      // FIXED_SIZE_LIST: does not have a second buffer\n+      this->buffers[1].data = nullptr;\n+      this->buffers[1].size = 0;\n\nReview Comment:\n   `BufferSpan` has all fields zero-initialized, so are such explicit zero-initializations required?\n\n\n\n##########\ncpp/src/arrow/compute/kernels/scalar_nested_test.cc:\n##########\n@@ -603,11 +603,17 @@ TEST(MakeStruct, Scalar) {\n   EXPECT_THAT(MakeStructor({i32, f64, str}),\n               ResultWith(Datum(*StructScalar::Make({i32, f64, str}, {\"0\", \"1\", \"2\"}))));\n \n-  // No field names or input values is fine\n-  EXPECT_THAT(MakeStructor({}), ResultWith(Datum(*StructScalar::Make({}, {}))));\n-\n   // Three field names but one input value\n   EXPECT_THAT(MakeStructor({str}, {\"i\", \"f\", \"s\"}), Raises(StatusCode::Invalid));\n+\n+  // ARROW-16757: No input values yields empty struct array of length 1\n\nReview Comment:\n   Length 0 is passed to `MakeArrayFromScalar`, is there something wrong?\n\n\n\n##########\ncpp/src/arrow/python/udf.cc:\n##########\n@@ -27,18 +27,15 @@ using compute::ExecSpan;\n namespace py {\n \n namespace {\n-Status CheckOutputType(const DataType& expected, const DataType& actual) {\n-  if (!expected.Equals(actual)) {\n-    return Status::TypeError(\"Expected output datatype \", expected.ToString(),\n-                             \", but function returned datatype \", actual.ToString());\n-  }\n-  return Status::OK();\n-}\n \n-struct PythonUdf {\n+struct PythonUdf : public compute::KernelState {\n   ScalarUdfWrapperCallback cb;\n   std::shared_ptr<OwnedRefNoGIL> function;\n-  compute::OutputType output_type;\n+  std::shared_ptr<DataType> output_type;\n+\n+  PythonUdf(ScalarUdfWrapperCallback cb, std::shared_ptr<OwnedRefNoGIL> function,\n+            const std::shared_ptr<DataType>& output_type)\n+      : cb(cb), function(function), output_type(output_type) {}\n\nReview Comment:\n   ```suggestion\r\n         : cb(std::move(cb)), function(std::move(function)), output_type(output_type) {}\r\n   ```\n\n\n\n##########\ncpp/src/arrow/compute/exec.h:\n##########\n@@ -235,12 +235,11 @@ struct ARROW_EXPORT ExecBatch {\n \n   ExecBatch Slice(int64_t offset, int64_t length) const;\n \n-  /// \\brief A convenience for returning the ValueDescr objects (types and\n-  /// shapes) from the batch.\n-  std::vector<ValueDescr> GetDescriptors() const {\n-    std::vector<ValueDescr> result;\n+  /// \\brief A convenience for returning the types from the batch.\n+  std::vector<TypeHolder> GetTypes() const {\n+    std::vector<TypeHolder> result;\n\nReview Comment:\n   Might want to presize the array to avoid spurious upsizes.\n\n\n\n##########\ncpp/src/arrow/compute/kernels/scalar_compare.cc:\n##########\n@@ -661,14 +601,17 @@ struct FixedSizeBinaryScalarMinMax {\n             const auto data = array.GetValues<uint8_t>(1, /*absolute_offset=*/0);\n             visit_value(string_view(\n                 reinterpret_cast<const char*>(data) + row * byte_width, byte_width));\n+            num_valid_values += 1;\n           } else if (!options.skip_nulls) {\n-            result = string_view();\n+            // If we encounter a null, exit the loop and mark num_row_values to\n\nReview Comment:\n   Same question here re: num_row_values\n\n\n\n##########\ncpp/src/arrow/compute/cast.cc:\n##########\n@@ -213,36 +201,48 @@ Result<const Kernel*> CastFunction::DispatchExact(\n   return candidate_kernels[0];\n }\n \n+Result<std::shared_ptr<CastFunction>> GetCastFunction(const TypeHolder& to_type) {\n+  return internal::GetCastFunctionInternal(to_type);\n\nReview Comment:\n   So there's `internal::GetCastFunction` which redirects to `internal::GetCastFunctionInternal`? Can this perhaps be simplified?\n\n\n\n##########\ncpp/src/arrow/compute/exec_test.cc:\n##########\n@@ -1154,8 +1155,9 @@ TEST_F(TestCallScalarFunction, ArgumentValidation) {\n   ASSERT_RAISES(Invalid, CallFunction(\"test_copy\", args));\n \n   // Cannot do scalar\n\nReview Comment:\n   Should this comment be removed since it now seems to be supported?\n\n\n\n##########\ncpp/src/arrow/compute/kernel.h:\n##########\n@@ -227,21 +208,16 @@ class ARROW_EXPORT InputType {\n   /// \\brief Render a human-readable string representation.\n   std::string ToString() const;\n \n-  /// \\brief Return true if the value matches this argument kind in type\n-  /// and shape.\n+  /// \\brief Return true if the Datum matches this argument kind in\n+  /// type (and only allows scalar or array-like Datums).\n   bool Matches(const Datum& value) const;\n \n-  /// \\brief Return true if the value descriptor matches this argument kind in\n-  /// type and shape.\n-  bool Matches(const ValueDescr& value) const;\n+  /// \\brief Return true if the type matches this InputType\n+  bool Matches(const TypeHolder& type) const;\n\nReview Comment:\n   Same here: why not `const DataType&`? I suppose this isn't keeping a copy of the `TypeHolder`?\n\n\n\n##########\ncpp/src/arrow/array/data.cc:\n##########\n@@ -174,27 +175,197 @@ void ArraySpan::SetMembers(const ArrayData& data) {\n   }\n }\n \n+template <typename offset_type>\n+void SetOffsetsForScalar(ArraySpan* span, uint8_t* buffer, int64_t value_size,\n\nReview Comment:\n   Make these helpers static/put them in the anonymous namespace?\n\n\n\n##########\ncpp/src/arrow/compute/kernels/scalar_cast_string.cc:\n##########\n@@ -323,14 +318,31 @@ BinaryToBinaryCastExec(KernelContext* ctx, const ExecSpan& batch, ExecResult* ou\n         arrow::internal::CopyBitmap(ctx->memory_pool(), input.buffers[0].data,\n                                     input.offset, input.length));\n   }\n-  // Data buffer (index 1) for FWBinary becomes data buffer for\n-  // VarBinary (index 2)\n-  output->buffers[2] = input.GetBuffer(1);\n+\n+  // This buffer is preallocated\n   output_offset_type* offsets = output->GetMutableValues<output_offset_type>(1);\n   offsets[0] = static_cast<output_offset_type>(input.offset * width);\n   for (int64_t i = 0; i < input.length; i++) {\n     offsets[i + 1] = offsets[i] + width;\n   }\n+\n+  // Data buffer (index 1) for FWBinary becomes data buffer for VarBinary\n+  // (index 2). After ARROW-16757, we need to copy this memory instead of\n+  // zero-copy it because a Scalar value promoted to an ArraySpan may be\n+  // referencing a temporary buffer whose scope does not extend beyond the\n+  // kernel execution. In that scenario, the validity bitmap above can be\n\nReview Comment:\n   This is a bit of a pity. Perhaps we should open a JIRA to try and improve this?\n\n\n\n##########\ncpp/src/arrow/compute/function.cc:\n##########\n@@ -186,87 +170,106 @@ const Kernel* DispatchExactImpl(const Function* func,\n }  // namespace detail\n \n Result<const Kernel*> Function::DispatchExact(\n-    const std::vector<ValueDescr>& values) const {\n+    const std::vector<TypeHolder>& values) const {\n   if (kind_ == Function::META) {\n     return Status::NotImplemented(\"Dispatch for a MetaFunction's Kernels\");\n   }\n-  RETURN_NOT_OK(CheckArity(values));\n+  RETURN_NOT_OK(CheckArity(values.size()));\n \n   if (auto kernel = detail::DispatchExactImpl(this, values)) {\n     return kernel;\n   }\n   return detail::NoMatchingKernel(this, values);\n }\n \n-Result<const Kernel*> Function::DispatchBest(std::vector<ValueDescr>* values) const {\n+Result<const Kernel*> Function::DispatchBest(std::vector<TypeHolder>* values) const {\n   // TODO(ARROW-11508) permit generic conversions here\n   return DispatchExact(*values);\n }\n \n-Result<Datum> Function::Execute(const std::vector<Datum>& args,\n-                                const FunctionOptions* options, ExecContext* ctx) const {\n-  return ExecuteInternal(args, /*passed_length=*/-1, options, ctx);\n+namespace {\n+\n+/// \\brief Check that each Datum is of a \"value\" type, which means either\n+/// SCALAR, ARRAY, or CHUNKED_ARRAY.\n+Status CheckAllValues(const std::vector<Datum>& values) {\n+  for (const auto& value : values) {\n+    if (!value.is_value()) {\n+      return Status::Invalid(\"Tried executing function with non-value type: \",\n+                             value.ToString());\n+    }\n+  }\n+  return Status::OK();\n }\n \n-Result<Datum> Function::Execute(const ExecBatch& batch, const FunctionOptions* options,\n-                                ExecContext* ctx) const {\n-  return ExecuteInternal(batch.values, batch.length, options, ctx);\n+Status CheckOptions(const Function& function, const FunctionOptions* options) {\n+  if (options == nullptr && function.doc().options_required) {\n+    return Status::Invalid(\"Function '\", function.name(),\n+                           \"' cannot be called without options\");\n+  }\n+  return Status::OK();\n }\n \n-Result<Datum> Function::ExecuteInternal(const std::vector<Datum>& args,\n-                                        int64_t passed_length,\n-                                        const FunctionOptions* options,\n-                                        ExecContext* ctx) const {\n+Result<Datum> ExecuteInternal(const Function& func, std::vector<Datum> args,\n\nReview Comment:\n   For the record, if you want to further micro-optimize function execution, you might want to migrate `args` to `SmallVector`, to avoid dynamic allocation. Or perhaps that's a bit overkill.\n\n\n\n##########\ncpp/src/arrow/array/data.cc:\n##########\n@@ -174,27 +175,197 @@ void ArraySpan::SetMembers(const ArrayData& data) {\n   }\n }\n \n+template <typename offset_type>\n+void SetOffsetsForScalar(ArraySpan* span, uint8_t* buffer, int64_t value_size,\n+                         int buffer_index = 1) {\n+  auto offsets = reinterpret_cast<offset_type*>(buffer);\n+  offsets[0] = 0;\n+  offsets[1] = static_cast<offset_type>(value_size);\n+  span->buffers[buffer_index].data = buffer;\n+  span->buffers[buffer_index].size = 2 * sizeof(offset_type);\n+}\n+\n+int GetNumBuffers(const DataType& type) {\n+  switch (type.id()) {\n+    case Type::NA:\n+    case Type::STRUCT:\n+    case Type::FIXED_SIZE_LIST:\n+      return 1;\n+    case Type::BINARY:\n+    case Type::LARGE_BINARY:\n+    case Type::STRING:\n+    case Type::LARGE_STRING:\n+    case Type::DENSE_UNION:\n+      return 3;\n+    case Type::EXTENSION:\n+      // The number of buffers depends on the storage type\n+      return GetNumBuffers(\n+          *internal::checked_cast<const ExtensionType&>(type).storage_type());\n+    default:\n+      // Everything else has 2 buffers\n+      return 2;\n+  }\n+}\n+\n+namespace internal {\n+\n+void FillZeroLengthArray(const DataType* type, ArraySpan* span) {\n+  memset(span->scratch_space, 0x00, 16);\n\nReview Comment:\n   ```suggestion\r\n     memset(span->scratch_space, 0x00, sizeof(span->scratch_space));\r\n   ```\n\n\n\n##########\ncpp/src/arrow/array/data.cc:\n##########\n@@ -174,27 +175,197 @@ void ArraySpan::SetMembers(const ArrayData& data) {\n   }\n }\n \n+template <typename offset_type>\n+void SetOffsetsForScalar(ArraySpan* span, uint8_t* buffer, int64_t value_size,\n+                         int buffer_index = 1) {\n+  auto offsets = reinterpret_cast<offset_type*>(buffer);\n+  offsets[0] = 0;\n+  offsets[1] = static_cast<offset_type>(value_size);\n+  span->buffers[buffer_index].data = buffer;\n+  span->buffers[buffer_index].size = 2 * sizeof(offset_type);\n+}\n+\n+int GetNumBuffers(const DataType& type) {\n+  switch (type.id()) {\n+    case Type::NA:\n+    case Type::STRUCT:\n+    case Type::FIXED_SIZE_LIST:\n+      return 1;\n+    case Type::BINARY:\n+    case Type::LARGE_BINARY:\n+    case Type::STRING:\n+    case Type::LARGE_STRING:\n+    case Type::DENSE_UNION:\n+      return 3;\n+    case Type::EXTENSION:\n+      // The number of buffers depends on the storage type\n+      return GetNumBuffers(\n+          *internal::checked_cast<const ExtensionType&>(type).storage_type());\n+    default:\n+      // Everything else has 2 buffers\n+      return 2;\n+  }\n+}\n+\n+namespace internal {\n+\n+void FillZeroLengthArray(const DataType* type, ArraySpan* span) {\n+  memset(span->scratch_space, 0x00, 16);\n+\n+  span->type = type;\n+  span->length = 0;\n+  int num_buffers = GetNumBuffers(*type);\n+  for (int i = 0; i < num_buffers; ++i) {\n+    span->buffers[i].data = span->scratch_space;\n+    span->buffers[i].size = 0;\n+  }\n+\n+  for (int i = num_buffers; i < 3; ++i) {\n+    span->ClearBuffer(i);\n+  }\n+\n+  // Fill children\n+  span->child_data.resize(type->num_fields());\n+  for (int i = 0; i < type->num_fields(); ++i) {\n+    FillZeroLengthArray(type->field(i)->type().get(), &span->child_data[i]);\n+  }\n+}\n+\n+}  // namespace internal\n+\n void ArraySpan::FillFromScalar(const Scalar& value) {\n-  static const uint8_t kValidByte = 0x01;\n-  static const uint8_t kNullByte = 0x00;\n+  static uint8_t kTrueBit = 0x01;\n+  static uint8_t kFalseBit = 0x00;\n \n   this->type = value.type.get();\n   this->length = 1;\n \n-  // Populate null count and validity bitmap\n+  Type::type type_id = value.type->id();\n+\n+  // Populate null count and validity bitmap (only for non-union types)\n   this->null_count = value.is_valid ? 0 : 1;\n-  this->buffers[0].data = const_cast<uint8_t*>(value.is_valid ? &kValidByte : &kNullByte);\n-  this->buffers[0].size = 1;\n+  if (!is_union(type_id)) {\n+    this->buffers[0].data = value.is_valid ? &kTrueBit : &kFalseBit;\n+    this->buffers[0].size = 1;\n+  }\n \n-  if (is_primitive(value.type->id())) {\n-    const auto& scalar =\n-        internal::checked_cast<const internal::PrimitiveScalarBase&>(value);\n+  if (type_id == Type::BOOL) {\n+    const auto& scalar = checked_cast<const BooleanScalar&>(value);\n+    this->buffers[1].data = scalar.value ? &kTrueBit : &kFalseBit;\n+    this->buffers[1].size = 1;\n+  } else if (is_primitive(type_id) || is_decimal(type_id) ||\n+             type_id == Type::DICTIONARY) {\n+    const auto& scalar = checked_cast<const internal::PrimitiveScalarBase&>(value);\n     const uint8_t* scalar_data = reinterpret_cast<const uint8_t*>(scalar.view().data());\n     this->buffers[1].data = const_cast<uint8_t*>(scalar_data);\n     this->buffers[1].size = scalar.type->byte_width();\n+    if (type_id == Type::DICTIONARY) {\n+      // Populate dictionary data\n+      const auto& dict_scalar = checked_cast<const DictionaryScalar&>(value);\n+      this->child_data.resize(1);\n+      this->child_data[0].SetMembers(*dict_scalar.value.dictionary->data());\n+    }\n+  } else if (is_base_binary_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = this->scratch_space;\n+    const uint8_t* data_buffer = nullptr;\n+    int64_t data_size = 0;\n+    if (scalar.is_valid) {\n+      data_buffer = scalar.value->data();\n+      data_size = scalar.value->size();\n+    }\n+    if (is_binary_like(type_id)) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, data_size);\n+    } else {\n+      // is_large_binary_like\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, data_size);\n+    }\n+    this->buffers[2].data = const_cast<uint8_t*>(data_buffer);\n+    this->buffers[2].size = data_size;\n+  } else if (type_id == Type::FIXED_SIZE_BINARY) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = const_cast<uint8_t*>(scalar.value->data());\n+    this->buffers[1].size = scalar.value->size();\n+  } else if (is_list_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseListScalar&>(value);\n+\n+    int64_t value_length = 0;\n+    this->child_data.resize(1);\n+    if (scalar.value != nullptr) {\n+      // When the scalar is null, scalar.value can also be null\n+      this->child_data[0].SetMembers(*scalar.value->data());\n+      value_length = scalar.value->length();\n+    } else {\n+      // Even when the value is null, we still must populate the\n+      // child_data to yield a valid array. Tedious\n+      internal::FillZeroLengthArray(this->type->field(0)->type().get(),\n+                                    &this->child_data[0]);\n+    }\n+\n+    if (type_id == Type::LIST || type_id == Type::MAP) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, value_length);\n+    } else if (type_id == Type::LARGE_LIST) {\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, value_length);\n+    } else {\n+      // FIXED_SIZE_LIST: does not have a second buffer\n+      this->buffers[1].data = nullptr;\n+      this->buffers[1].size = 0;\n+    }\n+  } else if (type_id == Type::STRUCT) {\n+    const auto& scalar = checked_cast<const StructScalar&>(value);\n+    this->child_data.resize(this->type->num_fields());\n+    DCHECK_EQ(this->type->num_fields(), static_cast<int>(scalar.value.size()));\n+    for (size_t i = 0; i < scalar.value.size(); ++i) {\n+      this->child_data[i].FillFromScalar(*scalar.value[i]);\n+    }\n+  } else if (is_union(type_id)) {\n+    // First buffer is kept null since unions have no validity vector\n+    this->buffers[0].data = nullptr;\n+    this->buffers[0].size = 0;\n+\n+    this->buffers[1].data = this->scratch_space;\n+    this->buffers[1].size = 1;\n+    int8_t* type_codes = reinterpret_cast<int8_t*>(this->scratch_space);\n+    type_codes[0] = checked_cast<const UnionScalar&>(value).type_code;\n+\n+    this->child_data.resize(this->type->num_fields());\n+    if (type_id == Type::DENSE_UNION) {\n+      const auto& scalar = checked_cast<const DenseUnionScalar&>(value);\n+      // Has offset; start 4 bytes in so it's aligned to a 32-bit boundaries\n\nReview Comment:\n   What does adding 4 change to 4-alignment?\n\n\n\n##########\ncpp/src/arrow/compute/kernels/scalar_compare.cc:\n##########\n@@ -645,13 +581,17 @@ struct FixedSizeBinaryScalarMinMax {\n         result = result.empty() ? value : Op::Call(result, value);\n       };\n \n+      int num_valid_values = 0;\n       for (int col = 0; col < batch.num_values(); col++) {\n         if (batch[col].is_scalar()) {\n           const Scalar& scalar = *batch[col].scalar;\n           if (scalar.is_valid) {\n             visit_value(UnboxScalar<FixedSizeBinaryType>::Unbox(scalar));\n+            num_valid_values += 1;\n           } else if (!options.skip_nulls) {\n-            result = string_view();\n+            // If we encounter a null, exit the loop and mark num_row_values to\n\nReview Comment:\n   Hmm, I don't see a num_row_values?\n\n\n\n##########\ncpp/src/arrow/compute/function_benchmark.cc:\n##########\n@@ -153,31 +151,26 @@ void BM_ExecuteScalarFunctionOnScalar(benchmark::State& state) {\n \n void BM_ExecuteScalarKernelOnScalar(benchmark::State& state) {\n   // Execute a trivial function, with argument dispatch outside the hot path\n-  const int64_t N = 10000;\n-\n   auto function = *GetFunctionRegistry()->GetFunction(\"is_valid\");\n-  auto kernel = *function->DispatchExact({ValueDescr::Scalar(int64())});\n+  auto kernel = *function->DispatchExact({int64()});\n   const auto& exec = static_cast<const ScalarKernel&>(*kernel).exec;\n \n-  const auto scalars = MakeScalarsForIsValid(N);\n-\n   ExecContext exec_context;\n   KernelContext kernel_context(&exec_context);\n \n-  ExecSpan input;\n-  input.length = 1;\n+  ASSERT_OK_AND_ASSIGN(std::shared_ptr<Array> input_arr, MakeArrayOfNull(int64(), 1));\n+  ExecSpan input({*input_arr->data()}, 1);\n+\n+  ExecResult output;\n+  ASSERT_OK_AND_ASSIGN(std::shared_ptr<Array> output_arr, MakeArrayOfNull(int64(), 1));\n+  output.array_span()->SetMembers(*output_arr->data());\n+\n+  const int64_t N = 10000;\n   for (auto _ : state) {\n-    int64_t total = 0;\n-    for (const std::shared_ptr<Scalar>& scalar : scalars) {\n-      ExecResult result;\n-      result.value = MakeNullScalar(int64());\n-      input.values = {scalar.get()};\n-      ABORT_NOT_OK(exec(&kernel_context, input, &result));\n-      total += result.scalar()->is_valid;\n+    for (int i = 0; i < N; ++i) {\n+      ABORT_NOT_OK(exec(&kernel_context, input, &output));\n     }\n-    benchmark::DoNotOptimize(total);\n\nReview Comment:\n   This was meant to ensure that the compiler didn't start to optimize the computation away. Not sure whether it's actually necessary but probably good to keep?\n\n\n\n##########\ncpp/src/arrow/python/udf.cc:\n##########\n@@ -73,34 +66,29 @@ struct PythonUdf {\n     OwnedRef result(cb(function->obj(), udf_context, arg_tuple.obj()));\n     RETURN_NOT_OK(CheckPyError());\n     // unwrapping the output for expected output type\n-    if (is_scalar(result.obj())) {\n-      if (out->is_array_data()) {\n-        return Status::TypeError(\n-            \"UDF executor expected an array result but a \"\n-            \"scalar was returned\");\n-      }\n-      ARROW_ASSIGN_OR_RAISE(std::shared_ptr<Scalar> val, unwrap_scalar(result.obj()));\n-      RETURN_NOT_OK(CheckOutputType(*output_type.type(), *val->type));\n-      out->value = val;\n-      return Status::OK();\n-    } else if (is_array(result.obj())) {\n-      if (out->is_scalar()) {\n-        return Status::TypeError(\n-            \"UDF executor expected a scalar result but an \"\n-            \"array was returned\");\n-      }\n+    if (is_array(result.obj())) {\n       ARROW_ASSIGN_OR_RAISE(std::shared_ptr<Array> val, unwrap_array(result.obj()));\n-      RETURN_NOT_OK(CheckOutputType(*output_type.type(), *val->type()));\n+      if (!output_type->Equals(*val->type())) {\n+        return Status::TypeError(\"Expected output datatype \", output_type->ToString(),\n+                                 \", but function returned datatype \",\n+                                 val->type()->ToString());\n+      }\n       out->value = std::move(val->data());\n       return Status::OK();\n     } else {\n       return Status::TypeError(\"Unexpected output type: \", Py_TYPE(result.obj())->tp_name,\n-                               \" (expected Scalar or Array)\");\n+                               \" (expected Array)\");\n     }\n     return Status::OK();\n   }\n };\n \n+Status PythonUdfExec(compute::KernelContext* ctx, const ExecSpan& batch,\n+                     ExecResult* out) {\n+  auto udf = static_cast<PythonUdf*>(ctx->kernel()->data.get());\n\nReview Comment:\n   Is it possible to use `checked_cast` here?\n\n\n\n##########\ncpp/src/arrow/compute/function.cc:\n##########\n@@ -275,9 +278,9 @@ Result<Datum> Function::ExecuteInternal(const std::vector<Datum>& args,\n     bool all_same_length = false;\n     int64_t inferred_length = detail::InferBatchLength(input.values, &all_same_length);\n     input.length = inferred_length;\n-    if (kind() == Function::SCALAR) {\n+    if (func.kind() == Function::SCALAR) {\n       DCHECK(passed_length == -1 || passed_length == inferred_length);\n\nReview Comment:\n   Code didn't change in this PR, but could we change this `DCHECK` into a proper error return?\n\n\n\n##########\ncpp/src/arrow/scalar.h:\n##########\n@@ -479,37 +480,52 @@ struct ARROW_EXPORT StructScalar : public Scalar {\n \n   Result<std::shared_ptr<Scalar>> field(FieldRef ref) const;\n \n-  StructScalar(ValueType value, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)) {}\n+  StructScalar(ValueType value, std::shared_ptr<DataType> type, bool is_valid = true)\n+      : Scalar(std::move(type), is_valid), value(std::move(value)) {}\n \n   static Result<std::shared_ptr<StructScalar>> Make(ValueType value,\n                                                     std::vector<std::string> field_names);\n-\n-  explicit StructScalar(std::shared_ptr<DataType> type) : Scalar(std::move(type)) {}\n };\n \n struct ARROW_EXPORT UnionScalar : public Scalar {\n-  using Scalar::Scalar;\n-  using ValueType = std::shared_ptr<Scalar>;\n-\n-  ValueType value;\n   int8_t type_code;\n \n-  UnionScalar(int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), false), type_code(type_code) {}\n-\n-  UnionScalar(ValueType value, int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)), type_code(type_code) {}\n+ protected:\n+  UnionScalar(std::shared_ptr<DataType> type, int8_t type_code, bool is_valid)\n+      : Scalar(std::move(type), is_valid), type_code(type_code) {}\n };\n \n struct ARROW_EXPORT SparseUnionScalar : public UnionScalar {\n-  using UnionScalar::UnionScalar;\n   using TypeClass = SparseUnionType;\n+\n+  // Even though only one of the union values is relevant for this scalar, we\n+  // nonetheless construct a vector of scalars, one per union value, to have\n+  // enough data to reconstruct a valid ArraySpan of length 1 from this scalar\n+  using ValueType = std::vector<std::shared_ptr<Scalar>>;\n+  ValueType value;\n+\n+  // The value index corresponding to the active type code\n+  int child_id;\n\nReview Comment:\n   Can we also have a `const std::shared_ptr<Scalar>& child_value() const` accessor to ease the work of SparseUnionScalar consumers?\n\n\n\n##########\ncpp/src/arrow/scalar.h:\n##########\n@@ -479,37 +480,52 @@ struct ARROW_EXPORT StructScalar : public Scalar {\n \n   Result<std::shared_ptr<Scalar>> field(FieldRef ref) const;\n \n-  StructScalar(ValueType value, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)) {}\n+  StructScalar(ValueType value, std::shared_ptr<DataType> type, bool is_valid = true)\n+      : Scalar(std::move(type), is_valid), value(std::move(value)) {}\n \n   static Result<std::shared_ptr<StructScalar>> Make(ValueType value,\n                                                     std::vector<std::string> field_names);\n-\n-  explicit StructScalar(std::shared_ptr<DataType> type) : Scalar(std::move(type)) {}\n };\n \n struct ARROW_EXPORT UnionScalar : public Scalar {\n-  using Scalar::Scalar;\n-  using ValueType = std::shared_ptr<Scalar>;\n-\n-  ValueType value;\n   int8_t type_code;\n \n-  UnionScalar(int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), false), type_code(type_code) {}\n-\n-  UnionScalar(ValueType value, int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)), type_code(type_code) {}\n+ protected:\n+  UnionScalar(std::shared_ptr<DataType> type, int8_t type_code, bool is_valid)\n+      : Scalar(std::move(type), is_valid), type_code(type_code) {}\n };\n \n struct ARROW_EXPORT SparseUnionScalar : public UnionScalar {\n-  using UnionScalar::UnionScalar;\n   using TypeClass = SparseUnionType;\n+\n+  // Even though only one of the union values is relevant for this scalar, we\n+  // nonetheless construct a vector of scalars, one per union value, to have\n+  // enough data to reconstruct a valid ArraySpan of length 1 from this scalar\n+  using ValueType = std::vector<std::shared_ptr<Scalar>>;\n+  ValueType value;\n+\n+  // The value index corresponding to the active type code\n+  int child_id;\n+\n+  SparseUnionScalar(ValueType value, int8_t type_code, std::shared_ptr<DataType> type);\n+\n+  /// \\brief Construct a SparseUnionScalar from a single value, versus having\n+  /// to construct a vector of scalars\n+  static std::shared_ptr<Scalar> FromValue(std::shared_ptr<Scalar> value, int field_index,\n+                                           std::shared_ptr<DataType> type);\n };\n \n struct ARROW_EXPORT DenseUnionScalar : public UnionScalar {\n-  using UnionScalar::UnionScalar;\n   using TypeClass = DenseUnionType;\n+\n+  // For DenseUnionScalar, we can make a valid ArraySpan of length 1 from this\n+  // scalar\n+  using ValueType = std::shared_ptr<Scalar>;\n+  ValueType value;\n\nReview Comment:\n   If we add `const std::shared_ptr<Scalar>& child_value() const` to SparseUnionScalar, can we also add it here for consistency and to allow more code reuse at call sites?\n\n\n\n##########\ncpp/src/arrow/scalar.cc:\n##########\n@@ -703,7 +792,11 @@ std::string Scalar::ToString() const {\n   if (maybe_repr.ok()) {\n     return checked_cast<const StringScalar&>(*maybe_repr.ValueOrDie()).value->ToString();\n   }\n-  return \"...\";\n+\n+  std::string result;\n\nReview Comment:\n   Should we instead open a JIRA if the scalar cast is not implemented for some types?\n\n\n\n##########\ncpp/src/arrow/scalar_test.cc:\n##########\n@@ -1370,27 +1373,61 @@ TEST(TestDictionaryScalar, Cast) {\n   }\n }\n \n+const Scalar& GetUnionValue(const Scalar& value) {\n+  if (value.type->id() == Type::DENSE_UNION) {\n+    return *checked_cast<const DenseUnionScalar&>(value).value;\n+  } else {\n+    const auto& union_scalar = checked_cast<const SparseUnionScalar&>(value);\n+    return *union_scalar.value[union_scalar.child_id];\n+  }\n+}\n+\n void CheckGetValidUnionScalar(const Array& arr, int64_t index, const Scalar& expected,\n                               const Scalar& expected_value) {\n   ASSERT_OK_AND_ASSIGN(auto scalar, arr.GetScalar(index));\n   ASSERT_OK(scalar->ValidateFull());\n   ASSERT_TRUE(scalar->Equals(expected));\n \n-  const auto& as_union = checked_cast<const UnionScalar&>(*scalar);\n-  ASSERT_TRUE(as_union.is_valid);\n-  ASSERT_TRUE(as_union.value->Equals(expected_value));\n+  ASSERT_TRUE(scalar->is_valid);\n+  ASSERT_TRUE(GetUnionValue(*scalar).Equals(expected_value));\n }\n \n void CheckGetNullUnionScalar(const Array& arr, int64_t index) {\n   ASSERT_OK_AND_ASSIGN(auto scalar, arr.GetScalar(index));\n   ASSERT_TRUE(scalar->Equals(MakeNullScalar(arr.type())));\n \n-  const auto& as_union = checked_cast<const UnionScalar&>(*scalar);\n-  ASSERT_FALSE(as_union.is_valid);\n-  // XXX in reality, the union array doesn't have a validity bitmap.\n-  // Validity is inferred from the underlying child value, which should maybe\n-  // be reflected here...\n-  ASSERT_EQ(as_union.value, nullptr);\n+  ASSERT_FALSE(scalar->is_valid);\n+  ASSERT_FALSE(GetUnionValue(*scalar).is_valid);\n+}\n+\n+std::shared_ptr<Scalar> MakeUnionScalar(const SparseUnionType& type,\n\nReview Comment:\n   These four specific helpers might be useful enough to be made static methods of `{Dense,Sparse}UnionScalar` ?\n\n\n\n##########\ncpp/src/arrow/type.h:\n##########\n@@ -210,9 +210,68 @@ class ARROW_EXPORT DataType : public std::enable_shared_from_this<DataType>,\n   ARROW_DISALLOW_COPY_AND_ASSIGN(DataType);\n };\n \n+/// \\brief EXPERIMENTAL: Container for a type pointer which can hold a\n+/// dynamically created shared_ptr<DataType> if it needs to.\n+struct ARROW_EXPORT TypeHolder {\n+  const DataType* type = NULLPTR;\n+  std::shared_ptr<DataType> owned_type;\n+\n+  TypeHolder() = default;\n+  TypeHolder(const TypeHolder& other) = default;\n+  TypeHolder& operator=(const TypeHolder& other) = default;\n+  TypeHolder(TypeHolder&& other) = default;\n+  TypeHolder& operator=(TypeHolder&& other) = default;\n+\n+  TypeHolder(std::shared_ptr<DataType> owned_type)  // NOLINT implicit construction\n+      : type(owned_type.get()), owned_type(std::move(owned_type)) {}\n+\n+  TypeHolder(const DataType* type)  // NOLINT implicit construction\n+      : type(type) {}\n+\n+  Type::type id() const { return this->type->id(); }\n+\n+  std::shared_ptr<DataType> GetSharedPtr() const {\n+    return this->type != NULLPTR ? this->type->GetSharedPtr() : NULLPTR;\n+  }\n+\n+  const DataType& operator*() const { return *this->type; }\n+\n+  operator bool() { return this->type != NULLPTR; }\n+\n+  bool operator==(const TypeHolder& other) const {\n+    if (type == other.type) return true;\n+    if (type == NULLPTR || other.type == NULLPTR) return false;\n+    return type->Equals(*other.type);\n+  }\n+\n+  bool operator==(decltype(NULLPTR)) const { return this->type == NULLPTR; }\n+\n+  bool operator==(const DataType& other) const {\n+    if (this->type == NULLPTR) return false;\n+    return other.Equals(*this->type);\n+  }\n+\n+  bool operator!=(const DataType& other) const { return !(*this == other); }\n+\n+  bool operator==(const std::shared_ptr<DataType>& other) const {\n\nReview Comment:\n   Neither does this one?\n\n\n\n##########\ncpp/src/arrow/type.h:\n##########\n@@ -210,9 +210,68 @@ class ARROW_EXPORT DataType : public std::enable_shared_from_this<DataType>,\n   ARROW_DISALLOW_COPY_AND_ASSIGN(DataType);\n };\n \n+/// \\brief EXPERIMENTAL: Container for a type pointer which can hold a\n+/// dynamically created shared_ptr<DataType> if it needs to.\n+struct ARROW_EXPORT TypeHolder {\n+  const DataType* type = NULLPTR;\n+  std::shared_ptr<DataType> owned_type;\n+\n+  TypeHolder() = default;\n+  TypeHolder(const TypeHolder& other) = default;\n+  TypeHolder& operator=(const TypeHolder& other) = default;\n+  TypeHolder(TypeHolder&& other) = default;\n+  TypeHolder& operator=(TypeHolder&& other) = default;\n+\n+  TypeHolder(std::shared_ptr<DataType> owned_type)  // NOLINT implicit construction\n+      : type(owned_type.get()), owned_type(std::move(owned_type)) {}\n+\n+  TypeHolder(const DataType* type)  // NOLINT implicit construction\n+      : type(type) {}\n+\n+  Type::type id() const { return this->type->id(); }\n+\n+  std::shared_ptr<DataType> GetSharedPtr() const {\n+    return this->type != NULLPTR ? this->type->GetSharedPtr() : NULLPTR;\n+  }\n+\n+  const DataType& operator*() const { return *this->type; }\n+\n+  operator bool() { return this->type != NULLPTR; }\n+\n+  bool operator==(const TypeHolder& other) const {\n+    if (type == other.type) return true;\n+    if (type == NULLPTR || other.type == NULLPTR) return false;\n+    return type->Equals(*other.type);\n+  }\n+\n+  bool operator==(decltype(NULLPTR)) const { return this->type == NULLPTR; }\n\nReview Comment:\n   This one has no corresponding `operator!=`?\n\n\n\n##########\ncpp/src/arrow/compute/kernel.cc:\n##########\n@@ -87,7 +87,9 @@ class SameTypeIdMatcher : public TypeMatcher {\n  public:\n   explicit SameTypeIdMatcher(Type::type accepted_id) : accepted_id_(accepted_id) {}\n \n-  bool Matches(const DataType& type) const override { return type.id() == accepted_id_; }\n+  bool Matches(const TypeHolder& type) const override {\n\nReview Comment:\n   Is there a reason to change this? `type` is not stored and it's probably a bit more efficient to simply pass `const DataType&`.\n\n\n\n##########\ncpp/src/arrow/array/data.cc:\n##########\n@@ -174,27 +175,197 @@ void ArraySpan::SetMembers(const ArrayData& data) {\n   }\n }\n \n+template <typename offset_type>\n+void SetOffsetsForScalar(ArraySpan* span, uint8_t* buffer, int64_t value_size,\n+                         int buffer_index = 1) {\n+  auto offsets = reinterpret_cast<offset_type*>(buffer);\n+  offsets[0] = 0;\n+  offsets[1] = static_cast<offset_type>(value_size);\n+  span->buffers[buffer_index].data = buffer;\n+  span->buffers[buffer_index].size = 2 * sizeof(offset_type);\n+}\n+\n+int GetNumBuffers(const DataType& type) {\n+  switch (type.id()) {\n+    case Type::NA:\n+    case Type::STRUCT:\n+    case Type::FIXED_SIZE_LIST:\n+      return 1;\n+    case Type::BINARY:\n+    case Type::LARGE_BINARY:\n+    case Type::STRING:\n+    case Type::LARGE_STRING:\n+    case Type::DENSE_UNION:\n+      return 3;\n+    case Type::EXTENSION:\n+      // The number of buffers depends on the storage type\n+      return GetNumBuffers(\n+          *internal::checked_cast<const ExtensionType&>(type).storage_type());\n+    default:\n+      // Everything else has 2 buffers\n+      return 2;\n+  }\n+}\n+\n+namespace internal {\n+\n+void FillZeroLengthArray(const DataType* type, ArraySpan* span) {\n+  memset(span->scratch_space, 0x00, 16);\n+\n+  span->type = type;\n+  span->length = 0;\n+  int num_buffers = GetNumBuffers(*type);\n+  for (int i = 0; i < num_buffers; ++i) {\n+    span->buffers[i].data = span->scratch_space;\n+    span->buffers[i].size = 0;\n+  }\n+\n+  for (int i = num_buffers; i < 3; ++i) {\n+    span->ClearBuffer(i);\n+  }\n+\n+  // Fill children\n+  span->child_data.resize(type->num_fields());\n+  for (int i = 0; i < type->num_fields(); ++i) {\n+    FillZeroLengthArray(type->field(i)->type().get(), &span->child_data[i]);\n+  }\n+}\n+\n+}  // namespace internal\n+\n void ArraySpan::FillFromScalar(const Scalar& value) {\n-  static const uint8_t kValidByte = 0x01;\n-  static const uint8_t kNullByte = 0x00;\n+  static uint8_t kTrueBit = 0x01;\n+  static uint8_t kFalseBit = 0x00;\n \n   this->type = value.type.get();\n   this->length = 1;\n \n-  // Populate null count and validity bitmap\n+  Type::type type_id = value.type->id();\n+\n+  // Populate null count and validity bitmap (only for non-union types)\n\nReview Comment:\n   Even for `Type::NA`?\n\n\n\n##########\npython/pyarrow/scalar.pxi:\n##########\n@@ -931,12 +938,15 @@ cdef class ExtensionScalar(Scalar):\n         else:\n             storage = scalar(value, typ.storage_type)\n \n-        sp_scalar = make_shared[CExtensionScalar](typ.sp_type)\n-        ext_scalar = sp_scalar.get()\n-        ext_scalar.is_valid = storage is not None and storage.is_valid\n-        if ext_scalar.is_valid:\n-            ext_scalar.value = pyarrow_unwrap_scalar(storage)\n-        check_status(ext_scalar.Validate())\n+        cdef c_bool is_valid = storage is not None and storage.is_valid\n+        if is_valid:\n+            sp_storage = pyarrow_unwrap_scalar(storage)\n+        else:\n+            sp_storage = MakeNullScalar((<DataType> typ.storage_type).sp_type)\n\nReview Comment:\n   Hmm, if `storage is not None`, then we should also use `pyarrow_unwrap_scalar(storage)`, no?\n\n\n\n##########\ncpp/gdb_arrow.py:\n##########\n@@ -1463,7 +1464,24 @@ def to_string(self):\n         return f\"{self._format_type()}\"\n \n \n-class UnionScalarPrinter(ScalarPrinter):\n+class SparseUnionScalarPrinter(ScalarPrinter):\n+    \"\"\"\n+    Pretty-printer for arrow::UnionScalar and subclasses.\n\nReview Comment:\n   ```suggestion\r\n       Pretty-printer for arrow::SparseUnionScalar.\r\n   ```\n\n\n\n##########\ncpp/src/arrow/array/data.cc:\n##########\n@@ -174,27 +175,197 @@ void ArraySpan::SetMembers(const ArrayData& data) {\n   }\n }\n \n+template <typename offset_type>\n+void SetOffsetsForScalar(ArraySpan* span, uint8_t* buffer, int64_t value_size,\n+                         int buffer_index = 1) {\n+  auto offsets = reinterpret_cast<offset_type*>(buffer);\n+  offsets[0] = 0;\n+  offsets[1] = static_cast<offset_type>(value_size);\n+  span->buffers[buffer_index].data = buffer;\n+  span->buffers[buffer_index].size = 2 * sizeof(offset_type);\n+}\n+\n+int GetNumBuffers(const DataType& type) {\n+  switch (type.id()) {\n+    case Type::NA:\n+    case Type::STRUCT:\n+    case Type::FIXED_SIZE_LIST:\n+      return 1;\n+    case Type::BINARY:\n+    case Type::LARGE_BINARY:\n+    case Type::STRING:\n+    case Type::LARGE_STRING:\n+    case Type::DENSE_UNION:\n+      return 3;\n+    case Type::EXTENSION:\n+      // The number of buffers depends on the storage type\n+      return GetNumBuffers(\n+          *internal::checked_cast<const ExtensionType&>(type).storage_type());\n+    default:\n+      // Everything else has 2 buffers\n+      return 2;\n+  }\n+}\n+\n+namespace internal {\n+\n+void FillZeroLengthArray(const DataType* type, ArraySpan* span) {\n+  memset(span->scratch_space, 0x00, 16);\n+\n+  span->type = type;\n+  span->length = 0;\n+  int num_buffers = GetNumBuffers(*type);\n+  for (int i = 0; i < num_buffers; ++i) {\n+    span->buffers[i].data = span->scratch_space;\n+    span->buffers[i].size = 0;\n+  }\n+\n+  for (int i = num_buffers; i < 3; ++i) {\n+    span->ClearBuffer(i);\n+  }\n+\n+  // Fill children\n+  span->child_data.resize(type->num_fields());\n+  for (int i = 0; i < type->num_fields(); ++i) {\n+    FillZeroLengthArray(type->field(i)->type().get(), &span->child_data[i]);\n+  }\n+}\n+\n+}  // namespace internal\n+\n void ArraySpan::FillFromScalar(const Scalar& value) {\n-  static const uint8_t kValidByte = 0x01;\n-  static const uint8_t kNullByte = 0x00;\n+  static uint8_t kTrueBit = 0x01;\n+  static uint8_t kFalseBit = 0x00;\n \n   this->type = value.type.get();\n   this->length = 1;\n \n-  // Populate null count and validity bitmap\n+  Type::type type_id = value.type->id();\n+\n+  // Populate null count and validity bitmap (only for non-union types)\n   this->null_count = value.is_valid ? 0 : 1;\n-  this->buffers[0].data = const_cast<uint8_t*>(value.is_valid ? &kValidByte : &kNullByte);\n-  this->buffers[0].size = 1;\n+  if (!is_union(type_id)) {\n+    this->buffers[0].data = value.is_valid ? &kTrueBit : &kFalseBit;\n+    this->buffers[0].size = 1;\n+  }\n \n-  if (is_primitive(value.type->id())) {\n-    const auto& scalar =\n-        internal::checked_cast<const internal::PrimitiveScalarBase&>(value);\n+  if (type_id == Type::BOOL) {\n+    const auto& scalar = checked_cast<const BooleanScalar&>(value);\n+    this->buffers[1].data = scalar.value ? &kTrueBit : &kFalseBit;\n+    this->buffers[1].size = 1;\n+  } else if (is_primitive(type_id) || is_decimal(type_id) ||\n+             type_id == Type::DICTIONARY) {\n+    const auto& scalar = checked_cast<const internal::PrimitiveScalarBase&>(value);\n     const uint8_t* scalar_data = reinterpret_cast<const uint8_t*>(scalar.view().data());\n     this->buffers[1].data = const_cast<uint8_t*>(scalar_data);\n     this->buffers[1].size = scalar.type->byte_width();\n+    if (type_id == Type::DICTIONARY) {\n+      // Populate dictionary data\n+      const auto& dict_scalar = checked_cast<const DictionaryScalar&>(value);\n+      this->child_data.resize(1);\n+      this->child_data[0].SetMembers(*dict_scalar.value.dictionary->data());\n+    }\n+  } else if (is_base_binary_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = this->scratch_space;\n+    const uint8_t* data_buffer = nullptr;\n+    int64_t data_size = 0;\n+    if (scalar.is_valid) {\n+      data_buffer = scalar.value->data();\n+      data_size = scalar.value->size();\n+    }\n+    if (is_binary_like(type_id)) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, data_size);\n+    } else {\n+      // is_large_binary_like\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, data_size);\n+    }\n+    this->buffers[2].data = const_cast<uint8_t*>(data_buffer);\n+    this->buffers[2].size = data_size;\n+  } else if (type_id == Type::FIXED_SIZE_BINARY) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = const_cast<uint8_t*>(scalar.value->data());\n+    this->buffers[1].size = scalar.value->size();\n+  } else if (is_list_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseListScalar&>(value);\n+\n+    int64_t value_length = 0;\n+    this->child_data.resize(1);\n+    if (scalar.value != nullptr) {\n+      // When the scalar is null, scalar.value can also be null\n+      this->child_data[0].SetMembers(*scalar.value->data());\n+      value_length = scalar.value->length();\n+    } else {\n+      // Even when the value is null, we still must populate the\n+      // child_data to yield a valid array. Tedious\n+      internal::FillZeroLengthArray(this->type->field(0)->type().get(),\n+                                    &this->child_data[0]);\n+    }\n+\n+    if (type_id == Type::LIST || type_id == Type::MAP) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, value_length);\n+    } else if (type_id == Type::LARGE_LIST) {\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, value_length);\n+    } else {\n+      // FIXED_SIZE_LIST: does not have a second buffer\n+      this->buffers[1].data = nullptr;\n+      this->buffers[1].size = 0;\n+    }\n+  } else if (type_id == Type::STRUCT) {\n+    const auto& scalar = checked_cast<const StructScalar&>(value);\n+    this->child_data.resize(this->type->num_fields());\n+    DCHECK_EQ(this->type->num_fields(), static_cast<int>(scalar.value.size()));\n+    for (size_t i = 0; i < scalar.value.size(); ++i) {\n+      this->child_data[i].FillFromScalar(*scalar.value[i]);\n+    }\n+  } else if (is_union(type_id)) {\n+    // First buffer is kept null since unions have no validity vector\n+    this->buffers[0].data = nullptr;\n+    this->buffers[0].size = 0;\n+\n+    this->buffers[1].data = this->scratch_space;\n+    this->buffers[1].size = 1;\n+    int8_t* type_codes = reinterpret_cast<int8_t*>(this->scratch_space);\n+    type_codes[0] = checked_cast<const UnionScalar&>(value).type_code;\n+\n+    this->child_data.resize(this->type->num_fields());\n+    if (type_id == Type::DENSE_UNION) {\n+      const auto& scalar = checked_cast<const DenseUnionScalar&>(value);\n+      // Has offset; start 4 bytes in so it's aligned to a 32-bit boundaries\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space + sizeof(int32_t), 1,\n+                                   /*buffer_index=*/2);\n+      // We can't \"see\" the other arrays in the union, but we put the \"active\"\n+      // union array in the right place and fill zero-length arrays for the\n+      // others\n+      const std::vector<int>& child_ids =\n+          static_cast<const UnionType*>(this->type)->child_ids();\n\nReview Comment:\n   ```suggestion\r\n         const std::vector<int>& child_ids =\r\n             checked_cast<const UnionType*>(this->type)->child_ids();\r\n   ```\n\n\n\n##########\ncpp/src/arrow/scalar_test.cc:\n##########\n@@ -1429,19 +1477,37 @@ class TestUnionScalar : public ::testing::Test {\n \n   void TestValidateErrors() {\n     // Type code doesn't exist\n-    AssertValidationFails(ScalarType(alpha_, 0, type_));\n-    AssertValidationFails(ScalarType(alpha_, 0, type_));\n-    AssertValidationFails(ScalarType(0, type_));\n-    AssertValidationFails(ScalarType(alpha_, -42, type_));\n-    AssertValidationFails(ScalarType(-42, type_));\n+    auto scalar = ScalarFromValue(0, alpha_);\n+    UnionScalar* union_scalar = static_cast<UnionScalar*>(scalar.get());\n+\n+    // Invalid type code\n\nReview Comment:\n   Is this redundant with the previous comment above?\n\n\n\n##########\ncpp/gdb_arrow.py:\n##########\n@@ -1463,7 +1464,24 @@ def to_string(self):\n         return f\"{self._format_type()}\"\n \n \n-class UnionScalarPrinter(ScalarPrinter):\n+class SparseUnionScalarPrinter(ScalarPrinter):\n+    \"\"\"\n+    Pretty-printer for arrow::UnionScalar and subclasses.\n+    \"\"\"\n+\n+    def to_string(self):\n+        type_code = self.val['type_code'].cast(gdb.lookup_type('int'))\n+        if not self.is_valid:\n+            return (f\"{self._format_type()} of type {self.type}, \"\n+                    f\"type code {type_code}, null value\")\n+        eval_values = StdVector(self.val['value'])\n+        child_id = self.val['child_id'].cast(gdb.lookup_type('int'))\n+        return (f\"{self._format_type()} of type code {type_code}, \"\n+                f\"value {deref(eval_values[child_id])}\")\n+\n+\n+\n+class DenseUnionScalarPrinter(ScalarPrinter):\n     \"\"\"\n     Pretty-printer for arrow::UnionScalar and subclasses.\n\nReview Comment:\n   ```suggestion\r\n       Pretty-printer for arrow::DenseUnionScalar and subclasses.\r\n   ```\r\n   \n\n\n\n##########\ncpp/src/arrow/compute/exec/expression.h:\n##########\n@@ -55,7 +55,7 @@ class ARROW_EXPORT Expression {\n     std::shared_ptr<Function> function;\n     const Kernel* kernel = NULLPTR;\n     std::shared_ptr<KernelState> kernel_state;\n-    ValueDescr descr;\n+    TypeHolder type;\n\nReview Comment:\n   @bkietz @westonpace Does this look generally ok?\n\n\n\n##########\ncpp/src/arrow/compute/kernel.cc:\n##########\n@@ -348,22 +335,30 @@ bool InputType::Equals(const InputType& other) const {\n   }\n }\n \n-bool InputType::Matches(const ValueDescr& descr) const {\n-  if (shape_ != ValueDescr::ANY && descr.shape != shape_) {\n-    return false;\n-  }\n+bool InputType::Matches(const TypeHolder& type) const {\n\nReview Comment:\n   Similarly, taking `const DataType&` would be slightly more efficient still.\n\n\n\n##########\ncpp/src/arrow/compute/kernels/scalar_cast_test.cc:\n##########\n@@ -2031,7 +2031,10 @@ TEST(Cast, BinaryToString) {\n \n     // N.B. null buffer is not always the same if input sliced\n     AssertBufferSame(*invalid_utf8, *strings, 0);\n-    ASSERT_EQ(invalid_utf8->data()->buffers[1].get(), strings->data()->buffers[2].get());\n+\n+    // ARROW-16757: we no longer zero copy, but the contents are equal\n\nReview Comment:\n   Rather than the JIRA that introduced the change, would be more useful to reference a JIRA about making this zero-copy again?\n\n\n\n##########\ncpp/src/arrow/compute/cast.cc:\n##########\n@@ -69,9 +69,9 @@ void EnsureInitCastTable() { std::call_once(cast_table_initialized, InitCastTabl\n // Private version of GetCastFunction with better error reporting\n // if the input type is known.\n Result<std::shared_ptr<CastFunction>> GetCastFunctionInternal(\n-    const std::shared_ptr<DataType>& to_type, const DataType* from_type = nullptr) {\n+    const TypeHolder& to_type, const DataType* from_type = nullptr) {\n\nReview Comment:\n   Nit, but why not just take `const DataType&`? We're not storing `to_type` anywhere AFAICT.\n\n\n\n##########\ncpp/gdb_arrow.py:\n##########\n@@ -1463,7 +1464,24 @@ def to_string(self):\n         return f\"{self._format_type()}\"\n \n \n-class UnionScalarPrinter(ScalarPrinter):\n+class SparseUnionScalarPrinter(ScalarPrinter):\n+    \"\"\"\n+    Pretty-printer for arrow::UnionScalar and subclasses.\n+    \"\"\"\n+\n+    def to_string(self):\n+        type_code = self.val['type_code'].cast(gdb.lookup_type('int'))\n+        if not self.is_valid:\n+            return (f\"{self._format_type()} of type {self.type}, \"\n+                    f\"type code {type_code}, null value\")\n+        eval_values = StdVector(self.val['value'])\n+        child_id = self.val['child_id'].cast(gdb.lookup_type('int'))\n\nReview Comment:\n   I don't think the cast is needed as it's already a C `int`?\r\n   \r\n   (note: calls to gdb evaluation of C stuff can be costly, so this is not just pedantic)\n\n\n\n##########\ncpp/src/arrow/compute/function.cc:\n##########\n@@ -186,87 +170,106 @@ const Kernel* DispatchExactImpl(const Function* func,\n }  // namespace detail\n \n Result<const Kernel*> Function::DispatchExact(\n-    const std::vector<ValueDescr>& values) const {\n+    const std::vector<TypeHolder>& values) const {\n   if (kind_ == Function::META) {\n     return Status::NotImplemented(\"Dispatch for a MetaFunction's Kernels\");\n   }\n-  RETURN_NOT_OK(CheckArity(values));\n+  RETURN_NOT_OK(CheckArity(values.size()));\n \n   if (auto kernel = detail::DispatchExactImpl(this, values)) {\n     return kernel;\n   }\n   return detail::NoMatchingKernel(this, values);\n }\n \n-Result<const Kernel*> Function::DispatchBest(std::vector<ValueDescr>* values) const {\n+Result<const Kernel*> Function::DispatchBest(std::vector<TypeHolder>* values) const {\n   // TODO(ARROW-11508) permit generic conversions here\n   return DispatchExact(*values);\n }\n \n-Result<Datum> Function::Execute(const std::vector<Datum>& args,\n-                                const FunctionOptions* options, ExecContext* ctx) const {\n-  return ExecuteInternal(args, /*passed_length=*/-1, options, ctx);\n+namespace {\n+\n+/// \\brief Check that each Datum is of a \"value\" type, which means either\n+/// SCALAR, ARRAY, or CHUNKED_ARRAY.\n\nReview Comment:\n   Uh, can we use a less vague terminology than \"value\"? For example, \"one-dimensional\" isn't very pretty but at least quite explicit. Perhaps @lidavidm @westonpace have better suggestions, though (\"array-compatible\"?).\n\n\n\n##########\ncpp/src/arrow/compute/exec.cc:\n##########\n@@ -328,8 +321,17 @@ bool ExecBatchIterator::Next(ExecBatch* batch) {\n // ----------------------------------------------------------------------\n // ExecSpanIterator; to eventually replace ExecBatchIterator\n \n-Status ExecSpanIterator::Init(const ExecBatch& batch, ValueDescr::Shape output_shape,\n-                              int64_t max_chunksize) {\n+bool CheckIfAllScalar(const ExecBatch& batch) {\n\nReview Comment:\n   Make this static or put in the anonymous namespace (if not already there)?\n\n\n\n##########\ncpp/src/arrow/compute/exec.cc:\n##########\n@@ -995,14 +996,24 @@ class ScalarExecutor : public KernelExecutorImpl<ScalarKernel> {\n   ExecSpanIterator span_iterator_;\n };\n \n+Status CheckCanExecuteChunked(const VectorKernel* kernel) {\n\nReview Comment:\n   static / anonymous?\n\n\n\n##########\ncpp/src/arrow/compute/exec.cc:\n##########\n@@ -385,13 +387,20 @@ int64_t ExecSpanIterator::GetNextChunkSpan(int64_t iteration_size, ExecSpan* spa\n   return iteration_size;\n }\n \n-bool ExecSpanIterator::Next(ExecSpan* span) {\n-  if (position_ == length_) {\n-    // This also protects from degenerate cases like ChunkedArrays\n-    // without any chunks\n-    return false;\n+void PromoteExecSpanScalars(ExecSpan* span) {\n\nReview Comment:\n   Make this static / anonymous as well?\n\n\n\n##########\ncpp/src/arrow/array/data.h:\n##########\n@@ -266,16 +266,19 @@ struct ARROW_EXPORT ArraySpan {\n   int64_t offset = 0;\n   BufferSpan buffers[3];\n \n+  // 16 bytes of scratch space to enable this ArraySpan to be a view onto\n+  // scalar values including binary scalars (where we need to create a buffer\n+  // that looks like two 32-bit or 64-bit offsets)\n+  uint8_t scratch_space[16];\n\nReview Comment:\n   I'm not sure I understand actually: why do you need a scratch space if the ArraySpan is a view onto an existing scalar?\r\n   \r\n   (also, you probably want to make this 8-byte aligned?)\n\n\n\n##########\ncpp/src/arrow/scalar.h:\n##########\n@@ -479,37 +481,52 @@ struct ARROW_EXPORT StructScalar : public Scalar {\n \n   Result<std::shared_ptr<Scalar>> field(FieldRef ref) const;\n \n-  StructScalar(ValueType value, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)) {}\n+  StructScalar(ValueType value, std::shared_ptr<DataType> type, bool is_valid = true)\n+      : Scalar(std::move(type), is_valid), value(std::move(value)) {}\n \n   static Result<std::shared_ptr<StructScalar>> Make(ValueType value,\n                                                     std::vector<std::string> field_names);\n-\n-  explicit StructScalar(std::shared_ptr<DataType> type) : Scalar(std::move(type)) {}\n };\n \n struct ARROW_EXPORT UnionScalar : public Scalar {\n-  using Scalar::Scalar;\n-  using ValueType = std::shared_ptr<Scalar>;\n-\n-  ValueType value;\n   int8_t type_code;\n \n-  UnionScalar(int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), false), type_code(type_code) {}\n-\n-  UnionScalar(ValueType value, int8_t type_code, std::shared_ptr<DataType> type)\n-      : Scalar(std::move(type), true), value(std::move(value)), type_code(type_code) {}\n+ protected:\n+  UnionScalar(std::shared_ptr<DataType> type, int8_t type_code, bool is_valid)\n+      : Scalar(std::move(type), is_valid), type_code(type_code) {}\n };\n \n struct ARROW_EXPORT SparseUnionScalar : public UnionScalar {\n-  using UnionScalar::UnionScalar;\n   using TypeClass = SparseUnionType;\n+\n+  // Even though only one of the union values is relevant for this scalar, we\n+  // nonetheless construct a vector of scalars, one per union value, to have\n+  // enough data to reconstruct a valid ArraySpan of length 1 from this scalar\n+  using ValueType = std::vector<std::shared_ptr<Scalar>>;\n+  ValueType value;\n\nReview Comment:\n   This sounds ok. We already had similarly quandaries with union scalars in the past.\n\n\n\n##########\ncpp/src/arrow/array/data.cc:\n##########\n@@ -174,27 +175,197 @@ void ArraySpan::SetMembers(const ArrayData& data) {\n   }\n }\n \n+template <typename offset_type>\n+void SetOffsetsForScalar(ArraySpan* span, uint8_t* buffer, int64_t value_size,\n+                         int buffer_index = 1) {\n+  auto offsets = reinterpret_cast<offset_type*>(buffer);\n+  offsets[0] = 0;\n+  offsets[1] = static_cast<offset_type>(value_size);\n+  span->buffers[buffer_index].data = buffer;\n+  span->buffers[buffer_index].size = 2 * sizeof(offset_type);\n+}\n+\n+int GetNumBuffers(const DataType& type) {\n+  switch (type.id()) {\n+    case Type::NA:\n+    case Type::STRUCT:\n+    case Type::FIXED_SIZE_LIST:\n+      return 1;\n+    case Type::BINARY:\n+    case Type::LARGE_BINARY:\n+    case Type::STRING:\n+    case Type::LARGE_STRING:\n+    case Type::DENSE_UNION:\n+      return 3;\n+    case Type::EXTENSION:\n+      // The number of buffers depends on the storage type\n+      return GetNumBuffers(\n+          *internal::checked_cast<const ExtensionType&>(type).storage_type());\n+    default:\n+      // Everything else has 2 buffers\n+      return 2;\n+  }\n+}\n+\n+namespace internal {\n+\n+void FillZeroLengthArray(const DataType* type, ArraySpan* span) {\n+  memset(span->scratch_space, 0x00, 16);\n+\n+  span->type = type;\n+  span->length = 0;\n+  int num_buffers = GetNumBuffers(*type);\n+  for (int i = 0; i < num_buffers; ++i) {\n+    span->buffers[i].data = span->scratch_space;\n+    span->buffers[i].size = 0;\n+  }\n+\n+  for (int i = num_buffers; i < 3; ++i) {\n+    span->ClearBuffer(i);\n+  }\n+\n+  // Fill children\n+  span->child_data.resize(type->num_fields());\n+  for (int i = 0; i < type->num_fields(); ++i) {\n+    FillZeroLengthArray(type->field(i)->type().get(), &span->child_data[i]);\n+  }\n+}\n+\n+}  // namespace internal\n+\n void ArraySpan::FillFromScalar(const Scalar& value) {\n-  static const uint8_t kValidByte = 0x01;\n-  static const uint8_t kNullByte = 0x00;\n+  static uint8_t kTrueBit = 0x01;\n+  static uint8_t kFalseBit = 0x00;\n \n   this->type = value.type.get();\n   this->length = 1;\n \n-  // Populate null count and validity bitmap\n+  Type::type type_id = value.type->id();\n+\n+  // Populate null count and validity bitmap (only for non-union types)\n   this->null_count = value.is_valid ? 0 : 1;\n-  this->buffers[0].data = const_cast<uint8_t*>(value.is_valid ? &kValidByte : &kNullByte);\n-  this->buffers[0].size = 1;\n+  if (!is_union(type_id)) {\n+    this->buffers[0].data = value.is_valid ? &kTrueBit : &kFalseBit;\n+    this->buffers[0].size = 1;\n+  }\n \n-  if (is_primitive(value.type->id())) {\n-    const auto& scalar =\n-        internal::checked_cast<const internal::PrimitiveScalarBase&>(value);\n+  if (type_id == Type::BOOL) {\n+    const auto& scalar = checked_cast<const BooleanScalar&>(value);\n+    this->buffers[1].data = scalar.value ? &kTrueBit : &kFalseBit;\n+    this->buffers[1].size = 1;\n+  } else if (is_primitive(type_id) || is_decimal(type_id) ||\n+             type_id == Type::DICTIONARY) {\n+    const auto& scalar = checked_cast<const internal::PrimitiveScalarBase&>(value);\n     const uint8_t* scalar_data = reinterpret_cast<const uint8_t*>(scalar.view().data());\n     this->buffers[1].data = const_cast<uint8_t*>(scalar_data);\n     this->buffers[1].size = scalar.type->byte_width();\n+    if (type_id == Type::DICTIONARY) {\n+      // Populate dictionary data\n+      const auto& dict_scalar = checked_cast<const DictionaryScalar&>(value);\n+      this->child_data.resize(1);\n+      this->child_data[0].SetMembers(*dict_scalar.value.dictionary->data());\n+    }\n+  } else if (is_base_binary_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = this->scratch_space;\n+    const uint8_t* data_buffer = nullptr;\n+    int64_t data_size = 0;\n+    if (scalar.is_valid) {\n+      data_buffer = scalar.value->data();\n+      data_size = scalar.value->size();\n+    }\n+    if (is_binary_like(type_id)) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, data_size);\n+    } else {\n+      // is_large_binary_like\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, data_size);\n+    }\n+    this->buffers[2].data = const_cast<uint8_t*>(data_buffer);\n+    this->buffers[2].size = data_size;\n+  } else if (type_id == Type::FIXED_SIZE_BINARY) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = const_cast<uint8_t*>(scalar.value->data());\n+    this->buffers[1].size = scalar.value->size();\n+  } else if (is_list_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseListScalar&>(value);\n+\n+    int64_t value_length = 0;\n+    this->child_data.resize(1);\n+    if (scalar.value != nullptr) {\n+      // When the scalar is null, scalar.value can also be null\n+      this->child_data[0].SetMembers(*scalar.value->data());\n+      value_length = scalar.value->length();\n+    } else {\n+      // Even when the value is null, we still must populate the\n+      // child_data to yield a valid array. Tedious\n+      internal::FillZeroLengthArray(this->type->field(0)->type().get(),\n+                                    &this->child_data[0]);\n+    }\n+\n+    if (type_id == Type::LIST || type_id == Type::MAP) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, value_length);\n+    } else if (type_id == Type::LARGE_LIST) {\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, value_length);\n+    } else {\n+      // FIXED_SIZE_LIST: does not have a second buffer\n+      this->buffers[1].data = nullptr;\n+      this->buffers[1].size = 0;\n\nReview Comment:\n   Same question for the various `ClearBuffer` calls...\r\n   \n\n\n\n##########\ncpp/src/arrow/array/data.cc:\n##########\n@@ -174,27 +175,197 @@ void ArraySpan::SetMembers(const ArrayData& data) {\n   }\n }\n \n+template <typename offset_type>\n+void SetOffsetsForScalar(ArraySpan* span, uint8_t* buffer, int64_t value_size,\n+                         int buffer_index = 1) {\n+  auto offsets = reinterpret_cast<offset_type*>(buffer);\n+  offsets[0] = 0;\n+  offsets[1] = static_cast<offset_type>(value_size);\n+  span->buffers[buffer_index].data = buffer;\n+  span->buffers[buffer_index].size = 2 * sizeof(offset_type);\n+}\n+\n+int GetNumBuffers(const DataType& type) {\n+  switch (type.id()) {\n+    case Type::NA:\n+    case Type::STRUCT:\n+    case Type::FIXED_SIZE_LIST:\n+      return 1;\n+    case Type::BINARY:\n+    case Type::LARGE_BINARY:\n+    case Type::STRING:\n+    case Type::LARGE_STRING:\n+    case Type::DENSE_UNION:\n+      return 3;\n+    case Type::EXTENSION:\n+      // The number of buffers depends on the storage type\n+      return GetNumBuffers(\n+          *internal::checked_cast<const ExtensionType&>(type).storage_type());\n+    default:\n+      // Everything else has 2 buffers\n+      return 2;\n+  }\n+}\n+\n+namespace internal {\n+\n+void FillZeroLengthArray(const DataType* type, ArraySpan* span) {\n+  memset(span->scratch_space, 0x00, 16);\n+\n+  span->type = type;\n+  span->length = 0;\n+  int num_buffers = GetNumBuffers(*type);\n+  for (int i = 0; i < num_buffers; ++i) {\n+    span->buffers[i].data = span->scratch_space;\n+    span->buffers[i].size = 0;\n+  }\n+\n+  for (int i = num_buffers; i < 3; ++i) {\n+    span->ClearBuffer(i);\n+  }\n+\n+  // Fill children\n+  span->child_data.resize(type->num_fields());\n+  for (int i = 0; i < type->num_fields(); ++i) {\n+    FillZeroLengthArray(type->field(i)->type().get(), &span->child_data[i]);\n+  }\n+}\n+\n+}  // namespace internal\n+\n void ArraySpan::FillFromScalar(const Scalar& value) {\n-  static const uint8_t kValidByte = 0x01;\n-  static const uint8_t kNullByte = 0x00;\n+  static uint8_t kTrueBit = 0x01;\n+  static uint8_t kFalseBit = 0x00;\n \n   this->type = value.type.get();\n   this->length = 1;\n \n-  // Populate null count and validity bitmap\n+  Type::type type_id = value.type->id();\n+\n+  // Populate null count and validity bitmap (only for non-union types)\n   this->null_count = value.is_valid ? 0 : 1;\n-  this->buffers[0].data = const_cast<uint8_t*>(value.is_valid ? &kValidByte : &kNullByte);\n-  this->buffers[0].size = 1;\n+  if (!is_union(type_id)) {\n+    this->buffers[0].data = value.is_valid ? &kTrueBit : &kFalseBit;\n+    this->buffers[0].size = 1;\n+  }\n \n-  if (is_primitive(value.type->id())) {\n-    const auto& scalar =\n-        internal::checked_cast<const internal::PrimitiveScalarBase&>(value);\n+  if (type_id == Type::BOOL) {\n+    const auto& scalar = checked_cast<const BooleanScalar&>(value);\n+    this->buffers[1].data = scalar.value ? &kTrueBit : &kFalseBit;\n+    this->buffers[1].size = 1;\n+  } else if (is_primitive(type_id) || is_decimal(type_id) ||\n+             type_id == Type::DICTIONARY) {\n+    const auto& scalar = checked_cast<const internal::PrimitiveScalarBase&>(value);\n     const uint8_t* scalar_data = reinterpret_cast<const uint8_t*>(scalar.view().data());\n     this->buffers[1].data = const_cast<uint8_t*>(scalar_data);\n     this->buffers[1].size = scalar.type->byte_width();\n+    if (type_id == Type::DICTIONARY) {\n+      // Populate dictionary data\n+      const auto& dict_scalar = checked_cast<const DictionaryScalar&>(value);\n+      this->child_data.resize(1);\n+      this->child_data[0].SetMembers(*dict_scalar.value.dictionary->data());\n+    }\n+  } else if (is_base_binary_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = this->scratch_space;\n+    const uint8_t* data_buffer = nullptr;\n+    int64_t data_size = 0;\n+    if (scalar.is_valid) {\n+      data_buffer = scalar.value->data();\n+      data_size = scalar.value->size();\n+    }\n+    if (is_binary_like(type_id)) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, data_size);\n+    } else {\n+      // is_large_binary_like\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, data_size);\n+    }\n+    this->buffers[2].data = const_cast<uint8_t*>(data_buffer);\n+    this->buffers[2].size = data_size;\n+  } else if (type_id == Type::FIXED_SIZE_BINARY) {\n+    const auto& scalar = checked_cast<const BaseBinaryScalar&>(value);\n+    this->buffers[1].data = const_cast<uint8_t*>(scalar.value->data());\n+    this->buffers[1].size = scalar.value->size();\n+  } else if (is_list_like(type_id)) {\n+    const auto& scalar = checked_cast<const BaseListScalar&>(value);\n+\n+    int64_t value_length = 0;\n+    this->child_data.resize(1);\n+    if (scalar.value != nullptr) {\n+      // When the scalar is null, scalar.value can also be null\n+      this->child_data[0].SetMembers(*scalar.value->data());\n+      value_length = scalar.value->length();\n+    } else {\n+      // Even when the value is null, we still must populate the\n+      // child_data to yield a valid array. Tedious\n+      internal::FillZeroLengthArray(this->type->field(0)->type().get(),\n+                                    &this->child_data[0]);\n+    }\n+\n+    if (type_id == Type::LIST || type_id == Type::MAP) {\n+      SetOffsetsForScalar<int32_t>(this, this->scratch_space, value_length);\n+    } else if (type_id == Type::LARGE_LIST) {\n+      SetOffsetsForScalar<int64_t>(this, this->scratch_space, value_length);\n+    } else {\n+      // FIXED_SIZE_LIST: does not have a second buffer\n+      this->buffers[1].data = nullptr;\n+      this->buffers[1].size = 0;\n\nReview Comment:\n   In any case you can probably simply write:\r\n   ```suggestion\r\n         this->buffers[1] = {};\r\n   ```\r\n   \n\n\n\n",
                    "created": "2022-07-07T16:21:22.918+0000",
                    "updated": "2022-07-07T16:21:22.918+0000",
                    "started": "2022-07-07T16:21:22.917+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788670",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788684",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r916116990\n\n\n##########\ncpp/src/arrow/array/builder_nested.h:\n##########\n@@ -304,10 +304,12 @@ class ARROW_EXPORT MapBuilder : public ArrayBuilder {\n       if (!validity || bit_util::GetBit(validity, array.offset + row)) {\n         ARROW_RETURN_NOT_OK(Append());\n         const int64_t slot_length = offsets[row + 1] - offsets[row];\n+        // Add together the inner StructArray offset to the Map/List offset\n+        int64_t key_value_offset = array.child_data[0].offset + offsets[row];\n         ARROW_RETURN_NOT_OK(key_builder_->AppendArraySlice(\n-            array.child_data[0].child_data[0], offsets[row], slot_length));\n+            array.child_data[0].child_data[0], key_value_offset, slot_length));\n         ARROW_RETURN_NOT_OK(item_builder_->AppendArraySlice(\n-            array.child_data[0].child_data[1], offsets[row], slot_length));\n+            array.child_data[0].child_data[1], key_value_offset, slot_length));\n\nReview Comment:\n   Yes \u2014 the bug got exposed by the scalar input tests when now pass through the ArraySpan path now that the Scalar path has been deleted (e.g. the `MapLookupScalar` implementation \u2014 now passes through MapBuilder). \n\n\n\n",
                    "created": "2022-07-07T17:26:17.409+0000",
                    "updated": "2022-07-07T17:26:17.409+0000",
                    "started": "2022-07-07T17:26:17.409+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788684",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788720",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r916198877\n\n\n##########\ncpp/src/arrow/array/data.h:\n##########\n@@ -266,16 +266,19 @@ struct ARROW_EXPORT ArraySpan {\n   int64_t offset = 0;\n   BufferSpan buffers[3];\n \n+  // 16 bytes of scratch space to enable this ArraySpan to be a view onto\n+  // scalar values including binary scalars (where we need to create a buffer\n+  // that looks like two 32-bit or 64-bit offsets)\n+  uint8_t scratch_space[16];\n\nReview Comment:\n   Scalars that are a view onto a variable-size array (list, large list, binary, utf8, large binary, etc.) do not have an offsets buffer in their representation\n\n\n\n",
                    "created": "2022-07-07T19:07:13.462+0000",
                    "updated": "2022-07-07T19:07:13.462+0000",
                    "started": "2022-07-07T19:07:13.461+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788720",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788721",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r916201356\n\n\n##########\ncpp/src/arrow/array/data.h:\n##########\n@@ -266,16 +266,19 @@ struct ARROW_EXPORT ArraySpan {\n   int64_t offset = 0;\n   BufferSpan buffers[3];\n \n+  // 16 bytes of scratch space to enable this ArraySpan to be a view onto\n+  // scalar values including binary scalars (where we need to create a buffer\n+  // that looks like two 32-bit or 64-bit offsets)\n+  uint8_t scratch_space[16];\n\nReview Comment:\n   I'm making this aligned (by changing the type to be two uint64's)\n\n\n\n",
                    "created": "2022-07-07T19:10:38.865+0000",
                    "updated": "2022-07-07T19:10:38.865+0000",
                    "started": "2022-07-07T19:10:38.864+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788721",
                    "issueId": "13448618"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/worklog/788723",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on code in PR #13521:\nURL: https://github.com/apache/arrow/pull/13521#discussion_r916202446\n\n\n##########\ncpp/src/arrow/array/data.h:\n##########\n@@ -266,16 +266,19 @@ struct ARROW_EXPORT ArraySpan {\n   int64_t offset = 0;\n   BufferSpan buffers[3];\n \n+  // 16 bytes of scratch space to enable this ArraySpan to be a view onto\n+  // scalar values including binary scalars (where we need to create a buffer\n+  // that looks like two 32-bit or 64-bit offsets)\n+  uint8_t scratch_space[16];\n\nReview Comment:\n   You can also use [`alignas`](https://en.cppreference.com/w/cpp/language/alignas)\n\n\n\n",
                    "created": "2022-07-07T19:12:14.003+0000",
                    "updated": "2022-07-07T19:12:14.003+0000",
                    "started": "2022-07-07T19:12:14.002+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788723",
                    "issueId": "13448618"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 19800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@3f6f56d1[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5117cda6[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@52c38698[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@3d560b9b[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@71036898[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@1aac51a7[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5415e32c[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@591230e6[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@33bfd4f4[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@4be68a4d[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@30111c9e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@784c8f7a[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 19800,
        "customfield_12312520": null,
        "customfield_12312521": "Fri Jul 08 02:06:58 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-07-08T02:06:58.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16757/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2022-06-06T16:11:49.000+0000",
        "updated": "2022-07-13T19:37:07.000+0000",
        "timeoriginalestimate": null,
        "description": "Supporting scalar outputs from array kernels (where all the inputs are scalars) introduces needless complexity into the kernel implementations, causing duplication of effort and excess code generation for paltry benefit. In the scenario where all inputs are scalars, it would be better to promote them all to arrays of length 1 (either by creating the arrays or constructing an appropriate ArraySpan per ARROW-16756) and invoking the array code path. This would enable us to delete thousands of lines of code and ease the ongoing development and maintenance of the array kernels codebase",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "5.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 19800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Remove \"scalar\" output modality from array kernels",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13448618/comment/17564049",
                    "id": "17564049",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 13521\n[https://github.com/apache/arrow/pull/13521]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-07-08T02:06:58.169+0000",
                    "updated": "2022-07-08T02:06:58.169+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z12zl4:",
        "customfield_12314139": null
    }
}