{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13394689",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689",
    "key": "ARROW-13607",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12350591",
                "id": "12350591",
                "description": "",
                "name": "7.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-02-03"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12642767",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12642767",
                "type": {
                    "id": "12310051",
                    "name": "Supercedes",
                    "inward": "is superceded by",
                    "outward": "supercedes",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310051"
                },
                "outwardIssue": {
                    "id": "13339805",
                    "key": "ARROW-10549",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13339805",
                    "fields": {
                        "summary": "[C++][Dataset] RADOS dataset",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            },
            {
                "id": "12642765",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12642765",
                "type": {
                    "id": "12310051",
                    "name": "Supercedes",
                    "inward": "is superceded by",
                    "outward": "supercedes",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310051"
                },
                "outwardIssue": {
                    "id": "13381544",
                    "key": "ARROW-12921",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13381544",
                    "fields": {
                        "summary": "[C++][Dataset] Add RadosParquetFileFormat to Dataset API",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=Jayjeet",
            "name": "Jayjeet",
            "key": "jayjeet",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Jayjeet Chakraborty",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=Jayjeet",
            "name": "Jayjeet",
            "key": "jayjeet",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Jayjeet Chakraborty",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=Jayjeet",
            "name": "Jayjeet",
            "key": "jayjeet",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Jayjeet Chakraborty",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 51600,
            "total": 51600,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 51600,
            "total": 51600,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-13607/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 86,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/636905",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#issuecomment-896846537\n\n\n   https://issues.apache.org/jira/browse/ARROW-13607\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-11T13:53:23.000+0000",
                    "updated": "2021-08-11T13:53:23.000+0000",
                    "started": "2021-08-11T13:53:22.999+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "636905",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/639679",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r687195979\n\n\n\n##########\nFile path: ci/scripts/integration_skyhook.sh\n##########\n@@ -0,0 +1,134 @@\n+#!/usr/bin/env bash\n\nReview comment:\n       This is just a warning, no action required, but this file requires a fair amount of Ceph knowledge to understand (more than I have).  This will limit the # of people who are able to maintain it.  I don't know if it would be easy but is there any \"standard ceph server install\" (a maintained docker image or something) that could be used?\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n\nReview comment:\n       ```suggestion\r\n     ARROW_EXPECT_OK(format->Init());\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  arrow::dataset::InspectOptions inspect_options;\n+  arrow::dataset::FinishOptions finish_options;\n+  auto schema = factory->Inspect(inspect_options).ValueOrDie();\n+  auto child = factory->Finish(finish_options).ValueOrDie();\n+\n+  arrow::dataset::DatasetVector children{1, child};\n+  auto dataset =\n+      arrow::dataset::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                            std::string* path) {\n+  return arrow::fs::FileSystemFromUri(uri, path).ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromPath(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string path) {\n+  auto info = fs->GetFileInfo(path).ValueOrDie();\n+  return GetDatasetFromDirectory(fs, format, path);\n+}\n+\n+std::shared_ptr<arrow::dataset::Scanner> GetScannerFromDataset(\n+    std::shared_ptr<arrow::dataset::Dataset> dataset, std::vector<std::string> columns,\n+    arrow::compute::Expression filter, bool use_threads) {\n+  auto scanner_builder = dataset->NewScan().ValueOrDie();\n+\n+  if (!columns.empty()) {\n+    scanner_builder->Project(columns);\n+  }\n+\n+  scanner_builder->Filter(filter);\n+  scanner_builder->UseThreads(use_threads);\n\nReview comment:\n       ```suggestion\r\n     ARROW_EXPECT_OK(scanner_builder->UseThreads(use_threads));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  arrow::dataset::InspectOptions inspect_options;\n+  arrow::dataset::FinishOptions finish_options;\n+  auto schema = factory->Inspect(inspect_options).ValueOrDie();\n+  auto child = factory->Finish(finish_options).ValueOrDie();\n+\n+  arrow::dataset::DatasetVector children{1, child};\n+  auto dataset =\n+      arrow::dataset::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                            std::string* path) {\n+  return arrow::fs::FileSystemFromUri(uri, path).ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromPath(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string path) {\n+  auto info = fs->GetFileInfo(path).ValueOrDie();\n+  return GetDatasetFromDirectory(fs, format, path);\n+}\n+\n+std::shared_ptr<arrow::dataset::Scanner> GetScannerFromDataset(\n+    std::shared_ptr<arrow::dataset::Dataset> dataset, std::vector<std::string> columns,\n+    arrow::compute::Expression filter, bool use_threads) {\n+  auto scanner_builder = dataset->NewScan().ValueOrDie();\n+\n+  if (!columns.empty()) {\n+    scanner_builder->Project(columns);\n+  }\n+\n+  scanner_builder->Filter(filter);\n+  scanner_builder->UseThreads(use_threads);\n+  return scanner_builder->Finish().ValueOrDie();\n\nReview comment:\n       ```suggestion\r\n     EXPECT_OK_AND_ASSIGN(auto scanner, scanner_builder->Finish());\r\n     return scanner;\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n+\n+ private:\n+  arrow::Status s_;\n+  int code_;\n+};\n+\n+class IoCtxInterface {\n+ public:\n+  IoCtxInterface() {}\n+\n+  /// \\brief Write data to an object.\n+  ///\n+  /// \\param[in] oid the ID of the object to write.\n+  /// \\param[in] bl a bufferlist containing the data to write to the object.\n+  virtual RadosStatus write_full(const std::string& oid, ceph::bufferlist& bl) = 0;\n\nReview comment:\n       Nit: Is this method used anywhere?\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook.cc\n##########\n@@ -0,0 +1,258 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include <rados/objclass.h>\n+#include <memory>\n+\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/compression.h\"\n+\n+CLS_VER(1, 0)\n+CLS_NAME(skyhook)\n+\n+cls_handle_t h_class;\n+cls_method_handle_t h_scan_op;\n+\n+/// \\brief Log skyhook errors using RADOS object class SDK's logger.\n+void LogSkyhookError(const std::string& msg) { CLS_LOG(0, \"error: %s\", msg.c_str()); }\n+\n+/// \\class RandomAccessObject\n+/// \\brief An interface to provide a file-like view over RADOS objects.\n+class RandomAccessObject : public arrow::io::RandomAccessFile {\n+ public:\n+  explicit RandomAccessObject(cls_method_context_t hctx, int64_t file_size) {\n+    hctx_ = hctx;\n+    content_length_ = file_size;\n+    chunks_ = std::vector<ceph::bufferlist*>();\n+  }\n+\n+  ~RandomAccessObject() { Close(); }\n+\n+  /// Check if the file stream is closed.\n+  arrow::Status CheckClosed() const {\n+    if (closed_) {\n+      return arrow::Status::Invalid(\"Operation on closed stream\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Check if the position of the object is valid.\n+  arrow::Status CheckPosition(int64_t position, const char* action) const {\n+    if (position < 0) {\n+      return arrow::Status::Invalid(\"Cannot \", action, \" from negative position\");\n+    }\n+    if (position > content_length_) {\n+      return arrow::Status::IOError(\"Cannot \", action, \" past end of file\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<int64_t> ReadAt(int64_t position, int64_t nbytes, void* out) {\n+    return arrow::Status::NotImplemented(\n+        \"ReadAt has not been implemented in RandomAccessObject\");\n+  }\n+\n+  /// Read a specified number of bytes from a specified position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> ReadAt(int64_t position, int64_t nbytes) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"read\"));\n+\n+    // No need to allocate more than the remaining number of bytes\n+    nbytes = std::min(nbytes, content_length_ - position);\n+\n+    if (nbytes > 0) {\n+      ceph::bufferlist* bl = new ceph::bufferlist();\n+      cls_cxx_read(hctx_, position, nbytes, bl);\n+      chunks_.push_back(bl);\n+      return std::make_shared<arrow::Buffer>((uint8_t*)bl->c_str(), bl->length());\n+    }\n+    return std::make_shared<arrow::Buffer>(\"\");\n+  }\n+\n+  /// Read a specified number of bytes from the current position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> Read(int64_t nbytes) {\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, ReadAt(pos_, nbytes));\n+    pos_ += buffer->size();\n+    return std::move(buffer);\n+  }\n+\n+  /// Read a specified number of bytes from the current position into an output stream.\n+  arrow::Result<int64_t> Read(int64_t nbytes, void* out) {\n+    ARROW_ASSIGN_OR_RAISE(int64_t bytes_read, ReadAt(pos_, nbytes, out));\n+    pos_ += bytes_read;\n+    return bytes_read;\n+  }\n+\n+  /// Return the size of the file.\n+  arrow::Result<int64_t> GetSize() {\n+    RETURN_NOT_OK(CheckClosed());\n+    return content_length_;\n+  }\n+\n+  /// Sets the file-pointer offset, measured from the beginning of the\n+  /// file, at which the next read or write occurs.\n+  arrow::Status Seek(int64_t position) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"seek\"));\n+\n+    pos_ = position;\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Returns the file-pointer offset.\n+  arrow::Result<int64_t> Tell() const {\n+    RETURN_NOT_OK(CheckClosed());\n+    return pos_;\n+  }\n+\n+  /// Closes the file stream and deletes the chunks and releases the memory\n+  /// used by the chunks.\n+  arrow::Status Close() {\n+    closed_ = true;\n+    for (auto chunk : chunks_) {\n+      delete chunk;\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  bool closed() const { return closed_; }\n+\n+ private:\n+  cls_method_context_t hctx_;\n+  bool closed_ = false;\n+  int64_t pos_ = 0;\n+  int64_t content_length_ = -1;\n+  std::vector<ceph::bufferlist*> chunks_;\n+};\n+\n+/// \\brief  Driver function to execute the Scan operations.\n+/// \\param[in] hctx RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[in] format The file format instance to use in the scan.\n+/// \\param[in] fragment_scan_options The fragment scan options to use to customize the\n+/// scan. \\return Table.\n+arrow::Result<std::shared_ptr<arrow::Table>> DoScan(\n+    cls_method_context_t hctx, skyhook::ScanRequest req,\n+    std::shared_ptr<arrow::dataset::FileFormat> format,\n+    std::shared_ptr<arrow::dataset::FragmentScanOptions> fragment_scan_options) {\n+  auto file = std::make_shared<RandomAccessObject>(hctx, req.file_size);\n+  auto source = std::make_shared<arrow::dataset::FileSource>(file);\n+  ARROW_ASSIGN_OR_RAISE(auto fragment,\n+                        format->MakeFragment(*source, req.partition_expression));\n+  auto options = std::make_shared<arrow::dataset::ScanOptions>();\n+  auto builder = std::make_shared<arrow::dataset::ScannerBuilder>(req.dataset_schema,\n+                                                                  fragment, options);\n\nReview comment:\n       ```suggestion\r\n                                                                     std::move(fragment), std::move(options));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.cc\n##########\n@@ -0,0 +1,112 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/rados_protocol.h\"\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace skyhook {\n+namespace rados {\n+\n+RadosStatus GetStatusFromReturnCode(int code, std::string msg) {\n+  if (code) return RadosStatus(arrow::Status::Invalid(msg), code);\n+  return RadosStatus(arrow::Status::OK(), code);\n+}\n+\n+RadosStatus IoCtxWrapper::write_full(const std::string& oid, ceph::bufferlist& bl) {\n+  return GetStatusFromReturnCode(this->ioCtx->write_full(oid, bl),\n\nReview comment:\n       Nit: It's a little inconsistent that you start using the optional `this->` but only in this file.\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol_test.cc\n##########\n@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/test_util.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+\n+std::shared_ptr<arrow::Table> CreateTable() {\n+  auto schema = arrow::schema({\n+      {arrow::field(\"a\", arrow::uint8())},\n+      {arrow::field(\"b\", arrow::uint32())},\n+  });\n+\n+  std::shared_ptr<arrow::Table> table;\n+  return TableFromJSON(schema, {R\"([{\"a\": null, \"b\": 5},\n+                                     {\"a\": 1,    \"b\": 3},\n+                                     {\"a\": 3,    \"b\": null},\n+                                     {\"a\": null, \"b\": null},\n+                                     {\"a\": 2,    \"b\": 5},\n+                                     {\"a\": 1,    \"b\": 5}\n+                                    ])\"});\n+}\n+\n+TEST(TestSkyhookProtocol, ScanRequestSerializeDeserialize) {\n+  ceph::bufferlist bl;\n+  skyhook::ScanRequest req;\n+  req.filter_expression = arrow::compute::literal(true);\n+  req.partition_expression = arrow::compute::literal(false);\n+  req.projection_schema = arrow::schema({arrow::field(\"a\", arrow::int64())});\n+  req.dataset_schema = arrow::schema({arrow::field(\"a\", arrow::int64())});\n+  req.file_size = 1000000;\n+  req.file_format = skyhook::SkyhookFileType::type::IPC;\n+  skyhook::SerializeScanRequest(req, bl);\n+\n+  skyhook::ScanRequest req_;\n+  skyhook::DeserializeScanRequest(req_, bl);\n\nReview comment:\n       ```suggestion\r\n     ASSERT_OK(skyhook::DeserializeScanRequest(req_, bl));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol_test.cc\n##########\n@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/test_util.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+\n+std::shared_ptr<arrow::Table> CreateTable() {\n+  auto schema = arrow::schema({\n+      {arrow::field(\"a\", arrow::uint8())},\n+      {arrow::field(\"b\", arrow::uint32())},\n+  });\n+\n+  std::shared_ptr<arrow::Table> table;\n+  return TableFromJSON(schema, {R\"([{\"a\": null, \"b\": 5},\n+                                     {\"a\": 1,    \"b\": 3},\n+                                     {\"a\": 3,    \"b\": null},\n+                                     {\"a\": null, \"b\": null},\n+                                     {\"a\": 2,    \"b\": 5},\n+                                     {\"a\": 1,    \"b\": 5}\n+                                    ])\"});\n+}\n+\n+TEST(TestSkyhookProtocol, ScanRequestSerializeDeserialize) {\n+  ceph::bufferlist bl;\n+  skyhook::ScanRequest req;\n+  req.filter_expression = arrow::compute::literal(true);\n+  req.partition_expression = arrow::compute::literal(false);\n+  req.projection_schema = arrow::schema({arrow::field(\"a\", arrow::int64())});\n+  req.dataset_schema = arrow::schema({arrow::field(\"a\", arrow::int64())});\n+  req.file_size = 1000000;\n+  req.file_format = skyhook::SkyhookFileType::type::IPC;\n+  skyhook::SerializeScanRequest(req, bl);\n\nReview comment:\n       ```suggestion\r\n     ASSERT_OK(skyhook::SerializeScanRequest(req, bl));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/CMakeLists.txt\n##########\n@@ -0,0 +1,108 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitationsn\n+# under the License.\n+\n+#\n+# arrow_skyhook\n+#\n+# define project properties\n+project(arrow_skyhook)\n+cmake_minimum_required(VERSION 3.11)\n+set(ARROW_BUILD_STATIC OFF)\n+\n+# install skyhook headers\n+install(FILES client/file_skyhook.h\n+        DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/skyhook/client\")\n+\n+# define the targets to build\n+add_custom_target(arrow_skyhook_client)\n+add_custom_target(cls_skyhook)\n+\n+# define the dependencies\n+find_package(librados REQUIRED)\n+include_directories(${LIBRADOS_INCLUDE_DIR})\n+set(ARROW_DATASET_LINK_STATIC arrow_dataset_static)\n+set(ARROW_DATASET_LINK_SHARED arrow_dataset_shared)\n+set(ARROW_DATASET_LINK_STATIC ${ARROW_DATASET_LINK_STATIC} ${LIBRADOS_LIBRARIES})\n+set(ARROW_DATASET_LINK_SHARED ${ARROW_DATASET_LINK_SHARED} ${LIBRADOS_LIBRARIES})\n+\n+# define the client and cls sources\n+set(ARROW_SKYHOOK_CLIENT_SOURCES client/file_skyhook.cc protocol/rados_protocol.cc\n+                                 protocol/skyhook_protocol.cc)\n+set(ARROW_SKYHOOK_CLS_SOURCES cls/cls_skyhook.cc protocol/rados_protocol.cc\n+                              protocol/skyhook_protocol.cc)\n+\n+# define the client library\n+add_arrow_lib(arrow_skyhook_client\n+              BUILD_SHARED\n+              ON\n+              SOURCES\n+              ${ARROW_SKYHOOK_CLIENT_SOURCES}\n+              OUTPUTS\n+              ARROW_SKYHOOK_CLIENT_LIBRARIES\n+              SHARED_LINK_LIBS\n+              ${ARROW_DATASET_LINK_SHARED}\n+              STATIC_LINK_LIBS\n+              ${ARROW_DATASET_LINK_STATIC}\n+              DEPENDENCIES\n+              arrow_dataset_static)\n\nReview comment:\n       I had to remove these `DEPENDENCIES` sections to get things to compile for me.  I'm not a CMake expert so I'm not sure the issue.  The error was...\r\n   \r\n   ```\r\n   CMake Error at cmake_modules/BuildUtils.cmake:291 (add_dependencies):\r\n     The dependency target \"arrow_dataset_static\" of target\r\n     \"arrow_skyhook_client_objlib\" does not exist.\r\n   Call Stack (most recent call first):\r\n     src/skyhook/CMakeLists.txt:49 (add_arrow_lib)\r\n   \r\n   \r\n   CMake Error at cmake_modules/BuildUtils.cmake:291 (add_dependencies):\r\n     The dependency target \"arrow_dataset_static\" of target \"cls_skyhook_objlib\"\r\n     does not exist.\r\n   Call Stack (most recent call first):\r\n     src/skyhook/CMakeLists.txt:64 (add_arrow_lib)\r\n   \r\n   ```\r\n   \r\n   I wonder if maybe there is a bootstrapping type problem where this will only work if arrow happens to also be installed.\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  arrow::dataset::InspectOptions inspect_options;\n+  arrow::dataset::FinishOptions finish_options;\n+  auto schema = factory->Inspect(inspect_options).ValueOrDie();\n+  auto child = factory->Finish(finish_options).ValueOrDie();\n+\n+  arrow::dataset::DatasetVector children{1, child};\n+  auto dataset =\n+      arrow::dataset::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                            std::string* path) {\n+  return arrow::fs::FileSystemFromUri(uri, path).ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromPath(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string path) {\n+  auto info = fs->GetFileInfo(path).ValueOrDie();\n\nReview comment:\n       ```suggestion\r\n     EXPECT_OK_AND_ASSIGN(auto info, fs->GetFileInfo(path));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  arrow::dataset::InspectOptions inspect_options;\n+  arrow::dataset::FinishOptions finish_options;\n+  auto schema = factory->Inspect(inspect_options).ValueOrDie();\n+  auto child = factory->Finish(finish_options).ValueOrDie();\n+\n+  arrow::dataset::DatasetVector children{1, child};\n+  auto dataset =\n+      arrow::dataset::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                            std::string* path) {\n+  return arrow::fs::FileSystemFromUri(uri, path).ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromPath(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string path) {\n+  auto info = fs->GetFileInfo(path).ValueOrDie();\n+  return GetDatasetFromDirectory(fs, format, path);\n+}\n+\n+std::shared_ptr<arrow::dataset::Scanner> GetScannerFromDataset(\n+    std::shared_ptr<arrow::dataset::Dataset> dataset, std::vector<std::string> columns,\n+    arrow::compute::Expression filter, bool use_threads) {\n+  auto scanner_builder = dataset->NewScan().ValueOrDie();\n\nReview comment:\n       ```suggestion\r\n     EXPECT_OK_AND_ASSIGN(auto scanner_builder, dataset->NewScan());\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  arrow::dataset::InspectOptions inspect_options;\n+  arrow::dataset::FinishOptions finish_options;\n+  auto schema = factory->Inspect(inspect_options).ValueOrDie();\n+  auto child = factory->Finish(finish_options).ValueOrDie();\n+\n+  arrow::dataset::DatasetVector children{1, child};\n+  auto dataset =\n+      arrow::dataset::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                            std::string* path) {\n+  return arrow::fs::FileSystemFromUri(uri, path).ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromPath(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string path) {\n+  auto info = fs->GetFileInfo(path).ValueOrDie();\n+  return GetDatasetFromDirectory(fs, format, path);\n+}\n+\n+std::shared_ptr<arrow::dataset::Scanner> GetScannerFromDataset(\n+    std::shared_ptr<arrow::dataset::Dataset> dataset, std::vector<std::string> columns,\n+    arrow::compute::Expression filter, bool use_threads) {\n+  auto scanner_builder = dataset->NewScan().ValueOrDie();\n+\n+  if (!columns.empty()) {\n+    scanner_builder->Project(columns);\n+  }\n+\n+  scanner_builder->Filter(filter);\n+  scanner_builder->UseThreads(use_threads);\n+  return scanner_builder->Finish().ValueOrDie();\n+}\n+\n+TEST(TestSkyhookCLS, SelectEntireDataset) {\n+  std::string path;\n+  auto fs = GetFileSystemFromUri(\"file:///mnt/cephfs/nyc\", &path);\n+  std::vector<std::string> columns;\n+\n+  auto format = GetParquetFormat();\n+  auto dataset = GetDatasetFromPath(fs, format, path);\n+  auto scanner =\n+      GetScannerFromDataset(dataset, columns, arrow::compute::literal(true), true);\n+  auto table_parquet = scanner->ToTable().ValueOrDie();\n\nReview comment:\n       Use `EXPECT_...` and `ASSERT_` over `ValueOrDie` for the rest of the file.\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (options->skip_compute) {\n\nReview comment:\n       This skips compute in the sync scanner.  The sync scanner is slowly becoming deprecated and will likely not be the default scanner in 6.0.0.  You will also need to skip compute in the async scanner.  The equivalent spot would probably be `MakeScanNode` in `scanner.cc`.\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n+\n+ private:\n+  arrow::Status s_;\n+  int code_;\n+};\n\nReview comment:\n       Another option is to use `StatusDetail` to encapsulate the `code`.  For an example see https://github.com/apache/arrow/blob/4591d76fce2846a29dac33bf01e9ba0337b118e9/cpp/src/arrow/util/io_util.h#L216\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  arrow::dataset::InspectOptions inspect_options;\n+  arrow::dataset::FinishOptions finish_options;\n+  auto schema = factory->Inspect(inspect_options).ValueOrDie();\n+  auto child = factory->Finish(finish_options).ValueOrDie();\n+\n+  arrow::dataset::DatasetVector children{1, child};\n+  auto dataset =\n+      arrow::dataset::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n\nReview comment:\n       ```suggestion\r\n     EXPECT_OK_AND_ASSIGN(auto schema, factory->Inspect(inspect_options));\r\n     EXPECT_OK_AND_ASSIGN(auto dataset, factory->Finish(finish_options));\r\n     return dataset;\r\n   ```\r\n   \r\n   I can't see any reason to use `UnionDataset`.  Prefer `EXPECT_...` or `ASSERT_...` variants over `ValueOrDie`.\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  arrow::dataset::InspectOptions inspect_options;\n+  arrow::dataset::FinishOptions finish_options;\n+  auto schema = factory->Inspect(inspect_options).ValueOrDie();\n+  auto child = factory->Finish(finish_options).ValueOrDie();\n+\n+  arrow::dataset::DatasetVector children{1, child};\n+  auto dataset =\n+      arrow::dataset::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                            std::string* path) {\n+  return arrow::fs::FileSystemFromUri(uri, path).ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromPath(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string path) {\n+  auto info = fs->GetFileInfo(path).ValueOrDie();\n+  return GetDatasetFromDirectory(fs, format, path);\n+}\n+\n+std::shared_ptr<arrow::dataset::Scanner> GetScannerFromDataset(\n+    std::shared_ptr<arrow::dataset::Dataset> dataset, std::vector<std::string> columns,\n+    arrow::compute::Expression filter, bool use_threads) {\n+  auto scanner_builder = dataset->NewScan().ValueOrDie();\n+\n+  if (!columns.empty()) {\n+    scanner_builder->Project(columns);\n\nReview comment:\n       ```suggestion\r\n       ARROW_EXPECT_OK(scanner_builder->Project(columns));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n\nReview comment:\n       Use `EXPECT_OK_AND_ASSIGN`\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook.cc\n##########\n@@ -0,0 +1,258 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include <rados/objclass.h>\n+#include <memory>\n+\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/compression.h\"\n+\n+CLS_VER(1, 0)\n+CLS_NAME(skyhook)\n+\n+cls_handle_t h_class;\n+cls_method_handle_t h_scan_op;\n+\n+/// \\brief Log skyhook errors using RADOS object class SDK's logger.\n+void LogSkyhookError(const std::string& msg) { CLS_LOG(0, \"error: %s\", msg.c_str()); }\n+\n+/// \\class RandomAccessObject\n+/// \\brief An interface to provide a file-like view over RADOS objects.\n+class RandomAccessObject : public arrow::io::RandomAccessFile {\n+ public:\n+  explicit RandomAccessObject(cls_method_context_t hctx, int64_t file_size) {\n+    hctx_ = hctx;\n+    content_length_ = file_size;\n+    chunks_ = std::vector<ceph::bufferlist*>();\n+  }\n+\n+  ~RandomAccessObject() { Close(); }\n+\n+  /// Check if the file stream is closed.\n+  arrow::Status CheckClosed() const {\n+    if (closed_) {\n+      return arrow::Status::Invalid(\"Operation on closed stream\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Check if the position of the object is valid.\n+  arrow::Status CheckPosition(int64_t position, const char* action) const {\n+    if (position < 0) {\n+      return arrow::Status::Invalid(\"Cannot \", action, \" from negative position\");\n+    }\n+    if (position > content_length_) {\n+      return arrow::Status::IOError(\"Cannot \", action, \" past end of file\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<int64_t> ReadAt(int64_t position, int64_t nbytes, void* out) {\n+    return arrow::Status::NotImplemented(\n+        \"ReadAt has not been implemented in RandomAccessObject\");\n+  }\n+\n+  /// Read a specified number of bytes from a specified position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> ReadAt(int64_t position, int64_t nbytes) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"read\"));\n+\n+    // No need to allocate more than the remaining number of bytes\n+    nbytes = std::min(nbytes, content_length_ - position);\n+\n+    if (nbytes > 0) {\n+      ceph::bufferlist* bl = new ceph::bufferlist();\n+      cls_cxx_read(hctx_, position, nbytes, bl);\n+      chunks_.push_back(bl);\n+      return std::make_shared<arrow::Buffer>((uint8_t*)bl->c_str(), bl->length());\n+    }\n+    return std::make_shared<arrow::Buffer>(\"\");\n+  }\n+\n+  /// Read a specified number of bytes from the current position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> Read(int64_t nbytes) {\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, ReadAt(pos_, nbytes));\n+    pos_ += buffer->size();\n+    return std::move(buffer);\n+  }\n+\n+  /// Read a specified number of bytes from the current position into an output stream.\n+  arrow::Result<int64_t> Read(int64_t nbytes, void* out) {\n+    ARROW_ASSIGN_OR_RAISE(int64_t bytes_read, ReadAt(pos_, nbytes, out));\n+    pos_ += bytes_read;\n+    return bytes_read;\n+  }\n+\n+  /// Return the size of the file.\n+  arrow::Result<int64_t> GetSize() {\n+    RETURN_NOT_OK(CheckClosed());\n+    return content_length_;\n+  }\n+\n+  /// Sets the file-pointer offset, measured from the beginning of the\n+  /// file, at which the next read or write occurs.\n+  arrow::Status Seek(int64_t position) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"seek\"));\n+\n+    pos_ = position;\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Returns the file-pointer offset.\n+  arrow::Result<int64_t> Tell() const {\n+    RETURN_NOT_OK(CheckClosed());\n+    return pos_;\n+  }\n+\n+  /// Closes the file stream and deletes the chunks and releases the memory\n+  /// used by the chunks.\n+  arrow::Status Close() {\n+    closed_ = true;\n+    for (auto chunk : chunks_) {\n+      delete chunk;\n\nReview comment:\n       It seems like it would be more idiomatic to extend `Buffer` with a version that has `std::unique_ptr<ceph::bufferlist>` and then the `RandomAccessObject` doesn't need to worry about ownership.  Otherwise you're relying on the callers to stop accessing the buffers after the `RandomAccessObject` is destroyed which seems unsafe.  See `arrow::io::MemoryMappedFile::MemoryMap::Region` in `src/arrow/io/file.cc` for an example of something similar.\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook.cc\n##########\n@@ -0,0 +1,258 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include <rados/objclass.h>\n+#include <memory>\n+\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/compression.h\"\n+\n+CLS_VER(1, 0)\n+CLS_NAME(skyhook)\n+\n+cls_handle_t h_class;\n+cls_method_handle_t h_scan_op;\n+\n+/// \\brief Log skyhook errors using RADOS object class SDK's logger.\n+void LogSkyhookError(const std::string& msg) { CLS_LOG(0, \"error: %s\", msg.c_str()); }\n+\n+/// \\class RandomAccessObject\n+/// \\brief An interface to provide a file-like view over RADOS objects.\n+class RandomAccessObject : public arrow::io::RandomAccessFile {\n+ public:\n+  explicit RandomAccessObject(cls_method_context_t hctx, int64_t file_size) {\n+    hctx_ = hctx;\n+    content_length_ = file_size;\n+    chunks_ = std::vector<ceph::bufferlist*>();\n+  }\n+\n+  ~RandomAccessObject() { Close(); }\n+\n+  /// Check if the file stream is closed.\n+  arrow::Status CheckClosed() const {\n+    if (closed_) {\n+      return arrow::Status::Invalid(\"Operation on closed stream\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Check if the position of the object is valid.\n+  arrow::Status CheckPosition(int64_t position, const char* action) const {\n+    if (position < 0) {\n+      return arrow::Status::Invalid(\"Cannot \", action, \" from negative position\");\n+    }\n+    if (position > content_length_) {\n+      return arrow::Status::IOError(\"Cannot \", action, \" past end of file\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<int64_t> ReadAt(int64_t position, int64_t nbytes, void* out) {\n+    return arrow::Status::NotImplemented(\n+        \"ReadAt has not been implemented in RandomAccessObject\");\n+  }\n+\n+  /// Read a specified number of bytes from a specified position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> ReadAt(int64_t position, int64_t nbytes) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"read\"));\n+\n+    // No need to allocate more than the remaining number of bytes\n+    nbytes = std::min(nbytes, content_length_ - position);\n+\n+    if (nbytes > 0) {\n+      ceph::bufferlist* bl = new ceph::bufferlist();\n+      cls_cxx_read(hctx_, position, nbytes, bl);\n+      chunks_.push_back(bl);\n+      return std::make_shared<arrow::Buffer>((uint8_t*)bl->c_str(), bl->length());\n+    }\n+    return std::make_shared<arrow::Buffer>(\"\");\n+  }\n+\n+  /// Read a specified number of bytes from the current position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> Read(int64_t nbytes) {\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, ReadAt(pos_, nbytes));\n+    pos_ += buffer->size();\n+    return std::move(buffer);\n+  }\n+\n+  /// Read a specified number of bytes from the current position into an output stream.\n+  arrow::Result<int64_t> Read(int64_t nbytes, void* out) {\n+    ARROW_ASSIGN_OR_RAISE(int64_t bytes_read, ReadAt(pos_, nbytes, out));\n+    pos_ += bytes_read;\n+    return bytes_read;\n+  }\n+\n+  /// Return the size of the file.\n+  arrow::Result<int64_t> GetSize() {\n+    RETURN_NOT_OK(CheckClosed());\n+    return content_length_;\n+  }\n+\n+  /// Sets the file-pointer offset, measured from the beginning of the\n+  /// file, at which the next read or write occurs.\n+  arrow::Status Seek(int64_t position) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"seek\"));\n+\n+    pos_ = position;\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Returns the file-pointer offset.\n+  arrow::Result<int64_t> Tell() const {\n+    RETURN_NOT_OK(CheckClosed());\n+    return pos_;\n+  }\n+\n+  /// Closes the file stream and deletes the chunks and releases the memory\n+  /// used by the chunks.\n+  arrow::Status Close() {\n+    closed_ = true;\n+    for (auto chunk : chunks_) {\n+      delete chunk;\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  bool closed() const { return closed_; }\n+\n+ private:\n+  cls_method_context_t hctx_;\n+  bool closed_ = false;\n+  int64_t pos_ = 0;\n+  int64_t content_length_ = -1;\n+  std::vector<ceph::bufferlist*> chunks_;\n+};\n+\n+/// \\brief  Driver function to execute the Scan operations.\n+/// \\param[in] hctx RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[in] format The file format instance to use in the scan.\n+/// \\param[in] fragment_scan_options The fragment scan options to use to customize the\n+/// scan. \\return Table.\n+arrow::Result<std::shared_ptr<arrow::Table>> DoScan(\n+    cls_method_context_t hctx, skyhook::ScanRequest req,\n+    std::shared_ptr<arrow::dataset::FileFormat> format,\n+    std::shared_ptr<arrow::dataset::FragmentScanOptions> fragment_scan_options) {\n+  auto file = std::make_shared<RandomAccessObject>(hctx, req.file_size);\n+  auto source = std::make_shared<arrow::dataset::FileSource>(file);\n+  ARROW_ASSIGN_OR_RAISE(auto fragment,\n+                        format->MakeFragment(*source, req.partition_expression));\n+  auto options = std::make_shared<arrow::dataset::ScanOptions>();\n+  auto builder = std::make_shared<arrow::dataset::ScannerBuilder>(req.dataset_schema,\n+                                                                  fragment, options);\n+\n+  ARROW_RETURN_NOT_OK(builder->Filter(req.filter_expression));\n+  ARROW_RETURN_NOT_OK(builder->Project(req.projection_schema->field_names()));\n+  ARROW_RETURN_NOT_OK(builder->UseThreads(true));\n+  ARROW_RETURN_NOT_OK(builder->FragmentScanOptions(fragment_scan_options));\n+\n+  ARROW_ASSIGN_OR_RAISE(auto scanner, builder->Finish());\n+  ARROW_ASSIGN_OR_RAISE(auto table, scanner->ToTable());\n+  return table;\n+}\n+\n+/// \\brief Scan RADOS objects containing Arrow IPC data.\n+/// \\param[in] hctx The RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[out] result_table A table to store the resultant data.\n+/// \\return Status.\n+static arrow::Status ScanIpcObject(cls_method_context_t hctx, skyhook::ScanRequest req,\n+                                   std::shared_ptr<arrow::Table>* result_table) {\n+  auto format = std::make_shared<arrow::dataset::IpcFileFormat>();\n+  auto fragment_scan_options = std::make_shared<arrow::dataset::IpcFragmentScanOptions>();\n+\n+  ARROW_ASSIGN_OR_RAISE(*result_table, DoScan(hctx, req, format, fragment_scan_options));\n\nReview comment:\n       ```suggestion\r\n     ARROW_ASSIGN_OR_RAISE(*result_table, DoScan(hctx, req, std::move(format), std::move(fragment_scan_options)));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook.cc\n##########\n@@ -0,0 +1,258 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include <rados/objclass.h>\n+#include <memory>\n+\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/compression.h\"\n+\n+CLS_VER(1, 0)\n+CLS_NAME(skyhook)\n+\n+cls_handle_t h_class;\n+cls_method_handle_t h_scan_op;\n+\n+/// \\brief Log skyhook errors using RADOS object class SDK's logger.\n+void LogSkyhookError(const std::string& msg) { CLS_LOG(0, \"error: %s\", msg.c_str()); }\n+\n+/// \\class RandomAccessObject\n+/// \\brief An interface to provide a file-like view over RADOS objects.\n+class RandomAccessObject : public arrow::io::RandomAccessFile {\n+ public:\n+  explicit RandomAccessObject(cls_method_context_t hctx, int64_t file_size) {\n+    hctx_ = hctx;\n+    content_length_ = file_size;\n+    chunks_ = std::vector<ceph::bufferlist*>();\n+  }\n+\n+  ~RandomAccessObject() { Close(); }\n+\n+  /// Check if the file stream is closed.\n+  arrow::Status CheckClosed() const {\n+    if (closed_) {\n+      return arrow::Status::Invalid(\"Operation on closed stream\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Check if the position of the object is valid.\n+  arrow::Status CheckPosition(int64_t position, const char* action) const {\n+    if (position < 0) {\n+      return arrow::Status::Invalid(\"Cannot \", action, \" from negative position\");\n+    }\n+    if (position > content_length_) {\n+      return arrow::Status::IOError(\"Cannot \", action, \" past end of file\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<int64_t> ReadAt(int64_t position, int64_t nbytes, void* out) {\n+    return arrow::Status::NotImplemented(\n+        \"ReadAt has not been implemented in RandomAccessObject\");\n+  }\n+\n+  /// Read a specified number of bytes from a specified position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> ReadAt(int64_t position, int64_t nbytes) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"read\"));\n+\n+    // No need to allocate more than the remaining number of bytes\n+    nbytes = std::min(nbytes, content_length_ - position);\n+\n+    if (nbytes > 0) {\n+      ceph::bufferlist* bl = new ceph::bufferlist();\n+      cls_cxx_read(hctx_, position, nbytes, bl);\n+      chunks_.push_back(bl);\n+      return std::make_shared<arrow::Buffer>((uint8_t*)bl->c_str(), bl->length());\n+    }\n+    return std::make_shared<arrow::Buffer>(\"\");\n+  }\n+\n+  /// Read a specified number of bytes from the current position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> Read(int64_t nbytes) {\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, ReadAt(pos_, nbytes));\n+    pos_ += buffer->size();\n+    return std::move(buffer);\n+  }\n+\n+  /// Read a specified number of bytes from the current position into an output stream.\n+  arrow::Result<int64_t> Read(int64_t nbytes, void* out) {\n+    ARROW_ASSIGN_OR_RAISE(int64_t bytes_read, ReadAt(pos_, nbytes, out));\n+    pos_ += bytes_read;\n+    return bytes_read;\n+  }\n+\n+  /// Return the size of the file.\n+  arrow::Result<int64_t> GetSize() {\n+    RETURN_NOT_OK(CheckClosed());\n+    return content_length_;\n+  }\n+\n+  /// Sets the file-pointer offset, measured from the beginning of the\n+  /// file, at which the next read or write occurs.\n+  arrow::Status Seek(int64_t position) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"seek\"));\n+\n+    pos_ = position;\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Returns the file-pointer offset.\n+  arrow::Result<int64_t> Tell() const {\n+    RETURN_NOT_OK(CheckClosed());\n+    return pos_;\n+  }\n+\n+  /// Closes the file stream and deletes the chunks and releases the memory\n+  /// used by the chunks.\n+  arrow::Status Close() {\n+    closed_ = true;\n+    for (auto chunk : chunks_) {\n+      delete chunk;\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  bool closed() const { return closed_; }\n+\n+ private:\n+  cls_method_context_t hctx_;\n+  bool closed_ = false;\n+  int64_t pos_ = 0;\n+  int64_t content_length_ = -1;\n+  std::vector<ceph::bufferlist*> chunks_;\n+};\n+\n+/// \\brief  Driver function to execute the Scan operations.\n+/// \\param[in] hctx RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[in] format The file format instance to use in the scan.\n+/// \\param[in] fragment_scan_options The fragment scan options to use to customize the\n+/// scan. \\return Table.\n+arrow::Result<std::shared_ptr<arrow::Table>> DoScan(\n+    cls_method_context_t hctx, skyhook::ScanRequest req,\n+    std::shared_ptr<arrow::dataset::FileFormat> format,\n+    std::shared_ptr<arrow::dataset::FragmentScanOptions> fragment_scan_options) {\n+  auto file = std::make_shared<RandomAccessObject>(hctx, req.file_size);\n+  auto source = std::make_shared<arrow::dataset::FileSource>(file);\n+  ARROW_ASSIGN_OR_RAISE(auto fragment,\n+                        format->MakeFragment(*source, req.partition_expression));\n+  auto options = std::make_shared<arrow::dataset::ScanOptions>();\n+  auto builder = std::make_shared<arrow::dataset::ScannerBuilder>(req.dataset_schema,\n+                                                                  fragment, options);\n+\n+  ARROW_RETURN_NOT_OK(builder->Filter(req.filter_expression));\n+  ARROW_RETURN_NOT_OK(builder->Project(req.projection_schema->field_names()));\n+  ARROW_RETURN_NOT_OK(builder->UseThreads(true));\n+  ARROW_RETURN_NOT_OK(builder->FragmentScanOptions(fragment_scan_options));\n+\n+  ARROW_ASSIGN_OR_RAISE(auto scanner, builder->Finish());\n+  ARROW_ASSIGN_OR_RAISE(auto table, scanner->ToTable());\n+  return table;\n+}\n+\n+/// \\brief Scan RADOS objects containing Arrow IPC data.\n+/// \\param[in] hctx The RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[out] result_table A table to store the resultant data.\n+/// \\return Status.\n+static arrow::Status ScanIpcObject(cls_method_context_t hctx, skyhook::ScanRequest req,\n\nReview comment:\n       Consider returning `Result<std::shared_ptr<Table>>` instead of using a single out parameter.\n\n##########\nFile path: cpp/src/skyhook/protocol/ScanRequest.fbs\n##########\n@@ -0,0 +1,33 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+/// EXPERIMENTAL: Metadata for n-dimensional arrays, aka \"tensors\" or\n+/// \"ndarrays\". Arrow implementations in general are not required to implement\n+/// this type\n+\n+namespace org.apache.arrow.flatbuf;\n+\n+table ScanRequest {\n+  file_size: long;\n+  file_format: short;\n+  filter: [ubyte];\n+  partition: [ubyte];\n+  dataset_schema: [ubyte];\n+  projection_schema: [ubyte];\n+}\n+\n+root_type ScanRequest;\n\nReview comment:\n       ```suggestion\r\n   root_type ScanRequest;\r\n   \r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook.cc\n##########\n@@ -0,0 +1,258 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include <rados/objclass.h>\n+#include <memory>\n+\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/compression.h\"\n+\n+CLS_VER(1, 0)\n+CLS_NAME(skyhook)\n+\n+cls_handle_t h_class;\n+cls_method_handle_t h_scan_op;\n+\n+/// \\brief Log skyhook errors using RADOS object class SDK's logger.\n+void LogSkyhookError(const std::string& msg) { CLS_LOG(0, \"error: %s\", msg.c_str()); }\n+\n+/// \\class RandomAccessObject\n+/// \\brief An interface to provide a file-like view over RADOS objects.\n+class RandomAccessObject : public arrow::io::RandomAccessFile {\n+ public:\n+  explicit RandomAccessObject(cls_method_context_t hctx, int64_t file_size) {\n+    hctx_ = hctx;\n+    content_length_ = file_size;\n+    chunks_ = std::vector<ceph::bufferlist*>();\n+  }\n+\n+  ~RandomAccessObject() { Close(); }\n+\n+  /// Check if the file stream is closed.\n+  arrow::Status CheckClosed() const {\n+    if (closed_) {\n+      return arrow::Status::Invalid(\"Operation on closed stream\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Check if the position of the object is valid.\n+  arrow::Status CheckPosition(int64_t position, const char* action) const {\n+    if (position < 0) {\n+      return arrow::Status::Invalid(\"Cannot \", action, \" from negative position\");\n+    }\n+    if (position > content_length_) {\n+      return arrow::Status::IOError(\"Cannot \", action, \" past end of file\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<int64_t> ReadAt(int64_t position, int64_t nbytes, void* out) {\n+    return arrow::Status::NotImplemented(\n+        \"ReadAt has not been implemented in RandomAccessObject\");\n+  }\n+\n+  /// Read a specified number of bytes from a specified position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> ReadAt(int64_t position, int64_t nbytes) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"read\"));\n+\n+    // No need to allocate more than the remaining number of bytes\n+    nbytes = std::min(nbytes, content_length_ - position);\n+\n+    if (nbytes > 0) {\n+      ceph::bufferlist* bl = new ceph::bufferlist();\n+      cls_cxx_read(hctx_, position, nbytes, bl);\n+      chunks_.push_back(bl);\n+      return std::make_shared<arrow::Buffer>((uint8_t*)bl->c_str(), bl->length());\n+    }\n+    return std::make_shared<arrow::Buffer>(\"\");\n+  }\n+\n+  /// Read a specified number of bytes from the current position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> Read(int64_t nbytes) {\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, ReadAt(pos_, nbytes));\n+    pos_ += buffer->size();\n+    return std::move(buffer);\n+  }\n+\n+  /// Read a specified number of bytes from the current position into an output stream.\n+  arrow::Result<int64_t> Read(int64_t nbytes, void* out) {\n+    ARROW_ASSIGN_OR_RAISE(int64_t bytes_read, ReadAt(pos_, nbytes, out));\n+    pos_ += bytes_read;\n+    return bytes_read;\n+  }\n+\n+  /// Return the size of the file.\n+  arrow::Result<int64_t> GetSize() {\n+    RETURN_NOT_OK(CheckClosed());\n+    return content_length_;\n+  }\n+\n+  /// Sets the file-pointer offset, measured from the beginning of the\n+  /// file, at which the next read or write occurs.\n+  arrow::Status Seek(int64_t position) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"seek\"));\n+\n+    pos_ = position;\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Returns the file-pointer offset.\n+  arrow::Result<int64_t> Tell() const {\n+    RETURN_NOT_OK(CheckClosed());\n+    return pos_;\n+  }\n+\n+  /// Closes the file stream and deletes the chunks and releases the memory\n+  /// used by the chunks.\n+  arrow::Status Close() {\n+    closed_ = true;\n+    for (auto chunk : chunks_) {\n+      delete chunk;\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  bool closed() const { return closed_; }\n+\n+ private:\n+  cls_method_context_t hctx_;\n+  bool closed_ = false;\n+  int64_t pos_ = 0;\n+  int64_t content_length_ = -1;\n+  std::vector<ceph::bufferlist*> chunks_;\n+};\n+\n+/// \\brief  Driver function to execute the Scan operations.\n+/// \\param[in] hctx RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[in] format The file format instance to use in the scan.\n+/// \\param[in] fragment_scan_options The fragment scan options to use to customize the\n+/// scan. \\return Table.\n\nReview comment:\n       ```suggestion\r\n   /// scan.\r\n   /// \\return Table.\r\n   ```\r\n   Or, alternatively, just don't include the `\\return` line if there is nothing useful to add\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.cc\n##########\n@@ -0,0 +1,112 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/rados_protocol.h\"\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace skyhook {\n+namespace rados {\n+\n+RadosStatus GetStatusFromReturnCode(int code, std::string msg) {\n+  if (code) return RadosStatus(arrow::Status::Invalid(msg), code);\n+  return RadosStatus(arrow::Status::OK(), code);\n+}\n+\n+RadosStatus IoCtxWrapper::write_full(const std::string& oid, ceph::bufferlist& bl) {\n+  return GetStatusFromReturnCode(this->ioCtx->write_full(oid, bl),\n+                                 \"ioctx->write_full failed.\");\n+}\n+\n+RadosStatus IoCtxWrapper::read(const std::string& oid, ceph::bufferlist& bl, size_t len,\n+                               uint64_t offset) {\n+  return GetStatusFromReturnCode(this->ioCtx->read(oid, bl, len, offset),\n+                                 \"ioctx->read failed.\");\n+}\n+\n+RadosStatus IoCtxWrapper::exec(const std::string& oid, const char* cls,\n+                               const char* method, ceph::bufferlist& in,\n+                               ceph::bufferlist& out) {\n+  return GetStatusFromReturnCode(this->ioCtx->exec(oid, cls, method, in, out),\n+                                 \"ioctx->exec failed.\");\n+}\n+\n+RadosStatus IoCtxWrapper::stat(const std::string& oid, uint64_t* psize) {\n+  return GetStatusFromReturnCode(this->ioCtx->stat(oid, psize, NULL),\n+                                 \"ioctx->stat failed.\");\n+}\n+\n+std::vector<std::string> IoCtxWrapper::list() {\n+  std::vector<std::string> oids;\n+  librados::NObjectIterator begin = this->ioCtx->nobjects_begin();\n+  librados::NObjectIterator end = this->ioCtx->nobjects_end();\n+  for (; begin != end; begin++) {\n+    oids.push_back(begin->get_oid());\n+  }\n+  return oids;\n+}\n+\n+RadosStatus RadosWrapper::init2(const char* const name, const char* const clustername,\n+                                uint64_t flags) {\n+  return GetStatusFromReturnCode(this->cluster->init2(name, clustername, flags),\n+                                 \"rados->init failed.\");\n+}\n+\n+RadosStatus RadosWrapper::ioctx_create(const char* name, IoCtxInterface* pioctx) {\n+  librados::IoCtx ioCtx;\n+  int ret = this->cluster->ioctx_create(name, ioCtx);\n+  pioctx->setIoCtx(&ioCtx);\n+  return GetStatusFromReturnCode(ret, \"rados->ioctx_create failed.\");\n+}\n+\n+RadosStatus RadosWrapper::conf_read_file(const char* const path) {\n+  return GetStatusFromReturnCode(this->cluster->conf_read_file(path),\n+                                 \"rados->conf_read_file failed.\");\n+}\n+\n+RadosStatus RadosWrapper::connect() {\n+  return GetStatusFromReturnCode(this->cluster->connect(), \"rados->connect failed.\");\n+}\n+\n+void RadosWrapper::shutdown() { this->cluster->shutdown(); }\n+\n+RadosConn::~RadosConn() { Shutdown(); }\n+\n+arrow::Status RadosConn::Connect() {\n+  if (connected) {\n+    return arrow::Status::OK();\n+  }\n+\n+  ARROW_RETURN_NOT_OK(\n+      rados->init2(ctx->ceph_user_name.c_str(), ctx->ceph_cluster_name.c_str(), 0)\n+          .status());\n+  ARROW_RETURN_NOT_OK(rados->conf_read_file(ctx->ceph_config_path.c_str()).status());\n+  ARROW_RETURN_NOT_OK(rados->connect().status());\n+  ARROW_RETURN_NOT_OK(rados->ioctx_create(ctx->ceph_data_pool.c_str(), io_ctx).status());\n+  return arrow::Status::OK();\n+}\n+\n+arrow::Status RadosConn::Shutdown() {\n+  if (connected) {\n+    rados->shutdown();\n+    connected = false;\n+  }\n+  return arrow::Status::OK();\n+}\n\nReview comment:\n       ```suggestion\r\n   void RadosConn::Shutdown() {\r\n     if (connected) {\r\n       rados->shutdown();\r\n       connected = false;\r\n     }\r\n   }\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n\nReview comment:\n       ```suggestion\r\n     int code() const { return code_; }\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook_test.cc\n##########\n@@ -0,0 +1,208 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"gtest/gtest.h\"\n+\n+#include \"parquet/arrow/reader.h\"\n+#include \"parquet/arrow/writer.h\"\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> GetSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"skyhook\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = std::make_shared<skyhook::SkyhookFileFormat>(rados_ctx, \"parquet\");\n+  format->Init();\n+  return format;\n+}\n+\n+std::shared_ptr<arrow::dataset::ParquetFileFormat> GetParquetFormat() {\n+  return std::make_shared<arrow::dataset::ParquetFileFormat>();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string dir) {\n+  arrow::fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  arrow::dataset::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<arrow::dataset::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+  auto factory =\n+      arrow::dataset::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  arrow::dataset::InspectOptions inspect_options;\n+  arrow::dataset::FinishOptions finish_options;\n+  auto schema = factory->Inspect(inspect_options).ValueOrDie();\n+  auto child = factory->Finish(finish_options).ValueOrDie();\n+\n+  arrow::dataset::DatasetVector children{1, child};\n+  auto dataset =\n+      arrow::dataset::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                            std::string* path) {\n+  return arrow::fs::FileSystemFromUri(uri, path).ValueOrDie();\n+}\n+\n+std::shared_ptr<arrow::dataset::Dataset> GetDatasetFromPath(\n+    std::shared_ptr<arrow::fs::FileSystem> fs,\n+    std::shared_ptr<arrow::dataset::FileFormat> format, std::string path) {\n+  auto info = fs->GetFileInfo(path).ValueOrDie();\n+  return GetDatasetFromDirectory(fs, format, path);\n+}\n+\n+std::shared_ptr<arrow::dataset::Scanner> GetScannerFromDataset(\n+    std::shared_ptr<arrow::dataset::Dataset> dataset, std::vector<std::string> columns,\n+    arrow::compute::Expression filter, bool use_threads) {\n+  auto scanner_builder = dataset->NewScan().ValueOrDie();\n+\n+  if (!columns.empty()) {\n+    scanner_builder->Project(columns);\n+  }\n+\n+  scanner_builder->Filter(filter);\n\nReview comment:\n       ```suggestion\r\n     ARROW_EXPECT_OK(scanner_builder->Filter(filter));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook.cc\n##########\n@@ -0,0 +1,258 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include <rados/objclass.h>\n+#include <memory>\n+\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/compression.h\"\n+\n+CLS_VER(1, 0)\n+CLS_NAME(skyhook)\n+\n+cls_handle_t h_class;\n+cls_method_handle_t h_scan_op;\n+\n+/// \\brief Log skyhook errors using RADOS object class SDK's logger.\n+void LogSkyhookError(const std::string& msg) { CLS_LOG(0, \"error: %s\", msg.c_str()); }\n+\n+/// \\class RandomAccessObject\n+/// \\brief An interface to provide a file-like view over RADOS objects.\n+class RandomAccessObject : public arrow::io::RandomAccessFile {\n+ public:\n+  explicit RandomAccessObject(cls_method_context_t hctx, int64_t file_size) {\n+    hctx_ = hctx;\n+    content_length_ = file_size;\n+    chunks_ = std::vector<ceph::bufferlist*>();\n+  }\n+\n+  ~RandomAccessObject() { Close(); }\n+\n+  /// Check if the file stream is closed.\n+  arrow::Status CheckClosed() const {\n+    if (closed_) {\n+      return arrow::Status::Invalid(\"Operation on closed stream\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Check if the position of the object is valid.\n+  arrow::Status CheckPosition(int64_t position, const char* action) const {\n+    if (position < 0) {\n+      return arrow::Status::Invalid(\"Cannot \", action, \" from negative position\");\n+    }\n+    if (position > content_length_) {\n+      return arrow::Status::IOError(\"Cannot \", action, \" past end of file\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<int64_t> ReadAt(int64_t position, int64_t nbytes, void* out) {\n+    return arrow::Status::NotImplemented(\n+        \"ReadAt has not been implemented in RandomAccessObject\");\n+  }\n+\n+  /// Read a specified number of bytes from a specified position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> ReadAt(int64_t position, int64_t nbytes) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"read\"));\n+\n+    // No need to allocate more than the remaining number of bytes\n+    nbytes = std::min(nbytes, content_length_ - position);\n+\n+    if (nbytes > 0) {\n+      ceph::bufferlist* bl = new ceph::bufferlist();\n+      cls_cxx_read(hctx_, position, nbytes, bl);\n+      chunks_.push_back(bl);\n+      return std::make_shared<arrow::Buffer>((uint8_t*)bl->c_str(), bl->length());\n+    }\n+    return std::make_shared<arrow::Buffer>(\"\");\n+  }\n+\n+  /// Read a specified number of bytes from the current position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> Read(int64_t nbytes) {\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, ReadAt(pos_, nbytes));\n+    pos_ += buffer->size();\n+    return std::move(buffer);\n+  }\n+\n+  /// Read a specified number of bytes from the current position into an output stream.\n+  arrow::Result<int64_t> Read(int64_t nbytes, void* out) {\n+    ARROW_ASSIGN_OR_RAISE(int64_t bytes_read, ReadAt(pos_, nbytes, out));\n+    pos_ += bytes_read;\n+    return bytes_read;\n+  }\n+\n+  /// Return the size of the file.\n+  arrow::Result<int64_t> GetSize() {\n+    RETURN_NOT_OK(CheckClosed());\n+    return content_length_;\n+  }\n+\n+  /// Sets the file-pointer offset, measured from the beginning of the\n+  /// file, at which the next read or write occurs.\n+  arrow::Status Seek(int64_t position) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"seek\"));\n+\n+    pos_ = position;\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Returns the file-pointer offset.\n+  arrow::Result<int64_t> Tell() const {\n+    RETURN_NOT_OK(CheckClosed());\n+    return pos_;\n+  }\n+\n+  /// Closes the file stream and deletes the chunks and releases the memory\n+  /// used by the chunks.\n+  arrow::Status Close() {\n+    closed_ = true;\n+    for (auto chunk : chunks_) {\n+      delete chunk;\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  bool closed() const { return closed_; }\n+\n+ private:\n+  cls_method_context_t hctx_;\n+  bool closed_ = false;\n+  int64_t pos_ = 0;\n+  int64_t content_length_ = -1;\n+  std::vector<ceph::bufferlist*> chunks_;\n+};\n+\n+/// \\brief  Driver function to execute the Scan operations.\n+/// \\param[in] hctx RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[in] format The file format instance to use in the scan.\n+/// \\param[in] fragment_scan_options The fragment scan options to use to customize the\n+/// scan. \\return Table.\n+arrow::Result<std::shared_ptr<arrow::Table>> DoScan(\n+    cls_method_context_t hctx, skyhook::ScanRequest req,\n+    std::shared_ptr<arrow::dataset::FileFormat> format,\n+    std::shared_ptr<arrow::dataset::FragmentScanOptions> fragment_scan_options) {\n+  auto file = std::make_shared<RandomAccessObject>(hctx, req.file_size);\n+  auto source = std::make_shared<arrow::dataset::FileSource>(file);\n+  ARROW_ASSIGN_OR_RAISE(auto fragment,\n+                        format->MakeFragment(*source, req.partition_expression));\n+  auto options = std::make_shared<arrow::dataset::ScanOptions>();\n+  auto builder = std::make_shared<arrow::dataset::ScannerBuilder>(req.dataset_schema,\n+                                                                  fragment, options);\n+\n+  ARROW_RETURN_NOT_OK(builder->Filter(req.filter_expression));\n+  ARROW_RETURN_NOT_OK(builder->Project(req.projection_schema->field_names()));\n+  ARROW_RETURN_NOT_OK(builder->UseThreads(true));\n+  ARROW_RETURN_NOT_OK(builder->FragmentScanOptions(fragment_scan_options));\n+\n+  ARROW_ASSIGN_OR_RAISE(auto scanner, builder->Finish());\n+  ARROW_ASSIGN_OR_RAISE(auto table, scanner->ToTable());\n+  return table;\n+}\n+\n+/// \\brief Scan RADOS objects containing Arrow IPC data.\n+/// \\param[in] hctx The RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[out] result_table A table to store the resultant data.\n+/// \\return Status.\n+static arrow::Status ScanIpcObject(cls_method_context_t hctx, skyhook::ScanRequest req,\n+                                   std::shared_ptr<arrow::Table>* result_table) {\n+  auto format = std::make_shared<arrow::dataset::IpcFileFormat>();\n+  auto fragment_scan_options = std::make_shared<arrow::dataset::IpcFragmentScanOptions>();\n+\n+  ARROW_ASSIGN_OR_RAISE(*result_table, DoScan(hctx, req, format, fragment_scan_options));\n+\n+  return arrow::Status::OK();\n+}\n+\n+/// \\brief Scan RADOS objects containing Parquet binary data.\n+/// \\param[in] hctx The RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[out] result_table A table to store the resultant data.\n+/// \\return Status.\n+static arrow::Status ScanParquetObject(cls_method_context_t hctx,\n+                                       skyhook::ScanRequest req,\n+                                       std::shared_ptr<arrow::Table>* result_table) {\n+  auto format = std::make_shared<arrow::dataset::ParquetFileFormat>();\n+  auto fragment_scan_options =\n+      std::make_shared<arrow::dataset::ParquetFragmentScanOptions>();\n+\n+  ARROW_ASSIGN_OR_RAISE(*result_table, DoScan(hctx, req, format, fragment_scan_options));\n\nReview comment:\n       ```suggestion\r\n     ARROW_ASSIGN_OR_RAISE(*result_table, DoScan(hctx, req, std::move(format), std::move(fragment_scan_options)));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook.cc\n##########\n@@ -0,0 +1,258 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include <rados/objclass.h>\n+#include <memory>\n+\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/compression.h\"\n+\n+CLS_VER(1, 0)\n+CLS_NAME(skyhook)\n+\n+cls_handle_t h_class;\n+cls_method_handle_t h_scan_op;\n+\n+/// \\brief Log skyhook errors using RADOS object class SDK's logger.\n+void LogSkyhookError(const std::string& msg) { CLS_LOG(0, \"error: %s\", msg.c_str()); }\n+\n+/// \\class RandomAccessObject\n+/// \\brief An interface to provide a file-like view over RADOS objects.\n+class RandomAccessObject : public arrow::io::RandomAccessFile {\n+ public:\n+  explicit RandomAccessObject(cls_method_context_t hctx, int64_t file_size) {\n+    hctx_ = hctx;\n+    content_length_ = file_size;\n+    chunks_ = std::vector<ceph::bufferlist*>();\n+  }\n+\n+  ~RandomAccessObject() { Close(); }\n+\n+  /// Check if the file stream is closed.\n+  arrow::Status CheckClosed() const {\n+    if (closed_) {\n+      return arrow::Status::Invalid(\"Operation on closed stream\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Check if the position of the object is valid.\n+  arrow::Status CheckPosition(int64_t position, const char* action) const {\n+    if (position < 0) {\n+      return arrow::Status::Invalid(\"Cannot \", action, \" from negative position\");\n+    }\n+    if (position > content_length_) {\n+      return arrow::Status::IOError(\"Cannot \", action, \" past end of file\");\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<int64_t> ReadAt(int64_t position, int64_t nbytes, void* out) {\n+    return arrow::Status::NotImplemented(\n+        \"ReadAt has not been implemented in RandomAccessObject\");\n+  }\n+\n+  /// Read a specified number of bytes from a specified position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> ReadAt(int64_t position, int64_t nbytes) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"read\"));\n+\n+    // No need to allocate more than the remaining number of bytes\n+    nbytes = std::min(nbytes, content_length_ - position);\n+\n+    if (nbytes > 0) {\n+      ceph::bufferlist* bl = new ceph::bufferlist();\n+      cls_cxx_read(hctx_, position, nbytes, bl);\n+      chunks_.push_back(bl);\n+      return std::make_shared<arrow::Buffer>((uint8_t*)bl->c_str(), bl->length());\n+    }\n+    return std::make_shared<arrow::Buffer>(\"\");\n+  }\n+\n+  /// Read a specified number of bytes from the current position.\n+  arrow::Result<std::shared_ptr<arrow::Buffer>> Read(int64_t nbytes) {\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, ReadAt(pos_, nbytes));\n+    pos_ += buffer->size();\n+    return std::move(buffer);\n+  }\n+\n+  /// Read a specified number of bytes from the current position into an output stream.\n+  arrow::Result<int64_t> Read(int64_t nbytes, void* out) {\n+    ARROW_ASSIGN_OR_RAISE(int64_t bytes_read, ReadAt(pos_, nbytes, out));\n+    pos_ += bytes_read;\n+    return bytes_read;\n+  }\n+\n+  /// Return the size of the file.\n+  arrow::Result<int64_t> GetSize() {\n+    RETURN_NOT_OK(CheckClosed());\n+    return content_length_;\n+  }\n+\n+  /// Sets the file-pointer offset, measured from the beginning of the\n+  /// file, at which the next read or write occurs.\n+  arrow::Status Seek(int64_t position) {\n+    RETURN_NOT_OK(CheckClosed());\n+    RETURN_NOT_OK(CheckPosition(position, \"seek\"));\n+\n+    pos_ = position;\n+    return arrow::Status::OK();\n+  }\n+\n+  /// Returns the file-pointer offset.\n+  arrow::Result<int64_t> Tell() const {\n+    RETURN_NOT_OK(CheckClosed());\n+    return pos_;\n+  }\n+\n+  /// Closes the file stream and deletes the chunks and releases the memory\n+  /// used by the chunks.\n+  arrow::Status Close() {\n+    closed_ = true;\n+    for (auto chunk : chunks_) {\n+      delete chunk;\n+    }\n+    return arrow::Status::OK();\n+  }\n+\n+  bool closed() const { return closed_; }\n+\n+ private:\n+  cls_method_context_t hctx_;\n+  bool closed_ = false;\n+  int64_t pos_ = 0;\n+  int64_t content_length_ = -1;\n+  std::vector<ceph::bufferlist*> chunks_;\n+};\n+\n+/// \\brief  Driver function to execute the Scan operations.\n+/// \\param[in] hctx RADOS object context.\n+/// \\param[in] req The scan request received from the client.\n+/// \\param[in] format The file format instance to use in the scan.\n+/// \\param[in] fragment_scan_options The fragment scan options to use to customize the\n+/// scan. \\return Table.\n+arrow::Result<std::shared_ptr<arrow::Table>> DoScan(\n+    cls_method_context_t hctx, skyhook::ScanRequest req,\n+    std::shared_ptr<arrow::dataset::FileFormat> format,\n+    std::shared_ptr<arrow::dataset::FragmentScanOptions> fragment_scan_options) {\n+  auto file = std::make_shared<RandomAccessObject>(hctx, req.file_size);\n+  auto source = std::make_shared<arrow::dataset::FileSource>(file);\n+  ARROW_ASSIGN_OR_RAISE(auto fragment,\n+                        format->MakeFragment(*source, req.partition_expression));\n\nReview comment:\n       ```suggestion\r\n     arrow::dataset::FileSource source(file);\r\n     ARROW_ASSIGN_OR_RAISE(auto fragment,\r\n                           format->MakeFragment(std::move(source), req.partition_expression));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n+\n+ private:\n+  arrow::Status s_;\n+  int code_;\n+};\n+\n+class IoCtxInterface {\n+ public:\n+  IoCtxInterface() {}\n+\n+  /// \\brief Write data to an object.\n+  ///\n+  /// \\param[in] oid the ID of the object to write.\n+  /// \\param[in] bl a bufferlist containing the data to write to the object.\n+  virtual RadosStatus write_full(const std::string& oid, ceph::bufferlist& bl) = 0;\n+\n+  /// \\brief Read a RADOS object.\n+  ///\n+  /// \\param[in] oid the object ID which to read.\n+  /// \\param[in] bl a bufferlist to hold the contents of the read object.\n+  /// \\param[in] len the length of data to read from an object.\n+  /// \\param[in] offset the offset of the object to read from.\n+  virtual RadosStatus read(const std::string& oid, ceph::bufferlist& bl, size_t len,\n+                           uint64_t offset) = 0;\n+\n+  /// \\brief Executes a CLS function.\n+  ///\n+  /// \\param[in] oid the object ID on which to execute the CLS function.\n+  /// \\param[in] cls the name of the CLS.\n+  /// \\param[in] method the name of the CLS function.\n+  /// \\param[in] in a bufferlist to send data to the CLS function.\n+  /// \\param[in] out a bufferlist to recieve data from the CLS function.\n+  virtual RadosStatus exec(const std::string& oid, const char* cls, const char* method,\n+                           ceph::bufferlist& in, ceph::bufferlist& out) = 0;\n+\n+  virtual std::vector<std::string> list() = 0;\n+\n+  virtual RadosStatus stat(const std::string& oid, uint64_t* psize) = 0;\n+\n+ private:\n+  friend class RadosWrapper;\n+  /// \\brief Set the `librados::IoCtx` instance inside a IoCtxInterface instance.\n+  virtual void setIoCtx(librados::IoCtx* ioCtx_) = 0;\n+};\n+\n+class IoCtxWrapper : public IoCtxInterface {\n+ public:\n+  IoCtxWrapper() { ioCtx = new librados::IoCtx(); }\n+  ~IoCtxWrapper() { delete ioCtx; }\n+  RadosStatus write_full(const std::string& oid, ceph::bufferlist& bl) override;\n+  RadosStatus read(const std::string& oid, ceph::bufferlist& bl, size_t len,\n+                   uint64_t offset) override;\n+  RadosStatus exec(const std::string& oid, const char* cls, const char* method,\n+                   ceph::bufferlist& in, ceph::bufferlist& out) override;\n+  std::vector<std::string> list() override;\n+\n+  RadosStatus stat(const std::string& oid, uint64_t* psize) override;\n+\n+ private:\n+  void setIoCtx(librados::IoCtx* ioCtx_) override { *ioCtx = *ioCtx_; }\n+  librados::IoCtx* ioCtx;\n+};\n+\n+class RadosInterface {\n+ public:\n+  RadosInterface() {}\n+\n+  /// \\brief Initializes a cluster handle.\n+  ///\n+  /// \\param[in] name the username of the client.\n+  /// \\param[in] clustername the name of the Ceph cluster.\n+  /// \\param[in] flags some extra flags to pass.\n+  virtual RadosStatus init2(const char* const name, const char* const clustername,\n+                            uint64_t flags) = 0;\n+\n+  /// \\brief Create an I/O context\n+  ///\n+  /// \\param[in] name the RADOS pool to connect to.\n+  /// \\param[in] pioctx an instance of IoCtxInterface.\n+  virtual RadosStatus ioctx_create(const char* name, IoCtxInterface* pioctx) = 0;\n+\n+  /// \\brief Read the Ceph config file.\n+  ///\n+  /// \\param[in] path the path to the config file.\n+  virtual RadosStatus conf_read_file(const char* const path) = 0;\n+\n+  /// \\brief Connect to the Ceph cluster.\n+  virtual RadosStatus connect() = 0;\n+\n+  /// \\brief Close connection to the Ceph cluster.\n+  virtual void shutdown() = 0;\n+};\n+\n+class RadosWrapper : public RadosInterface {\n+ public:\n+  RadosWrapper() { cluster = new librados::Rados(); }\n+  ~RadosWrapper() { delete cluster; }\n+  RadosStatus init2(const char* const name, const char* const clustername,\n+                    uint64_t flags) override;\n+  RadosStatus ioctx_create(const char* name, IoCtxInterface* pioctx) override;\n+  RadosStatus conf_read_file(const char* const path) override;\n+  RadosStatus connect() override;\n+  void shutdown() override;\n+\n+ private:\n+  librados::Rados* cluster;\n+};\n+\n+/// Connect to a Ceph cluster and hold the connection\n+/// information for use in later stages.\n+class RadosConn {\n+ public:\n+  explicit RadosConn(std::shared_ptr<skyhook::RadosConnCtx> ctx)\n+      : ctx(ctx),\n\nReview comment:\n       ```suggestion\r\n         : ctx(std::move(ctx)),\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol.h\n##########\n@@ -0,0 +1,115 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"skyhook/protocol/rados_protocol.h\"\n+\n+#include <sys/stat.h>\n+#include <sstream>\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/type.h\"\n+\n+#define SCAN_UNKNOWN_ERR_MSG \"something went wrong while scanning file fragment\"\n+#define SCAN_ERR_CODE 25\n+#define SCAN_ERR_MSG \"failed to scan file fragment\"\n+#define SCAN_REQ_DESER_ERR_CODE 26\n+#define SCAN_REQ_DESER_ERR_MSG \"failed to deserialize scan request\"\n+#define SCAN_RES_SER_ERR_CODE 27\n+#define SCAN_RES_SER_ERR_MSG \"failed to serialize result table\"\n+\n+namespace skyhook {\n+\n+/// An enum to represent the different\n+/// types of file formats that Skyhook supports.\n+struct SkyhookFileType {\n+  enum type { PARQUET, IPC };\n+};\n+\n+/// A struct encapsulating all the parameters\n+/// required to be serialized in the form of flatbuffers for\n+/// sending to the cls.\n+struct ScanRequest {\n+  arrow::compute::Expression filter_expression;\n+  arrow::compute::Expression partition_expression;\n+  std::shared_ptr<arrow::Schema> projection_schema;\n+  std::shared_ptr<arrow::Schema> dataset_schema;\n+  int64_t file_size;\n+  SkyhookFileType::type file_format;\n+};\n+\n+/// Utility functions to serialize and deserialize scan requests and result Arrow tables.\n+arrow::Status SerializeScanRequest(ScanRequest req, ceph::bufferlist& bl);\n+arrow::Status DeserializeScanRequest(ScanRequest& req, ceph::bufferlist bl);\n+arrow::Status SerializeTable(std::shared_ptr<arrow::Table> table, ceph::bufferlist& bl);\n+arrow::Status DeserializeTable(arrow::RecordBatchVector& batches, ceph::bufferlist bl,\n+                               bool use_threads);\n+\n+/// Utility function to invoke a RADOS object class function on an RADOS object.\n+arrow::Status ExecuteObjectClassFn(std::shared_ptr<rados::RadosConn> connection_,\n+                                   const std::string& oid, const std::string& fn,\n+                                   ceph::bufferlist& in, ceph::bufferlist& out);\n+\n+/// An interface for translating the name of a file in CephFS to its\n+/// corresponding object ID in RADOS assuming 1:1 mapping between a file\n+/// and it's underlying object.\n+class SkyhookDirectObjectAccess {\n+ public:\n+  explicit SkyhookDirectObjectAccess(const std::shared_ptr<rados::RadosConn>& connection)\n+      : connection_(std::move(connection)) {}\n\nReview comment:\n       ```suggestion\r\n         : connection_(connection) {}\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n\nReview comment:\n       ```suggestion\r\n     RadosStatus(arrow::Status s, int code) : s_(std::move(s)), code_(code) {}\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/client/file_skyhook.h\n##########\n@@ -0,0 +1,96 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/dataset/scanner.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n\nReview comment:\n       This is good!  `file_skyhook.h` has no direct dependency on rados which was the goal.  Thank you.\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol.cc\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include <flatbuffers/flatbuffers.h>\n+\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/result.h\"\n+\n+#include \"ScanRequest_generated.h\"\n+\n+namespace skyhook {\n+\n+namespace flatbuf = org::apache::arrow::flatbuf;\n+\n+arrow::Status SerializeScanRequest(ScanRequest req, ceph::bufferlist& bl) {\n+  auto filter_expression = arrow::compute::Serialize(req.filter_expression).ValueOrDie();\n+  auto partition_expression =\n+      arrow::compute::Serialize(req.partition_expression).ValueOrDie();\n+  auto projection_schema =\n+      arrow::ipc::SerializeSchema(*req.projection_schema).ValueOrDie();\n+  auto dataset_schema = arrow::ipc::SerializeSchema(*req.dataset_schema).ValueOrDie();\n\nReview comment:\n       Replace `ValueOrDie` with `ARROW_ASSIGN_OR_RAISE`\n\n##########\nFile path: cpp/cmake_modules/Findlibrados.cmake\n##########\n@@ -0,0 +1,31 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n\nReview comment:\n       It's unfortunate there is no librados2 in conda-forge.  I tried to make it work with a hybrid build but my system librados2 linked with system libcrypto while parquet linked with conda's libssl and the mismatch caused errors.  I ended up making a cmake build that used all system libraries and that worked.\n\n##########\nFile path: cpp/src/skyhook/client/file_skyhook.cc\n##########\n@@ -0,0 +1,160 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+#include \"skyhook/protocol/rados_protocol.h\"\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/util/compression.h\"\n+\n+namespace skyhook {\n+\n+/// A ScanTask to scan a file fragment in Skyhook format.\n+class SkyhookScanTask : public arrow::dataset::ScanTask {\n+ public:\n+  SkyhookScanTask(std::shared_ptr<arrow::dataset::ScanOptions> options,\n+                  std::shared_ptr<arrow::dataset::Fragment> fragment,\n+                  arrow::dataset::FileSource source,\n+                  std::shared_ptr<skyhook::SkyhookDirectObjectAccess> doa,\n+                  skyhook::SkyhookFileType::type file_format,\n+                  arrow::compute::Expression partition_expression)\n+      : ScanTask(std::move(options), std::move(fragment)),\n+        source_(std::move(source)),\n+        doa_(std::move(doa)),\n+        file_format_(file_format),\n+        partition_expression_(partition_expression) {}\n+\n+  arrow::Result<arrow::RecordBatchIterator> Execute() override {\n+    /// Retrieve the size of the file using POSIX `stat`.\n+    struct stat st {};\n+    RETURN_NOT_OK(doa_->Stat(source_.path(), st));\n+\n+    /// Create a ScanRequest instance.\n+    skyhook::ScanRequest req;\n+    req.filter_expression = options_->filter;\n+    req.partition_expression = partition_expression_;\n+    req.projection_schema = options_->projected_schema;\n+    req.dataset_schema = options_->dataset_schema;\n+    req.file_size = st.st_size;\n+    req.file_format = file_format_;\n+\n+    /// Serialize the ScanRequest into a ceph bufferlist.\n+    ceph::bufferlist request;\n+    RETURN_NOT_OK(skyhook::SerializeScanRequest(req, request));\n+\n+    /// Execute the Ceph object class method `scan_op`.\n+    ceph::bufferlist result;\n+    RETURN_NOT_OK(doa_->Exec(st.st_ino, \"scan_op\", request, result));\n+\n+    /// Read RecordBatches from the result bufferlist. Since, this step might use\n+    /// threads for decompressing compressed batches, to avoid running into\n+    /// [ARROW-12597], we switch off threaded decompression to avoid nested threading\n+    /// scenarios when scan tasks are executed in parallel by the CpuThreadPool.\n+    arrow::RecordBatchVector batches;\n+    RETURN_NOT_OK(skyhook::DeserializeTable(batches, result, !options_->use_threads));\n+    return arrow::MakeVectorIterator(batches);\n+  }\n+\n+ protected:\n+  arrow::dataset::FileSource source_;\n+  std::shared_ptr<skyhook::SkyhookDirectObjectAccess> doa_;\n+  skyhook::SkyhookFileType::type file_format_;\n+  arrow::compute::Expression partition_expression_;\n+};\n+\n+class SkyhookFileFormat::Impl {\n+ public:\n+  Impl(std::shared_ptr<RadosConnCtx> ctx, std::string file_format)\n+      : ctx_(std::move(ctx)), file_format_(file_format) {}\n+\n+  ~Impl() {}\n+\n+  arrow::Status Init() {\n+    /// Connect to the RADOS cluster and instantiate a `SkyhookDirectObjectAccess`\n+    /// instance.\n+    auto connection = std::make_shared<skyhook::rados::RadosConn>(ctx_);\n+    RETURN_NOT_OK(connection->Connect());\n+    doa_ = std::make_shared<skyhook::SkyhookDirectObjectAccess>(connection);\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<arrow::dataset::ScanTaskIterator> ScanFile(\n+      const std::shared_ptr<arrow::dataset::ScanOptions>& options,\n+      const std::shared_ptr<arrow::dataset::FileFragment>& file) const {\n+    /// Make sure client-side filtering and projection is turned off.\n+    file->handles_compute = false;\n+\n+    /// Convert string file format name to Enum.\n+    skyhook::SkyhookFileType::type file_format;\n+    if (file_format_ == \"parquet\") {\n+      file_format = skyhook::SkyhookFileType::type::PARQUET;\n+    } else if (file_format_ == \"ipc\") {\n+      file_format = skyhook::SkyhookFileType::type::IPC;\n+    } else {\n+      return arrow::Status::Invalid(\"Unsupported file format.\");\n+    }\n+\n+    arrow::dataset::ScanTaskVector v{std::make_shared<SkyhookScanTask>(\n+        std::move(options), std::move(file), file->source(), std::move(doa_), file_format,\n\nReview comment:\n       Is this move of `doa_` safe?\n\n##########\nFile path: cpp/src/arrow/dataset/scanner.h\n##########\n@@ -117,6 +117,8 @@ struct ARROW_DS_EXPORT ScanOptions {\n   /// makes extensive use of threading and is still considered experimental\n   bool use_async = false;\n \n+  bool skip_compute = false;\n+\n\nReview comment:\n       Is this used?\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (!fragment->handles_compute) {\n+      return std::move(scan_task_it);\n+    }\n+\n\nReview comment:\n       The `AsyncScanner` will need the equivalent.  I think it would belong in `arrow::dataset::AsyncScanner::ScanBatchesUnorderedAsync`\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol.cc\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include <flatbuffers/flatbuffers.h>\n+\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/result.h\"\n+\n+#include \"ScanRequest_generated.h\"\n+\n+namespace skyhook {\n+\n+namespace flatbuf = org::apache::arrow::flatbuf;\n+\n+arrow::Status SerializeScanRequest(ScanRequest req, ceph::bufferlist& bl) {\n+  auto filter_expression = arrow::compute::Serialize(req.filter_expression).ValueOrDie();\n+  auto partition_expression =\n+      arrow::compute::Serialize(req.partition_expression).ValueOrDie();\n+  auto projection_schema =\n+      arrow::ipc::SerializeSchema(*req.projection_schema).ValueOrDie();\n+  auto dataset_schema = arrow::ipc::SerializeSchema(*req.dataset_schema).ValueOrDie();\n+\n+  flatbuffers::FlatBufferBuilder builder(1024);\n+  auto filter_expression_vector =\n+      builder.CreateVector(filter_expression->data(), filter_expression->size());\n+  auto partition_expression_vector =\n+      builder.CreateVector(partition_expression->data(), partition_expression->size());\n+  auto projected_schema_vector =\n+      builder.CreateVector(projection_schema->data(), projection_schema->size());\n+  auto dataset_schema_vector =\n+      builder.CreateVector(dataset_schema->data(), dataset_schema->size());\n+\n+  auto request = flatbuf::CreateScanRequest(\n+      builder, req.file_size, static_cast<int>(req.file_format), filter_expression_vector,\n+      partition_expression_vector, dataset_schema_vector, projected_schema_vector);\n+  builder.Finish(request);\n+  uint8_t* buf = builder.GetBufferPointer();\n+  int size = builder.GetSize();\n+\n+  bl.append((char*)buf, size);\n+  return arrow::Status::OK();\n+}\n+\n+arrow::Status DeserializeScanRequest(ScanRequest& req, ceph::bufferlist bl) {\n+  auto request = flatbuf::GetScanRequest((uint8_t*)bl.c_str());\n+\n+  auto filter_expression_ = arrow::compute::Deserialize(\n+                                std::make_shared<arrow::Buffer>(\n+                                    request->filter()->data(), request->filter()->size()))\n+                                .ValueOrDie();\n+  req.filter_expression = filter_expression_;\n+\n+  auto partition_expression_ =\n+      arrow::compute::Deserialize(\n+          std::make_shared<arrow::Buffer>(request->partition()->data(),\n+                                          request->partition()->size()))\n+          .ValueOrDie();\n+  req.partition_expression = partition_expression_;\n+\n+  arrow::ipc::DictionaryMemo empty_memo;\n+  arrow::io::BufferReader projection_schema_reader(request->projection_schema()->data(),\n+                                                   request->projection_schema()->size());\n+  arrow::io::BufferReader dataset_schema_reader(request->dataset_schema()->data(),\n+                                                request->dataset_schema()->size());\n+\n+  req.projection_schema =\n+      arrow::ipc::ReadSchema(&projection_schema_reader, &empty_memo).ValueOrDie();\n+  req.dataset_schema =\n+      arrow::ipc::ReadSchema(&dataset_schema_reader, &empty_memo).ValueOrDie();\n+\n+  req.file_size = request->file_size();\n+  req.file_format = (SkyhookFileType::type)request->file_format();\n+  return arrow::Status::OK();\n+}\n+\n+arrow::Status SerializeTable(std::shared_ptr<arrow::Table> table, ceph::bufferlist& bl) {\n+  auto buffer_output_stream = arrow::io::BufferOutputStream::Create().ValueOrDie();\n+\n+  auto options = arrow::ipc::IpcWriteOptions::Defaults();\n+  auto codec = arrow::Compression::LZ4_FRAME;\n+\n+  options.codec =\n+      arrow::util::Codec::Create(codec, std::numeric_limits<int>::min()).ValueOrDie();\n\nReview comment:\n       `std::numeric_limits<int>::min()` should be the default.  Don't specify the second argument in case that changes someday.\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol_test.cc\n##########\n@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/test_util.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+\n+std::shared_ptr<arrow::Table> CreateTable() {\n+  auto schema = arrow::schema({\n+      {arrow::field(\"a\", arrow::uint8())},\n+      {arrow::field(\"b\", arrow::uint32())},\n+  });\n+\n+  std::shared_ptr<arrow::Table> table;\n+  return TableFromJSON(schema, {R\"([{\"a\": null, \"b\": 5},\n+                                     {\"a\": 1,    \"b\": 3},\n+                                     {\"a\": 3,    \"b\": null},\n+                                     {\"a\": null, \"b\": null},\n+                                     {\"a\": 2,    \"b\": 5},\n+                                     {\"a\": 1,    \"b\": 5}\n+                                    ])\"});\n+}\n+\n+TEST(TestSkyhookProtocol, ScanRequestSerializeDeserialize) {\n+  ceph::bufferlist bl;\n+  skyhook::ScanRequest req;\n+  req.filter_expression = arrow::compute::literal(true);\n+  req.partition_expression = arrow::compute::literal(false);\n+  req.projection_schema = arrow::schema({arrow::field(\"a\", arrow::int64())});\n+  req.dataset_schema = arrow::schema({arrow::field(\"a\", arrow::int64())});\n+  req.file_size = 1000000;\n+  req.file_format = skyhook::SkyhookFileType::type::IPC;\n+  skyhook::SerializeScanRequest(req, bl);\n+\n+  skyhook::ScanRequest req_;\n+  skyhook::DeserializeScanRequest(req_, bl);\n+  ASSERT_EQ(req.filter_expression.Equals(req_.filter_expression), 1);\n+  ASSERT_EQ(req.partition_expression.Equals(req_.partition_expression), 1);\n+  ASSERT_EQ(req.projection_schema->Equals(req_.projection_schema), 1);\n+  ASSERT_EQ(req.dataset_schema->Equals(req_.dataset_schema), 1);\n+  ASSERT_EQ(req.file_size, req_.file_size);\n+  ASSERT_EQ(req.file_format, req_.file_format);\n+}\n+\n+TEST(TestSkyhookProtocol, SerializeDeserializeTable) {\n+  std::shared_ptr<arrow::Table> table = CreateTable();\n+  ceph::bufferlist bl;\n+  skyhook::SerializeTable(table, bl);\n\nReview comment:\n       ```suggestion\r\n     ASSERT_OK(skyhook::SerializeTable(table, bl));\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/CMakeLists.txt\n##########\n@@ -0,0 +1,108 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n\nReview comment:\n       @kou @kszucs Any thoughts on the cmake configurations added as part of this PR?\n\n##########\nFile path: ci/scripts/integration_skyhook.sh\n##########\n@@ -0,0 +1,134 @@\n+#!/usr/bin/env bash\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+set -e\n+set -x\n+set -u\n+\n+ARROW_BUILD_DIR=${1}/cpp\n+DIR=/tmp/integration-skyhook\n+\n+# reset\n+pkill ceph || true\n+rm -rf ${DIR}/*\n+LOG_DIR=${DIR}/log\n+MON_DATA=${DIR}/mon\n+MDS_DATA=${DIR}/mds\n+MOUNTPT=${MDS_DATA}/mnt\n+OSD_DATA=${DIR}/osd\n+mkdir -p ${LOG_DIR} ${MON_DATA} ${OSD_DATA} ${MDS_DATA} ${MOUNTPT}\n+MDS_NAME=\"Z\"\n+MON_NAME=\"a\"\n+MGR_NAME=\"x\"\n+MIRROR_ID=\"m\"\n+\n+# cluster wide parameters\n+cat >> ${DIR}/ceph.conf <<EOF\n+[global]\n+fsid = $(uuidgen)\n+osd crush chooseleaf type = 0\n+run dir = ${DIR}/run\n+auth cluster required = none\n+auth service required = none\n+auth client required = none\n+osd pool default size = 1\n+mon host = ${HOSTNAME}\n+[mds.${MDS_NAME}]\n+host = ${HOSTNAME}\n+[mon.${MON_NAME}]\n+log file = ${LOG_DIR}/mon.log\n+chdir = \"\"\n+mon cluster log file = ${LOG_DIR}/mon-cluster.log\n+mon data = ${MON_DATA}\n+mon data avail crit = 0\n+mon addr = ${HOSTNAME}\n+mon allow pool delete = true\n+[osd.0]\n+log file = ${LOG_DIR}/osd.log\n+chdir = \"\"\n+osd data = ${OSD_DATA}\n+osd journal = ${OSD_DATA}.journal\n+osd journal size = 100\n+osd objectstore = memstore\n+osd class load list = *\n+osd class default list = *\n+EOF\n+\n+export CEPH_CONF=${DIR}/ceph.conf\n+cp $CEPH_CONF /etc/ceph/ceph.conf\n+\n+# start an osd\n+ceph-mon --id ${MON_NAME} --mkfs --keyring /dev/null\n+touch ${MON_DATA}/keyring\n+ceph-mon --id ${MON_NAME}\n+\n+# start an osd\n+OSD_ID=$(ceph osd create)\n+ceph osd crush add osd.${OSD_ID} 1 root=default\n+ceph-osd --id ${OSD_ID} --mkjournal --mkfs\n+ceph-osd --id ${OSD_ID} || ceph-osd --id ${OSD_ID} || ceph-osd --id ${OSD_ID}\n+\n+# start an mds for cephfs\n+ceph auth get-or-create mds.${MDS_NAME} mon 'profile mds' mgr 'profile mds' mds 'allow *' osd 'allow *' > ${MDS_DATA}/keyring\n+ceph osd pool create cephfs_data 8\n+ceph osd pool create cephfs_metadata 8\n+ceph fs new cephfs cephfs_metadata cephfs_data\n+ceph fs ls\n+ceph-mds -i ${MDS_NAME}\n+ceph status\n+while [[ ! $(ceph mds stat | grep \"up:active\") ]]; do sleep 1; done\n+\n+# start a manager\n+ceph-mgr --id ${MGR_NAME}\n+\n+# test the setup\n+ceph --version\n+ceph status\n+\n+apt update\n+apt install -y ceph-fuse attr\n+\n+pushd ${ARROW_BUILD_DIR}\n+    # create the rados-classes, if not there already\n+    mkdir -p /usr/lib/x86_64-linux-gnu/rados-classes/\n+    cp debug/libcls_skyhook* /usr/lib/x86_64-linux-gnu/rados-classes/\n+\n+    # mount a ceph filesystem to /mnt/cephfs in the user-space using ceph-fuse\n+    mkdir -p /mnt/cephfs\n+    ceph-fuse /mnt/cephfs\n+    sleep 5\n+\n+    # download an example dataset and copy into the mounted dir\n+    rm -rf nyc*\n+    wget https://raw.githubusercontent.com/JayjeetAtGithub/zips/main/nyc.zip\n+    unzip nyc.zip\n+    cp -r nyc /mnt/cephfs/\n+    sleep 10\n\nReview comment:\n       I think it would be nice if this were generated test data although the risk should be somewhat isolated since this only runs on a docker container.  You mentioned generate_dataset.py and that would be great I think.\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol_test.cc\n##########\n@@ -0,0 +1,71 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/test_util.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+\n+std::shared_ptr<arrow::Table> CreateTable() {\n+  auto schema = arrow::schema({\n+      {arrow::field(\"a\", arrow::uint8())},\n+      {arrow::field(\"b\", arrow::uint32())},\n+  });\n+\n+  std::shared_ptr<arrow::Table> table;\n+  return TableFromJSON(schema, {R\"([{\"a\": null, \"b\": 5},\n+                                     {\"a\": 1,    \"b\": 3},\n+                                     {\"a\": 3,    \"b\": null},\n+                                     {\"a\": null, \"b\": null},\n+                                     {\"a\": 2,    \"b\": 5},\n+                                     {\"a\": 1,    \"b\": 5}\n+                                    ])\"});\n+}\n+\n+TEST(TestSkyhookProtocol, ScanRequestSerializeDeserialize) {\n+  ceph::bufferlist bl;\n+  skyhook::ScanRequest req;\n+  req.filter_expression = arrow::compute::literal(true);\n+  req.partition_expression = arrow::compute::literal(false);\n+  req.projection_schema = arrow::schema({arrow::field(\"a\", arrow::int64())});\n+  req.dataset_schema = arrow::schema({arrow::field(\"a\", arrow::int64())});\n+  req.file_size = 1000000;\n+  req.file_format = skyhook::SkyhookFileType::type::IPC;\n+  skyhook::SerializeScanRequest(req, bl);\n+\n+  skyhook::ScanRequest req_;\n+  skyhook::DeserializeScanRequest(req_, bl);\n+  ASSERT_EQ(req.filter_expression.Equals(req_.filter_expression), 1);\n+  ASSERT_EQ(req.partition_expression.Equals(req_.partition_expression), 1);\n+  ASSERT_EQ(req.projection_schema->Equals(req_.projection_schema), 1);\n+  ASSERT_EQ(req.dataset_schema->Equals(req_.dataset_schema), 1);\n+  ASSERT_EQ(req.file_size, req_.file_size);\n+  ASSERT_EQ(req.file_format, req_.file_format);\n+}\n+\n+TEST(TestSkyhookProtocol, SerializeDeserializeTable) {\n+  std::shared_ptr<arrow::Table> table = CreateTable();\n+  ceph::bufferlist bl;\n+  skyhook::SerializeTable(table, bl);\n+\n+  arrow::RecordBatchVector batches;\n+  skyhook::DeserializeTable(batches, bl, false);\n\nReview comment:\n       ```suggestion\r\n     ASSERT_OK(skyhook::DeserializeTable(batches, bl, false));\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-19T01:53:56.389+0000",
                    "updated": "2021-08-19T01:53:56.389+0000",
                    "started": "2021-08-19T01:53:56.389+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "639679",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/639684",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r691722004\n\n\n\n##########\nFile path: .github/workflows/cpp.yml\n##########\n@@ -60,11 +60,17 @@ jobs:\n         image:\n           - conda-cpp\n           - ubuntu-cpp-sanitizer\n+          - ubuntu-cpp-skyhook\n         include:\n           - image: conda-cpp\n             title: AMD64 Conda C++\n           - image: ubuntu-cpp-sanitizer\n             title: AMD64 Ubuntu 20.04 C++ ASAN UBSAN\n+          - image: |\n+              -e CPP_MAKE_PARALLELISM=2 \\\n\nReview comment:\n       Is this needed?\n\n##########\nFile path: cpp/cmake_modules/Findlibrados.cmake\n##########\n@@ -0,0 +1,31 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+find_path(LIBRADOS_INCLUDE_DIR rados/librados.hpp)\n\nReview comment:\n       Could you use `librados_` not `LIBRADOS` for prefix?\r\n   Because `Findlibrados.cmake` means that `librados` is the package name.\n\n##########\nFile path: cpp/src/skyhook/CMakeLists.txt\n##########\n@@ -0,0 +1,108 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitationsn\n+# under the License.\n+\n+#\n+# arrow_skyhook\n+#\n+# define project properties\n+project(arrow_skyhook)\n+cmake_minimum_required(VERSION 3.11)\n+set(ARROW_BUILD_STATIC OFF)\n+\n+# install skyhook headers\n+install(FILES client/file_skyhook.h\n+        DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/skyhook/client\")\n\nReview comment:\n       Can we use `arrow_install_all_headers()` instead of this?\n\n##########\nFile path: cpp/cmake_modules/Findlibrados.cmake\n##########\n@@ -0,0 +1,31 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+find_path(LIBRADOS_INCLUDE_DIR rados/librados.hpp)\n+\n+find_library(LIBRADOS_LIBRARY NAMES rados)\n+\n+mark_as_advanced(LIBRADOS_LIBRARY LIBRADOS_INCLUDE_DIR)\n+\n+include(FindPackageHandleStandardArgs)\n+find_package_handle_standard_args(librados DEFAULT_MSG LIBRADOS_LIBRARY\n+                                  LIBRADOS_INCLUDE_DIR)\n+\n+if(LIBRADOS_FOUND)\n+  set(LIBRADOS_INCLUDE_DIRS ${LIBRADOS_INCLUDE_DIR})\n+  set(LIBRADOS_LIBRARIES ${LIBRADOS_LIBRARY})\n\nReview comment:\n       Could you create an import library that has these information?\r\n   \r\n   ```cmake\r\n     add_library(librados::rados UNKNOWN IMPORTED)\r\n     set_target_property(librados::rados ...)\r\n   ```\r\n   \r\n   See also other `Find*.cmake` in `cpp/cmake_modules/`.\n\n##########\nFile path: cpp/src/skyhook/CMakeLists.txt\n##########\n@@ -0,0 +1,108 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitationsn\n+# under the License.\n+\n+#\n+# arrow_skyhook\n+#\n+# define project properties\n+project(arrow_skyhook)\n+cmake_minimum_required(VERSION 3.11)\n+set(ARROW_BUILD_STATIC OFF)\n+\n+# install skyhook headers\n+install(FILES client/file_skyhook.h\n+        DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/skyhook/client\")\n+\n+# define the targets to build\n+add_custom_target(arrow_skyhook_client)\n+add_custom_target(cls_skyhook)\n+\n+# define the dependencies\n+find_package(librados REQUIRED)\n+include_directories(${LIBRADOS_INCLUDE_DIR})\n+set(ARROW_DATASET_LINK_STATIC arrow_dataset_static)\n+set(ARROW_DATASET_LINK_SHARED arrow_dataset_shared)\n+set(ARROW_DATASET_LINK_STATIC ${ARROW_DATASET_LINK_STATIC} ${LIBRADOS_LIBRARIES})\n+set(ARROW_DATASET_LINK_SHARED ${ARROW_DATASET_LINK_SHARED} ${LIBRADOS_LIBRARIES})\n+\n+# define the client and cls sources\n+set(ARROW_SKYHOOK_CLIENT_SOURCES client/file_skyhook.cc protocol/rados_protocol.cc\n+                                 protocol/skyhook_protocol.cc)\n+set(ARROW_SKYHOOK_CLS_SOURCES cls/cls_skyhook.cc protocol/rados_protocol.cc\n+                              protocol/skyhook_protocol.cc)\n+\n+# define the client library\n+add_arrow_lib(arrow_skyhook_client\n+              BUILD_SHARED\n+              ON\n\nReview comment:\n       Why do we need this?\n\n##########\nFile path: cpp/src/skyhook/CMakeLists.txt\n##########\n@@ -0,0 +1,108 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitationsn\n+# under the License.\n+\n+#\n+# arrow_skyhook\n+#\n+# define project properties\n+project(arrow_skyhook)\n+cmake_minimum_required(VERSION 3.11)\n\nReview comment:\n       We don't need them because we call them in `cpp/CMakeLists.txt`.\n\n##########\nFile path: cpp/src/skyhook/CMakeLists.txt\n##########\n@@ -0,0 +1,108 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitationsn\n+# under the License.\n+\n+#\n+# arrow_skyhook\n+#\n+# define project properties\n+project(arrow_skyhook)\n+cmake_minimum_required(VERSION 3.11)\n+set(ARROW_BUILD_STATIC OFF)\n+\n+# install skyhook headers\n+install(FILES client/file_skyhook.h\n+        DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/skyhook/client\")\n+\n+# define the targets to build\n+add_custom_target(arrow_skyhook_client)\n+add_custom_target(cls_skyhook)\n+\n+# define the dependencies\n+find_package(librados REQUIRED)\n+include_directories(${LIBRADOS_INCLUDE_DIR})\n+set(ARROW_DATASET_LINK_STATIC arrow_dataset_static)\n+set(ARROW_DATASET_LINK_SHARED arrow_dataset_shared)\n+set(ARROW_DATASET_LINK_STATIC ${ARROW_DATASET_LINK_STATIC} ${LIBRADOS_LIBRARIES})\n+set(ARROW_DATASET_LINK_SHARED ${ARROW_DATASET_LINK_SHARED} ${LIBRADOS_LIBRARIES})\n\nReview comment:\n       Could you use difference prefix such as `ARROW_SKYHOOK_*`?\n\n##########\nFile path: cpp/src/skyhook/CMakeLists.txt\n##########\n@@ -0,0 +1,108 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitationsn\n+# under the License.\n+\n+#\n+# arrow_skyhook\n+#\n+# define project properties\n+project(arrow_skyhook)\n+cmake_minimum_required(VERSION 3.11)\n+set(ARROW_BUILD_STATIC OFF)\n\nReview comment:\n       Please don't override options.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-19T02:20:49.842+0000",
                    "updated": "2021-08-19T02:20:49.842+0000",
                    "started": "2021-08-19T02:20:49.841+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "639684",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/639852",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r692111675\n\n\n\n##########\nFile path: cpp/src/skyhook/client/file_skyhook.h\n##########\n@@ -0,0 +1,96 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/dataset/scanner.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+\n+namespace skyhook {\n+\n+/// \\addtogroup dataset-file-formats\n+///\n+/// @{\n+\n+/// \\struct RadosConnCtx\n+/// \\brief A struct to hold the parameters required\n+/// for connecting to a RADOS cluster.\n+struct RadosConnCtx {\n+  std::string ceph_config_path;\n+  std::string ceph_data_pool;\n+  std::string ceph_user_name;\n+  std::string ceph_cluster_name;\n+  std::string ceph_cls_name;\n+\n+  RadosConnCtx(const std::string& ceph_config_path, const std::string& ceph_data_pool,\n+               const std::string& ceph_user_name, const std::string& ceph_cluster_name,\n+               const std::string& ceph_cls_name)\n+      : ceph_config_path(ceph_config_path),\n+        ceph_data_pool(ceph_data_pool),\n+        ceph_user_name(ceph_user_name),\n+        ceph_cluster_name(ceph_cluster_name),\n+        ceph_cls_name(ceph_cls_name) {}\n+};\n+\n+/// \\class SkyhookFileFormat\n+/// \\brief A FileFormat implementation that offloads fragment\n+/// scan operations to the Ceph OSDs.\n+class SkyhookFileFormat : public arrow::dataset::ParquetFileFormat {\n\nReview comment:\n       I think it'd be appreciated to link to the Skyhook paper or docs as well here as developers are much less likely to be familiar with it.\n\n##########\nFile path: cpp/src/arrow/dataset/dataset.h\n##########\n@@ -90,6 +90,8 @@ class ARROW_DS_EXPORT Fragment : public std::enable_shared_from_this<Fragment> {\n \n   virtual ~Fragment() = default;\n \n+  bool handles_compute = true;\n\nReview comment:\n       Can we document what this flag means?\n\n##########\nFile path: cpp/src/skyhook/cls/cls_skyhook.cc\n##########\n@@ -0,0 +1,258 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include <rados/objclass.h>\n+#include <memory>\n+\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/dataset.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/compression.h\"\n+\n+CLS_VER(1, 0)\n+CLS_NAME(skyhook)\n+\n+cls_handle_t h_class;\n+cls_method_handle_t h_scan_op;\n+\n+/// \\brief Log skyhook errors using RADOS object class SDK's logger.\n+void LogSkyhookError(const std::string& msg) { CLS_LOG(0, \"error: %s\", msg.c_str()); }\n+\n+/// \\class RandomAccessObject\n+/// \\brief An interface to provide a file-like view over RADOS objects.\n+class RandomAccessObject : public arrow::io::RandomAccessFile {\n+ public:\n+  explicit RandomAccessObject(cls_method_context_t hctx, int64_t file_size) {\n+    hctx_ = hctx;\n+    content_length_ = file_size;\n+    chunks_ = std::vector<ceph::bufferlist*>();\n+  }\n+\n+  ~RandomAccessObject() { Close(); }\n+\n+  /// Check if the file stream is closed.\n+  arrow::Status CheckClosed() const {\n\nReview comment:\n       These methods are missing `override` specifiers.\n\n##########\nFile path: cpp/src/skyhook/client/file_skyhook.cc\n##########\n@@ -0,0 +1,160 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+#include \"skyhook/protocol/rados_protocol.h\"\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/util/compression.h\"\n+\n+namespace skyhook {\n+\n+/// A ScanTask to scan a file fragment in Skyhook format.\n+class SkyhookScanTask : public arrow::dataset::ScanTask {\n+ public:\n+  SkyhookScanTask(std::shared_ptr<arrow::dataset::ScanOptions> options,\n+                  std::shared_ptr<arrow::dataset::Fragment> fragment,\n+                  arrow::dataset::FileSource source,\n+                  std::shared_ptr<skyhook::SkyhookDirectObjectAccess> doa,\n+                  skyhook::SkyhookFileType::type file_format,\n+                  arrow::compute::Expression partition_expression)\n+      : ScanTask(std::move(options), std::move(fragment)),\n+        source_(std::move(source)),\n+        doa_(std::move(doa)),\n+        file_format_(file_format),\n+        partition_expression_(partition_expression) {}\n+\n+  arrow::Result<arrow::RecordBatchIterator> Execute() override {\n+    /// Retrieve the size of the file using POSIX `stat`.\n+    struct stat st {};\n+    RETURN_NOT_OK(doa_->Stat(source_.path(), st));\n+\n+    /// Create a ScanRequest instance.\n+    skyhook::ScanRequest req;\n+    req.filter_expression = options_->filter;\n+    req.partition_expression = partition_expression_;\n+    req.projection_schema = options_->projected_schema;\n+    req.dataset_schema = options_->dataset_schema;\n+    req.file_size = st.st_size;\n+    req.file_format = file_format_;\n+\n+    /// Serialize the ScanRequest into a ceph bufferlist.\n+    ceph::bufferlist request;\n+    RETURN_NOT_OK(skyhook::SerializeScanRequest(req, request));\n+\n+    /// Execute the Ceph object class method `scan_op`.\n+    ceph::bufferlist result;\n+    RETURN_NOT_OK(doa_->Exec(st.st_ino, \"scan_op\", request, result));\n+\n+    /// Read RecordBatches from the result bufferlist. Since, this step might use\n+    /// threads for decompressing compressed batches, to avoid running into\n+    /// [ARROW-12597], we switch off threaded decompression to avoid nested threading\n+    /// scenarios when scan tasks are executed in parallel by the CpuThreadPool.\n+    arrow::RecordBatchVector batches;\n+    RETURN_NOT_OK(skyhook::DeserializeTable(batches, result, !options_->use_threads));\n+    return arrow::MakeVectorIterator(batches);\n+  }\n+\n+ protected:\n+  arrow::dataset::FileSource source_;\n+  std::shared_ptr<skyhook::SkyhookDirectObjectAccess> doa_;\n+  skyhook::SkyhookFileType::type file_format_;\n+  arrow::compute::Expression partition_expression_;\n+};\n+\n+class SkyhookFileFormat::Impl {\n+ public:\n+  Impl(std::shared_ptr<RadosConnCtx> ctx, std::string file_format)\n+      : ctx_(std::move(ctx)), file_format_(file_format) {}\n+\n+  ~Impl() {}\n+\n+  arrow::Status Init() {\n+    /// Connect to the RADOS cluster and instantiate a `SkyhookDirectObjectAccess`\n+    /// instance.\n+    auto connection = std::make_shared<skyhook::rados::RadosConn>(ctx_);\n+    RETURN_NOT_OK(connection->Connect());\n+    doa_ = std::make_shared<skyhook::SkyhookDirectObjectAccess>(connection);\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<arrow::dataset::ScanTaskIterator> ScanFile(\n+      const std::shared_ptr<arrow::dataset::ScanOptions>& options,\n+      const std::shared_ptr<arrow::dataset::FileFragment>& file) const {\n+    /// Make sure client-side filtering and projection is turned off.\n+    file->handles_compute = false;\n+\n+    /// Convert string file format name to Enum.\n+    skyhook::SkyhookFileType::type file_format;\n+    if (file_format_ == \"parquet\") {\n+      file_format = skyhook::SkyhookFileType::type::PARQUET;\n+    } else if (file_format_ == \"ipc\") {\n+      file_format = skyhook::SkyhookFileType::type::IPC;\n+    } else {\n+      return arrow::Status::Invalid(\"Unsupported file format.\");\n\nReview comment:\n       ```suggestion\r\n         return arrow::Status::Invalid(\"Unsupported file format \", file_format_);\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/client/file_skyhook.cc\n##########\n@@ -0,0 +1,160 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/client/file_skyhook.h\"\n+#include \"skyhook/protocol/rados_protocol.h\"\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/dataset/file_base.h\"\n+#include \"arrow/dataset/file_ipc.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/util/compression.h\"\n+\n+namespace skyhook {\n+\n+/// A ScanTask to scan a file fragment in Skyhook format.\n+class SkyhookScanTask : public arrow::dataset::ScanTask {\n+ public:\n+  SkyhookScanTask(std::shared_ptr<arrow::dataset::ScanOptions> options,\n+                  std::shared_ptr<arrow::dataset::Fragment> fragment,\n+                  arrow::dataset::FileSource source,\n+                  std::shared_ptr<skyhook::SkyhookDirectObjectAccess> doa,\n+                  skyhook::SkyhookFileType::type file_format,\n+                  arrow::compute::Expression partition_expression)\n+      : ScanTask(std::move(options), std::move(fragment)),\n+        source_(std::move(source)),\n+        doa_(std::move(doa)),\n+        file_format_(file_format),\n+        partition_expression_(partition_expression) {}\n+\n+  arrow::Result<arrow::RecordBatchIterator> Execute() override {\n+    /// Retrieve the size of the file using POSIX `stat`.\n+    struct stat st {};\n+    RETURN_NOT_OK(doa_->Stat(source_.path(), st));\n+\n+    /// Create a ScanRequest instance.\n+    skyhook::ScanRequest req;\n+    req.filter_expression = options_->filter;\n+    req.partition_expression = partition_expression_;\n+    req.projection_schema = options_->projected_schema;\n+    req.dataset_schema = options_->dataset_schema;\n+    req.file_size = st.st_size;\n+    req.file_format = file_format_;\n+\n+    /// Serialize the ScanRequest into a ceph bufferlist.\n+    ceph::bufferlist request;\n+    RETURN_NOT_OK(skyhook::SerializeScanRequest(req, request));\n+\n+    /// Execute the Ceph object class method `scan_op`.\n+    ceph::bufferlist result;\n+    RETURN_NOT_OK(doa_->Exec(st.st_ino, \"scan_op\", request, result));\n+\n+    /// Read RecordBatches from the result bufferlist. Since, this step might use\n+    /// threads for decompressing compressed batches, to avoid running into\n+    /// [ARROW-12597], we switch off threaded decompression to avoid nested threading\n+    /// scenarios when scan tasks are executed in parallel by the CpuThreadPool.\n+    arrow::RecordBatchVector batches;\n+    RETURN_NOT_OK(skyhook::DeserializeTable(batches, result, !options_->use_threads));\n+    return arrow::MakeVectorIterator(batches);\n+  }\n+\n+ protected:\n+  arrow::dataset::FileSource source_;\n+  std::shared_ptr<skyhook::SkyhookDirectObjectAccess> doa_;\n+  skyhook::SkyhookFileType::type file_format_;\n+  arrow::compute::Expression partition_expression_;\n+};\n+\n+class SkyhookFileFormat::Impl {\n+ public:\n+  Impl(std::shared_ptr<RadosConnCtx> ctx, std::string file_format)\n+      : ctx_(std::move(ctx)), file_format_(file_format) {}\n+\n+  ~Impl() {}\n+\n+  arrow::Status Init() {\n+    /// Connect to the RADOS cluster and instantiate a `SkyhookDirectObjectAccess`\n+    /// instance.\n+    auto connection = std::make_shared<skyhook::rados::RadosConn>(ctx_);\n+    RETURN_NOT_OK(connection->Connect());\n+    doa_ = std::make_shared<skyhook::SkyhookDirectObjectAccess>(connection);\n+    return arrow::Status::OK();\n+  }\n+\n+  arrow::Result<arrow::dataset::ScanTaskIterator> ScanFile(\n+      const std::shared_ptr<arrow::dataset::ScanOptions>& options,\n+      const std::shared_ptr<arrow::dataset::FileFragment>& file) const {\n+    /// Make sure client-side filtering and projection is turned off.\n+    file->handles_compute = false;\n+\n+    /// Convert string file format name to Enum.\n+    skyhook::SkyhookFileType::type file_format;\n+    if (file_format_ == \"parquet\") {\n+      file_format = skyhook::SkyhookFileType::type::PARQUET;\n+    } else if (file_format_ == \"ipc\") {\n+      file_format = skyhook::SkyhookFileType::type::IPC;\n+    } else {\n+      return arrow::Status::Invalid(\"Unsupported file format.\");\n+    }\n+\n+    arrow::dataset::ScanTaskVector v{std::make_shared<SkyhookScanTask>(\n+        std::move(options), std::move(file), file->source(), std::move(doa_), file_format,\n+        file->partition_expression())};\n+    return arrow::MakeVectorIterator(v);\n+  }\n+\n+  arrow::Result<std::shared_ptr<arrow::Schema>> Inspect(\n+      const arrow::dataset::FileSource& source) const {\n+    std::shared_ptr<arrow::dataset::FileFormat> file_format;\n+    if (file_format_ == \"parquet\") {\n+      file_format = std::make_shared<arrow::dataset::ParquetFileFormat>();\n+    } else if (file_format_ == \"ipc\") {\n+      file_format = std::make_shared<arrow::dataset::IpcFileFormat>();\n+    } else {\n+      return arrow::Status::Invalid(\"Unsupported file format.\");\n\nReview comment:\n       ```suggestion\r\n         return arrow::Status::Invalid(\"Unsupported file format \", file_format_);\r\n   ```\n\n##########\nFile path: cpp/src/skyhook/protocol/ScanRequest.fbs\n##########\n@@ -0,0 +1,33 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+/// EXPERIMENTAL: Metadata for n-dimensional arrays, aka \"tensors\" or\n+/// \"ndarrays\". Arrow implementations in general are not required to implement\n+/// this type\n\nReview comment:\n       This comment needs updating.\n\n##########\nFile path: cpp/src/skyhook/client/file_skyhook.h\n##########\n@@ -0,0 +1,96 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/dataset/file_parquet.h\"\n+#include \"arrow/dataset/scanner.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+\n+namespace skyhook {\n+\n+/// \\addtogroup dataset-file-formats\n+///\n+/// @{\n+\n+/// \\struct RadosConnCtx\n+/// \\brief A struct to hold the parameters required\n+/// for connecting to a RADOS cluster.\n+struct RadosConnCtx {\n+  std::string ceph_config_path;\n+  std::string ceph_data_pool;\n+  std::string ceph_user_name;\n+  std::string ceph_cluster_name;\n+  std::string ceph_cls_name;\n+\n+  RadosConnCtx(const std::string& ceph_config_path, const std::string& ceph_data_pool,\n+               const std::string& ceph_user_name, const std::string& ceph_cluster_name,\n+               const std::string& ceph_cls_name)\n+      : ceph_config_path(ceph_config_path),\n+        ceph_data_pool(ceph_data_pool),\n+        ceph_user_name(ceph_user_name),\n+        ceph_cluster_name(ceph_cluster_name),\n+        ceph_cls_name(ceph_cls_name) {}\n+};\n+\n+/// \\class SkyhookFileFormat\n+/// \\brief A FileFormat implementation that offloads fragment\n+/// scan operations to the Ceph OSDs.\n+class SkyhookFileFormat : public arrow::dataset::ParquetFileFormat {\n+ public:\n+  SkyhookFileFormat(std::shared_ptr<RadosConnCtx> ctx, std::string file_format);\n+  ~SkyhookFileFormat();\n+\n+  std::string type_name() const override { return \"skyhook\"; }\n+\n+  bool splittable() const { return true; }\n+\n+  bool Equals(const arrow::dataset::FileFormat& other) const override {\n+    return type_name() == other.type_name();\n+  }\n+\n+  /// \\brief Initialize the SkyhookFileFormat by connecting to RADOS.\n+  arrow::Status Init();\n\nReview comment:\n       If there's an Init needed after initialization, it would be good to make the constructor private and provide a static Make() method so that you cannot forget to call Init.\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n+\n+ private:\n+  arrow::Status s_;\n+  int code_;\n+};\n+\n+class IoCtxInterface {\n+ public:\n+  IoCtxInterface() {}\n+\n+  /// \\brief Write data to an object.\n+  ///\n+  /// \\param[in] oid the ID of the object to write.\n+  /// \\param[in] bl a bufferlist containing the data to write to the object.\n+  virtual RadosStatus write_full(const std::string& oid, ceph::bufferlist& bl) = 0;\n+\n+  /// \\brief Read a RADOS object.\n+  ///\n+  /// \\param[in] oid the object ID which to read.\n+  /// \\param[in] bl a bufferlist to hold the contents of the read object.\n+  /// \\param[in] len the length of data to read from an object.\n+  /// \\param[in] offset the offset of the object to read from.\n+  virtual RadosStatus read(const std::string& oid, ceph::bufferlist& bl, size_t len,\n+                           uint64_t offset) = 0;\n+\n+  /// \\brief Executes a CLS function.\n+  ///\n+  /// \\param[in] oid the object ID on which to execute the CLS function.\n+  /// \\param[in] cls the name of the CLS.\n+  /// \\param[in] method the name of the CLS function.\n+  /// \\param[in] in a bufferlist to send data to the CLS function.\n+  /// \\param[in] out a bufferlist to recieve data from the CLS function.\n+  virtual RadosStatus exec(const std::string& oid, const char* cls, const char* method,\n+                           ceph::bufferlist& in, ceph::bufferlist& out) = 0;\n+\n+  virtual std::vector<std::string> list() = 0;\n\nReview comment:\n       nit: what is this a list of?\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n+\n+ private:\n+  arrow::Status s_;\n+  int code_;\n+};\n+\n+class IoCtxInterface {\n\nReview comment:\n       Is there a need to have interfaces when there seems to be only one possible implementation? pImpl might be better suited\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-19T13:45:51.169+0000",
                    "updated": "2021-08-19T13:45:51.169+0000",
                    "started": "2021-08-19T13:45:51.168+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "639852",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/639916",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r692249358\n\n\n\n##########\nFile path: ci/scripts/integration_skyhook.sh\n##########\n@@ -0,0 +1,134 @@\n+#!/usr/bin/env bash\n\nReview comment:\n       I think the script is quite reliable as it is actually taken from a ceph project (https://github.com/ceph/go-ceph/blob/master/micro-osd.sh). \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-19T15:43:14.735+0000",
                    "updated": "2021-08-19T15:43:14.735+0000",
                    "started": "2021-08-19T15:43:14.734+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "639916",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/640464",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r693377153\n\n\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n+\n+ private:\n+  arrow::Status s_;\n+  int code_;\n+};\n+\n+class IoCtxInterface {\n+ public:\n+  IoCtxInterface() {}\n+\n+  /// \\brief Write data to an object.\n+  ///\n+  /// \\param[in] oid the ID of the object to write.\n+  /// \\param[in] bl a bufferlist containing the data to write to the object.\n+  virtual RadosStatus write_full(const std::string& oid, ceph::bufferlist& bl) = 0;\n+\n+  /// \\brief Read a RADOS object.\n+  ///\n+  /// \\param[in] oid the object ID which to read.\n+  /// \\param[in] bl a bufferlist to hold the contents of the read object.\n+  /// \\param[in] len the length of data to read from an object.\n+  /// \\param[in] offset the offset of the object to read from.\n+  virtual RadosStatus read(const std::string& oid, ceph::bufferlist& bl, size_t len,\n+                           uint64_t offset) = 0;\n+\n+  /// \\brief Executes a CLS function.\n+  ///\n+  /// \\param[in] oid the object ID on which to execute the CLS function.\n+  /// \\param[in] cls the name of the CLS.\n+  /// \\param[in] method the name of the CLS function.\n+  /// \\param[in] in a bufferlist to send data to the CLS function.\n+  /// \\param[in] out a bufferlist to recieve data from the CLS function.\n+  virtual RadosStatus exec(const std::string& oid, const char* cls, const char* method,\n+                           ceph::bufferlist& in, ceph::bufferlist& out) = 0;\n+\n+  virtual std::vector<std::string> list() = 0;\n\nReview comment:\n       it is a list of object ids\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n+\n+ private:\n+  arrow::Status s_;\n+  int code_;\n+};\n+\n+class IoCtxInterface {\n+ public:\n+  IoCtxInterface() {}\n+\n+  /// \\brief Write data to an object.\n+  ///\n+  /// \\param[in] oid the ID of the object to write.\n+  /// \\param[in] bl a bufferlist containing the data to write to the object.\n+  virtual RadosStatus write_full(const std::string& oid, ceph::bufferlist& bl) = 0;\n+\n+  /// \\brief Read a RADOS object.\n+  ///\n+  /// \\param[in] oid the object ID which to read.\n+  /// \\param[in] bl a bufferlist to hold the contents of the read object.\n+  /// \\param[in] len the length of data to read from an object.\n+  /// \\param[in] offset the offset of the object to read from.\n+  virtual RadosStatus read(const std::string& oid, ceph::bufferlist& bl, size_t len,\n+                           uint64_t offset) = 0;\n+\n+  /// \\brief Executes a CLS function.\n+  ///\n+  /// \\param[in] oid the object ID on which to execute the CLS function.\n+  /// \\param[in] cls the name of the CLS.\n+  /// \\param[in] method the name of the CLS function.\n+  /// \\param[in] in a bufferlist to send data to the CLS function.\n+  /// \\param[in] out a bufferlist to recieve data from the CLS function.\n+  virtual RadosStatus exec(const std::string& oid, const char* cls, const char* method,\n+                           ceph::bufferlist& in, ceph::bufferlist& out) = 0;\n+\n+  virtual std::vector<std::string> list() = 0;\n\nReview comment:\n       I think I can remove this though\r\n   \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-21T16:56:53.486+0000",
                    "updated": "2021-08-21T16:56:53.486+0000",
                    "started": "2021-08-21T16:56:53.485+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "640464",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/640516",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r693497691\n\n\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol.cc\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include <flatbuffers/flatbuffers.h>\n+\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/result.h\"\n+\n+#include \"ScanRequest_generated.h\"\n+\n+namespace skyhook {\n+\n+namespace flatbuf = org::apache::arrow::flatbuf;\n+\n+arrow::Status SerializeScanRequest(ScanRequest req, ceph::bufferlist& bl) {\n+  auto filter_expression = arrow::compute::Serialize(req.filter_expression).ValueOrDie();\n+  auto partition_expression =\n+      arrow::compute::Serialize(req.partition_expression).ValueOrDie();\n+  auto projection_schema =\n+      arrow::ipc::SerializeSchema(*req.projection_schema).ValueOrDie();\n+  auto dataset_schema = arrow::ipc::SerializeSchema(*req.dataset_schema).ValueOrDie();\n\nReview comment:\n       Looks like `ARROW_ASSIGN_OR_RAISE` is not available in `arrow` namespace.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-22T12:50:23.040+0000",
                    "updated": "2021-08-22T12:50:23.040+0000",
                    "started": "2021-08-22T12:50:23.040+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "640516",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/640517",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r693497788\n\n\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol.cc\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include <flatbuffers/flatbuffers.h>\n+\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/result.h\"\n+\n+#include \"ScanRequest_generated.h\"\n+\n+namespace skyhook {\n+\n+namespace flatbuf = org::apache::arrow::flatbuf;\n+\n+arrow::Status SerializeScanRequest(ScanRequest req, ceph::bufferlist& bl) {\n+  auto filter_expression = arrow::compute::Serialize(req.filter_expression).ValueOrDie();\n+  auto partition_expression =\n+      arrow::compute::Serialize(req.partition_expression).ValueOrDie();\n+  auto projection_schema =\n+      arrow::ipc::SerializeSchema(*req.projection_schema).ValueOrDie();\n+  auto dataset_schema = arrow::ipc::SerializeSchema(*req.dataset_schema).ValueOrDie();\n\nReview comment:\n       Can you please suggest some other solution ?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-22T12:51:09.503+0000",
                    "updated": "2021-08-22T12:51:09.503+0000",
                    "started": "2021-08-22T12:51:09.503+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "640517",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/643125",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r697907541\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (options->skip_compute) {\n\nReview comment:\n       Hi @westonpace , Can you please give me some idea on where to add the `handle_compute` check in `MakeScanNode` ? I am having a hard time understanding the AsyncScanner, so if you could guide a bit, it would be great. Thanks. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-28T19:18:50.388+0000",
                    "updated": "2021-08-28T19:18:50.388+0000",
                    "started": "2021-08-28T19:18:50.387+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643125",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/643829",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r698960690\n\n\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol.cc\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include <flatbuffers/flatbuffers.h>\n+\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/result.h\"\n+\n+#include \"ScanRequest_generated.h\"\n+\n+namespace skyhook {\n+\n+namespace flatbuf = org::apache::arrow::flatbuf;\n+\n+arrow::Status SerializeScanRequest(ScanRequest req, ceph::bufferlist& bl) {\n+  auto filter_expression = arrow::compute::Serialize(req.filter_expression).ValueOrDie();\n+  auto partition_expression =\n+      arrow::compute::Serialize(req.partition_expression).ValueOrDie();\n+  auto projection_schema =\n+      arrow::ipc::SerializeSchema(*req.projection_schema).ValueOrDie();\n+  auto dataset_schema = arrow::ipc::SerializeSchema(*req.dataset_schema).ValueOrDie();\n\nReview comment:\n       You shouldn't have to import anything.  It's actually used (I think from some of my suggestions) in this file already.  I've submitted a PR that should address the remaining cases.  Please take a look and see how it handles errors more gracefully.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T03:47:25.224+0000",
                    "updated": "2021-08-31T03:47:25.224+0000",
                    "started": "2021-08-31T03:47:25.224+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643829",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/643831",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r698961560\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (options->skip_compute) {\n\nReview comment:\n       I looked at this today and it's not as straightforward a port as I thought.  The exec plan drops the fragment information for the most part.  I'll try and take a more comprehensive stab at this later.  Worst case I don't think it will break things if we filter & project twice and the ExecPlan may not be where we want to do this kind of optimization.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T03:50:12.082+0000",
                    "updated": "2021-08-31T03:50:12.082+0000",
                    "started": "2021-08-31T03:50:12.082+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643831",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/643832",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r698961560\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (options->skip_compute) {\n\nReview comment:\n       I looked at this today and it's not as straightforward a port as I thought.  The exec plan drops the fragment information for the most part.  I'll try and take a more comprehensive stab at this tomorrow.  Worst case I don't think it will break things if we filter & project twice and the ExecPlan may not be where we want to do this kind of optimization.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T03:50:47.917+0000",
                    "updated": "2021-08-31T03:50:47.917+0000",
                    "started": "2021-08-31T03:50:47.917+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643832",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/644174",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r698960690\n\n\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol.cc\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include <flatbuffers/flatbuffers.h>\n+\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/result.h\"\n+\n+#include \"ScanRequest_generated.h\"\n+\n+namespace skyhook {\n+\n+namespace flatbuf = org::apache::arrow::flatbuf;\n+\n+arrow::Status SerializeScanRequest(ScanRequest req, ceph::bufferlist& bl) {\n+  auto filter_expression = arrow::compute::Serialize(req.filter_expression).ValueOrDie();\n+  auto partition_expression =\n+      arrow::compute::Serialize(req.partition_expression).ValueOrDie();\n+  auto projection_schema =\n+      arrow::ipc::SerializeSchema(*req.projection_schema).ValueOrDie();\n+  auto dataset_schema = arrow::ipc::SerializeSchema(*req.dataset_schema).ValueOrDie();\n\nReview comment:\n       You shouldn't have to import anything.  It's actually used (I think from some of my suggestions) in this file already.  I've submitted a PR that should address the remaining cases.  Please take a look and see how it handles errors more gracefully.\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (options->skip_compute) {\n\nReview comment:\n       I looked at this today and it's not as straightforward a port as I thought.  The exec plan drops the fragment information for the most part.  I'll try and take a more comprehensive stab at this later.  Worst case I don't think it will break things if we filter & project twice and the ExecPlan may not be where we want to do this kind of optimization.\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (options->skip_compute) {\n\nReview comment:\n       I looked at this today and it's not as straightforward a port as I thought.  The exec plan drops the fragment information for the most part.  I'll try and take a more comprehensive stab at this tomorrow.  Worst case I don't think it will break things if we filter & project twice and the ExecPlan may not be where we want to do this kind of optimization.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T14:55:36.070+0000",
                    "updated": "2021-08-31T14:55:36.070+0000",
                    "started": "2021-08-31T14:55:36.070+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644174",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/644735",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r699822754\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (options->skip_compute) {\n\nReview comment:\n       For this PR I think I recommend that we leave this alone.  It should be ok to leave `skip_compute` in the sync scanner (as it is eventually going away).\r\n   \r\n   Long term there is work underway to move the internals of the scanner out into something called the ExecPlan.  The ExecPlan is a relational algebra query engine (some might say query engine backend).  It runs the data through a series of operators (scan, project, filter, join, etc.)\r\n   \r\n   If a fragment provides its own filtering capabilities then I believe the appropriate way to handle this will be for the fragment to attach a \"guarantee\" to the record batch.\r\n   \r\n   In addition, fragments may not be able to handle the entire filter.  For example, imagine the SQL query `SELECT a.id, a.name from A a INNER JOIN B b ON a.id = b.a_id WHERE a.value < b.value AND b.type = 'x'` and imagine that the data for `a` comes from an SQL database somewhere and the data for `b` comes from a skyhook scan.  There are a lot of details that still need to be worked out (and a fair amount of discussion on the mailing list how this might happen) but I don't think it would be correct for Skyhook to simply tell the query engine to \"not filter\" because the \"a.value < b.value\" portion of the filter will need to be handled by the query engine.  Instead, skyhook would attach the guarantee \"b.type = 'x'\" to the returned batches.\r\n   \r\n   So, long story short, let's tackle this problem a later day.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-01T03:49:52.111+0000",
                    "updated": "2021-09-01T03:49:52.111+0000",
                    "started": "2021-09-01T03:49:52.111+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644735",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/644748",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r699825207\n\n\n\n##########\nFile path: .travis.yml\n##########\n@@ -61,6 +61,7 @@ jobs:\n           \"\n           -e ARROW_BUILD_STATIC=OFF\n           -e ARROW_ORC=OFF\n+          -e ARROW_SKYHOOK=ON\n\nReview comment:\n       This build is failing.  https://app.travis-ci.com/github/apache/arrow/jobs/534360330  At a minimum we need at least one integration style build hooked into CI.  You have `AMD64 Ubuntu 20.04 C++ (Skyhook Format)` so maybe just remove the Travis/ARM build for now and add it back in later?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-01T04:06:00.288+0000",
                    "updated": "2021-09-01T04:06:00.288+0000",
                    "started": "2021-09-01T04:06:00.288+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644748",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/645004",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r699822754\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_internal.h\n##########\n@@ -185,6 +185,10 @@ inline Result<ScanTaskIterator> GetScanTaskIterator(\n   auto fn = [options](std::shared_ptr<Fragment> fragment) -> Result<ScanTaskIterator> {\n     ARROW_ASSIGN_OR_RAISE(auto scan_task_it, fragment->Scan(options));\n \n+    if (options->skip_compute) {\n\nReview comment:\n       For this PR I think I recommend that we leave this alone.  It should be ok to leave `skip_compute` in the sync scanner (as it is eventually going away).\r\n   \r\n   Long term there is work underway to move the internals of the scanner out into something called the ExecPlan.  The ExecPlan is a relational algebra query engine (some might say query engine backend).  It runs the data through a series of operators (scan, project, filter, join, etc.)\r\n   \r\n   If a fragment provides its own filtering capabilities then I believe the appropriate way to handle this will be for the fragment to attach a \"guarantee\" to the record batch.\r\n   \r\n   In addition, fragments may not be able to handle the entire filter.  For example, imagine the SQL query `SELECT a.id, a.name from A a INNER JOIN B b ON a.id = b.a_id WHERE a.value < b.value AND b.type = 'x'` and imagine that the data for `a` comes from an SQL database somewhere and the data for `b` comes from a skyhook scan.  There are a lot of details that still need to be worked out (and a fair amount of discussion on the mailing list how this might happen) but I don't think it would be correct for Skyhook to simply tell the query engine to \"not filter\" because the \"a.value < b.value\" portion of the filter will need to be handled by the query engine.  Instead, skyhook would attach the guarantee \"b.type = 'x'\" to the returned batches.\r\n   \r\n   So, long story short, let's tackle this problem a later day.\n\n##########\nFile path: .travis.yml\n##########\n@@ -61,6 +61,7 @@ jobs:\n           \"\n           -e ARROW_BUILD_STATIC=OFF\n           -e ARROW_ORC=OFF\n+          -e ARROW_SKYHOOK=ON\n\nReview comment:\n       This build is failing.  https://app.travis-ci.com/github/apache/arrow/jobs/534360330  At a minimum we need at least one integration style build hooked into CI.  You have `AMD64 Ubuntu 20.04 C++ (Skyhook Format)` so maybe just remove the Travis/ARM build for now and add it back in later?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-01T09:25:36.633+0000",
                    "updated": "2021-09-01T09:25:36.633+0000",
                    "started": "2021-09-01T09:25:36.633+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "645004",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/646241",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r701763790\n\n\n\n##########\nFile path: cpp/src/skyhook/protocol/skyhook_protocol.cc\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#include \"skyhook/protocol/skyhook_protocol.h\"\n+\n+#include <flatbuffers/flatbuffers.h>\n+\n+#include \"arrow/io/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/result.h\"\n+\n+#include \"ScanRequest_generated.h\"\n+\n+namespace skyhook {\n+\n+namespace flatbuf = org::apache::arrow::flatbuf;\n+\n+arrow::Status SerializeScanRequest(ScanRequest req, ceph::bufferlist& bl) {\n+  auto filter_expression = arrow::compute::Serialize(req.filter_expression).ValueOrDie();\n+  auto partition_expression =\n+      arrow::compute::Serialize(req.partition_expression).ValueOrDie();\n+  auto projection_schema =\n+      arrow::ipc::SerializeSchema(*req.projection_schema).ValueOrDie();\n+  auto dataset_schema = arrow::ipc::SerializeSchema(*req.dataset_schema).ValueOrDie();\n\nReview comment:\n       Thanks a lot @westonpace . I have merged the changes. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-03T09:56:47.417+0000",
                    "updated": "2021-09-03T09:56:47.417+0000",
                    "started": "2021-09-03T09:56:47.417+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "646241",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/646249",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r701782355\n\n\n\n##########\nFile path: cpp/src/skyhook/protocol/rados_protocol.h\n##########\n@@ -0,0 +1,165 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <rados/librados.hpp>\n+\n+#include \"arrow/status.h\"\n+\n+#include \"skyhook/client/file_skyhook.h\"\n+\n+namespace skyhook {\n+namespace rados {\n+\n+/// Wrap Arrow Status with a custom return code.\n+class RadosStatus {\n+ public:\n+  RadosStatus(arrow::Status s, int code) : s_(s), code_(code) {}\n+  arrow::Status status() { return s_; }\n+  int code() { return code_; }\n+\n+ private:\n+  arrow::Status s_;\n+  int code_;\n+};\n+\n+class IoCtxInterface {\n\nReview comment:\n       Since, rados protocol and skyhook protocol is not meant to be exposed publicly, maybe doing PIMPL would be a overkill.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-03T10:27:52.125+0000",
                    "updated": "2021-09-03T10:27:52.125+0000",
                    "started": "2021-09-03T10:27:52.125+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "646249",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/646254",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r701804991\n\n\n\n##########\nFile path: .travis.yml\n##########\n@@ -61,6 +61,7 @@ jobs:\n           \"\n           -e ARROW_BUILD_STATIC=OFF\n           -e ARROW_ORC=OFF\n+          -e ARROW_SKYHOOK=ON\n\nReview comment:\n       Yeah, let's keep it to Github actions for now,\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-03T11:08:00.704+0000",
                    "updated": "2021-09-03T11:08:00.704+0000",
                    "started": "2021-09-03T11:08:00.704+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "646254",
                    "issueId": "13394689"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/worklog/647989",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #10913:\nURL: https://github.com/apache/arrow/pull/10913#discussion_r704482173\n\n\n\n##########\nFile path: ci/scripts/integration_skyhook.sh\n##########\n@@ -0,0 +1,133 @@\n+#!/usr/bin/env bash\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+set -e\n+set -x\n+set -u\n+\n+ARROW_BUILD_DIR=${1}/cpp\n+DIR=/tmp/integration_skyhook\n+\n+# reset\n+pkill ceph || true\n+rm -rf ${DIR}/*\n+LOG_DIR=${DIR}/log\n+MON_DATA=${DIR}/mon\n+MDS_DATA=${DIR}/mds\n+MOUNTPT=${MDS_DATA}/mnt\n+OSD_DATA=${DIR}/osd\n+mkdir -p ${LOG_DIR} ${MON_DATA} ${OSD_DATA} ${MDS_DATA} ${MOUNTPT}\n+MDS_NAME=\"Z\"\n+MON_NAME=\"a\"\n+MGR_NAME=\"x\"\n+MIRROR_ID=\"m\"\n+\n+# cluster wide parameters\n+cat >> ${DIR}/ceph.conf <<EOF\n+[global]\n+fsid = $(uuidgen)\n+osd crush chooseleaf type = 0\n+run dir = ${DIR}/run\n+auth cluster required = none\n+auth service required = none\n+auth client required = none\n+osd pool default size = 1\n+mon host = ${HOSTNAME}\n+[mds.${MDS_NAME}]\n+host = ${HOSTNAME}\n+[mon.${MON_NAME}]\n+log file = ${LOG_DIR}/mon.log\n+chdir = \"\"\n+mon cluster log file = ${LOG_DIR}/mon-cluster.log\n+mon data = ${MON_DATA}\n+mon data avail crit = 0\n+mon addr = ${HOSTNAME}\n+mon allow pool delete = true\n+[osd.0]\n+log file = ${LOG_DIR}/osd.log\n+chdir = \"\"\n+osd data = ${OSD_DATA}\n+osd journal = ${OSD_DATA}.journal\n+osd journal size = 100\n+osd objectstore = memstore\n+osd class load list = *\n+osd class default list = *\n+EOF\n+\n+export CEPH_CONF=${DIR}/ceph.conf\n+cp $CEPH_CONF /etc/ceph/ceph.conf\n+\n+# start an osd\n+ceph-mon --id ${MON_NAME} --mkfs --keyring /dev/null\n+touch ${MON_DATA}/keyring\n+ceph-mon --id ${MON_NAME}\n+\n+# start an osd\n+OSD_ID=$(ceph osd create)\n+ceph osd crush add osd.${OSD_ID} 1 root=default\n+ceph-osd --id ${OSD_ID} --mkjournal --mkfs\n+ceph-osd --id ${OSD_ID} || ceph-osd --id ${OSD_ID} || ceph-osd --id ${OSD_ID}\n+\n+# start an mds for cephfs\n+ceph auth get-or-create mds.${MDS_NAME} mon 'profile mds' mgr 'profile mds' mds 'allow *' osd 'allow *' > ${MDS_DATA}/keyring\n+ceph osd pool create cephfs_data 8\n+ceph osd pool create cephfs_metadata 8\n+ceph fs new cephfs cephfs_metadata cephfs_data\n+ceph fs ls\n+ceph-mds -i ${MDS_NAME}\n+ceph status\n+while [[ ! $(ceph mds stat | grep \"up:active\") ]]; do sleep 1; done\n+\n+# start a manager\n+ceph-mgr --id ${MGR_NAME}\n+\n+# test the setup\n+ceph --version\n+ceph status\n+\n+apt update\n+apt install -y ceph-fuse attr python3-pip\n\nReview comment:\n       Move this to install_ceph.sh\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-08T14:35:28.886+0000",
                    "updated": "2021-09-08T14:35:28.886+0000",
                    "started": "2021-09-08T14:35:28.885+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "647989",
                    "issueId": "13394689"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 51600,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@77e96883[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@61750b3b[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@76d4e87e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@3fb1194c[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@f4e44c1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@6c0e6279[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3d48f09e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@a84f502[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7791c0df[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@681369fe[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@12a5a862[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@3f2463d1[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 51600,
        "customfield_12312520": null,
        "customfield_12312521": "Fri Oct 22 18:18:04 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-10-22T18:18:04.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-13607/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2021-08-11T13:35:53.000+0000",
        "updated": "2022-06-28T19:37:01.000+0000",
        "timeoriginalestimate": null,
        "description": null,
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "14h 20m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 51600
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Add Skyhook to Arrow",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/comment/17397360",
                    "id": "17397360",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=Jayjeet",
                        "name": "Jayjeet",
                        "key": "jayjeet",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jayjeet Chakraborty",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "An updated version of ARROW-12921",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=Jayjeet",
                        "name": "Jayjeet",
                        "key": "jayjeet",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jayjeet Chakraborty",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2021-08-11T13:37:03.618+0000",
                    "updated": "2021-08-11T13:37:03.618+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13394689/comment/17433112",
                    "id": "17433112",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Issue resolved by pull request 10913\n[https://github.com/apache/arrow/pull/10913]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2021-10-22T18:18:04.652+0000",
                    "updated": "2021-10-22T18:18:04.652+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|z0tt88:",
        "customfield_12314139": null
    }
}