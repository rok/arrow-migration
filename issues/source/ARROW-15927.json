{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13433578",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578",
    "key": "ARROW-15927",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351947",
                "id": "12351947",
                "description": "",
                "name": "10.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-10-26"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
            "name": "Minor",
            "id": "4"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=heyjc",
            "name": "heyjc",
            "key": "heyjc",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"
            },
            "displayName": "Jayjeet Chakraborty",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=heyjc",
            "name": "heyjc",
            "key": "heyjc",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"
            },
            "displayName": "Jayjeet Chakraborty",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=heyjc",
            "name": "heyjc",
            "key": "heyjc",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34050",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34050",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34050",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34050"
            },
            "displayName": "Jayjeet Chakraborty",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 13800,
            "total": 13800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 13800,
            "total": 13800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-15927/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 23,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/740675",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub opened a new pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620\n\n\n   Add an example for the `SkyhookFileFormat` extension of Dataset API. \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-14T06:48:02.758+0000",
                    "updated": "2022-03-14T06:48:02.758+0000",
                    "started": "2022-03-14T06:48:02.758+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "740675",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/740676",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1066436165\n\n\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-14T06:48:27.067+0000",
                    "updated": "2022-03-14T06:48:27.067+0000",
                    "started": "2022-03-14T06:48:27.066+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "740676",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/740841",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r825900232\n\n\n\n##########\nFile path: cpp/examples/arrow/CMakeLists.txt\n##########\n@@ -123,6 +123,19 @@ if(ARROW_PARQUET AND ARROW_DATASET)\n                     ${DATASET_EXAMPLES_LINK_LIBS})\n   add_dependencies(dataset-parquet-scan-example parquet)\n \n+  if (ARROW_SKYHOOK)\n+    if (ARROW_BUILD_SHARED)\n+      set(DATASET_EXAMPLES_LINK_LIBS ${DATASET_EXAMPLES_LINK_LIBS}\n\nReview comment:\n       two nits: since we're reusing the same variable, maybe move this to the bottom of the enclosing if block so we don't link the other examples against Skyhook; and use `list(APPEND ...)`?\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,187 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} conf;\n\nReview comment:\n       nit: if this is effectively a static global, follow the naming convention and name it `kConfiguration` or something like that?\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,187 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} conf;\n+\n+std::shared_ptr<fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                     std::string* path) {\n+  return fs::FileSystemFromUri(uri, path).ValueOrDie();\n\nReview comment:\n       in general we could stick to using `ARROW_ASSIGN_FROM_RAISE` and only check the status in `main` (we can have a `Status Main()` or something to wrap all the Status/Result-using calls)\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,187 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} conf;\n\nReview comment:\n       Ah, I see now this is effectively based on the Parquet scan example, still, it would be good to clean up some of these things\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-14T12:41:23.005+0000",
                    "updated": "2022-03-14T12:41:23.005+0000",
                    "started": "2022-03-14T12:41:23.005+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "740841",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/740843",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r825904844\n\n\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,187 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} conf;\n+\n+std::shared_ptr<fs::FileSystem> GetFileSystemFromUri(const std::string& uri,\n+                                                     std::string* path) {\n+  return fs::FileSystemFromUri(uri, path).ValueOrDie();\n+}\n+\n+std::shared_ptr<ds::Dataset> GetDatasetFromDirectory(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string dir) {\n+  // Find all files under `path`\n+  fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  auto factory = ds::FileSystemDatasetFactory::Make(fs, s, format, options).ValueOrDie();\n+\n+  // Try to infer a common schema for all files.\n+  auto schema = factory->Inspect(conf.inspect_options).ValueOrDie();\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  auto child = factory->Finish(conf.finish_options).ValueOrDie();\n+\n+  ds::DatasetVector children{conf.repeat, child};\n+  auto dataset = ds::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<ds::Dataset> GetDatasetFromFile(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string file) {\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  auto factory =\n+      ds::FileSystemDatasetFactory::Make(fs, {file}, format, options).ValueOrDie();\n+\n+  // Try to infer a common schema for all files.\n+  auto schema = factory->Inspect(conf.inspect_options).ValueOrDie();\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  auto child = factory->Finish(conf.finish_options).ValueOrDie();\n+\n+  ds::DatasetVector children;\n+  children.resize(conf.repeat, child);\n+  auto dataset = ds::UnionDataset::Make(std::move(schema), std::move(children));\n+\n+  return dataset.ValueOrDie();\n+}\n+\n+std::shared_ptr<ds::Dataset> GetDatasetFromPath(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string path) {\n+  auto info = fs->GetFileInfo(path).ValueOrDie();\n+  if (info.IsDirectory()) {\n+    return GetDatasetFromDirectory(fs, format, path);\n+  }\n+  return GetDatasetFromFile(fs, format, path);\n+}\n+\n+std::shared_ptr<ds::Scanner> GetScannerFromDataset(std::shared_ptr<ds::Dataset> dataset,\n+                                                   std::vector<std::string> columns,\n+                                                   cp::Expression filter,\n+                                                   bool use_threads) {\n+  auto scanner_builder = dataset->NewScan().ValueOrDie();\n+\n+  if (!columns.empty()) {\n+    ABORT_ON_FAILURE(scanner_builder->Project(columns));\n+  }\n+\n+  ABORT_ON_FAILURE(scanner_builder->Filter(filter));\n+\n+  ABORT_ON_FAILURE(scanner_builder->UseThreads(use_threads));\n+\n+  return scanner_builder->Finish().ValueOrDie();\n+}\n+\n+std::shared_ptr<Table> GetTableFromScanner(std::shared_ptr<ds::Scanner> scanner) {\n+  return scanner->ToTable().ValueOrDie();\n+}\n+\n+std::shared_ptr<skyhook::SkyhookFileFormat> InstantiateSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"arrow\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  auto format = skyhook::SkyhookFileFormat::Make(rados_ctx, \"parquet\").ValueOrDie();\n+  return format;\n+}\n+\n+int main(int argc, char** argv) {\n+  auto format = InstantiateSkyhookFormat();\n\nReview comment:\n       nit, but we can move this after the argc check\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-14T12:42:00.525+0000",
                    "updated": "2022-03-14T12:42:00.525+0000",
                    "started": "2022-03-14T12:42:00.525+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "740843",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/741799",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1068362216\n\n\n   Thanks a lot for reviewing this PR @lidavidm . I made the code changes. I think I mistakenly requested review early, as of now, I am left with adding the docs. \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-15T19:10:51.108+0000",
                    "updated": "2022-03-15T19:10:51.108+0000",
                    "started": "2022-03-15T19:10:51.107+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "741799",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/741829",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r827325633\n\n\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,188 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} kConf;\n+\n+arrow::Result<std::shared_ptr<fs::FileSystem>> GetFileSystemFromUri(const std::string& uri,\n+                                                     std::string* path) {\n+  return fs::FileSystemFromUri(uri, path);\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromDirectory(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string dir) {\n+  // Find all files under `path`\n+  fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory, ds::FileSystemDatasetFactory::Make(fs, s, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children{kConf.repeat, child};\n+  ARROW_ASSIGN_OR_RAISE(auto dataset, ds::UnionDataset::Make(std::move(schema), std::move(children)));\n+\n+  return dataset;\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromFile(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string file) {\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory,\n+      ds::FileSystemDatasetFactory::Make(fs, {file}, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children;\n+  children.resize(kConf.repeat, child);\n+  ARROW_ASSIGN_OR_RAISE(auto dataset, ds::UnionDataset::Make(std::move(schema), std::move(children)));\n+\n+  return dataset;\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromPath(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string path) {\n+  ARROW_ASSIGN_OR_RAISE(auto info, fs->GetFileInfo(path));\n+  if (info.IsDirectory()) {\n+    return GetDatasetFromDirectory(fs, format, path);\n+  }\n+  return GetDatasetFromFile(fs, format, path);\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Scanner>> GetScannerFromDataset(std::shared_ptr<ds::Dataset> dataset,\n+                                                   std::vector<std::string> columns,\n+                                                   cp::Expression filter,\n+                                                   bool use_threads) {\n+  ARROW_ASSIGN_OR_RAISE(auto scanner_builder, dataset->NewScan());\n+\n+  if (!columns.empty()) {\n+    ABORT_ON_FAILURE(scanner_builder->Project(columns));\n\nReview comment:\n       ARROW_RETURN_NOT_OK?\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,188 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} kConf;\n+\n+arrow::Result<std::shared_ptr<fs::FileSystem>> GetFileSystemFromUri(const std::string& uri,\n+                                                     std::string* path) {\n+  return fs::FileSystemFromUri(uri, path);\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromDirectory(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string dir) {\n+  // Find all files under `path`\n+  fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory, ds::FileSystemDatasetFactory::Make(fs, s, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children{kConf.repeat, child};\n+  ARROW_ASSIGN_OR_RAISE(auto dataset, ds::UnionDataset::Make(std::move(schema), std::move(children)));\n+\n+  return dataset;\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromFile(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string file) {\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory,\n+      ds::FileSystemDatasetFactory::Make(fs, {file}, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children;\n+  children.resize(kConf.repeat, child);\n+  ARROW_ASSIGN_OR_RAISE(auto dataset, ds::UnionDataset::Make(std::move(schema), std::move(children)));\n+\n+  return dataset;\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromPath(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string path) {\n+  ARROW_ASSIGN_OR_RAISE(auto info, fs->GetFileInfo(path));\n+  if (info.IsDirectory()) {\n+    return GetDatasetFromDirectory(fs, format, path);\n+  }\n+  return GetDatasetFromFile(fs, format, path);\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Scanner>> GetScannerFromDataset(std::shared_ptr<ds::Dataset> dataset,\n+                                                   std::vector<std::string> columns,\n+                                                   cp::Expression filter,\n+                                                   bool use_threads) {\n+  ARROW_ASSIGN_OR_RAISE(auto scanner_builder, dataset->NewScan());\n+\n+  if (!columns.empty()) {\n+    ABORT_ON_FAILURE(scanner_builder->Project(columns));\n+  }\n+\n+  ABORT_ON_FAILURE(scanner_builder->Filter(filter));\n+\n+  ABORT_ON_FAILURE(scanner_builder->UseThreads(use_threads));\n+\n+  return scanner_builder->Finish();\n+}\n+\n+arrow::Result<std::shared_ptr<Table>> GetTableFromScanner(std::shared_ptr<ds::Scanner> scanner) {\n+  return scanner->ToTable();\n\nReview comment:\n       We can just inline this now.\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,192 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} kConf;\n+\n+arrow::Result<std::shared_ptr<fs::FileSystem>> GetFileSystemFromUri(\n+    const std::string& uri, std::string* path) {\n+  return fs::FileSystemFromUri(uri, path);\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromDirectory(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string dir) {\n+  // Find all files under `path`\n+  fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory,\n+                        ds::FileSystemDatasetFactory::Make(fs, s, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children{kConf.repeat, child};\n+  ARROW_ASSIGN_OR_RAISE(auto dataset,\n+                        ds::UnionDataset::Make(std::move(schema), std::move(children)));\n+\n+  return dataset;\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromFile(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string file) {\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory,\n+                        ds::FileSystemDatasetFactory::Make(fs, {file}, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children;\n+  children.resize(kConf.repeat, child);\n+  ARROW_ASSIGN_OR_RAISE(auto dataset,\n+                        ds::UnionDataset::Make(std::move(schema), std::move(children)));\n+\n+  return dataset;\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromPath(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string path) {\n+  ARROW_ASSIGN_OR_RAISE(auto info, fs->GetFileInfo(path));\n+  if (info.IsDirectory()) {\n+    return GetDatasetFromDirectory(fs, format, path);\n+  }\n+  return GetDatasetFromFile(fs, format, path);\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Scanner>> GetScannerFromDataset(\n+    std::shared_ptr<ds::Dataset> dataset, std::vector<std::string> columns,\n+    cp::Expression filter, bool use_threads) {\n+  ARROW_ASSIGN_OR_RAISE(auto scanner_builder, dataset->NewScan());\n+\n+  if (!columns.empty()) {\n+    ABORT_ON_FAILURE(scanner_builder->Project(columns));\n+  }\n+\n+  ABORT_ON_FAILURE(scanner_builder->Filter(filter));\n+\n+  ABORT_ON_FAILURE(scanner_builder->UseThreads(use_threads));\n+\n+  return scanner_builder->Finish();\n+}\n+\n+arrow::Result<std::shared_ptr<Table>> GetTableFromScanner(\n+    std::shared_ptr<ds::Scanner> scanner) {\n+  return scanner->ToTable();\n+}\n+\n+arrow::Result<std::shared_ptr<skyhook::SkyhookFileFormat>> InstantiateSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"arrow\";\n+  std::shared_ptr<skyhook::RadosConnCtx> rados_ctx =\n+      std::make_shared<skyhook::RadosConnCtx>(ceph_config_path, ceph_data_pool,\n+                                              ceph_user_name, ceph_cluster_name,\n+                                              ceph_cls_name);\n+  ARROW_ASSIGN_OR_RAISE(auto format,\n+                        skyhook::SkyhookFileFormat::Make(rados_ctx, \"parquet\"));\n+  return format;\n+}\n+\n+arrow::Status Main(char** argv) {\n+  ARROW_ASSIGN_OR_RAISE(auto format, InstantiateSkyhookFormat());\n+  std::string path;\n+\n+  ARROW_ASSIGN_OR_RAISE(auto fs, GetFileSystemFromUri(argv[1], &path));\n\nReview comment:\n       nit: use `Main(std::string dataset_root)` or something, and just call `Main(argv[1])` so that we aren't working with C-style strings here\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,188 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} kConf;\n+\n+arrow::Result<std::shared_ptr<fs::FileSystem>> GetFileSystemFromUri(const std::string& uri,\n+                                                     std::string* path) {\n+  return fs::FileSystemFromUri(uri, path);\n\nReview comment:\n       We can inline this now.\n\n##########\nFile path: cpp/examples/arrow/dataset_skyhook_scan_example.cc\n##########\n@@ -0,0 +1,188 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"pickup_at\", \"dropoff_at\",\n+                                                \"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter =\n+      cp::greater(cp::field_ref(\"total_amount\"), cp::literal(1000.0f));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} kConf;\n+\n+arrow::Result<std::shared_ptr<fs::FileSystem>> GetFileSystemFromUri(const std::string& uri,\n+                                                     std::string* path) {\n+  return fs::FileSystemFromUri(uri, path);\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromDirectory(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string dir) {\n+  // Find all files under `path`\n+  fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory, ds::FileSystemDatasetFactory::Make(fs, s, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children{kConf.repeat, child};\n+  ARROW_ASSIGN_OR_RAISE(auto dataset, ds::UnionDataset::Make(std::move(schema), std::move(children)));\n+\n+  return dataset;\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromFile(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string file) {\n+  ds::FileSystemFactoryOptions options;\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory,\n+      ds::FileSystemDatasetFactory::Make(fs, {file}, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children;\n+  children.resize(kConf.repeat, child);\n+  ARROW_ASSIGN_OR_RAISE(auto dataset, ds::UnionDataset::Make(std::move(schema), std::move(children)));\n+\n+  return dataset;\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromPath(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string path) {\n+  ARROW_ASSIGN_OR_RAISE(auto info, fs->GetFileInfo(path));\n+  if (info.IsDirectory()) {\n+    return GetDatasetFromDirectory(fs, format, path);\n+  }\n+  return GetDatasetFromFile(fs, format, path);\n+}\n+\n+arrow::Result<std::shared_ptr<ds::Scanner>> GetScannerFromDataset(std::shared_ptr<ds::Dataset> dataset,\n+                                                   std::vector<std::string> columns,\n+                                                   cp::Expression filter,\n+                                                   bool use_threads) {\n+  ARROW_ASSIGN_OR_RAISE(auto scanner_builder, dataset->NewScan());\n+\n+  if (!columns.empty()) {\n+    ABORT_ON_FAILURE(scanner_builder->Project(columns));\n+  }\n+\n+  ABORT_ON_FAILURE(scanner_builder->Filter(filter));\n+\n+  ABORT_ON_FAILURE(scanner_builder->UseThreads(use_threads));\n+\n+  return scanner_builder->Finish();\n+}\n+\n+arrow::Result<std::shared_ptr<Table>> GetTableFromScanner(std::shared_ptr<ds::Scanner> scanner) {\n+  return scanner->ToTable();\n+}\n+\n+arrow::Result<std::shared_ptr<skyhook::SkyhookFileFormat>> InstantiateSkyhookFormat() {\n+  std::string ceph_config_path = \"/etc/ceph/ceph.conf\";\n+  std::string ceph_data_pool = \"cephfs_data\";\n+  std::string ceph_user_name = \"client.admin\";\n+  std::string ceph_cluster_name = \"ceph\";\n+  std::string ceph_cls_name = \"arrow\";\n\nReview comment:\n       Is it worth documenting these parameters?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-15T19:43:17.030+0000",
                    "updated": "2022-03-15T19:43:17.030+0000",
                    "started": "2022-03-15T19:43:17.029+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "741829",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/741911",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1068506029\n\n\n   I did [this change](https://github.com/apache/arrow/pull/12620/commits/03756011809fa15bbd7c4ec7051f9e8ba2406e04) commit as I am currently, working on a Python API of Skyhook, and this rename will help in writing a cleaner Cython wrapper.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-15T21:52:09.839+0000",
                    "updated": "2022-03-15T21:52:09.839+0000",
                    "started": "2022-03-15T21:52:09.839+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "741911",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/741912",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1068507097\n\n\n   @github-actions crossbow submit test-skyhook-integration\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-15T21:53:44.638+0000",
                    "updated": "2022-03-15T21:53:44.638+0000",
                    "started": "2022-03-15T21:53:44.638+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "741912",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/741913",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1068507752\n\n\n   Revision: 03756011809fa15bbd7c4ec7051f9e8ba2406e04\n   \n   Submitted crossbow builds: [ursacomputing/crossbow @ actions-1769](https://github.com/ursacomputing/crossbow/branches/all?query=actions-1769)\n   \n   |Task|Status|\n   |----|------|\n   |test-skyhook-integration|[![Github Actions](https://github.com/ursacomputing/crossbow/workflows/Crossbow/badge.svg?branch=actions-1769-github-test-skyhook-integration)](https://github.com/ursacomputing/crossbow/actions?query=branch:actions-1769-github-test-skyhook-integration)|\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-15T21:54:47.754+0000",
                    "updated": "2022-03-15T21:54:47.754+0000",
                    "started": "2022-03-15T21:54:47.754+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "741913",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/744528",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1072905727\n\n\n   @lidavidm Is there a way to live preview the docs , like with a temporary deployment ?\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-19T00:44:11.823+0000",
                    "updated": "2022-03-19T00:44:11.823+0000",
                    "started": "2022-03-19T00:44:11.823+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "744528",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/744540",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub edited a comment on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1072905727\n\n\n   @lidavidm Is there a way to live preview the docs , like with a temporary deployment ? I am having a little trouble building the docs myself, I am running out of space in my development machine.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-19T01:10:05.680+0000",
                    "updated": "2022-03-19T01:10:05.680+0000",
                    "started": "2022-03-19T01:10:05.680+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "744540",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/744731",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1073290729\n\n\n   Ah\u2026there's not too good a way to build the docs without building PyArrow from source, though you can usually build individual files okay without issue. This should work:\r\n   \r\n   ```\r\n   # First, make sure pyarrow is installed (an existing release is OK, e.g. from PyPI or Conda)\r\n   $ cd docs\r\n   $ touch ./source/cpp/examples/temp_index.rst && sphinx-build ./source/cpp/examples ./source/cpp/_build -c ./source -D master_doc=temp_index\r\n   $ firefox source/cpp/_build/dataset_skyhook_scan_example.html\r\n   ```\r\n   \r\n   Rendered:\r\n   \r\n   ![image](https://user-images.githubusercontent.com/327919/159173596-5bf16e5c-d7ef-4701-be4e-c1ab8f85bc38.png)\r\n   \r\n   Looks like we may need to fiddle with the reST to get it to render as expected.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-20T16:57:48.544+0000",
                    "updated": "2022-03-20T16:57:48.544+0000",
                    "started": "2022-03-20T16:57:48.543+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "744731",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/744733",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r830644580\n\n\n\n##########\nFile path: docs/source/cpp/examples/dataset_skyhook_scan_example.rst\n##########\n@@ -0,0 +1,85 @@\n+.. Licensed to the Apache Software Foundation (ASF) under one\n+.. or more contributor license agreements.  See the NOTICE file\n+.. distributed with this work for additional information\n+.. regarding copyright ownership.  The ASF licenses this file\n+.. to you under the Apache License, Version 2.0 (the\n+.. \"License\"); you may not use this file except in compliance\n+.. with the License.  You may obtain a copy of the License at\n+\n+..   http://www.apache.org/licenses/LICENSE-2.0\n+\n+.. Unless required by applicable law or agreed to in writing,\n+.. software distributed under the License is distributed on an\n+.. \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+.. KIND, either express or implied.  See the License for the\n+.. specific language governing permissions and limitations\n+.. under the License.\n+\n+.. default-domain:: cpp\n+.. highlight:: cpp\n+\n+Arrow Skyhook example\n+=========================\n\nReview comment:\n       ```suggestion\r\n   \r\n   =====================\r\n   Arrow Skyhook example\r\n   =====================\r\n   ```\n\n##########\nFile path: docs/source/cpp/examples/dataset_skyhook_scan_example.rst\n##########\n@@ -0,0 +1,85 @@\n+.. Licensed to the Apache Software Foundation (ASF) under one\n+.. or more contributor license agreements.  See the NOTICE file\n+.. distributed with this work for additional information\n+.. regarding copyright ownership.  The ASF licenses this file\n+.. to you under the Apache License, Version 2.0 (the\n+.. \"License\"); you may not use this file except in compliance\n+.. with the License.  You may obtain a copy of the License at\n+\n+..   http://www.apache.org/licenses/LICENSE-2.0\n+\n+.. Unless required by applicable law or agreed to in writing,\n+.. software distributed under the License is distributed on an\n+.. \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+.. KIND, either express or implied.  See the License for the\n+.. specific language governing permissions and limitations\n+.. under the License.\n+\n+.. default-domain:: cpp\n+.. highlight:: cpp\n+\n+Arrow Skyhook example\n+=========================\n+\n+The file ``cpp/examples/arrow/dataset_skyhook_scan_example.cc``\n+located inside the source tree contains an example of using Skyhook to \n+offload filters and projections to a Ceph cluster.\n+\n+Instuctions\n+--------------------\n+\n+1. Install Ceph and Skyhook dependencies.\n+.. code-block:: bash\n+\n+    apt update \n+    apt install -y cmake \\\n+                    libradospp-dev \\\n+                    rados-objclass-dev \\\n+                    ceph \\\n+                    ceph-common \\\n+                    ceph-osd \\\n+                    ceph-mon \\\n+                    ceph-mgr \\\n+                    ceph-mds \\\n+                    rbd-mirror \\\n+                    ceph-fuse\n+\n+2. Build and install Skyhook.\n+\n+.. code-block:: bash\n+\n+    git clone https://github.com/apache/arrow\n+    cd arrow/\n+    mkdir -p cpp/release\n+    cd cpp/release\n+    cmake -DARROW_SKYHOOK=ON \\\n+    -DARROW_PARQUET=ON \\\n+    -DARROW_WITH_SNAPPY=ON \\\n+    -DARROW_BUILD_EXAMPLES=ON \\\n+    -DARROW_DATASET=ON \\\n+    -DARROW_CSV=ON \\\n+    -DARROW_WITH_LZ4=ON \\\n+    ..\n+\n+    make -j${nproc} install\n+    cp release/libcls_skyhook.so /usr/lib/x86_64-linux-gnu/rados-classes/\n+\n+3. Deploy a Ceph cluster with a single in-memory OSD.\n+\n+.. code-block:: bash\n+\n+    mkdir -p /tmp/skyhook\n+    ../examples/scripts/micro-osd.sh /tmp/skyhook\n+\n+4. Generate an example dataset.\n+\n+.. code-block:: bash\n+\n+    python3 ../../ci/scripts/generate_dataset.py\n+    cp -r nyc /mnt/cephfs/\n+\n+5. Compile and Run the example.\n+\n+.. code-block:: bash\n+    g++ -std=c++11 ../examples/arrow/dataset_skyhook_scan_example.cc -larrow -larrow_dataset -larrow_skyhook -o skyhook_example\n\nReview comment:\n       This should just be `make dataset_skyhook_scan_example`, the Arrow build system will build the examples\n\n##########\nFile path: docs/source/cpp/examples/dataset_skyhook_scan_example.rst\n##########\n@@ -0,0 +1,85 @@\n+.. Licensed to the Apache Software Foundation (ASF) under one\n+.. or more contributor license agreements.  See the NOTICE file\n+.. distributed with this work for additional information\n+.. regarding copyright ownership.  The ASF licenses this file\n+.. to you under the Apache License, Version 2.0 (the\n+.. \"License\"); you may not use this file except in compliance\n+.. with the License.  You may obtain a copy of the License at\n+\n+..   http://www.apache.org/licenses/LICENSE-2.0\n+\n+.. Unless required by applicable law or agreed to in writing,\n+.. software distributed under the License is distributed on an\n+.. \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+.. KIND, either express or implied.  See the License for the\n+.. specific language governing permissions and limitations\n+.. under the License.\n+\n+.. default-domain:: cpp\n+.. highlight:: cpp\n+\n+Arrow Skyhook example\n+=========================\n+\n+The file ``cpp/examples/arrow/dataset_skyhook_scan_example.cc``\n+located inside the source tree contains an example of using Skyhook to \n+offload filters and projections to a Ceph cluster.\n+\n+Instuctions\n+--------------------\n+\n+1. Install Ceph and Skyhook dependencies.\n+.. code-block:: bash\n+\n+    apt update \n\nReview comment:\n       Is this for Debian or Ubuntu? Can we mention the distro's version?\n\n##########\nFile path: cpp/examples/scripts/micro-osd.sh\n##########\n@@ -0,0 +1,103 @@\n+#\n+#    Copyright (C) 2013,2014 Loic Dachary <loic@dachary.org>\n+#\n+#    This program is free software: you can redistribute it and/or modify\n+#    it under the terms of the GNU Affero General Public License as published by\n+#    the Free Software Foundation, either version 3 of the License, or\n+#    (at your option) any later version.\n+#\n+#    This program is distributed in the hope that it will be useful,\n+#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n+#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+#    GNU Affero General Public License for more details.\n+#\n+#    You should have received a copy of the GNU Affero General Public License\n+#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+#\n\nReview comment:\n       We can't commit an AGPL-licensed script into our repo. If it's available somewhere else, we can just remove it from here and link to it from the docs instead?\n\n##########\nFile path: docs/source/cpp/examples/dataset_skyhook_scan_example.rst\n##########\n@@ -0,0 +1,85 @@\n+.. Licensed to the Apache Software Foundation (ASF) under one\n+.. or more contributor license agreements.  See the NOTICE file\n+.. distributed with this work for additional information\n+.. regarding copyright ownership.  The ASF licenses this file\n+.. to you under the Apache License, Version 2.0 (the\n+.. \"License\"); you may not use this file except in compliance\n+.. with the License.  You may obtain a copy of the License at\n+\n+..   http://www.apache.org/licenses/LICENSE-2.0\n+\n+.. Unless required by applicable law or agreed to in writing,\n+.. software distributed under the License is distributed on an\n+.. \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+.. KIND, either express or implied.  See the License for the\n+.. specific language governing permissions and limitations\n+.. under the License.\n+\n+.. default-domain:: cpp\n+.. highlight:: cpp\n+\n+Arrow Skyhook example\n+=========================\n+\n+The file ``cpp/examples/arrow/dataset_skyhook_scan_example.cc``\n+located inside the source tree contains an example of using Skyhook to \n+offload filters and projections to a Ceph cluster.\n+\n+Instuctions\n+--------------------\n\nReview comment:\n       ```suggestion\r\n   Instuctions\r\n   ===========\r\n   ```\n\n##########\nFile path: docs/source/cpp/examples/dataset_skyhook_scan_example.rst\n##########\n@@ -0,0 +1,85 @@\n+.. Licensed to the Apache Software Foundation (ASF) under one\n+.. or more contributor license agreements.  See the NOTICE file\n+.. distributed with this work for additional information\n+.. regarding copyright ownership.  The ASF licenses this file\n+.. to you under the Apache License, Version 2.0 (the\n+.. \"License\"); you may not use this file except in compliance\n+.. with the License.  You may obtain a copy of the License at\n+\n+..   http://www.apache.org/licenses/LICENSE-2.0\n+\n+.. Unless required by applicable law or agreed to in writing,\n+.. software distributed under the License is distributed on an\n+.. \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+.. KIND, either express or implied.  See the License for the\n+.. specific language governing permissions and limitations\n+.. under the License.\n+\n+.. default-domain:: cpp\n+.. highlight:: cpp\n+\n+Arrow Skyhook example\n+=========================\n+\n+The file ``cpp/examples/arrow/dataset_skyhook_scan_example.cc``\n+located inside the source tree contains an example of using Skyhook to \n+offload filters and projections to a Ceph cluster.\n+\n+Instuctions\n+--------------------\n+\n+1. Install Ceph and Skyhook dependencies.\n+.. code-block:: bash\n+\n+    apt update \n+    apt install -y cmake \\\n+                    libradospp-dev \\\n+                    rados-objclass-dev \\\n+                    ceph \\\n+                    ceph-common \\\n+                    ceph-osd \\\n+                    ceph-mon \\\n+                    ceph-mgr \\\n+                    ceph-mds \\\n+                    rbd-mirror \\\n+                    ceph-fuse\n+\n+2. Build and install Skyhook.\n+\n+.. code-block:: bash\n+\n+    git clone https://github.com/apache/arrow\n+    cd arrow/\n+    mkdir -p cpp/release\n+    cd cpp/release\n+    cmake -DARROW_SKYHOOK=ON \\\n+    -DARROW_PARQUET=ON \\\n+    -DARROW_WITH_SNAPPY=ON \\\n+    -DARROW_BUILD_EXAMPLES=ON \\\n+    -DARROW_DATASET=ON \\\n+    -DARROW_CSV=ON \\\n+    -DARROW_WITH_LZ4=ON \\\n+    ..\n\nReview comment:\n       nit, but the indentation-after-backslash is a little inconsistent for each of these code blocks\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-20T17:06:04.504+0000",
                    "updated": "2022-03-20T17:06:04.504+0000",
                    "started": "2022-03-20T17:06:04.504+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "744733",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/744817",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1073449497\n\n\n   > Ah\u2026there's not too good a way to build the docs without building PyArrow from source, though you can usually build individual files okay without issue. This should work:\r\n   \r\n   Thanks a lot for this, @lidavidm. \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-21T03:29:40.831+0000",
                    "updated": "2022-03-21T03:29:40.831+0000",
                    "started": "2022-03-21T03:29:40.830+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "744817",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/744821",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on a change in pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r830735668\n\n\n\n##########\nFile path: cpp/examples/scripts/micro-osd.sh\n##########\n@@ -0,0 +1,103 @@\n+#\n+#    Copyright (C) 2013,2014 Loic Dachary <loic@dachary.org>\n+#\n+#    This program is free software: you can redistribute it and/or modify\n+#    it under the terms of the GNU Affero General Public License as published by\n+#    the Free Software Foundation, either version 3 of the License, or\n+#    (at your option) any later version.\n+#\n+#    This program is distributed in the hope that it will be useful,\n+#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n+#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+#    GNU Affero General Public License for more details.\n+#\n+#    You should have received a copy of the GNU Affero General Public License\n+#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+#\n\nReview comment:\n       This is actually a modified version of https://github.com/ceph/ceph-rust/blob/master/micro-osd.sh. I added some commands to create a CephFS mount after creating a Ceph cluster. I don't really know a lot about licensing, but can we instead move this to ASF license and reference the original script ?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-21T03:37:15.058+0000",
                    "updated": "2022-03-21T03:37:15.058+0000",
                    "started": "2022-03-21T03:37:15.057+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "744821",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/744993",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r831025282\n\n\n\n##########\nFile path: cpp/examples/scripts/micro-osd.sh\n##########\n@@ -0,0 +1,103 @@\n+#\n+#    Copyright (C) 2013,2014 Loic Dachary <loic@dachary.org>\n+#\n+#    This program is free software: you can redistribute it and/or modify\n+#    it under the terms of the GNU Affero General Public License as published by\n+#    the Free Software Foundation, either version 3 of the License, or\n+#    (at your option) any later version.\n+#\n+#    This program is distributed in the hope that it will be useful,\n+#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n+#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+#    GNU Affero General Public License for more details.\n+#\n+#    You should have received a copy of the GNU Affero General Public License\n+#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+#\n\nReview comment:\n       No, if it's derived from an AGPL script it must still be AGPL. We can reference the file, but we can't hve this script here.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-21T11:57:44.376+0000",
                    "updated": "2022-03-21T11:57:44.376+0000",
                    "started": "2022-03-21T11:57:44.376+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "744993",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/795533",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on PR #12620:\nURL: https://github.com/apache/arrow/pull/12620#issuecomment-1196324990\n\n   Hi @lidavidm, my apologies for abandoning this PR. I fixed the PR according to your comments and verified that the code changes work properly.  It would be great if you can please take a look. I plan to resume working on skyhook especially the Python API for skyhook. Thanks.\n\n\n",
                    "created": "2022-07-27T06:41:14.455+0000",
                    "updated": "2022-07-27T06:41:14.455+0000",
                    "started": "2022-07-27T06:41:14.455+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "795533",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/795690",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on code in PR #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r931155402\n\n\n##########\ncpp/examples/arrow/dataset_skyhook_scan_example.cc:\n##########\n@@ -0,0 +1,201 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter = cp::greater(cp::field_ref(\"payment_type\"), cp::literal(1));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} kConf;\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromDirectory(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string dir) {\n+  // Find all files under `path`\n+  fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  // Set partitioning strategy\n+  ds::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<ds::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+\n+  // The factory will try to build a child dataset.\n+  ARROW_ASSIGN_OR_RAISE(auto factory,\n+                        ds::FileSystemDatasetFactory::Make(fs, s, format, options));\n+\n+  // Try to infer a common schema for all files.\n+  ARROW_ASSIGN_OR_RAISE(auto schema, factory->Inspect(kConf.inspect_options));\n+  // Caller can optionally decide another schema as long as it is compatible\n+  // with the previous one, e.g. `factory->Finish(compatible_schema)`.\n+  ARROW_ASSIGN_OR_RAISE(auto child, factory->Finish(kConf.finish_options));\n+\n+  ds::DatasetVector children{kConf.repeat, child};\n\nReview Comment:\n   IMO instead of complicating it with the repeat, let's just return the dataset directly (ditto below)\n\n\n\n##########\ncpp/examples/arrow/dataset_skyhook_scan_example.cc:\n##########\n@@ -0,0 +1,201 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n\nReview Comment:\n   We recently rewrote the examples to avoid this style - instead functions appropriately return `arrow::Status` or `arrow::Result`, and then we have a `Status Main()`; finally in `int main()` we check the status of `Main()` and print/exit as appropriate. For reference see #13598\n\n\n\n##########\ncpp/examples/arrow/dataset_skyhook_scan_example.cc:\n##########\n@@ -0,0 +1,201 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n\nReview Comment:\n   It looks like things here are already in that style, so can we just inline this macro into `main`?\n\n\n\n##########\ncpp/examples/arrow/dataset_skyhook_scan_example.cc:\n##########\n@@ -0,0 +1,201 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/discovery.h>\n+#include <arrow/dataset/file_base.h>\n+#include <arrow/dataset/scanner.h>\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/filesystem/path_util.h>\n+#include <skyhook/client/file_skyhook.h>\n+\n+#include <cstdlib>\n+#include <iostream>\n+\n+using arrow::field;\n+using arrow::int16;\n+using arrow::Schema;\n+using arrow::Table;\n+\n+namespace fs = arrow::fs;\n+\n+namespace ds = arrow::dataset;\n+\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+struct Configuration {\n+  // Increase the ds::DataSet by repeating `repeat` times the ds::Dataset.\n+  size_t repeat = 1;\n+\n+  // Indicates if the Scanner::ToTable should consume in parallel.\n+  bool use_threads = true;\n+\n+  // Indicates to the Scan operator which columns are requested. This\n+  // optimization avoid deserializing unneeded columns.\n+  std::vector<std::string> projected_columns = {\"total_amount\"};\n+\n+  // Indicates the filter by which rows will be filtered. This optimization can\n+  // make use of partition information and/or file metadata if possible.\n+  cp::Expression filter = cp::greater(cp::field_ref(\"payment_type\"), cp::literal(1));\n+\n+  ds::InspectOptions inspect_options{};\n+  ds::FinishOptions finish_options{};\n+} kConf;\n+\n+arrow::Result<std::shared_ptr<ds::Dataset>> GetDatasetFromDirectory(\n+    std::shared_ptr<fs::FileSystem> fs, std::shared_ptr<ds::FileFormat> format,\n+    std::string dir) {\n+  // Find all files under `path`\n+  fs::FileSelector s;\n+  s.base_dir = dir;\n+  s.recursive = true;\n+\n+  // Set partitioning strategy\n+  ds::FileSystemFactoryOptions options;\n+  options.partitioning = std::make_shared<ds::HivePartitioning>(\n+      arrow::schema({arrow::field(\"payment_type\", arrow::int32()),\n+                     arrow::field(\"VendorID\", arrow::int32())}));\n+\n+  // The factory will try to build a child dataset.\n\nReview Comment:\n   I'm not sure what's meant by child dataset (here and below)\n\n\n\n##########\ndocs/source/cpp/examples/dataset_skyhook_scan_example.rst:\n##########\n@@ -0,0 +1,93 @@\n+.. Licensed to the Apache Software Foundation (ASF) under one\n+.. or more contributor license agreements.  See the NOTICE file\n+.. distributed with this work for additional information\n+.. regarding copyright ownership.  The ASF licenses this file\n+.. to you under the Apache License, Version 2.0 (the\n+.. \"License\"); you may not use this file except in compliance\n+.. with the License.  You may obtain a copy of the License at\n+\n+..   http://www.apache.org/licenses/LICENSE-2.0\n+\n+.. Unless required by applicable law or agreed to in writing,\n+.. software distributed under the License is distributed on an\n+.. \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+.. KIND, either express or implied.  See the License for the\n+.. specific language governing permissions and limitations\n+.. under the License.\n+\n+.. default-domain:: cpp\n+.. highlight:: cpp\n+\n+=====================\n+Arrow Skyhook example\n+=====================\n+\n+The file ``cpp/examples/arrow/dataset_skyhook_scan_example.cc``\n+located inside the source tree contains an example of using Skyhook to \n+offload filters and projections to a Ceph cluster.\n+\n+Instuctions\n+===========\n+\n+.. note::\n+   The instructions below are for ubuntu 20.04 or above.\n+\n+1. Install Ceph and Skyhook dependencies.\n+\n+.. code-block:: bash\n\nReview Comment:\n   I think these need indentation to be properly formatted as part of the list, but I can push a fix later\n\n\n\n",
                    "created": "2022-07-27T14:47:34.341+0000",
                    "updated": "2022-07-27T14:47:34.341+0000",
                    "started": "2022-07-27T14:47:34.341+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "795690",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/795734",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "JayjeetAtGithub commented on code in PR #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r931246576\n\n\n##########\ndocs/source/cpp/examples/dataset_skyhook_scan_example.rst:\n##########\n@@ -0,0 +1,93 @@\n+.. Licensed to the Apache Software Foundation (ASF) under one\n+.. or more contributor license agreements.  See the NOTICE file\n+.. distributed with this work for additional information\n+.. regarding copyright ownership.  The ASF licenses this file\n+.. to you under the Apache License, Version 2.0 (the\n+.. \"License\"); you may not use this file except in compliance\n+.. with the License.  You may obtain a copy of the License at\n+\n+..   http://www.apache.org/licenses/LICENSE-2.0\n+\n+.. Unless required by applicable law or agreed to in writing,\n+.. software distributed under the License is distributed on an\n+.. \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+.. KIND, either express or implied.  See the License for the\n+.. specific language governing permissions and limitations\n+.. under the License.\n+\n+.. default-domain:: cpp\n+.. highlight:: cpp\n+\n+=====================\n+Arrow Skyhook example\n+=====================\n+\n+The file ``cpp/examples/arrow/dataset_skyhook_scan_example.cc``\n+located inside the source tree contains an example of using Skyhook to \n+offload filters and projections to a Ceph cluster.\n+\n+Instuctions\n+===========\n+\n+.. note::\n+   The instructions below are for ubuntu 20.04 or above.\n+\n+1. Install Ceph and Skyhook dependencies.\n+\n+.. code-block:: bash\n\nReview Comment:\n   I fixed the indentation. Is it ok now ?\n\n\n\n",
                    "created": "2022-07-27T16:05:30.244+0000",
                    "updated": "2022-07-27T16:05:30.244+0000",
                    "started": "2022-07-27T16:05:30.244+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "795734",
                    "issueId": "13433578"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/worklog/796478",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on code in PR #12620:\nURL: https://github.com/apache/arrow/pull/12620#discussion_r933542588\n\n\n##########\ndocs/source/cpp/examples/dataset_skyhook_scan_example.rst:\n##########\n@@ -0,0 +1,93 @@\n+.. Licensed to the Apache Software Foundation (ASF) under one\n+.. or more contributor license agreements.  See the NOTICE file\n+.. distributed with this work for additional information\n+.. regarding copyright ownership.  The ASF licenses this file\n+.. to you under the Apache License, Version 2.0 (the\n+.. \"License\"); you may not use this file except in compliance\n+.. with the License.  You may obtain a copy of the License at\n+\n+..   http://www.apache.org/licenses/LICENSE-2.0\n+\n+.. Unless required by applicable law or agreed to in writing,\n+.. software distributed under the License is distributed on an\n+.. \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+.. KIND, either express or implied.  See the License for the\n+.. specific language governing permissions and limitations\n+.. under the License.\n+\n+.. default-domain:: cpp\n+.. highlight:: cpp\n+\n+=====================\n+Arrow Skyhook example\n+=====================\n+\n+The file ``cpp/examples/arrow/dataset_skyhook_scan_example.cc``\n+located inside the source tree contains an example of using Skyhook to \n+offload filters and projections to a Ceph cluster.\n+\n+Instuctions\n+===========\n+\n+.. note::\n+   The instructions below are for ubuntu 20.04 or above.\n+\n+1. Install Ceph and Skyhook dependencies.\n+\n+.. code-block:: bash\n\nReview Comment:\n   See https://github.com/uccross/skyhookdm-arrow/pull/294\n\n\n\n",
                    "created": "2022-07-29T18:55:30.277+0000",
                    "updated": "2022-07-29T18:55:30.277+0000",
                    "started": "2022-07-29T18:55:30.277+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "796478",
                    "issueId": "13433578"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 13800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@6351e4c6[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5086531e[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@51e52182[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@33999603[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5ebe7fe1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@1720de64[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6fb11433[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@1067ae48[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3d0b9ad2[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@2c49b0e9[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4b3e39df[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@6606db1e[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 13800,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Aug 01 13:24:18 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-08-01T13:24:18.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-15927/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2022-03-14T06:44:04.000+0000",
        "updated": "2022-08-01T15:41:38.000+0000",
        "timeoriginalestimate": null,
        "description": "Add an example for using Skyhook using the C++ SkyhookFileFormat API.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "3h 50m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 13800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Skyhook] Add Skyhook example",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13433578/comment/17573764",
                    "id": "17573764",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 12620\n[https://github.com/apache/arrow/pull/12620]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-08-01T13:24:18.116+0000",
                    "updated": "2022-08-01T13:24:18.116+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z10g2w:",
        "customfield_12314139": null
    }
}