{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13253271",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271",
    "key": "ARROW-6368",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12345978",
                "id": "12345978",
                "description": "",
                "name": "0.15.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-10-05"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
            "name": "Minor",
            "id": "4"
        },
        "labels": [
            "dataset",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 20400,
            "total": 20400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 20400,
            "total": 20400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-6368/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 35,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304273",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319528311\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+      } else {\n+        auto out_type = to_->field(i)->type();\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, out_type, 0, &missing_columns_[i]));\n+      }\n+\n+      column_indices_[i] = matching_index;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Project(const RecordBatch& batch, std::shared_ptr<RecordBatch>* out) {\n+    std::vector<std::shared_ptr<Array>> columns(to_->num_fields());\n+\n+    if (missing_columns_length_ < batch.num_rows()) {\n+      RETURN_NOT_OK(ResizeMissingColumns(batch.num_rows()));\n+    }\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      int matching_index = column_indices_[i];\n+      if (matching_index != kNoMatch) {\n+        columns[i] = batch.column(matching_index);\n+        continue;\n+      }\n+\n+      columns[i] = missing_columns_[i]->Slice(0, batch.num_rows());\n+    }\n+\n+    *out = RecordBatch::Make(to_, batch.num_rows(), std::move(columns));\n+    return Status::OK();\n+  }\n+\n+  const std::shared_ptr<Schema>& from() const { return from_; }\n+\n+  const std::shared_ptr<Schema>& to() const { return to_; }\n+\n+ private:\n+  static constexpr int kNoMatch = -1;\n+\n+  Status ResizeMissingColumns(int64_t new_length) {\n+    // TODO(bkietz) MakeArrayOfNull could use fewer buffers by reusing a single zeroed\n+    // buffer for every buffer in every column which is null\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      if (missing_columns_[i] == nullptr) {\n+        continue;\n+      }\n+      if (scalars_[i] == nullptr) {\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, missing_columns_[i]->type(), new_length,\n+                                      &missing_columns_[i]));\n+        continue;\n+      }\n+      RETURN_NOT_OK(\n+          MakeArrayFromScalar(pool_, *scalars_[i], new_length, &missing_columns_[i]));\n+    }\n+    missing_columns_length_ = new_length;\n+    return Status::OK();\n+  }\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<Schema> from_, to_;\n+  int64_t missing_columns_length_ = 0;\n+  std::vector<std::shared_ptr<Array>> missing_columns_;\n+  std::vector<int> column_indices_;\n+  std::vector<std::shared_ptr<Scalar>> scalars_;\n+};\n+\n+constexpr int RecordBatchProjector::kNoMatch;\n+\n+class ProjectedRecordBatchReader : public RecordBatchReader {\n+ public:\n+  ProjectedRecordBatchReader(MemoryPool* pool, std::shared_ptr<Schema> schema,\n+                             std::vector<std::shared_ptr<Scalar>> scalars,\n \n Review comment:\n   It should just receive a RecordBatchProjector, and you can get rid of ResetProjector.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:08:19.912+0000",
                    "updated": "2019-08-30T14:08:19.912+0000",
                    "started": "2019-08-30T14:08:19.912+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304273",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304274",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319527400\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+      } else {\n+        auto out_type = to_->field(i)->type();\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, out_type, 0, &missing_columns_[i]));\n \n Review comment:\n   What happened to `scalars_` ?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:08:19.916+0000",
                    "updated": "2019-08-30T14:08:19.916+0000",
                    "started": "2019-08-30T14:08:19.915+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304274",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304275",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319526737\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n \n Review comment:\n   I'd refactor the Project classes to only takes the \"computed\" permutation and move the Init function in a factory, e.g. static RecordBatchProject::Make.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:08:20.355+0000",
                    "updated": "2019-08-30T14:08:20.355+0000",
                    "started": "2019-08-30T14:08:20.354+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304275",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304276",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319526737\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n \n Review comment:\n   I'd refactor the Project classes to only takes the \"computed\" permutation and move the Init function in a factory, e.g. `static RecordBatchProject::Make`.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:08:55.665+0000",
                    "updated": "2019-08-30T14:08:55.665+0000",
                    "started": "2019-08-30T14:08:55.665+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304276",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304277",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319529403\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n \n Review comment:\n   will do\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:09:10.890+0000",
                    "updated": "2019-08-30T14:09:10.890+0000",
                    "started": "2019-08-30T14:09:10.889+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304277",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304279",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319529835\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+      } else {\n+        auto out_type = to_->field(i)->type();\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, out_type, 0, &missing_columns_[i]));\n \n Review comment:\n   This is zero length for now; it's just a placeholder\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:10:10.895+0000",
                    "updated": "2019-08-30T14:10:10.895+0000",
                    "started": "2019-08-30T14:10:10.894+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304279",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304280",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319530352\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+      } else {\n+        auto out_type = to_->field(i)->type();\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, out_type, 0, &missing_columns_[i]));\n \n Review comment:\n   I'll add a comment\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:11:17.477+0000",
                    "updated": "2019-08-30T14:11:17.477+0000",
                    "started": "2019-08-30T14:11:17.476+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304280",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304287",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319535663\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+      } else {\n+        auto out_type = to_->field(i)->type();\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, out_type, 0, &missing_columns_[i]));\n+      }\n+\n+      column_indices_[i] = matching_index;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Project(const RecordBatch& batch, std::shared_ptr<RecordBatch>* out) {\n+    std::vector<std::shared_ptr<Array>> columns(to_->num_fields());\n+\n+    if (missing_columns_length_ < batch.num_rows()) {\n+      RETURN_NOT_OK(ResizeMissingColumns(batch.num_rows()));\n+    }\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      int matching_index = column_indices_[i];\n+      if (matching_index != kNoMatch) {\n+        columns[i] = batch.column(matching_index);\n+        continue;\n+      }\n+\n+      columns[i] = missing_columns_[i]->Slice(0, batch.num_rows());\n+    }\n+\n+    *out = RecordBatch::Make(to_, batch.num_rows(), std::move(columns));\n+    return Status::OK();\n+  }\n+\n+  const std::shared_ptr<Schema>& from() const { return from_; }\n+\n+  const std::shared_ptr<Schema>& to() const { return to_; }\n+\n+ private:\n+  static constexpr int kNoMatch = -1;\n+\n+  Status ResizeMissingColumns(int64_t new_length) {\n+    // TODO(bkietz) MakeArrayOfNull could use fewer buffers by reusing a single zeroed\n+    // buffer for every buffer in every column which is null\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      if (missing_columns_[i] == nullptr) {\n+        continue;\n+      }\n+      if (scalars_[i] == nullptr) {\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, missing_columns_[i]->type(), new_length,\n+                                      &missing_columns_[i]));\n+        continue;\n+      }\n+      RETURN_NOT_OK(\n+          MakeArrayFromScalar(pool_, *scalars_[i], new_length, &missing_columns_[i]));\n+    }\n+    missing_columns_length_ = new_length;\n+    return Status::OK();\n+  }\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<Schema> from_, to_;\n+  int64_t missing_columns_length_ = 0;\n+  std::vector<std::shared_ptr<Array>> missing_columns_;\n+  std::vector<int> column_indices_;\n+  std::vector<std::shared_ptr<Scalar>> scalars_;\n+};\n+\n+constexpr int RecordBatchProjector::kNoMatch;\n+\n+class ProjectedRecordBatchReader : public RecordBatchReader {\n+ public:\n+  ProjectedRecordBatchReader(MemoryPool* pool, std::shared_ptr<Schema> schema,\n+                             std::vector<std::shared_ptr<Scalar>> scalars,\n+                             std::unique_ptr<RecordBatchIterator> wrapped)\n+      : pool_(pool),\n+        schema_(std::move(schema)),\n+        wrapped_(std::move(wrapped)),\n+        scalars_(std::move(scalars)) {}\n+\n+  static Status Make(MemoryPool* pool, std::shared_ptr<Schema> from_schema,\n+                     std::shared_ptr<Schema> to_schema,\n+                     std::unique_ptr<RecordBatchIterator> wrapped,\n+                     std::unique_ptr<RecordBatchIterator>* out) {\n+    return Make(pool, std::move(from_schema), std::move(to_schema),\n+                std::vector<std::shared_ptr<Scalar>>(to_schema->num_fields(), nullptr),\n+                std::move(wrapped), out);\n+  }\n+\n+  static Status Make(MemoryPool* pool, std::shared_ptr<Schema> from_schema,\n+                     std::shared_ptr<Schema> to_schema,\n+                     std::vector<std::shared_ptr<Scalar>> scalars,\n+                     std::unique_ptr<RecordBatchIterator> wrapped,\n+                     std::unique_ptr<RecordBatchIterator>* out) {\n+    auto it = internal::make_unique<ProjectedRecordBatchReader>(\n+        pool, std::move(to_schema), std::move(scalars), std::move(wrapped));\n+    RETURN_NOT_OK(it->ResetProjector(std::move(from_schema)));\n+    *out = std::move(it);\n+    return Status::OK();\n+  }\n+\n+  Status ReadNext(std::shared_ptr<RecordBatch>* out) override {\n+    std::shared_ptr<RecordBatch> rb;\n+    RETURN_NOT_OK(wrapped_->Next(&rb));\n+    if (rb == nullptr) {\n+      *out = nullptr;\n+      return Status::OK();\n+    }\n+\n+    if (!projector_->from()->Equals(*rb->schema())) {\n+      projector_.reset(new RecordBatchProjector(pool_, rb->schema(), schema_));\n \n Review comment:\n   It should call ResetProjector\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:23:19.927+0000",
                    "updated": "2019-08-30T14:23:19.927+0000",
                    "started": "2019-08-30T14:23:19.926+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304287",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304288",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319536130\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,207 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Columns will be reordered to match the given schema.\n+///\n+/// Columns present in the given schema but absent from a record batch will be added as\n+/// null or as arrays of a constant value.\n+class RecordBatchProjector {\n+ public:\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> from,\n+                       std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        from_(std::move(from)),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Init() {\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+      } else {\n+        auto out_type = to_->field(i)->type();\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, out_type, 0, &missing_columns_[i]));\n+      }\n+\n+      column_indices_[i] = matching_index;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Project(const RecordBatch& batch, std::shared_ptr<RecordBatch>* out) {\n+    std::vector<std::shared_ptr<Array>> columns(to_->num_fields());\n+\n+    if (missing_columns_length_ < batch.num_rows()) {\n+      RETURN_NOT_OK(ResizeMissingColumns(batch.num_rows()));\n+    }\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      int matching_index = column_indices_[i];\n+      if (matching_index != kNoMatch) {\n+        columns[i] = batch.column(matching_index);\n+        continue;\n+      }\n+\n+      columns[i] = missing_columns_[i]->Slice(0, batch.num_rows());\n+    }\n+\n+    *out = RecordBatch::Make(to_, batch.num_rows(), std::move(columns));\n+    return Status::OK();\n+  }\n+\n+  const std::shared_ptr<Schema>& from() const { return from_; }\n+\n+  const std::shared_ptr<Schema>& to() const { return to_; }\n+\n+ private:\n+  static constexpr int kNoMatch = -1;\n+\n+  Status ResizeMissingColumns(int64_t new_length) {\n+    // TODO(bkietz) MakeArrayOfNull could use fewer buffers by reusing a single zeroed\n+    // buffer for every buffer in every column which is null\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      if (missing_columns_[i] == nullptr) {\n+        continue;\n+      }\n+      if (scalars_[i] == nullptr) {\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, missing_columns_[i]->type(), new_length,\n+                                      &missing_columns_[i]));\n+        continue;\n+      }\n+      RETURN_NOT_OK(\n+          MakeArrayFromScalar(pool_, *scalars_[i], new_length, &missing_columns_[i]));\n+    }\n+    missing_columns_length_ = new_length;\n+    return Status::OK();\n+  }\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<Schema> from_, to_;\n+  int64_t missing_columns_length_ = 0;\n+  std::vector<std::shared_ptr<Array>> missing_columns_;\n+  std::vector<int> column_indices_;\n+  std::vector<std::shared_ptr<Scalar>> scalars_;\n+};\n+\n+constexpr int RecordBatchProjector::kNoMatch;\n+\n+class ProjectedRecordBatchReader : public RecordBatchReader {\n \n Review comment:\n   Add a comment that the Projector is dynamic in the sense that it adapts to the next record batch schema.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T14:24:09.361+0000",
                    "updated": "2019-08-30T14:24:09.361+0000",
                    "started": "2019-08-30T14:24:09.360+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304288",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304461",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319619254\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,197 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Projected record batches will reorder columns from input record batches when possible,\n+/// otherwise the given schema will be satisfied by augmenting with null or constant\n+/// columns.\n+///\n+/// RecordBatchProjector is most efficient when projecting record batches with a\n+/// consistent schema (for example batches from a table), but it can project record\n+/// batches having any schema.\n+class RecordBatchProjector {\n+ public:\n+  /// A column required by the given schema but absent from a record batch will be added\n+  /// to the projected record batch with all its slots null.\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  /// A column required by the given schema but absent from a record batch will be added\n+  /// to the projected record batch with all its slots equal to the corresponding entry in\n+  /// scalars or null if the correspondign entry in scalars is nullptr.\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Project(const RecordBatch& batch, std::shared_ptr<RecordBatch>* out) {\n+    if (from_ == nullptr || !batch.schema()->Equals(*from_)) {\n+      RETURN_NOT_OK(SetInputSchema(batch.schema()));\n+    }\n+\n+    if (missing_columns_length_ < batch.num_rows()) {\n+      RETURN_NOT_OK(ResizeMissingColumns(batch.num_rows()));\n+    }\n+\n+    std::vector<std::shared_ptr<Array>> columns(to_->num_fields());\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      int matching_index = column_indices_[i];\n+      if (matching_index != kNoMatch) {\n+        columns[i] = batch.column(matching_index);\n+        continue;\n+      }\n+\n+      columns[i] = missing_columns_[i]->Slice(0, batch.num_rows());\n+    }\n+\n+    *out = RecordBatch::Make(to_, batch.num_rows(), std::move(columns));\n+    return Status::OK();\n+  }\n+\n+  const std::shared_ptr<Schema>& schema() const { return to_; }\n+\n+  Status SetInputSchema(std::shared_ptr<Schema> from) {\n+    from_ = std::move(from);\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+\n+        // Mark column i as not missing by setting missing_columns_[i] to nullptr\n+        missing_columns_[i] = nullptr;\n+      } else {\n+        // Mark column i as missing by setting missing_columns_[i]\n+        // to a non-null placeholder.\n+        RETURN_NOT_OK(\n+            MakeArrayOfNull(pool_, to_->field(i)->type(), 0, &missing_columns_[i]));\n+      }\n+\n+      column_indices_[i] = matching_index;\n+    }\n+    return Status::OK();\n+  }\n+\n+ private:\n+  static constexpr int kNoMatch = -1;\n+\n+  Status ResizeMissingColumns(int64_t new_length) {\n+    // TODO(bkietz) MakeArrayOfNull could use fewer buffers by reusing a single zeroed\n+    // buffer for every buffer in every column which is null\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      if (missing_columns_[i] == nullptr) {\n+        continue;\n+      }\n+      if (scalars_[i] == nullptr) {\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, missing_columns_[i]->type(), new_length,\n+                                      &missing_columns_[i]));\n+        continue;\n+      }\n+      RETURN_NOT_OK(\n+          MakeArrayFromScalar(pool_, *scalars_[i], new_length, &missing_columns_[i]));\n+    }\n+    missing_columns_length_ = new_length;\n+    return Status::OK();\n+  }\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<Schema> from_, to_;\n+  int64_t missing_columns_length_ = 0;\n+  std::vector<std::shared_ptr<Array>> missing_columns_;\n+  std::vector<int> column_indices_;\n+  std::vector<std::shared_ptr<Scalar>> scalars_;\n+};\n+\n+constexpr int RecordBatchProjector::kNoMatch;\n+\n+/// Wraps a RecordBatchIterator and projects each yielded batch using the given projector.\n+///\n+/// Note that as with RecordBatchProjector, ProjectedRecordBatchReader is most efficient\n+/// when projecting record batches with a consistent schema (for example batches from a\n+/// table), but it can project record batches having any schema.\n+class ProjectedRecordBatchReader : public RecordBatchReader {\n+ public:\n+  static Status Make(MemoryPool* pool, std::unique_ptr<RecordBatchProjector> projector,\n+                     std::unique_ptr<RecordBatchIterator> wrapped,\n+                     std::unique_ptr<RecordBatchIterator>* out) {\n+    out->reset(\n+        new ProjectedRecordBatchReader(pool, std::move(projector), std::move(wrapped)));\n+    return Status::OK();\n+  }\n+\n+  Status ReadNext(std::shared_ptr<RecordBatch>* out) override {\n \n Review comment:\n   In ARROW-6242, there's `MaybeMapIterator` which you could just wrap the call to `projector->Project` into a lambda.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T17:59:19.641+0000",
                    "updated": "2019-08-30T17:59:19.641+0000",
                    "started": "2019-08-30T17:59:19.640+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304461",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304468",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319620169\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_test.cc\n ##########\n @@ -58,5 +59,54 @@ TEST_F(TestSimpleDataSource, GetFragments) {\n   AssertDataSourceEquals(reader.get(), &source);\n }\n \n+TEST(TestProjector, AugmentWithNull) {\n+  constexpr int64_t kBatchSize = 1024;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema);\n+\n+  std::shared_ptr<Array> null_i32;\n+  ASSERT_OK(MakeArrayOfNull(int32(), batch->num_rows(), &null_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {null_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n+TEST(TestProjector, AugmentWithScalar) {\n \n Review comment:\n   Can you add tests for notable failures, e.g. type mismatch.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:01:57.459+0000",
                    "updated": "2019-08-30T18:01:57.459+0000",
                    "started": "2019-08-30T18:01:57.458+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304468",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304471",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319620366\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_test.cc\n ##########\n @@ -58,5 +59,54 @@ TEST_F(TestSimpleDataSource, GetFragments) {\n   AssertDataSourceEquals(reader.get(), &source);\n }\n \n+TEST(TestProjector, AugmentWithNull) {\n+  constexpr int64_t kBatchSize = 1024;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema);\n+\n+  std::shared_ptr<Array> null_i32;\n+  ASSERT_OK(MakeArrayOfNull(int32(), batch->num_rows(), &null_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {null_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n+TEST(TestProjector, AugmentWithScalar) {\n+  constexpr int64_t kBatchSize = 1024;\n+  constexpr int64_t kScalarValue = 3;\n \n Review comment:\n   int32_t\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:02:25.132+0000",
                    "updated": "2019-08-30T18:02:25.132+0000",
                    "started": "2019-08-30T18:02:25.132+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304471",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304473",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319620840\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_test.cc\n ##########\n @@ -58,5 +59,54 @@ TEST_F(TestSimpleDataSource, GetFragments) {\n   AssertDataSourceEquals(reader.get(), &source);\n }\n \n+TEST(TestProjector, AugmentWithNull) {\n+  constexpr int64_t kBatchSize = 1024;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema);\n+\n+  std::shared_ptr<Array> null_i32;\n+  ASSERT_OK(MakeArrayOfNull(int32(), batch->num_rows(), &null_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {null_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n+TEST(TestProjector, AugmentWithScalar) {\n+  constexpr int64_t kBatchSize = 1024;\n+  constexpr int64_t kScalarValue = 3;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n \n Review comment:\n   I'd use `schema({field(\"f64\", float64()), field(\"b\", bool())});` so you also test re-ordering and dropping a column.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:03:47.886+0000",
                    "updated": "2019-08-30T18:03:47.886+0000",
                    "started": "2019-08-30T18:03:47.886+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304473",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304474",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319620840\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_test.cc\n ##########\n @@ -58,5 +59,54 @@ TEST_F(TestSimpleDataSource, GetFragments) {\n   AssertDataSourceEquals(reader.get(), &source);\n }\n \n+TEST(TestProjector, AugmentWithNull) {\n+  constexpr int64_t kBatchSize = 1024;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema);\n+\n+  std::shared_ptr<Array> null_i32;\n+  ASSERT_OK(MakeArrayOfNull(int32(), batch->num_rows(), &null_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {null_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n+TEST(TestProjector, AugmentWithScalar) {\n+  constexpr int64_t kBatchSize = 1024;\n+  constexpr int64_t kScalarValue = 3;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n \n Review comment:\n   I'd use `schema({field(\"f64\", float64()), field(\"b\", bool())});` so you also test re-ordering and dropping a column.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:04:14.407+0000",
                    "updated": "2019-08-30T18:04:14.407+0000",
                    "started": "2019-08-30T18:04:14.406+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304474",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304475",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319621353\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_test.cc\n ##########\n @@ -58,5 +59,54 @@ TEST_F(TestSimpleDataSource, GetFragments) {\n   AssertDataSourceEquals(reader.get(), &source);\n }\n \n+TEST(TestProjector, AugmentWithNull) {\n+  constexpr int64_t kBatchSize = 1024;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema);\n+\n+  std::shared_ptr<Array> null_i32;\n+  ASSERT_OK(MakeArrayOfNull(int32(), batch->num_rows(), &null_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {null_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n+TEST(TestProjector, AugmentWithScalar) {\n+  constexpr int64_t kBatchSize = 1024;\n+  constexpr int64_t kScalarValue = 3;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  auto scalar_i32 = std::make_shared<Int32Scalar>(kScalarValue);\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema, {scalar_i32, nullptr});\n+\n+  std::shared_ptr<Array> array_i32;\n+  Int32Builder builder;\n+  ASSERT_OK(builder.AppendValues(std::vector<int32_t>(kBatchSize, kScalarValue)));\n+  ASSERT_OK(builder.Finish(&array_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {array_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n \n Review comment:\n   I'd add a third test with a lot of re-ordering and subsetting + extra null + extra scalar, e.g:\r\n   ```\r\n   from = {i8, u8, i16, u16, i32, u32}\r\n   to = {u32, u16, u8, bool (null), float64(pi)}\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:05:17.836+0000",
                    "updated": "2019-08-30T18:05:17.836+0000",
                    "started": "2019-08-30T18:05:17.836+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304475",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304476",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319621353\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_test.cc\n ##########\n @@ -58,5 +59,54 @@ TEST_F(TestSimpleDataSource, GetFragments) {\n   AssertDataSourceEquals(reader.get(), &source);\n }\n \n+TEST(TestProjector, AugmentWithNull) {\n+  constexpr int64_t kBatchSize = 1024;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema);\n+\n+  std::shared_ptr<Array> null_i32;\n+  ASSERT_OK(MakeArrayOfNull(int32(), batch->num_rows(), &null_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {null_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n+TEST(TestProjector, AugmentWithScalar) {\n+  constexpr int64_t kBatchSize = 1024;\n+  constexpr int64_t kScalarValue = 3;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  auto scalar_i32 = std::make_shared<Int32Scalar>(kScalarValue);\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema, {scalar_i32, nullptr});\n+\n+  std::shared_ptr<Array> array_i32;\n+  Int32Builder builder;\n+  ASSERT_OK(builder.AppendValues(std::vector<int32_t>(kBatchSize, kScalarValue)));\n+  ASSERT_OK(builder.Finish(&array_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {array_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n \n Review comment:\n   I'd add a third test with a lot of re-ordering and sub-selection + extra null + extra scalar, e.g:\r\n   ```\r\n   from = {i8, u8, i16, u16, i32, u32}\r\n   to = {u32, u16, u8, bool (null), float64(pi)}\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:05:27.676+0000",
                    "updated": "2019-08-30T18:05:27.676+0000",
                    "started": "2019-08-30T18:05:27.675+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304476",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304479",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319621985\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,197 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Projected record batches will reorder columns from input record batches when possible,\n+/// otherwise the given schema will be satisfied by augmenting with null or constant\n+/// columns.\n+///\n+/// RecordBatchProjector is most efficient when projecting record batches with a\n+/// consistent schema (for example batches from a table), but it can project record\n+/// batches having any schema.\n+class RecordBatchProjector {\n+ public:\n+  /// A column required by the given schema but absent from a record batch will be added\n+  /// to the projected record batch with all its slots null.\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  /// A column required by the given schema but absent from a record batch will be added\n+  /// to the projected record batch with all its slots equal to the corresponding entry in\n+  /// scalars or null if the correspondign entry in scalars is nullptr.\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Project(const RecordBatch& batch, std::shared_ptr<RecordBatch>* out) {\n+    if (from_ == nullptr || !batch.schema()->Equals(*from_)) {\n+      RETURN_NOT_OK(SetInputSchema(batch.schema()));\n+    }\n+\n+    if (missing_columns_length_ < batch.num_rows()) {\n+      RETURN_NOT_OK(ResizeMissingColumns(batch.num_rows()));\n+    }\n+\n+    std::vector<std::shared_ptr<Array>> columns(to_->num_fields());\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      int matching_index = column_indices_[i];\n+      if (matching_index != kNoMatch) {\n+        columns[i] = batch.column(matching_index);\n+        continue;\n+      }\n+\n+      columns[i] = missing_columns_[i]->Slice(0, batch.num_rows());\n+    }\n+\n+    *out = RecordBatch::Make(to_, batch.num_rows(), std::move(columns));\n+    return Status::OK();\n+  }\n+\n+  const std::shared_ptr<Schema>& schema() const { return to_; }\n+\n+  Status SetInputSchema(std::shared_ptr<Schema> from) {\n+    from_ = std::move(from);\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+\n+        // Mark column i as not missing by setting missing_columns_[i] to nullptr\n+        missing_columns_[i] = nullptr;\n+      } else {\n+        // Mark column i as missing by setting missing_columns_[i]\n+        // to a non-null placeholder.\n+        RETURN_NOT_OK(\n+            MakeArrayOfNull(pool_, to_->field(i)->type(), 0, &missing_columns_[i]));\n+      }\n+\n+      column_indices_[i] = matching_index;\n+    }\n+    return Status::OK();\n+  }\n+\n+ private:\n+  static constexpr int kNoMatch = -1;\n+\n+  Status ResizeMissingColumns(int64_t new_length) {\n+    // TODO(bkietz) MakeArrayOfNull could use fewer buffers by reusing a single zeroed\n+    // buffer for every buffer in every column which is null\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      if (missing_columns_[i] == nullptr) {\n+        continue;\n+      }\n+      if (scalars_[i] == nullptr) {\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, missing_columns_[i]->type(), new_length,\n+                                      &missing_columns_[i]));\n+        continue;\n+      }\n+      RETURN_NOT_OK(\n+          MakeArrayFromScalar(pool_, *scalars_[i], new_length, &missing_columns_[i]));\n+    }\n+    missing_columns_length_ = new_length;\n+    return Status::OK();\n+  }\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<Schema> from_, to_;\n+  int64_t missing_columns_length_ = 0;\n+  std::vector<std::shared_ptr<Array>> missing_columns_;\n+  std::vector<int> column_indices_;\n+  std::vector<std::shared_ptr<Scalar>> scalars_;\n+};\n+\n+constexpr int RecordBatchProjector::kNoMatch;\n+\n+/// Wraps a RecordBatchIterator and projects each yielded batch using the given projector.\n+///\n+/// Note that as with RecordBatchProjector, ProjectedRecordBatchReader is most efficient\n+/// when projecting record batches with a consistent schema (for example batches from a\n+/// table), but it can project record batches having any schema.\n+class ProjectedRecordBatchReader : public RecordBatchReader {\n+ public:\n+  static Status Make(MemoryPool* pool, std::unique_ptr<RecordBatchProjector> projector,\n+                     std::unique_ptr<RecordBatchIterator> wrapped,\n+                     std::unique_ptr<RecordBatchIterator>* out) {\n+    out->reset(\n+        new ProjectedRecordBatchReader(pool, std::move(projector), std::move(wrapped)));\n+    return Status::OK();\n+  }\n+\n+  Status ReadNext(std::shared_ptr<RecordBatch>* out) override {\n \n Review comment:\n   That sounds fine; I'll remove this ProjectedRecordBatchReader then\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:07:15.134+0000",
                    "updated": "2019-08-30T18:07:15.134+0000",
                    "started": "2019-08-30T18:07:15.134+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304479",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304481",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319622130\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_test.cc\n ##########\n @@ -58,5 +59,54 @@ TEST_F(TestSimpleDataSource, GetFragments) {\n   AssertDataSourceEquals(reader.get(), &source);\n }\n \n+TEST(TestProjector, AugmentWithNull) {\n+  constexpr int64_t kBatchSize = 1024;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema);\n+\n+  std::shared_ptr<Array> null_i32;\n+  ASSERT_OK(MakeArrayOfNull(int32(), batch->num_rows(), &null_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {null_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n+TEST(TestProjector, AugmentWithScalar) {\n \n Review comment:\n   will do\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:07:40.100+0000",
                    "updated": "2019-08-30T18:07:40.100+0000",
                    "started": "2019-08-30T18:07:40.100+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304481",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304482",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319622394\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_internal.h\n ##########\n @@ -0,0 +1,197 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/dataset/type_fwd.h\"\n+#include \"arrow/dataset/visibility.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/iterator.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/stl.h\"\n+\n+namespace arrow {\n+namespace dataset {\n+\n+/// \\brief Project a RecordBatch to a given schema.\n+///\n+/// Projected record batches will reorder columns from input record batches when possible,\n+/// otherwise the given schema will be satisfied by augmenting with null or constant\n+/// columns.\n+///\n+/// RecordBatchProjector is most efficient when projecting record batches with a\n+/// consistent schema (for example batches from a table), but it can project record\n+/// batches having any schema.\n+class RecordBatchProjector {\n+ public:\n+  /// A column required by the given schema but absent from a record batch will be added\n+  /// to the projected record batch with all its slots null.\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> to)\n+      : pool_(pool),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(to_->num_fields(), nullptr) {}\n+\n+  /// A column required by the given schema but absent from a record batch will be added\n+  /// to the projected record batch with all its slots equal to the corresponding entry in\n+  /// scalars or null if the correspondign entry in scalars is nullptr.\n+  RecordBatchProjector(MemoryPool* pool, std::shared_ptr<Schema> to,\n+                       std::vector<std::shared_ptr<Scalar>> scalars)\n+      : pool_(pool),\n+        to_(std::move(to)),\n+        missing_columns_(to_->num_fields(), nullptr),\n+        column_indices_(to_->num_fields(), kNoMatch),\n+        scalars_(std::move(scalars)) {\n+    DCHECK_EQ(scalars_.size(), missing_columns_.size());\n+  }\n+\n+  Status Project(const RecordBatch& batch, std::shared_ptr<RecordBatch>* out) {\n+    if (from_ == nullptr || !batch.schema()->Equals(*from_)) {\n+      RETURN_NOT_OK(SetInputSchema(batch.schema()));\n+    }\n+\n+    if (missing_columns_length_ < batch.num_rows()) {\n+      RETURN_NOT_OK(ResizeMissingColumns(batch.num_rows()));\n+    }\n+\n+    std::vector<std::shared_ptr<Array>> columns(to_->num_fields());\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      int matching_index = column_indices_[i];\n+      if (matching_index != kNoMatch) {\n+        columns[i] = batch.column(matching_index);\n+        continue;\n+      }\n+\n+      columns[i] = missing_columns_[i]->Slice(0, batch.num_rows());\n+    }\n+\n+    *out = RecordBatch::Make(to_, batch.num_rows(), std::move(columns));\n+    return Status::OK();\n+  }\n+\n+  const std::shared_ptr<Schema>& schema() const { return to_; }\n+\n+  Status SetInputSchema(std::shared_ptr<Schema> from) {\n+    from_ = std::move(from);\n+\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      const auto& field = to_->field(i);\n+      int matching_index = from_->GetFieldIndex(field->name());\n+\n+      if (matching_index != kNoMatch) {\n+        if (!from_->field(matching_index)->Equals(field)) {\n+          return Status::Invalid(\"fields had matching names but were not equivalent \",\n+                                 from_->field(matching_index)->ToString(), \" vs \",\n+                                 field->ToString());\n+        }\n+\n+        // Mark column i as not missing by setting missing_columns_[i] to nullptr\n+        missing_columns_[i] = nullptr;\n+      } else {\n+        // Mark column i as missing by setting missing_columns_[i]\n+        // to a non-null placeholder.\n+        RETURN_NOT_OK(\n+            MakeArrayOfNull(pool_, to_->field(i)->type(), 0, &missing_columns_[i]));\n+      }\n+\n+      column_indices_[i] = matching_index;\n+    }\n+    return Status::OK();\n+  }\n+\n+ private:\n+  static constexpr int kNoMatch = -1;\n+\n+  Status ResizeMissingColumns(int64_t new_length) {\n+    // TODO(bkietz) MakeArrayOfNull could use fewer buffers by reusing a single zeroed\n+    // buffer for every buffer in every column which is null\n+    for (int i = 0; i < to_->num_fields(); ++i) {\n+      if (missing_columns_[i] == nullptr) {\n+        continue;\n+      }\n+      if (scalars_[i] == nullptr) {\n+        RETURN_NOT_OK(MakeArrayOfNull(pool_, missing_columns_[i]->type(), new_length,\n+                                      &missing_columns_[i]));\n+        continue;\n+      }\n+      RETURN_NOT_OK(\n+          MakeArrayFromScalar(pool_, *scalars_[i], new_length, &missing_columns_[i]));\n+    }\n+    missing_columns_length_ = new_length;\n+    return Status::OK();\n+  }\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<Schema> from_, to_;\n+  int64_t missing_columns_length_ = 0;\n+  std::vector<std::shared_ptr<Array>> missing_columns_;\n+  std::vector<int> column_indices_;\n+  std::vector<std::shared_ptr<Scalar>> scalars_;\n+};\n+\n+constexpr int RecordBatchProjector::kNoMatch;\n+\n+/// Wraps a RecordBatchIterator and projects each yielded batch using the given projector.\n+///\n+/// Note that as with RecordBatchProjector, ProjectedRecordBatchReader is most efficient\n+/// when projecting record batches with a consistent schema (for example batches from a\n+/// table), but it can project record batches having any schema.\n+class ProjectedRecordBatchReader : public RecordBatchReader {\n+ public:\n+  static Status Make(MemoryPool* pool, std::unique_ptr<RecordBatchProjector> projector,\n+                     std::unique_ptr<RecordBatchIterator> wrapped,\n+                     std::unique_ptr<RecordBatchIterator>* out) {\n+    out->reset(\n+        new ProjectedRecordBatchReader(pool, std::move(projector), std::move(wrapped)));\n+    return Status::OK();\n+  }\n+\n+  Status ReadNext(std::shared_ptr<RecordBatch>* out) override {\n \n Review comment:\n   No, keep it, it's still useful, I was just adding a note that you could achieve the same with a tiny refactor (if ARROW-6242 lands).\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:08:29.988+0000",
                    "updated": "2019-08-30T18:08:29.988+0000",
                    "started": "2019-08-30T18:08:29.987+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304482",
                    "issueId": "13253271"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/worklog/304517",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #5207: ARROW-6368: [C++][Dataset] RecordBatch projection\nURL: https://github.com/apache/arrow/pull/5207#discussion_r319638127\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/dataset_test.cc\n ##########\n @@ -58,5 +59,54 @@ TEST_F(TestSimpleDataSource, GetFragments) {\n   AssertDataSourceEquals(reader.get(), &source);\n }\n \n+TEST(TestProjector, AugmentWithNull) {\n+  constexpr int64_t kBatchSize = 1024;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema);\n+\n+  std::shared_ptr<Array> null_i32;\n+  ASSERT_OK(MakeArrayOfNull(int32(), batch->num_rows(), &null_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {null_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n+TEST(TestProjector, AugmentWithScalar) {\n+  constexpr int64_t kBatchSize = 1024;\n+  constexpr int64_t kScalarValue = 3;\n+\n+  auto from_schema = schema({field(\"f64\", float64())});\n+\n+  auto batch = GetRecordBatch(kBatchSize, from_schema);\n+\n+  auto to_schema = schema({field(\"i32\", int32()), field(\"f64\", float64())});\n+\n+  auto scalar_i32 = std::make_shared<Int32Scalar>(kScalarValue);\n+\n+  RecordBatchProjector projector(default_memory_pool(), to_schema, {scalar_i32, nullptr});\n+\n+  std::shared_ptr<Array> array_i32;\n+  Int32Builder builder;\n+  ASSERT_OK(builder.AppendValues(std::vector<int32_t>(kBatchSize, kScalarValue)));\n+  ASSERT_OK(builder.Finish(&array_i32));\n+  auto expected_batch =\n+      RecordBatch::Make(to_schema, batch->num_rows(), {array_i32, batch->column(0)});\n+\n+  std::shared_ptr<RecordBatch> reconciled_batch;\n+  ASSERT_OK(projector.Project(*batch, &reconciled_batch));\n+\n+  AssertBatchesEqual(*expected_batch, *reconciled_batch);\n+}\n+\n \n Review comment:\n   Done\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-08-30T18:53:37.595+0000",
                    "updated": "2019-08-30T18:53:37.595+0000",
                    "started": "2019-08-30T18:53:37.593+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "304517",
                    "issueId": "13253271"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 20400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@679fdca0[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4caae698[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2469cafe[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@3f6c66cd[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@308a3166[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@5eb79737[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@34639825[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@6865da6a[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@985c701[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@6b69e729[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4363e8d1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@513dc5d[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 20400,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Sep 09 12:39:58 UTC 2019",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2019-09-09T12:39:58.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-6368/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2019-08-27T14:26:43.000+0000",
        "updated": "2019-09-09T12:47:40.000+0000",
        "timeoriginalestimate": null,
        "description": "define classes RecordBatchProjector (which projects from one schema to another, augmenting with null/constant columns where necessary) and a subtype of RecordBatchIterator which projects each batch yielded by a wrapped iterator.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "5h 40m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 20400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Add RecordBatch projection functionality",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/comment/16916790",
                    "id": "16916790",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "You might consider making this general enough to handle type alterations or other operations, too. This could be addressed later also",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-08-27T15:08:21.751+0000",
                    "updated": "2019-08-27T15:08:21.751+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/comment/16916880",
                    "id": "16916880",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "If the operation is potentially expensive then we might want to avoid hiding it in the projector; in the case of augmenting as described above the columns to augment can be generated once then reused for each yielded batch.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-08-27T16:54:28.704+0000",
                    "updated": "2019-08-27T16:54:28.704+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13253271/comment/16925648",
                    "id": "16925648",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=fsaintjacques",
                        "name": "fsaintjacques",
                        "key": "fsaintjacques",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=fsaintjacques&avatarId=37276",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fsaintjacques&avatarId=37276",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fsaintjacques&avatarId=37276",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fsaintjacques&avatarId=37276"
                        },
                        "displayName": "Francois Saint-Jacques",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 5207\n[https://github.com/apache/arrow/pull/5207]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=fsaintjacques",
                        "name": "fsaintjacques",
                        "key": "fsaintjacques",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=fsaintjacques&avatarId=37276",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fsaintjacques&avatarId=37276",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fsaintjacques&avatarId=37276",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fsaintjacques&avatarId=37276"
                        },
                        "displayName": "Francois Saint-Jacques",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-09-09T12:39:58.517+0000",
                    "updated": "2019-09-09T12:39:58.517+0000"
                }
            ],
            "maxResults": 3,
            "total": 3,
            "startAt": 0
        },
        "customfield_12311820": "0|z062zc:",
        "customfield_12314139": null
    }
}