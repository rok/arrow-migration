{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13187264",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264",
    "key": "ARROW-3769",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343937",
                "id": "12343937",
                "description": "",
                "name": "0.13.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-04-01"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "parquet",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12552634",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12552634",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13211734",
                    "key": "PARQUET-1508",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13211734",
                    "fields": {
                        "summary": "[C++] Enable reading from ByteArray and FixedLenByteArray decoders directly into arrow::BinaryBuilder or arrow::BinaryDictionaryBuilder",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12543948",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12543948",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "inwardIssue": {
                    "id": "13187263",
                    "key": "ARROW-3325",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187263",
                    "fields": {
                        "summary": "[Python] Support reading Parquet binary/string columns directly as DictionaryArray",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=hatem",
            "name": "hatem",
            "key": "hatem",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
            },
            "displayName": "Hatem Helal",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 51000,
            "total": 51000,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 51000,
            "total": 51000,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3769/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 89,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/201502",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "hatemhelal commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721\n \n \n   Much of this is adding unittests and some benchmarks for the different overloaded methods `DecodeArrow` and `DecodeArrowNonNull`.   Here's the benchmark output from a release build on my mac:\r\n   \r\n   ```\r\n   ./release/parquet-encoding-benchmark --benchmark_filter=PlainDecodingByteArray\r\n   2019-02-19 14:06:40\r\n   Running ./release/parquet-encoding-benchmark\r\n   Run on (8 X 4000 MHz CPU s)\r\n   CPU Caches:\r\n     L1 Data 32K (x4)\r\n     L1 Instruction 32K (x4)\r\n     L2 Unified 262K (x4)\r\n     L3 Unified 8388K (x1)\r\n   ------------------------------------------------------------------------------------------------\r\n   Benchmark                                                         Time           CPU Iterations\r\n   ------------------------------------------------------------------------------------------------\r\n   BM_PlainDecodingByteArray/DecodeArrow_Dense/1024              23333 ns      23319 ns      29933   226.245MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrow_Dense/4096              97339 ns      97272 ns       7165   240.839MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrow_Dense/32768            774543 ns     774048 ns        892    244.32MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrow_Dense/65536           1553857 ns    1552977 ns        439   242.106MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrowNonNull_Dense/1024       22625 ns      22609 ns      30943   233.349MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrowNonNull_Dense/4096       91492 ns      91439 ns       7626   256.204MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrowNonNull_Dense/32768     734536 ns     734100 ns        927   257.615MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrowNonNull_Dense/65536    1468381 ns    1467237 ns        473   256.254MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrow_Dict/1024               25549 ns      25530 ns      27393    206.65MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrow_Dict/4096              115236 ns     115188 ns       6025   203.381MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrow_Dict/32768             991877 ns     991074 ns        699   190.819MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrow_Dict/65536            1987453 ns    1986290 ns        352    189.29MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrowNonNull_Dict/1024        24533 ns      24517 ns      28609   215.186MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrowNonNull_Dict/4096       110519 ns     110442 ns       6264   212.121MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrowNonNull_Dict/32768      949170 ns     948729 ns        730   199.336MB/s\r\n   BM_PlainDecodingByteArray/DecodeArrowNonNull_Dict/65536     1929999 ns    1928779 ns        366   194.934MB/s\r\n   ```\r\n   \r\n   Some next things to do:\r\n   \r\n   * Add benchmarks for dictionary decoding\r\n   * Add overloads for StringDictionaryBuilder (not sure about this one)\r\n   * Get to work on the related issues outlined by @wesm on [this thread](https://lists.apache.org/thread.html/73129e9eaf343a4662f127f6e0fc7b37a229ff98777a4209fb932ca9@%3Cdev.arrow.apache.org%3E)\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-20T18:20:32.006+0000",
                    "updated": "2019-02-20T18:20:32.006+0000",
                    "started": "2019-02-20T18:20:32.006+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "201502",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202293",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259170479\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n+                                                             size_t num_values) {\n+  const int64_t min_length = 2;\n+  const int64_t max_length = 10;\n+  std::vector<uint8_t> buffer(max_length);\n+  std::vector<std::string> dictionary(num_unique);\n+\n+  uint32_t seed = 0;\n+  std::default_random_engine gen(seed);\n+  std::uniform_int_distribution<int64_t> length_dist(min_length, max_length);\n+\n+  std::generate(dictionary.begin(), dictionary.end(), [&] {\n+    auto length = length_dist(gen);\n+    ::arrow::random_ascii(length, seed++, buffer.data());\n+    return std::string(buffer.begin(), buffer.begin() + length);\n+  });\n+\n+  std::uniform_int_distribution<int64_t> indices_dist(0, num_unique - 1);\n+  ::arrow::StringBuilder builder;\n+\n+  for (size_t i = 0; i < num_values; i++) {\n+    const auto index = indices_dist(gen);\n+    const auto value = dictionary[index];\n+    ABORT_NOT_OK(builder.Append(value));\n+  }\n+\n+  std::shared_ptr<::arrow::Array> result;\n+  ABORT_NOT_OK(builder.Finish(&result));\n+  return result;\n+}\n+\n+class BM_PlainDecodingByteArray : public ::benchmark::Fixture {\n+ public:\n+  void SetUp(const ::benchmark::State& state) override {\n+    num_values_ = static_cast<int>(state.range());\n+\n+    input_array_ = MakeRandomStringsWithRepeats(num_values_ / 8, num_values_);\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*input_array_);\n+    values_ = std::vector<ByteArray>();\n+    values_.reserve(num_values_);\n+    total_size_ = 0;\n+\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n+      auto view = binary_array.GetView(i);\n+      values_.emplace_back(static_cast<uint32_t>(view.length()),\n+                           reinterpret_cast<const uint8_t*>(view.data()));\n+      total_size_ += view.length();\n+    }\n+\n+    valid_bits_ =\n+        std::vector<uint8_t>(::arrow::BitUtil::BytesForBits(num_values_) + 1, 255);\n+\n+    auto encoder = MakeTypedEncoder<ByteArrayType>(Encoding::PLAIN);\n+    encoder->Put(values_.data(), num_values_);\n+    buffer_ = encoder->FlushValues();\n+  }\n+\n+  void TearDown(const ::benchmark::State& state) override {}\n+\n+ protected:\n+  int num_values_;\n+  std::shared_ptr<::arrow::Array> input_array_;\n+  uint64_t total_size_;\n+  std::vector<ByteArray> values_;\n+  std::vector<uint8_t> valid_bits_;\n+  std::shared_ptr<Buffer> buffer_;\n+};\n+\n+BENCHMARK_DEFINE_F(BM_PlainDecodingByteArray, DecodeArrow_Dense)\n+(benchmark::State& state) {\n+  while (state.KeepRunning()) {\n+    auto decoder = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN);\n+    decoder->SetData(num_values_, buffer_->data(), static_cast<int>(buffer_->size()));\n+    ::arrow::internal::ChunkedBinaryBuilder builder(static_cast<int>(buffer_->size()),\n+                                                    ::arrow::default_memory_pool());\n+    decoder->DecodeArrow(num_values_, 0, valid_bits_.data(), 0, &builder);\n+  }\n+\n+  state.SetBytesProcessed(state.iterations() * total_size_);\n+}\n+\n+BENCHMARK_REGISTER_F(BM_PlainDecodingByteArray, DecodeArrow_Dense)->Range(1024, 65536);\n+\n+BENCHMARK_DEFINE_F(BM_PlainDecodingByteArray, DecodeArrowNonNull_Dense)\n+(benchmark::State& state) {\n+  while (state.KeepRunning()) {\n+    auto decoder = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN);\n+    decoder->SetData(num_values_, buffer_->data(), static_cast<int>(buffer_->size()));\n+    ::arrow::internal::ChunkedBinaryBuilder builder(static_cast<int>(buffer_->size()),\n+                                                    ::arrow::default_memory_pool());\n+    decoder->DecodeArrowNonNull(num_values_, &builder);\n+  }\n+\n+  state.SetBytesProcessed(state.iterations() * total_size_);\n+}\n+\n+BENCHMARK_REGISTER_F(BM_PlainDecodingByteArray, DecodeArrowNonNull_Dense)\n+    ->Range(1024, 65536);\n+\n+BENCHMARK_DEFINE_F(BM_PlainDecodingByteArray, DecodeArrow_Dict)\n+(benchmark::State& state) {\n+  while (state.KeepRunning()) {\n+    auto decoder = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN);\n+    decoder->SetData(num_values_, buffer_->data(), static_cast<int>(buffer_->size()));\n+    ::arrow::BinaryDictionaryBuilder builder(::arrow::default_memory_pool());\n+    decoder->DecodeArrow(num_values_, 0, valid_bits_.data(), 0, &builder);\n+  }\n+\n+  state.SetBytesProcessed(state.iterations() * total_size_);\n+}\n+\n+BENCHMARK_REGISTER_F(BM_PlainDecodingByteArray, DecodeArrow_Dict)->Range(1024, 65536);\n \n Review comment:\n   Consider utilizing named constants for the Range values to increase readability here. Same comment for all other similar invocations of Range in this diff.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T00:17:14.733+0000",
                    "updated": "2019-02-22T00:17:14.733+0000",
                    "started": "2019-02-22T00:17:14.733+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202293",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202294",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259171232\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-test.cc\n ##########\n @@ -314,6 +318,185 @@ TEST(TestDictionaryEncoding, CannotDictDecodeBoolean) {\n   ASSERT_THROW(MakeDictDecoder<BooleanType>(nullptr), ParquetException);\n }\n \n+// ----------------------------------------------------------------------\n+// Shared arrow builder decode tests\n+class TestDecodeArrow : public ::testing::Test {\n+ public:\n+  void SetUp() override {\n+    InitDataInputs();\n+    SetupEncoderDecoder();\n+  }\n+\n+  void InitDataInputs() {\n+    // Build a dictionary array and its dense representation for testing building both\n+    auto dict_values = ::arrow::ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\"]\");\n+    auto dtype = ::arrow::dictionary(::arrow::int8(), dict_values);\n+    auto indices = ::arrow::ArrayFromJSON(::arrow::int8(), \"[0, 1, 0, 0]\");\n+    ASSERT_OK(::arrow::DictionaryArray::FromArrays(dtype, indices, &expected_dict_));\n+    expected_array_ =\n+        ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\", \\\"foo\\\", \\\"foo\\\"]\");\n+    num_values_ = static_cast<int>(expected_array_->length());\n+\n+    // arrow::BinaryType maps to parquet::ByteArray\n \n Review comment:\n   This is very minor, and I may not be understanding this correctly, but should this comment say `arrow::BinaryArray` instead of `arrow::BinaryType`?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T00:21:05.078+0000",
                    "updated": "2019-02-22T00:21:05.078+0000",
                    "started": "2019-02-22T00:21:05.077+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202294",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202300",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259173791\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-test.cc\n ##########\n @@ -314,6 +318,185 @@ TEST(TestDictionaryEncoding, CannotDictDecodeBoolean) {\n   ASSERT_THROW(MakeDictDecoder<BooleanType>(nullptr), ParquetException);\n }\n \n+// ----------------------------------------------------------------------\n+// Shared arrow builder decode tests\n+class TestDecodeArrow : public ::testing::Test {\n+ public:\n+  void SetUp() override {\n+    InitDataInputs();\n+    SetupEncoderDecoder();\n+  }\n+\n+  void InitDataInputs() {\n+    // Build a dictionary array and its dense representation for testing building both\n+    auto dict_values = ::arrow::ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\"]\");\n+    auto dtype = ::arrow::dictionary(::arrow::int8(), dict_values);\n+    auto indices = ::arrow::ArrayFromJSON(::arrow::int8(), \"[0, 1, 0, 0]\");\n+    ASSERT_OK(::arrow::DictionaryArray::FromArrays(dtype, indices, &expected_dict_));\n+    expected_array_ =\n+        ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\", \\\"foo\\\", \\\"foo\\\"]\");\n+    num_values_ = static_cast<int>(expected_array_->length());\n+\n+    // arrow::BinaryType maps to parquet::ByteArray\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*expected_array_);\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n \n Review comment:\n   Very minor nitpick - I think you can use pre-increment (`++i`) instead of post-increment (`i++`) here and in other `for` loops in this diff in order to [avoid the temporary copy that is returned by the post-increment operator](https://en.cppreference.com/w/cpp/language/operator_incdec#Notes), which isn't required in this context. Doing a [quick search through the Arrow codebase](https://github.com/apache/arrow/search?l=C%2B%2B&q=for+%28int+i) seems to suggest that using pre-increment in similar scenarios is fairly common.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T00:34:25.136+0000",
                    "updated": "2019-02-22T00:34:25.136+0000",
                    "started": "2019-02-22T00:34:25.136+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202300",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202306",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259175936\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n \n Review comment:\n   `MakeRandomStringsWithRepeats` seems like it could be useful elsewhere. Perhaps, this could be moved to somewhere under `arrow/cpp/src/arrow/util/`? \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T00:45:42.871+0000",
                    "updated": "2019-02-22T00:45:42.871+0000",
                    "started": "2019-02-22T00:45:42.870+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202306",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202317",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259170479\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n+                                                             size_t num_values) {\n+  const int64_t min_length = 2;\n+  const int64_t max_length = 10;\n+  std::vector<uint8_t> buffer(max_length);\n+  std::vector<std::string> dictionary(num_unique);\n+\n+  uint32_t seed = 0;\n+  std::default_random_engine gen(seed);\n+  std::uniform_int_distribution<int64_t> length_dist(min_length, max_length);\n+\n+  std::generate(dictionary.begin(), dictionary.end(), [&] {\n+    auto length = length_dist(gen);\n+    ::arrow::random_ascii(length, seed++, buffer.data());\n+    return std::string(buffer.begin(), buffer.begin() + length);\n+  });\n+\n+  std::uniform_int_distribution<int64_t> indices_dist(0, num_unique - 1);\n+  ::arrow::StringBuilder builder;\n+\n+  for (size_t i = 0; i < num_values; i++) {\n+    const auto index = indices_dist(gen);\n+    const auto value = dictionary[index];\n+    ABORT_NOT_OK(builder.Append(value));\n+  }\n+\n+  std::shared_ptr<::arrow::Array> result;\n+  ABORT_NOT_OK(builder.Finish(&result));\n+  return result;\n+}\n+\n+class BM_PlainDecodingByteArray : public ::benchmark::Fixture {\n+ public:\n+  void SetUp(const ::benchmark::State& state) override {\n+    num_values_ = static_cast<int>(state.range());\n+\n+    input_array_ = MakeRandomStringsWithRepeats(num_values_ / 8, num_values_);\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*input_array_);\n+    values_ = std::vector<ByteArray>();\n+    values_.reserve(num_values_);\n+    total_size_ = 0;\n+\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n+      auto view = binary_array.GetView(i);\n+      values_.emplace_back(static_cast<uint32_t>(view.length()),\n+                           reinterpret_cast<const uint8_t*>(view.data()));\n+      total_size_ += view.length();\n+    }\n+\n+    valid_bits_ =\n+        std::vector<uint8_t>(::arrow::BitUtil::BytesForBits(num_values_) + 1, 255);\n+\n+    auto encoder = MakeTypedEncoder<ByteArrayType>(Encoding::PLAIN);\n+    encoder->Put(values_.data(), num_values_);\n+    buffer_ = encoder->FlushValues();\n+  }\n+\n+  void TearDown(const ::benchmark::State& state) override {}\n+\n+ protected:\n+  int num_values_;\n+  std::shared_ptr<::arrow::Array> input_array_;\n+  uint64_t total_size_;\n+  std::vector<ByteArray> values_;\n+  std::vector<uint8_t> valid_bits_;\n+  std::shared_ptr<Buffer> buffer_;\n+};\n+\n+BENCHMARK_DEFINE_F(BM_PlainDecodingByteArray, DecodeArrow_Dense)\n+(benchmark::State& state) {\n+  while (state.KeepRunning()) {\n+    auto decoder = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN);\n+    decoder->SetData(num_values_, buffer_->data(), static_cast<int>(buffer_->size()));\n+    ::arrow::internal::ChunkedBinaryBuilder builder(static_cast<int>(buffer_->size()),\n+                                                    ::arrow::default_memory_pool());\n+    decoder->DecodeArrow(num_values_, 0, valid_bits_.data(), 0, &builder);\n+  }\n+\n+  state.SetBytesProcessed(state.iterations() * total_size_);\n+}\n+\n+BENCHMARK_REGISTER_F(BM_PlainDecodingByteArray, DecodeArrow_Dense)->Range(1024, 65536);\n+\n+BENCHMARK_DEFINE_F(BM_PlainDecodingByteArray, DecodeArrowNonNull_Dense)\n+(benchmark::State& state) {\n+  while (state.KeepRunning()) {\n+    auto decoder = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN);\n+    decoder->SetData(num_values_, buffer_->data(), static_cast<int>(buffer_->size()));\n+    ::arrow::internal::ChunkedBinaryBuilder builder(static_cast<int>(buffer_->size()),\n+                                                    ::arrow::default_memory_pool());\n+    decoder->DecodeArrowNonNull(num_values_, &builder);\n+  }\n+\n+  state.SetBytesProcessed(state.iterations() * total_size_);\n+}\n+\n+BENCHMARK_REGISTER_F(BM_PlainDecodingByteArray, DecodeArrowNonNull_Dense)\n+    ->Range(1024, 65536);\n+\n+BENCHMARK_DEFINE_F(BM_PlainDecodingByteArray, DecodeArrow_Dict)\n+(benchmark::State& state) {\n+  while (state.KeepRunning()) {\n+    auto decoder = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN);\n+    decoder->SetData(num_values_, buffer_->data(), static_cast<int>(buffer_->size()));\n+    ::arrow::BinaryDictionaryBuilder builder(::arrow::default_memory_pool());\n+    decoder->DecodeArrow(num_values_, 0, valid_bits_.data(), 0, &builder);\n+  }\n+\n+  state.SetBytesProcessed(state.iterations() * total_size_);\n+}\n+\n+BENCHMARK_REGISTER_F(BM_PlainDecodingByteArray, DecodeArrow_Dict)->Range(1024, 65536);\n \n Review comment:\n   Consider utilizing named constants for the `Range` values to increase readability here. Same comment for all other similar invocations of `Range` in this diff.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T01:00:13.118+0000",
                    "updated": "2019-02-22T01:00:13.118+0000",
                    "started": "2019-02-22T01:00:13.117+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202317",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202322",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259182253\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-test.cc\n ##########\n @@ -314,6 +318,185 @@ TEST(TestDictionaryEncoding, CannotDictDecodeBoolean) {\n   ASSERT_THROW(MakeDictDecoder<BooleanType>(nullptr), ParquetException);\n }\n \n+// ----------------------------------------------------------------------\n+// Shared arrow builder decode tests\n+class TestDecodeArrow : public ::testing::Test {\n+ public:\n+  void SetUp() override {\n+    InitDataInputs();\n+    SetupEncoderDecoder();\n+  }\n+\n+  void InitDataInputs() {\n+    // Build a dictionary array and its dense representation for testing building both\n+    auto dict_values = ::arrow::ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\"]\");\n+    auto dtype = ::arrow::dictionary(::arrow::int8(), dict_values);\n \n Review comment:\n   This is probably because I haven't worked with the `arrow::DictionaryType` before, and I didn't immediately realize that `::arrow::dictonary` is a factory function which returns an `arrow::DictionaryType` value, but I found the name `dtype` to be a bit overly generic in this context. I think it would be nice to use a consistent naming convention (e.g. `dict_type`) to parallel `dict_values`. Similarly, II think it would be nice to rename `indices` to `dict_indices`.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T01:19:34.309+0000",
                    "updated": "2019-02-22T01:19:34.309+0000",
                    "started": "2019-02-22T01:19:34.308+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202322",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202325",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259184233\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n \n Review comment:\n   Consider adding a comment here which provides an example of what the output of `MakeRandomStringsWithRepeats` might look like for two example values of `num_unique` and `num_values`,\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T01:30:37.252+0000",
                    "updated": "2019-02-22T01:30:37.252+0000",
                    "started": "2019-02-22T01:30:37.250+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202325",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202340",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259187981\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n \n Review comment:\n   Feel free to disregard this if you don't think it is helpful, but you could consider including `alphabet` (i.e. a list of letters from which to draw randomly) as one of the input arguments to `MakeRandomStringsWithRepeats`, rather than using `::arrow::random_ascii` inside of the function body. This might help facilitate greater flexibility/re-usability of this function in other contexts. For example, there might be a case in the future where a client might want to generate a random string containing Unicode characters, rather than just ASCII.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T01:52:42.016+0000",
                    "updated": "2019-02-22T01:52:42.016+0000",
                    "started": "2019-02-22T01:52:42.016+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202340",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202344",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259189326\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n+                                                             size_t num_values) {\n+  const int64_t min_length = 2;\n+  const int64_t max_length = 10;\n+  std::vector<uint8_t> buffer(max_length);\n+  std::vector<std::string> dictionary(num_unique);\n+\n+  uint32_t seed = 0;\n+  std::default_random_engine gen(seed);\n+  std::uniform_int_distribution<int64_t> length_dist(min_length, max_length);\n+\n+  std::generate(dictionary.begin(), dictionary.end(), [&] {\n+    auto length = length_dist(gen);\n+    ::arrow::random_ascii(length, seed++, buffer.data());\n+    return std::string(buffer.begin(), buffer.begin() + length);\n+  });\n+\n+  std::uniform_int_distribution<int64_t> indices_dist(0, num_unique - 1);\n+  ::arrow::StringBuilder builder;\n \n Review comment:\n   Since you know the number of values (`num_values`) that will be `Apppend`ed to the `arrow::StringBuilder`, it might be a good idea to call `builder.Reserve(num_values)` explicitly here.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T02:00:41.884+0000",
                    "updated": "2019-02-22T02:00:41.884+0000",
                    "started": "2019-02-22T02:00:41.883+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202344",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202353",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259193934\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n+                                                             size_t num_values) {\n+  const int64_t min_length = 2;\n+  const int64_t max_length = 10;\n+  std::vector<uint8_t> buffer(max_length);\n+  std::vector<std::string> dictionary(num_unique);\n+\n+  uint32_t seed = 0;\n+  std::default_random_engine gen(seed);\n+  std::uniform_int_distribution<int64_t> length_dist(min_length, max_length);\n+\n+  std::generate(dictionary.begin(), dictionary.end(), [&] {\n+    auto length = length_dist(gen);\n+    ::arrow::random_ascii(length, seed++, buffer.data());\n+    return std::string(buffer.begin(), buffer.begin() + length);\n+  });\n+\n+  std::uniform_int_distribution<int64_t> indices_dist(0, num_unique - 1);\n+  ::arrow::StringBuilder builder;\n+\n+  for (size_t i = 0; i < num_values; i++) {\n+    const auto index = indices_dist(gen);\n+    const auto value = dictionary[index];\n+    ABORT_NOT_OK(builder.Append(value));\n+  }\n+\n+  std::shared_ptr<::arrow::Array> result;\n+  ABORT_NOT_OK(builder.Finish(&result));\n+  return result;\n+}\n+\n+class BM_PlainDecodingByteArray : public ::benchmark::Fixture {\n+ public:\n+  void SetUp(const ::benchmark::State& state) override {\n+    num_values_ = static_cast<int>(state.range());\n+\n+    input_array_ = MakeRandomStringsWithRepeats(num_values_ / 8, num_values_);\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*input_array_);\n+    values_ = std::vector<ByteArray>();\n+    values_.reserve(num_values_);\n+    total_size_ = 0;\n+\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n+      auto view = binary_array.GetView(i);\n+      values_.emplace_back(static_cast<uint32_t>(view.length()),\n+                           reinterpret_cast<const uint8_t*>(view.data()));\n+      total_size_ += view.length();\n+    }\n+\n+    valid_bits_ =\n+        std::vector<uint8_t>(::arrow::BitUtil::BytesForBits(num_values_) + 1, 255);\n+\n+    auto encoder = MakeTypedEncoder<ByteArrayType>(Encoding::PLAIN);\n+    encoder->Put(values_.data(), num_values_);\n+    buffer_ = encoder->FlushValues();\n+  }\n+\n+  void TearDown(const ::benchmark::State& state) override {}\n+\n+ protected:\n+  int num_values_;\n+  std::shared_ptr<::arrow::Array> input_array_;\n+  uint64_t total_size_;\n+  std::vector<ByteArray> values_;\n+  std::vector<uint8_t> valid_bits_;\n+  std::shared_ptr<Buffer> buffer_;\n+};\n+\n+BENCHMARK_DEFINE_F(BM_PlainDecodingByteArray, DecodeArrow_Dense)\n+(benchmark::State& state) {\n+  while (state.KeepRunning()) {\n \n Review comment:\n   From the [google/benchmark `README.md`](https://github.com/google/benchmark#a-faster-keeprunning-loop): \r\n   \r\n   > \"In C++11 mode, a ranged-based for loop should be used in preference to the KeepRunning loop for running the benchmarks.\"\r\n   \r\n   Apparently, the generated assembly code for the range-based for loop in this context is slightly more efficient. However, looking at [other existing Parquet benchmarks](https://github.com/apache/arrow/blob/75c83578ced6de80015f3b93c1d290b9e74430e5/cpp/src/parquet/arrow/reader-writer-benchmark.cc#L210), the `while (state.KeepRunning())` paradigm seems to be widely in use in the Arrow project, so I will leave it up to other Arrow community members to comment further on whether the range-based for loop convention is worth following instead.\r\n   \r\n   Personally, I think `while (state.KeepRunning())` is slightly more readable.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T02:29:12.768+0000",
                    "updated": "2019-02-22T02:29:12.768+0000",
                    "started": "2019-02-22T02:29:12.767+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202353",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202354",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259193934\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n+                                                             size_t num_values) {\n+  const int64_t min_length = 2;\n+  const int64_t max_length = 10;\n+  std::vector<uint8_t> buffer(max_length);\n+  std::vector<std::string> dictionary(num_unique);\n+\n+  uint32_t seed = 0;\n+  std::default_random_engine gen(seed);\n+  std::uniform_int_distribution<int64_t> length_dist(min_length, max_length);\n+\n+  std::generate(dictionary.begin(), dictionary.end(), [&] {\n+    auto length = length_dist(gen);\n+    ::arrow::random_ascii(length, seed++, buffer.data());\n+    return std::string(buffer.begin(), buffer.begin() + length);\n+  });\n+\n+  std::uniform_int_distribution<int64_t> indices_dist(0, num_unique - 1);\n+  ::arrow::StringBuilder builder;\n+\n+  for (size_t i = 0; i < num_values; i++) {\n+    const auto index = indices_dist(gen);\n+    const auto value = dictionary[index];\n+    ABORT_NOT_OK(builder.Append(value));\n+  }\n+\n+  std::shared_ptr<::arrow::Array> result;\n+  ABORT_NOT_OK(builder.Finish(&result));\n+  return result;\n+}\n+\n+class BM_PlainDecodingByteArray : public ::benchmark::Fixture {\n+ public:\n+  void SetUp(const ::benchmark::State& state) override {\n+    num_values_ = static_cast<int>(state.range());\n+\n+    input_array_ = MakeRandomStringsWithRepeats(num_values_ / 8, num_values_);\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*input_array_);\n+    values_ = std::vector<ByteArray>();\n+    values_.reserve(num_values_);\n+    total_size_ = 0;\n+\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n+      auto view = binary_array.GetView(i);\n+      values_.emplace_back(static_cast<uint32_t>(view.length()),\n+                           reinterpret_cast<const uint8_t*>(view.data()));\n+      total_size_ += view.length();\n+    }\n+\n+    valid_bits_ =\n+        std::vector<uint8_t>(::arrow::BitUtil::BytesForBits(num_values_) + 1, 255);\n+\n+    auto encoder = MakeTypedEncoder<ByteArrayType>(Encoding::PLAIN);\n+    encoder->Put(values_.data(), num_values_);\n+    buffer_ = encoder->FlushValues();\n+  }\n+\n+  void TearDown(const ::benchmark::State& state) override {}\n+\n+ protected:\n+  int num_values_;\n+  std::shared_ptr<::arrow::Array> input_array_;\n+  uint64_t total_size_;\n+  std::vector<ByteArray> values_;\n+  std::vector<uint8_t> valid_bits_;\n+  std::shared_ptr<Buffer> buffer_;\n+};\n+\n+BENCHMARK_DEFINE_F(BM_PlainDecodingByteArray, DecodeArrow_Dense)\n+(benchmark::State& state) {\n+  while (state.KeepRunning()) {\n \n Review comment:\n   From the [google/benchmark `README.md`](https://github.com/google/benchmark#a-faster-keeprunning-loop): \r\n   \r\n   > \"In C++11 mode, a ranged-based for loop should be used in preference to the KeepRunning loop for running the benchmarks.\"\r\n   \r\n   Apparently, the generated assembly code for the range-based for loop in this context is slightly more efficient. However, looking at [other existing Parquet benchmarks](https://github.com/apache/arrow/blob/75c83578ced6de80015f3b93c1d290b9e74430e5/cpp/src/parquet/arrow/reader-writer-benchmark.cc#L210), the `while (state.KeepRunning())` paradigm seems to be widely in use across the Arrow project, so I will leave it up to other Arrow community members to comment further on whether the range-based for loop convention is worth following instead.\r\n   \r\n   Personally, I think `while (state.KeepRunning())` is slightly more readable.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T02:30:32.201+0000",
                    "updated": "2019-02-22T02:30:32.201+0000",
                    "started": "2019-02-22T02:30:32.199+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202354",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202362",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259201241\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n+                                                             size_t num_values) {\n+  const int64_t min_length = 2;\n+  const int64_t max_length = 10;\n+  std::vector<uint8_t> buffer(max_length);\n+  std::vector<std::string> dictionary(num_unique);\n+\n+  uint32_t seed = 0;\n+  std::default_random_engine gen(seed);\n+  std::uniform_int_distribution<int64_t> length_dist(min_length, max_length);\n+\n+  std::generate(dictionary.begin(), dictionary.end(), [&] {\n+    auto length = length_dist(gen);\n+    ::arrow::random_ascii(length, seed++, buffer.data());\n+    return std::string(buffer.begin(), buffer.begin() + length);\n+  });\n+\n+  std::uniform_int_distribution<int64_t> indices_dist(0, num_unique - 1);\n+  ::arrow::StringBuilder builder;\n+\n+  for (size_t i = 0; i < num_values; i++) {\n+    const auto index = indices_dist(gen);\n+    const auto value = dictionary[index];\n+    ABORT_NOT_OK(builder.Append(value));\n+  }\n+\n+  std::shared_ptr<::arrow::Array> result;\n+  ABORT_NOT_OK(builder.Finish(&result));\n+  return result;\n+}\n+\n+class BM_PlainDecodingByteArray : public ::benchmark::Fixture {\n+ public:\n+  void SetUp(const ::benchmark::State& state) override {\n+    num_values_ = static_cast<int>(state.range());\n+\n+    input_array_ = MakeRandomStringsWithRepeats(num_values_ / 8, num_values_);\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*input_array_);\n+    values_ = std::vector<ByteArray>();\n+    values_.reserve(num_values_);\n+    total_size_ = 0;\n+\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n \n Review comment:\n   According to my understanding, lines 212-229 are taking the random `arrow::Array` generated by `MakeRandomStringsWithRepeats` and \"plain encoding\" it as a Parquet `ByteArray`, with the intent that this `ByteArray` will be used as the test data for measuring the performance of decoding in the benchmark functions associated with this `benchmark::Fixture`.\r\n   \r\n   Assuming my understanding is correct, consider factoring lines 212-229 into a helper function like `PlainEncodeByteArray(std::shared_ptr<::arrow::Array> array)`, or similar, to help make clear what the fixture `SetUp` process is doing at a high level. It would be nice to be able to glance at this `SetUp` code in order to understand the pre-conditions of the benchmark functions.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T03:19:13.176+0000",
                    "updated": "2019-02-22T03:19:13.176+0000",
                    "started": "2019-02-22T03:19:13.175+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202362",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202363",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259184233\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n \n Review comment:\n   Consider adding a comment here which provides an example of what the output of `MakeRandomStringsWithRepeats` might look like for example values of `num_unique` and `num_values`,\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T03:21:44.616+0000",
                    "updated": "2019-02-22T03:21:44.616+0000",
                    "started": "2019-02-22T03:21:44.614+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202363",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202364",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259201241\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-benchmark.cc\n ##########\n @@ -163,4 +172,132 @@ static void BM_DictDecodingInt64_literals(benchmark::State& state) {\n \n BENCHMARK(BM_DictDecodingInt64_literals)->Range(1024, 65536);\n \n+std::shared_ptr<::arrow::Array> MakeRandomStringsWithRepeats(size_t num_unique,\n+                                                             size_t num_values) {\n+  const int64_t min_length = 2;\n+  const int64_t max_length = 10;\n+  std::vector<uint8_t> buffer(max_length);\n+  std::vector<std::string> dictionary(num_unique);\n+\n+  uint32_t seed = 0;\n+  std::default_random_engine gen(seed);\n+  std::uniform_int_distribution<int64_t> length_dist(min_length, max_length);\n+\n+  std::generate(dictionary.begin(), dictionary.end(), [&] {\n+    auto length = length_dist(gen);\n+    ::arrow::random_ascii(length, seed++, buffer.data());\n+    return std::string(buffer.begin(), buffer.begin() + length);\n+  });\n+\n+  std::uniform_int_distribution<int64_t> indices_dist(0, num_unique - 1);\n+  ::arrow::StringBuilder builder;\n+\n+  for (size_t i = 0; i < num_values; i++) {\n+    const auto index = indices_dist(gen);\n+    const auto value = dictionary[index];\n+    ABORT_NOT_OK(builder.Append(value));\n+  }\n+\n+  std::shared_ptr<::arrow::Array> result;\n+  ABORT_NOT_OK(builder.Finish(&result));\n+  return result;\n+}\n+\n+class BM_PlainDecodingByteArray : public ::benchmark::Fixture {\n+ public:\n+  void SetUp(const ::benchmark::State& state) override {\n+    num_values_ = static_cast<int>(state.range());\n+\n+    input_array_ = MakeRandomStringsWithRepeats(num_values_ / 8, num_values_);\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*input_array_);\n+    values_ = std::vector<ByteArray>();\n+    values_.reserve(num_values_);\n+    total_size_ = 0;\n+\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n \n Review comment:\n   If my understanding is correct, lines 212-229 are taking the random `arrow::Array` generated by `MakeRandomStringsWithRepeats` and \"plain encoding\" it as a Parquet `ByteArray`, with the intent that this `ByteArray` will be used as the test data for measuring the performance of decoding in the benchmark functions associated with this `benchmark::Fixture`.\r\n   \r\n   Assuming my understanding is correct, consider factoring lines 212-229 into a helper function like `PlainEncodeByteArray(std::shared_ptr<::arrow::Array> array)`, or similar, to help make clear what the fixture `SetUp` process is doing at a high level. It would be nice to be able to glance at this `SetUp` code in order to understand the pre-conditions of the benchmark functions.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T03:25:21.798+0000",
                    "updated": "2019-02-22T03:25:21.798+0000",
                    "started": "2019-02-22T03:25:21.797+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202364",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202369",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259207634\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-test.cc\n ##########\n @@ -314,6 +318,185 @@ TEST(TestDictionaryEncoding, CannotDictDecodeBoolean) {\n   ASSERT_THROW(MakeDictDecoder<BooleanType>(nullptr), ParquetException);\n }\n \n+// ----------------------------------------------------------------------\n+// Shared arrow builder decode tests\n+class TestDecodeArrow : public ::testing::Test {\n+ public:\n+  void SetUp() override {\n+    InitDataInputs();\n+    SetupEncoderDecoder();\n+  }\n+\n+  void InitDataInputs() {\n+    // Build a dictionary array and its dense representation for testing building both\n+    auto dict_values = ::arrow::ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\"]\");\n+    auto dtype = ::arrow::dictionary(::arrow::int8(), dict_values);\n+    auto indices = ::arrow::ArrayFromJSON(::arrow::int8(), \"[0, 1, 0, 0]\");\n+    ASSERT_OK(::arrow::DictionaryArray::FromArrays(dtype, indices, &expected_dict_));\n+    expected_array_ =\n \n Review comment:\n   Consider tweaking the name of this variable to something like `expected_dense_array` to make it easier to distinguish between the dictionary and dense representations of the test array.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T04:11:39.293+0000",
                    "updated": "2019-02-22T04:11:39.293+0000",
                    "started": "2019-02-22T04:11:39.292+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202369",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202370",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259207634\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-test.cc\n ##########\n @@ -314,6 +318,185 @@ TEST(TestDictionaryEncoding, CannotDictDecodeBoolean) {\n   ASSERT_THROW(MakeDictDecoder<BooleanType>(nullptr), ParquetException);\n }\n \n+// ----------------------------------------------------------------------\n+// Shared arrow builder decode tests\n+class TestDecodeArrow : public ::testing::Test {\n+ public:\n+  void SetUp() override {\n+    InitDataInputs();\n+    SetupEncoderDecoder();\n+  }\n+\n+  void InitDataInputs() {\n+    // Build a dictionary array and its dense representation for testing building both\n+    auto dict_values = ::arrow::ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\"]\");\n+    auto dtype = ::arrow::dictionary(::arrow::int8(), dict_values);\n+    auto indices = ::arrow::ArrayFromJSON(::arrow::int8(), \"[0, 1, 0, 0]\");\n+    ASSERT_OK(::arrow::DictionaryArray::FromArrays(dtype, indices, &expected_dict_));\n+    expected_array_ =\n \n Review comment:\n   Consider tweaking the name of this variable to something like `expected_dense_array_` to make it easier to distinguish between the dictionary and dense representations of the test array.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T04:17:17.984+0000",
                    "updated": "2019-02-22T04:17:17.984+0000",
                    "started": "2019-02-22T04:17:17.981+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202370",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202372",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259209248\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-test.cc\n ##########\n @@ -314,6 +318,185 @@ TEST(TestDictionaryEncoding, CannotDictDecodeBoolean) {\n   ASSERT_THROW(MakeDictDecoder<BooleanType>(nullptr), ParquetException);\n }\n \n+// ----------------------------------------------------------------------\n+// Shared arrow builder decode tests\n+class TestDecodeArrow : public ::testing::Test {\n+ public:\n+  void SetUp() override {\n+    InitDataInputs();\n+    SetupEncoderDecoder();\n+  }\n+\n+  void InitDataInputs() {\n+    // Build a dictionary array and its dense representation for testing building both\n+    auto dict_values = ::arrow::ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\"]\");\n+    auto dtype = ::arrow::dictionary(::arrow::int8(), dict_values);\n+    auto indices = ::arrow::ArrayFromJSON(::arrow::int8(), \"[0, 1, 0, 0]\");\n+    ASSERT_OK(::arrow::DictionaryArray::FromArrays(dtype, indices, &expected_dict_));\n+    expected_array_ =\n+        ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\", \\\"foo\\\", \\\"foo\\\"]\");\n+    num_values_ = static_cast<int>(expected_array_->length());\n+\n+    // arrow::BinaryType maps to parquet::ByteArray\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*expected_array_);\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n+      auto view = binary_array.GetView(i);\n+      input_data_.emplace_back(static_cast<uint32_t>(view.length()),\n+                               reinterpret_cast<const uint8_t*>(view.data()));\n+    }\n+\n+    valid_bits_ = vector<uint8_t>(::arrow::BitUtil::BytesForBits(num_values_) + 1, 255);\n+  }\n+\n+  // Setup encoder/decoder pair for testing with\n+  virtual void SetupEncoderDecoder() = 0;\n+\n+  void CheckDecodeDense(const int actual_num_values,\n+                        ::arrow::internal::ChunkedBinaryBuilder& builder) {\n+    ASSERT_EQ(actual_num_values, num_values_);\n+    ::arrow::ArrayVector actual_vec;\n+    ASSERT_OK(builder.Finish(&actual_vec));\n+    ASSERT_EQ(actual_vec.size(), 1);\n+    ASSERT_TRUE(actual_vec[0]->Equals(expected_array_))\n+        << \"Actual: \" << actual_vec[0] << \"\\nExpected: \" << expected_array_;\n+  }\n+\n+  void CheckDecodeDict(const int actual_num_values,\n+                       ::arrow::BinaryDictionaryBuilder& builder) {\n+    ASSERT_EQ(actual_num_values, num_values_);\n+    std::shared_ptr<::arrow::Array> actual;\n+    ASSERT_OK(builder.Finish(&actual));\n+    ASSERT_TRUE(actual->Equals(expected_dict_))\n+        << \"Actual: \" << actual << \"\\nExpected: \" << expected_dict_;\n+  }\n+\n+ protected:\n+  std::shared_ptr<::arrow::Array> expected_dict_;\n+  std::shared_ptr<::arrow::Array> expected_array_;\n+  int num_values_;\n+  vector<ByteArray> input_data_;\n+  vector<uint8_t> valid_bits_;\n+  std::unique_ptr<ByteArrayEncoder> encoder_;\n+  std::unique_ptr<ByteArrayDecoder> decoder_;\n+  std::shared_ptr<Buffer> buffer_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Arrow builder decode tests for PlainByteArrayDecoder\n+class TestDecodeArrowPlain : public TestDecodeArrow {\n+ public:\n+  void SetupEncoderDecoder() override {\n+    encoder_ = MakeTypedEncoder<ByteArrayType>(Encoding::PLAIN);\n+    decoder_ = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN);\n+    encoder_->Put(input_data_.data(), num_values_);\n \n Review comment:\n   Should this be wrapped in a call to `ASSERT_NO_THROW` like on line 436?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T04:25:53.651+0000",
                    "updated": "2019-02-22T04:25:53.651+0000",
                    "started": "2019-02-22T04:25:53.651+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202372",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202379",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on pull request #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#discussion_r259210835\n \n \n\n ##########\n File path: cpp/src/parquet/encoding-test.cc\n ##########\n @@ -314,6 +318,185 @@ TEST(TestDictionaryEncoding, CannotDictDecodeBoolean) {\n   ASSERT_THROW(MakeDictDecoder<BooleanType>(nullptr), ParquetException);\n }\n \n+// ----------------------------------------------------------------------\n+// Shared arrow builder decode tests\n+class TestDecodeArrow : public ::testing::Test {\n+ public:\n+  void SetUp() override {\n+    InitDataInputs();\n+    SetupEncoderDecoder();\n+  }\n+\n+  void InitDataInputs() {\n+    // Build a dictionary array and its dense representation for testing building both\n+    auto dict_values = ::arrow::ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\"]\");\n+    auto dtype = ::arrow::dictionary(::arrow::int8(), dict_values);\n+    auto indices = ::arrow::ArrayFromJSON(::arrow::int8(), \"[0, 1, 0, 0]\");\n+    ASSERT_OK(::arrow::DictionaryArray::FromArrays(dtype, indices, &expected_dict_));\n+    expected_array_ =\n+        ArrayFromJSON(::arrow::binary(), \"[\\\"foo\\\", \\\"bar\\\", \\\"foo\\\", \\\"foo\\\"]\");\n+    num_values_ = static_cast<int>(expected_array_->length());\n+\n+    // arrow::BinaryType maps to parquet::ByteArray\n+    const auto& binary_array = static_cast<const ::arrow::BinaryArray&>(*expected_array_);\n+    for (int64_t i = 0; i < binary_array.length(); i++) {\n+      auto view = binary_array.GetView(i);\n+      input_data_.emplace_back(static_cast<uint32_t>(view.length()),\n+                               reinterpret_cast<const uint8_t*>(view.data()));\n+    }\n+\n+    valid_bits_ = vector<uint8_t>(::arrow::BitUtil::BytesForBits(num_values_) + 1, 255);\n+  }\n+\n+  // Setup encoder/decoder pair for testing with\n+  virtual void SetupEncoderDecoder() = 0;\n+\n+  void CheckDecodeDense(const int actual_num_values,\n+                        ::arrow::internal::ChunkedBinaryBuilder& builder) {\n+    ASSERT_EQ(actual_num_values, num_values_);\n+    ::arrow::ArrayVector actual_vec;\n+    ASSERT_OK(builder.Finish(&actual_vec));\n+    ASSERT_EQ(actual_vec.size(), 1);\n+    ASSERT_TRUE(actual_vec[0]->Equals(expected_array_))\n+        << \"Actual: \" << actual_vec[0] << \"\\nExpected: \" << expected_array_;\n+  }\n+\n+  void CheckDecodeDict(const int actual_num_values,\n+                       ::arrow::BinaryDictionaryBuilder& builder) {\n+    ASSERT_EQ(actual_num_values, num_values_);\n+    std::shared_ptr<::arrow::Array> actual;\n+    ASSERT_OK(builder.Finish(&actual));\n+    ASSERT_TRUE(actual->Equals(expected_dict_))\n+        << \"Actual: \" << actual << \"\\nExpected: \" << expected_dict_;\n+  }\n+\n+ protected:\n+  std::shared_ptr<::arrow::Array> expected_dict_;\n+  std::shared_ptr<::arrow::Array> expected_array_;\n+  int num_values_;\n+  vector<ByteArray> input_data_;\n+  vector<uint8_t> valid_bits_;\n+  std::unique_ptr<ByteArrayEncoder> encoder_;\n+  std::unique_ptr<ByteArrayDecoder> decoder_;\n+  std::shared_ptr<Buffer> buffer_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Arrow builder decode tests for PlainByteArrayDecoder\n+class TestDecodeArrowPlain : public TestDecodeArrow {\n+ public:\n+  void SetupEncoderDecoder() override {\n+    encoder_ = MakeTypedEncoder<ByteArrayType>(Encoding::PLAIN);\n+    decoder_ = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN);\n+    encoder_->Put(input_data_.data(), num_values_);\n+    buffer_ = encoder_->FlushValues();\n+    decoder_->SetData(num_values_, buffer_->data(), static_cast<int>(buffer_->size()));\n+  }\n+\n+  void TearDown() override {}\n+};\n+\n+TEST_F(TestDecodeArrowPlain, DecodeDense) {\n+  ::arrow::internal::ChunkedBinaryBuilder builder(static_cast<int>(buffer_->size()),\n+                                                  default_memory_pool());\n+  auto actual_num_values =\n+      decoder_->DecodeArrow(num_values_, 0, valid_bits_.data(), 0, &builder);\n+  CheckDecodeDense(actual_num_values, builder);\n+}\n+\n+TEST_F(TestDecodeArrowPlain, DecodeNonNullDense) {\n+  ::arrow::internal::ChunkedBinaryBuilder builder(static_cast<int>(buffer_->size()),\n+                                                  default_memory_pool());\n+  auto actual_num_values = decoder_->DecodeArrowNonNull(num_values_, &builder);\n+  CheckDecodeDense(actual_num_values, builder);\n+}\n+\n+TEST_F(TestDecodeArrowPlain, DecodeDictionary) {\n+  ::arrow::BinaryDictionaryBuilder builder(default_memory_pool());\n+  auto actual_num_values =\n+      decoder_->DecodeArrow(num_values_, 0, valid_bits_.data(), 0, &builder);\n+  CheckDecodeDict(actual_num_values, builder);\n+}\n+\n+TEST_F(TestDecodeArrowPlain, DecodeNonNullDictionary) {\n+  ::arrow::BinaryDictionaryBuilder builder(default_memory_pool());\n+  auto actual_num_values = decoder_->DecodeArrowNonNull(num_values_, &builder);\n+  CheckDecodeDict(actual_num_values, builder);\n+}\n+\n+// ----------------------------------------------------------------------\n+// Arrow builder decode tests for DictByteArrayDecoder\n+class TestDecodeArrowDict : public TestDecodeArrow {\n+ public:\n+  void SetupEncoderDecoder() override {\n+    auto node = schema::ByteArray(\"name\");\n+    descr_ = std::unique_ptr<ColumnDescriptor>(new ColumnDescriptor(node, 0, 0));\n+    encoder_ = MakeTypedEncoder<ByteArrayType>(Encoding::PLAIN, /*use_dictionary=*/true,\n+                                               descr_.get());\n+    ASSERT_NO_THROW(encoder_->Put(input_data_.data(), num_values_));\n+    buffer_ = encoder_->FlushValues();\n+\n+    auto dict_encoder = dynamic_cast<DictEncoder<ByteArrayType>*>(encoder_.get());\n+    ASSERT_NE(dict_encoder, nullptr);\n+    dict_buffer_ =\n+        AllocateBuffer(default_memory_pool(), dict_encoder->dict_encoded_size());\n+    dict_encoder->WriteDict(dict_buffer_->mutable_data());\n+\n+    // Simulate reading the dictionary page followed by a data page\n+    decoder_ = MakeTypedDecoder<ByteArrayType>(Encoding::PLAIN, descr_.get());\n+    decoder_->SetData(dict_encoder->num_entries(), dict_buffer_->data(),\n+                      static_cast<int>(dict_buffer_->size()));\n+\n+    dict_decoder_ = MakeDictDecoder<ByteArrayType>(descr_.get());\n+    dict_decoder_->SetDict(decoder_.get());\n+    dict_decoder_->SetData(num_values_, buffer_->data(),\n+                           static_cast<int>(buffer_->size()));\n+  }\n+\n+  void TearDown() override {}\n+\n+ protected:\n+  std::unique_ptr<ColumnDescriptor> descr_;\n+  std::unique_ptr<DictDecoder<ByteArrayType>> dict_decoder_;\n+  std::shared_ptr<Buffer> dict_buffer_;\n+};\n+\n+TEST_F(TestDecodeArrowDict, DecodeDense) {\n+  ::arrow::internal::ChunkedBinaryBuilder builder(static_cast<int>(dict_buffer_->size()),\n+                                                  default_memory_pool());\n+  auto byte_array_decoder = dynamic_cast<ByteArrayDecoder*>(dict_decoder_.get());\n+  ASSERT_NE(byte_array_decoder, nullptr);\n+  auto actual_num_values =\n+      byte_array_decoder->DecodeArrow(num_values_, 0, valid_bits_.data(), 0, &builder);\n+  CheckDecodeDense(actual_num_values, builder);\n+}\n+\n+TEST_F(TestDecodeArrowDict, DecodeNonNullDense) {\n+  ::arrow::internal::ChunkedBinaryBuilder builder(static_cast<int>(dict_buffer_->size()),\n+                                                  default_memory_pool());\n+  auto byte_array_decoder = dynamic_cast<ByteArrayDecoder*>(dict_decoder_.get());\n+  ASSERT_NE(byte_array_decoder, nullptr);\n+  auto actual_num_values = byte_array_decoder->DecodeArrowNonNull(num_values_, &builder);\n+  CheckDecodeDense(actual_num_values, builder);\n+}\n+\n+TEST_F(TestDecodeArrowDict, DecodeDictionary) {\n \n Review comment:\n   For consistency, consider either naming this `DecodeDict`, or spelling out `Dictionary` in full elsewhere in this diff.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T04:39:43.115+0000",
                    "updated": "2019-02-22T04:39:43.115+0000",
                    "started": "2019-02-22T04:39:43.115+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202379",
                    "issueId": "13187264"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/worklog/202384",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kevingurney commented on issue #3721: ARROW-3769: [C++] Add support for reading non-dictionary encoded binary Parquet columns directly as DictionaryArray\nURL: https://github.com/apache/arrow/pull/3721#issuecomment-466275950\n \n \n   @hatemhelal I did an initial review of your changes, and overall they look good!\r\n   \r\n   Almost all of my feedback is minor and primarily stylistic in nature. I am new to this area of the code base, so you can take my comments with a grain of salt. Many of them may stem more from my own lack of knowledge in this area, and my attempt to learn more, than from actual issues with the code.\r\n   \r\n   Let me know if you have any questions regarding any of my feedback.\r\n   \r\n   Thanks!\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-02-22T05:10:22.847+0000",
                    "updated": "2019-02-22T05:10:22.847+0000",
                    "started": "2019-02-22T05:10:22.846+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "202384",
                    "issueId": "13187264"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 51000,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@1116008b[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6272d266[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@19003124[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@6d952180[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4bd7cd77[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@6820e498[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@703161a9[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@34ecd70e[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@41a51891[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@2e4e2019[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@55893050[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@78fd948[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 51000,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Mar 18 00:13:46 UTC 2019",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2019-03-18T00:13:46.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3769/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2018-09-25T11:25:51.000+0000",
        "updated": "2019-03-18T14:01:44.000+0000",
        "timeoriginalestimate": null,
        "description": "If the goal is to hash this data anyway into a categorical-type array, then it would be better to offer the option to \"push down\" the hashing into the Parquet read hot path rather than first fully materializing a dense vector of {{ByteArray}} values, which could use a lot of memory after decompression",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "14h 10m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 51000
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Support reading non-dictionary encoded binary Parquet columns directly as DictionaryArray",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/comment/16684401",
                    "id": "16684401",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Moved this here from the Parquet JIRA",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-11-12T21:58:26.893+0000",
                    "updated": "2018-11-12T21:58:26.893+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/comment/16753616",
                    "id": "16753616",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "This is implemented in in https://github.com/apache/arrow/pull/3492 for PARQUET-1508, but not tested. This JIRA should be used to add unit tests and probably some benchmarks, too",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-01-27T22:35:10.146+0000",
                    "updated": "2019-01-27T22:35:10.146+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/comment/16756031",
                    "id": "16756031",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=hatem",
                        "name": "hatem",
                        "key": "hatem",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
                        },
                        "displayName": "Hatem Helal",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "I've started looking into this and\u00a0starting with some unit tests to make sure I understand the inner workings.\u00a0\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=hatem",
                        "name": "hatem",
                        "key": "hatem",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
                        },
                        "displayName": "Hatem Helal",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2019-01-30T12:17:34.468+0000",
                    "updated": "2019-01-30T12:17:34.468+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/comment/16756155",
                    "id": "16756155",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Cool. This is only implemented at the encoder level, so you should be able to use {{ArrayFromJSON}} to make writing the unit tests easier -- so for this JIRA I am expecting tests in {{parquet-encoding-test}}",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-01-30T14:13:26.559+0000",
                    "updated": "2019-01-30T14:13:26.559+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/comment/16761825",
                    "id": "16761825",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=hatem",
                        "name": "hatem",
                        "key": "hatem",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
                        },
                        "displayName": "Hatem Helal",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Made a start on the unittests here:\r\n\r\n[https://github.com/mathworks/arrow/pull/12]\r\n\r\n[~wesmckinn], could you take a look and let me know if this is heading in the right direction?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=hatem",
                        "name": "hatem",
                        "key": "hatem",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
                        },
                        "displayName": "Hatem Helal",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2019-02-06T15:08:07.692+0000",
                    "updated": "2019-02-06T15:08:07.692+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/comment/16761855",
                    "id": "16761855",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "yes, I think that's the basic idea",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-02-06T15:28:46.714+0000",
                    "updated": "2019-02-06T15:28:46.714+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13187264/comment/16794622",
                    "id": "16794622",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 3721\n[https://github.com/apache/arrow/pull/3721]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-03-18T00:13:46.728+0000",
                    "updated": "2019-03-18T00:13:46.728+0000"
                }
            ],
            "maxResults": 7,
            "total": 7,
            "startAt": 0
        },
        "customfield_12311820": "0|i3ygmf:",
        "customfield_12314139": null
    }
}