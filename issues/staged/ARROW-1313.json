{
    "issue": {
        "title": "[C++/Python] Add troubleshooting section for setting up HDFS JNI interface",
        "body": "***Note**: This issue was originally created as [ARROW-1313](https://issues.apache.org/jira/browse/ARROW-1313). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe hadoop library directory contains a libhdfs.a and a libhadoop.so but no libhdfs.so.",
        "created_at": "2017-08-02T13:52:59.000Z",
        "updated_at": "2017-10-08T18:45:46.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Documentation",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2017-08-02T13:55:17.421Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1313?focusedCommentId=16110947) by Wes McKinney (wesm):*\nCan you provide more detail about your environment (i.e. so that this can be reproduced)? The location of libhdfs.so can vary a lot by Hadoop distribution. "
        },
        {
            "created_at": "2017-08-02T14:01:20.723Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1313?focusedCommentId=16110960) by Martin Durant (mdurant):*\nDocker file: https://github.com/dask/hdfs3/blob/master/continuous_integration/Dockerfile\n\nThis uses an official .deb of CDH5, installed into /usr/lib/hadoop. There is no libhdfs.so anywhere in that directory..\n\nUsing java-7-openjdk-amd64."
        },
        {
            "created_at": "2017-08-02T14:24:26.404Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1313?focusedCommentId=16111001) by Wes McKinney (wesm):*\nIt appears in this particular Hadoop distribution that libhdfs is packaged as a separate Linux package:\n\n```Java\napt-get install libhdfs0-dev\n```\n\nand then\n\n```Java\n# find /usr -name \\*.so -print | grep hdfs\n/usr/lib/libhdfs.so\n```"
        },
        {
            "created_at": "2017-08-02T14:36:37.479Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1313?focusedCommentId=16111018) by Martin Durant (mdurant):*\nThat would install the whole of hadoop as system packages, so there would be two separate ones with the CHD install from before. \nlibhdfs.so is only 200kB, can it not be distributed?"
        },
        {
            "created_at": "2017-08-02T14:58:27.482Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1313?focusedCommentId=16111067) by Wes McKinney (wesm):*\nMy understanding is that the safest thing to do in production is use the libhdfs.so that is shipped with a particular Hadoop distribution (since there may be internal details that are particular to that version of Hadoop); while the public C API is the same between versions, in theory there could be internal details in the JNI implementation that break the Java \"ABI\". The Hadoop community would be able to give better advice"
        }
    ]
}