{
    "issue": {
        "title": "[Python] PyArrow cannot read from R2 (Cloudflare's S3)",
        "body": "***Note**: This issue was originally created as [ARROW-18076](https://issues.apache.org/jira/browse/ARROW-18076). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen using pyarrow to read parquet data (as part of the Ray project), I get the following stracktrace:\r\n\r\n```\n\r\n(_sample_piece pid=49818) Traceback (most recent call last):\r\n(_sample_piece pid=49818)   File \"python/ray/_raylet.pyx\", line 859, in ray._raylet.execute_task\r\n(_sample_piece pid=49818)   File \"python/ray/_raylet.pyx\", line 863, in ray._raylet.execute_task\r\n(_sample_piece pid=49818)   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py\", line 446, in _sample_piece\r\n(_sample_piece pid=49818)     batch = next(batches)\r\n(_sample_piece pid=49818)   File \"pyarrow/_dataset.pyx\", line 3202, in _iterator\r\n(_sample_piece pid=49818)   File \"pyarrow/_dataset.pyx\", line 2891, in pyarrow._dataset.TaggedRecordBatchIterator.__next__\r\n(_sample_piece pid=49818)   File \"pyarrow/error.pxi\", line 143, in pyarrow.lib.pyarrow_internal_check_status\r\n(_sample_piece pid=49818)   File \"pyarrow/error.pxi\", line 114, in pyarrow.lib.check_status\r\n(_sample_piece pid=49818) OSError: AWS Error [code 99]: curlCode: 18, Transferred a partial file\r\n```\r\n\r\nI do not get this error when using Amazon S3 for the exact same data.\r\nThe error is coming from this line:\r\nhttps://github.com/ray-project/ray/blob/6fb605379a726d889bd25cf0ee4ed335c74408ff/python/ray/data/datasource/parquet_datasource.py#L446",
        "created_at": "2022-10-17T11:26:42.000Z",
        "updated_at": "2022-10-24T11:59:52.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-10-24T11:59:52.000Z"
    },
    "comments": [
        {
            "created_at": "2022-10-24T11:59:28.753Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-18076?focusedCommentId=17623138) by Alessandro Molina (amol-):*\nHave you tried reaching to Cloudflare to verify if it might be a problem with the file itself? That error is usually caused by a mismatch between `Content-Length` header and the actually transfered amount of bytes. In the majority of cases the problem is caused by the server setting a wrong `Content-Length` or truncating the connection. So I would check with Cloudflare support, especially if you say that when using S3 the same file works correctly.\r\n\r\nI'm going to close the ticket, if you get an answer from Cloudflare confirming that everything is fine on their side, feel free to reopen it."
        }
    ]
}