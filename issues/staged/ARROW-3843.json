{
    "issue": {
        "title": "[Python] Writing Parquet file from empty table created with Table.from_pandas(..., preserve_index=False) fails",
        "body": "***Note**: This issue was originally created as [ARROW-3843](https://issues.apache.org/jira/browse/ARROW-3843). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n```java\n\r\nimport pandas as pd\r\nimport pyarrow.parquet as pq\r\nimport pyarrow as pa\r\n\r\n\r\ndef test_write_empty_preserve_index():\r\n\r\n# passes\r\n\r\ndf = pd.DataFrame()\r\ntable = pa.Table.from_pandas(df, preserve_index=True)\r\npq.write_table(table, 'test1.parquet')\r\ntable2 = pq.read_table('test1.parquet')\r\ndf2 = table2.to_pandas()\r\npd.util.testing.assert_frame_equal(df, df2)\r\n\r\n\r\ndef test_write_empty_no_preserve_index():\r\ndf = pd.DataFrame()\r\ntable = pa.Table.from_pandas(df, preserve_index=False)\r\n\r\n# fails here\r\npq.write_table(table, 'test2.parquet')\r\n\r\ntable2 = pq.read_table('test2.parquet')\r\ndf2 = table2.to_pandas()\r\npd.util.testing.assert_frame_equal(df, df2)\n```\r\n\u00a0\r\n\r\nFirst test passes.\u00a0 Second one fails with this:\r\n\r\n\u00a0\r\n```java\n\r\n___________________________________ test_write_empty_no_preserve_index ___________________________________\r\n\r\ndef test_write_empty_no_preserve_index():\r\ndf = pd.DataFrame()\r\ntable = pa.Table.from_pandas(df, preserve_index=False)\r\n\r\n# fails here\r\n> pq.write_table(table, 'test2.parquet')\r\n\r\ntest_empty.py:24: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n../.conda/envs/pedlenv/lib/python3.6/site-packages/pyarrow/parquet.py:1125: in write_table\r\nwriter.write_table(table, row_group_size=row_group_size)\r\n../.conda/envs/pedlenv/lib/python3.6/site-packages/pyarrow/parquet.py:361: in __exit__\r\nself.close()\r\n../.conda/envs/pedlenv/lib/python3.6/site-packages/pyarrow/parquet.py:380: in close\r\nself.writer.close()\r\npyarrow/_parquet.pyx:916: in pyarrow._parquet.ParquetWriter.close\r\n???\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n> ???\r\nE pyarrow.lib.ArrowIOError: Root node did not have children\r\n\r\npyarrow/error.pxi:83: ArrowIOError\r\n```\r\n\u00a0\r\n\r\nI haven't had a chance to investigate but seems not desired behavior.\r\n\r\n\u00a0\r\n\r\n\u00a0",
        "created_at": "2018-11-20T16:41:30.000Z",
        "updated_at": "2019-03-22T14:41:28.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-03-22T14:41:28.000Z"
    },
    "comments": [
        {
            "created_at": "2018-11-20T17:33:54.189Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3843?focusedCommentId=16693551) by Wes McKinney (wesm):*\nI moved this to the Arrow issue tracker and clarified the title. A PR would be welcome"
        },
        {
            "created_at": "2018-11-21T19:41:01.505Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3843?focusedCommentId=16695179) by Justin Lewis (jlou2u):*\nI was able to get a dev environment on osx up and running after a few tries on linux (running into conda abi issues I think).\r\n\r\nI'm not too familiar with the code.\u00a0 The call to close() on this line is where I was starting to debug.\u00a0\u00a0\r\n\r\n<https://github.com/apache/arrow/blob/c04a62b9579d420da32ed6d962d92266508e6abe/python/pyarrow/_parquet.pyx#L916>\r\n\r\nI believe the FileWriter is implemented here\u00a0\r\n\r\n<https://github.com/apache/arrow/blob/c04a62b9579d420da32ed6d962d92266508e6abe/cpp/src/parquet/arrow/writer.cc#L938>\r\n\r\nFor now I'm trying to understand if the writer is ok with writing an empty file or not.\u00a0 I'm assuming the problem is the writer expects to write something and when nothing gets written it gets tripped up.\u00a0\r\n\r\n\u00a0\r\n\r\nI'm adding this both as a note to myself but also in case somebody can point me in the direction of success.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2018-11-21T22:39:36.309Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3843?focusedCommentId=16695328) by Justin Lewis (jlou2u):*\nAfter taking a look at this I have a better idea of what should be in the file.\u00a0https://github.com/apache/parquet-format"
        },
        {
            "created_at": "2019-03-19T17:02:50.914Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3843?focusedCommentId=16796288) by Ben Kietzman (bkietz):*\n`write_table` refuses to write empty tables which are not derived from pandas:\r\n```Java\n\r\nimport pyarrow.parquet as pq\r\nimport pyarrow as pa\r\n\r\nempty = pa.Table.from_arrays([])\r\npq.write_table(empty, 'empty.parquet') # pyarrow.lib.ArrowIOError: Root node did not have children\r\n```\r\n\u00a0\r\n\r\nWith `preserve_index=True`  an index column is present: \"__index_level_0__\". It seems to me that pandas metadata should be excluded from [FlatSchemaConverter::Convert's validation](https://github.com/apache/arrow/blob/c04a62b9579d420da32ed6d962d92266508e6abe/cpp/src/parquet/schema.cc#L371-L374), similar to: https://github.com/apache/arrow/pull/3744 - this way attempting to write a table which is empty except for pandas meta would also fail."
        },
        {
            "created_at": "2019-03-20T02:39:13.741Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3843?focusedCommentId=16796727) by Wes McKinney (wesm):*\nLet me try to fix this"
        },
        {
            "created_at": "2019-03-22T14:41:28.746Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3843?focusedCommentId=16799067) by Wes McKinney (wesm):*\nIssue resolved by pull request 3985\n<https://github.com/apache/arrow/pull/3985>"
        }
    ]
}