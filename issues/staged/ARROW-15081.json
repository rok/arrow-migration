{
    "issue": {
        "title": "[R][C++] Arrow crashes (OOM) on R client with large remote parquet files",
        "body": "***Note**: This issue was originally created as [ARROW-15081](https://issues.apache.org/jira/browse/ARROW-15081). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe below should be a reproducible crash:\r\n\r\n\r\n```java\n\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\nserver <- arrow::s3_bucket(\"ebird\",endpoint_override = \"minio.cirrus.carlboettiger.info\")\r\n\r\npath <- server$path(\"Oct-2021/observations\")\r\nobs <- arrow::open_dataset(path)\r\n\r\npath$ls() # observe -- 1 parquet file\r\n\r\nobs %>% count() # CRASH\r\n\r\nobs %>% to_duckdb() # also crash\n```\r\nI have attempted to split this large (~100 GB parquet file) into some smaller files, which helps: \r\n\r\n\r\n```java\n\r\npath <- server$path(\"partitioned\")\r\nobs <- arrow::open_dataset(path)\r\nobs$ls() # observe, multiple parquet files now\r\nobs %>% count()\u00a0\r\n \n```\r\n(These parquet files have also been created by arrow, btw, from a single large csv file provided by the original data provider (eBird).\u00a0 Unfortunately generating the partitioned versions is cumbersome as the data is very unevenly distributed, there's few columns that can avoid creating 1000s of parquet partition files and even so the bulk of the 1-billion rows fall within the same group.\u00a0 But all the same I think this is a bug as there's no indication why arrow cannot handle a single 100GB parquet file I think?).\u00a0\r\n\r\n\u00a0\r\n\r\nLet me know if I can provide more info! I'm testing in R with latest CRAN version of arrow on a machine with 200 GB RAM.\u00a0",
        "created_at": "2021-12-13T19:18:54.000Z",
        "updated_at": "2022-08-26T16:18:12.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-12-13T19:41:04.019Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17458660) by Weston Pace (westonpace):*\nI agree this should work.  I'll have to look at how we have count implemented as I believe we shouldn't even have to look at the data in that case and I thought we had some special paths in place for this."
        },
        {
            "created_at": "2022-02-07T18:12:46.289Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17488306) by Dewey Dunnington (paleolimbot):*\nThere was another user who reported an issue with count on a parquet file that seems to have been fixed in the development version (which is about to be released to CRAN). Perhaps ARROW-15201 is the same issue?\r\n\r\nIf it is not, when I try to reproduce the above I get an error (see below). Is there a more recent bucket with the files we can use to reproduce?\r\n\r\n```R\n\r\nlibrary(arrow, warn.conflicts = FALSE)\r\nlibrary(dplyr, warn.conflicts = FALSE)\r\n\r\nserver <- arrow::s3_bucket(\r\n  \"ebird\",\r\n  endpoint_override = \"minio.cirrus.carlboettiger.info\"\r\n)\r\n\r\npath <- server$path(\"Oct-2021/observations\")\r\npath$ls()\r\n#> Error: IOError: Path does not exist 'ebird/Oct-2021/observations'\r\n#> /Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/filesystem/s3fs.cc:1913  collector.Finish(this)\r\n#> /Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/filesystem/s3fs.cc:2275  impl_->Walk(select, base_path.bucket, base_path.key, &results)\r\n#> /Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/filesystem/filesystem.cc:341  base_fs_->GetFileInfo(selector)\r\n#> /Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/filesystem/filesystem.cc:341  base_fs_->GetFileInfo(selector)\r\n\r\npath <- server$path(\"partitioned\")\r\npath$ls()\r\n#> Error: IOError: Path does not exist 'ebird/partitioned'\r\n#> /Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/filesystem/s3fs.cc:1913  collector.Finish(this)\r\n#> /Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/filesystem/s3fs.cc:2275  impl_->Walk(select, base_path.bucket, base_path.key, &results)\r\n#> /Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/filesystem/filesystem.cc:341  base_fs_->GetFileInfo(selector)\r\n#> /Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/filesystem/filesystem.cc:341  base_fs_->GetFileInfo(selector)\r\n```\r\n"
        },
        {
            "created_at": "2022-02-09T02:13:26.979Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17489204) by Carl Boettiger (cboettig):*\nsorry about that, you caught me at a time I was doing a few server upgrades.\u00a0 Should be back up in a few hours."
        },
        {
            "created_at": "2022-02-09T15:31:24.569Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17489644) by Carl Boettiger (cboettig):*\nshould be back up now.\u00a0 Just a note I need to use collect() as well after count() to cause the OOM crash (on arrow 6.0.1).\u00a0"
        },
        {
            "created_at": "2022-02-09T16:07:29.345Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17489660) by Carl Boettiger (cboettig):*\nJust tested with the nightly build,\u00a0\r\n \u20187.0.0.20220208\u2019\r\nand arrow no longer crashes on the above example.\u00a0 yay!\u00a0 I do note that RStudio reports that it is already using 12 GB after running open_dataset, which goes up to 24 GB during/after running count() %>% compute().\u00a0 Not sure if that's expected (i.e. maybe arrow knows 24 GB is okay on this system?).\u00a0 I'm running inside a Docker container that is capped at 35 GB, though on a machine that has a total of 65 GB.\u00a0 I haven't tested on a more restricted container, but I'm curious what the minimum RAM requirements would be for working with data like this."
        },
        {
            "created_at": "2022-02-09T16:12:18.550Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17489663) by Carl Boettiger (cboettig):*\nOne more note: even the nightly arrow, I can't go very far without OOM errors still crashing my system when working with this dataset.\u00a0 For instance:\r\n\r\n\r\n```java\n\r\nobs %>% count(country_code, sort=TRUE) %>% collect()\r\n \n```\r\ncrashes my system in the example shown above.\u00a0"
        },
        {
            "created_at": "2022-02-09T21:39:09.906Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17489827) by Weston Pace (westonpace):*\nThere is definitely something going on here.  When I run this on a 1GB dataset stored on local disk I can verify that we only read ~29MB out of 1GB (which still seems a little high).  Extrapolating I would expect to see something on the order of ~300MB for a 100GB file.  Instead, when running against Carl's dataset, I see RAM hit 24GB before hitting the RAM limit on my system and crashing.\r\n\r\nEven just opening the dataset seems to take quite a while.  I verified that the execution plan is the same whether we are using S3 or local disk.  It is:\r\n\r\n```\n\r\nExecPlan with 5 nodes:\r\n4:SinkNode{}\r\n  3:ProjectNode{projection=[n]}\r\n    2:ScalarAggregateNode{aggregates=[\r\n\tsum(n, {skip_nulls=true, min_count=1}),\r\n]}\r\n      1:ProjectNode{projection=[\"n\": 1]}\r\n        0:SourceNode{}\r\n```\r\n\r\nEarlier I mentioned:\r\n\r\n> I thought we had some special paths in place for this.\r\n\r\nWe do, but the R bindings are not using them.  The special paths are in the scanner's \"lightweight consumer API\" and the dplyr bindings build and execute an exec plan directly, using the scanner only as a scanner.\r\n\r\nI'm guessing the solution will be to move this fast path from scanner and into the scan node as a scan option.  This still doesn't really explain why we are reading so efficiently from local filesystem so I think I don't yet have the full picture.\r\n\r\nI'll try and find some time to do some more instrumentation & debugging soon, probably Friday if I can't get to it any earlier."
        },
        {
            "created_at": "2022-02-11T22:39:06.009Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17491193) by Weston Pace (westonpace):*\nSo the measuring I was doing that claimed ~29 out of 1GB of the parquet file was read was incorrect.  It turns out we are simply reading the entire file when a count query is issued from R, regardless of filesystem.\r\n\r\nLong term, I think this will be addressed by ARROW-12311.  In the newly proposed ScanOptions, if no fields are selected for projection, then no data will be returned.  Today, as a convenience, we read all fields.  However, that convenience should live higher up than ScanOptions.\r\n\r\nIn the short term I think we could address this by allowing R to use the same kind of hack that C++/python is using.  If we get closer to 8.0.0 and it seems that ARROW-12311 is not going to be addressed then I will try and remember to put in the short-term fix."
        },
        {
            "created_at": "2022-05-02T17:54:47.539Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17530874) by Carl Boettiger (cboettig):*\nAny news on this? I'll keep an eye on https://issues.apache.org/jira/browse/ARROW-12311 as well.\u00a0 \r\n\r\nStill having examples of simple arrow+dplyr operations crash on the above dataset.\u00a0"
        },
        {
            "created_at": "2022-05-02T21:36:22.228Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17530949) by Weston Pace (westonpace):*\n8.0.0 should behave better when it comes to reading large parquet datasets and OOM (ARROW-15410).  If you have a chance to test out one of the RCs and see if it prevents the crash I'd be grateful.\r\n\r\nARROW-12311 is on my personal development roadmap for 9.0.0 but I can't promise anything.\r\n\r\nI unfortunately did not put in a short term fix for `count()` queries in 8.0.0."
        },
        {
            "created_at": "2022-05-02T22:29:05.926Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17530962) by Carl Boettiger (cboettig):*\nThanks Weston, I'll try that.\u00a0 Just to make sure I'm testing the right thing, it will suffice to test the nightlies,\u00a0\r\narrow-7.0.0.20220501\r\nWith that version I still see high RAM use that leads to a crash (ie. after it exceeds the 50 GB RAM I allocate to my container), e.g. which should be reproducible with this example:\r\n```java\n\r\n##\u00a0\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\npackageVersion(\"arrow\")\r\npath <- arrow::s3_bucket(\"ebird/Mar-2022/observations\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0endpoint_override = \"minio.carlboettiger.info\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0anonymous=TRUE)\r\nobs <- arrow::open_dataset(path)\u00a0\n```\r\n```java\n\r\ntmp <- obs |>\u00a0\r\n\u00a0 group_by(sampling_event_identifier, scientific_name) |>\r\n\u00a0 summarize(count = sum(observation_count, na.rm=TRUE),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .groups = \"drop\")\u00a0\r\ntmp <- tmp |> compute() # crashes\r\n \n```"
        },
        {
            "created_at": "2022-05-02T23:15:37.089Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17530967) by Weston Pace (westonpace):*\nThat should be new enough.  I'll try and reproduce and see what's going on."
        },
        {
            "created_at": "2022-05-03T04:18:16.457Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17531027) by Weston Pace (westonpace):*\nI'm going to keep looking into this but this doesn't seem to be backpressure related.  However, I think we are using more memory than we should be.  I haven't yet pinpointed what is using the memory.  It's possible there is some kind of per-batch leak that is cleaned up when the plan is destroyed.  I'm going to try and play more with this tomorrow."
        },
        {
            "created_at": "2022-05-04T03:03:42.835Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17531476) by Weston Pace (westonpace):*\nOne mystery solved, a few more remained, I managed to pinpoint the memory usage in my reproduction.  When we scan parquet files we store the metadata in the parquet fragment.  At one time this was added to make it slightly quicker to re-read the dataset because all of the metadata information is cached.  However:\r\n\r\n \\* Parquet is the only format to do this despite the fact that all formats follow a similar pattern\r\n \\* There is no way to turn this off\r\n \\* Parquet metadata can be surprisingly large (~10MB per file in your dataset)\r\n\r\nI've created ARROW-16451 to track this.\r\n\r\nIf I turn this off (clear the metadata from the fragment when we are done scanning it) then the following query uses, at most, 292MB of RSS:\r\n```\n\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\npackageVersion(\"arrow\")\r\npath <- arrow::s3_bucket(\"ebird/Mar-2022/observations\",\r\n                         endpoint_override = \"minio.carlboettiger.info\",\r\n                         anonymous=TRUE)\r\nobs <- arrow::open_dataset(path)\r\n\r\ntmp <- obs |> summarize(count = sum(observation_count, na.rm=TRUE), .groups = \"drop\") \r\nprint(tmp |> collect(as_data_frame=FALSE))\r\n```\r\n\r\nIf I run the query that you have posted (e.g. with the group-by) I see considerably more memory usage.  Some of this is expected because I now need to keep track of the key values for the groups and there are quite a few unique key combinations.  For example, from the first 20 files (~20 million rows):\r\n\r\n```\n\r\n# A tibble: 19,997,847 \u00d7 3\r\n   sampling_event_identifier scientific_name       count\r\n   <chr>                     <chr>                 <int>\r\n 1 S59303569                 Butorides striata         2\r\n 2 S67152642                 Calidris alpina           1\r\n 3 S51998273                 Setophaga virens          1\r\n 4 S58666072                 Hirundo rustica           8\r\n 5 S61157542                 Laniarius major           0\r\n 6 S22508263                 Leiothlypis peregrina     0\r\n 7 S16296356                 Pluvialis squatarola      0\r\n 8 S47732847                 Progne subis             25\r\n 9 S10054205                 Dendrocygna bicolor       0\r\n10 S48511589                 Empidonax traillii        1\r\n```\r\n\r\nSome of this is freed after garbage collection (ARROW-16452)\r\n\r\nAfter I run gc() then I get the amount of memory I would expect (e.g. arrow::default_memory_pool()::bytes_allocated == collected_dataframe$nbytes) but RSS still seems a little large.  I may do a touch more investigation there."
        },
        {
            "created_at": "2022-05-04T14:37:59.366Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17531751) by Carl Boettiger (cboettig):*\nThanks Weston, sounds promising!\u00a0 Hmm... in this particular case I have control of the serialization (the official eBird is distributed as a single giant tab-separated values file inside a tarball), so I wonder if this suggests tweaks I can do on my end.\u00a0 Previously I was actually serializing into a single parquet file, which would suggest lower memory use due to the metadata cache you mention.\u00a0\r\n\r\nWould it be possible to serialize the metadata cache to a parquet file in tempdir rather than turning it off?\u00a0 (Not sure if it really would improve things, but it seems impossibly magical that arrow can do these operations without write operations and in small memory).\u00a0\r\n\r\nNot sure if it is relevant, but I have identical OOM issues doing this in pure duckdb (with local copies of the parquet), see <https://github.com/duckdb/duckdb/issues/3554.>\u00a0 Hannes suggests that on the duckdb side that is expected since some operations are not yet done \"out-of-core\" (and suggests a similar issue impacts Arrow I think?)\r\n\r\n\u00a0\r\n\r\nAnyway thanks again for your sluething here!"
        },
        {
            "created_at": "2022-05-04T15:17:16.527Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17531783) by Weston Pace (westonpace):*\nMoving to one file instead of many files will save you ~10-11GB of RAM today.  I don't know if that is enough to prevent a crash.\r\n\r\nSerializing the metadata cache should be possible.  I think there is a bigger question around whether or not we should either invent a serialization format for the datasets API or adopt some kind of existing format (there is some discussion of this at ARROW-15317)\r\n\r\nI would guess the out-of-core part Hannes is referring to is keeping track of the group identities.  The `group_by(sampling_event_identifier, scientific_name)` operation is the culprit here.  If there are millions / billions of combinations of `(sampling_event_identifier, scientific_name)` then the output table is going to be very large.  That is where the bulk of the memory usage is in your query.\r\n\r\nWe also cannot stream the output because the very last row of your data might just happen to be in the same group as the very first row of your data.  So we don't know that our `count` is correct until we've seen every single row.\r\n\r\nThere are a few ways around this inability to stream but these are longer term goals.\r\n\r\nWe can spill the groupings to disk as we perform the query.  If the last row does happen to belong in the first group we saw then we have to load it back from disk, update it, and put it back on disk.  Once we've seen all the rows we can stream the result from our temporary disk storage.  This is what I assume Hannes is referring to when he describes an out-of-core operator.\r\n\r\nAnother approach we could take involves sorting/partitioning.  If the incoming data is sorted or partitioned by one of those two columns then we could emit results early.  For example, if we know that the incoming data is sorted on sampling_event_identifier then as soon as we stop seeing some sampling event (e.g. we've finished reading S10054205) we know that we can emit all combinations of `(S10054205, scientific_name)`.\r\n\r\nOf course, if you are doing `|> collect()` to collect the entire result into memory it won't make much difference.  However, if you're able to process results incrementally, then either of these two approaches could allow you to run this query with much less RAM."
        },
        {
            "created_at": "2022-05-04T17:18:51.406Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17531857) by Carl Boettiger (cboettig):*\nThanks, this is super.\u00a0\u00a0 Right, I have no need for `collect()` on this, in general it is pretty easy to postpone doing any collect() until later filter / summarize operations have further shrunk the data down to size; so this example is just an illustrative initial step.\u00a0 (this one is actually a standard pre-processing step in the eBird data, it merely aggregates subspecies counts into species-level counts; since most analyses focus on the species level.\u00a0 most such analyses would then do further subsetting/aggregation). \u00a0 \u00a0 I am used to using `compute()` with dplyr+duckdb to force the computation to occur without reading results into RAM in R; not sure if that's meaningful in arrow's streaming context though?\u00a0 I try instead doing something like calling head() before collect(), to limit the size of the R object, but this still quickly exceeds my 50 GB allocation and crashes.\u00a0 I rebuilt the parquet file collection to be 5x larger (i.e. 5e6 lines per file), but still even asking for head() on the above summarize operation exceeds my 50 GB RAM and crashes the R session.\r\n\r\nI'm very intrigued by the ability to spill onto disk, since that seems the most general strategy for these operations.\u00a0 Naively, I would think that should not be too rate-limiting in examples like this, since most users would have a faster disk I/O then network I/O?\u00a0 In general, taking a performance hit (and the required free disk space) for some disk operations would be acceptable in order to still be able to work with data like this that is much larger than available RAM. (i.e. in a one-off case for the above calculation, I guess I could manually iterate over each parquet file separately, but that seems very cumbersome compared to arrow...)\r\n\r\nNot sure if it should make a difference, but I tried the above with local set of parquet files rather than using the S3 network access, but experience the same issue.\u00a0"
        },
        {
            "created_at": "2022-05-09T19:23:29.417Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17533976) by Carl Boettiger (cboettig):*\nJust a note that even with a single parquet file I see the same crash after exceeding my 50 GB RAM, so I don't think the parquet per-file-metadata is the main culprit here?\u00a0 Probably the group-identities tracking like you say.\u00a0 Is it possible for arrow to use the local disk for this instead of attempting to keep all this in RAM?\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-05-09T20:05:38.283Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17534002) by Weston Pace (westonpace):*\nYes, the per-file metadata was only accounting for around 10GB.  There is another chunk potentially being wasted in ARROW-16452 but it is a bit more difficult to tell exactly how much but it won't be that significant.  So you are correct, the group-identities themselves are the main culprit here.\r\n\r\nYes, it is possible to use the local disk, but not trivial :)\r\n\r\nAt the moment I think someone is looking into ARROW-14163 which adds this to the join node.  My hope is that adding disk spilling to join will cover a lot of the ground needed to add disk spilling to group-by.\r\n\r\nCC `[~sakras]`"
        },
        {
            "created_at": "2022-05-09T20:16:08.369Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17534007) by Sasha Krassovsky (sakras):*\nI'm not actually sure how applicable Join's spilling is to GroupBy's, since GroupBy spilling involves spilling the hash table while Join spills batches before building hash table.\u00a0"
        },
        {
            "created_at": "2022-08-26T16:05:52.719Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15081?focusedCommentId=17585504) by @toddfarmer:*\nThis issue was last updated over 90 days ago, which may be an indication it is no longer being actively worked. To better reflect the current state, the issue is being unassigned per [project policy](https://arrow.apache.org/docs/dev/developers/bug_reports.html#issue-assignment). Please feel free to re-take assignment of the issue if it is being actively worked, or if you plan to start that work soon."
        }
    ]
}