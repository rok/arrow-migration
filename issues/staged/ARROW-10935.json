{
    "issue": {
        "title": "[Python] pa.array() doesn't support pa.lib.TimestampScalar objects",
        "body": "***Note**: This issue was originally created as [ARROW-10935](https://issues.apache.org/jira/browse/ARROW-10935). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI encountered this edge case bug in PyArrow v2.0.0. For some reason, pa.array() does not know how to support pa.lib.TimestampScalar objects. This bug completely blocks my specific use case, although I do recognize that this edge case seems kind of wonky. Nonetheless, I don't see any reason why PyArrow would not understand one of it's own object types.\r\n\r\n\u00a0\r\n\r\nStacktrace:\r\n```java\n\r\nArrowInvalid: Could not convert 2020-11-04 22:50:16.276892 with type pyarrow.lib.TimestampScalar: did not recognize Python value type when inferring an Arrow data type\r\n```\r\n\u00a0\r\n\r\nReproducible Code:\r\n```java\n\r\nimport pandas as pd\r\nimport pyarrow as pa\r\n\r\npa.array([pa.scalar(pd.to_datetime('2020-11-04 22:50:16.276892000'))])\r\n```",
        "created_at": "2020-12-16T04:04:47.000Z",
        "updated_at": "2020-12-16T16:33:52.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-12-16T08:44:16.000Z"
    },
    "comments": [
        {
            "created_at": "2020-12-16T08:43:34.773Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10935?focusedCommentId=17250173) by Joris Van den Bossche (jorisvandenbossche):*\nIndeed, our own scalars are at the moment not supported. See ARROW-5295 for a general issue about this (so will close this issue as a duplicate of that).\r\n\r\n> This bug completely blocks my specific use case\r\n\r\nCan you explain a bit how it completely blocks you? I understand it can be annoying, but normally you should always be able to convert to pyarrow scalars to python objects before passing them to `pa.array([..])` ?"
        },
        {
            "created_at": "2020-12-16T16:33:52.461Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10935?focusedCommentId=17250439) by slatebit (slatebit):*\nHi Joris,\r\n\r\nThanks for the reply. Apologies on my end for not finding that duplicate report. Regarding it blocking my use case, I'm using the Python library Vaex. Under the hood, it relies on PyArrow as one of it's supported backends. One of its key features is lazy evaluation in that columns/features are saved as expressions and only evaluated when necessary, such as printing out the dataframe.\r\n\r\nCurrently, Vaex is built in such a way that it will if a column is a PyArrow array or chunked array, it does not do any type conversions and assumes that PyArrow will handle everything. This assumption led to this bug report. However, given your proposed solution, I'll bring this up with the Vaex team via a GitHub issue. Appreciate your help!"
        }
    ]
}