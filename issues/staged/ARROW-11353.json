{
    "issue": {
        "title": "[C++][Python][Parquet] We should allow for overriding to  types by providing a schema",
        "body": "***Note**: This issue was originally created as [ARROW-11353](https://issues.apache.org/jira/browse/ARROW-11353). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n`The following shouldn't throw`\r\n\r\n`>>> import pyarrow as pa`\r\n`>>> import pyarrow.parquet as pq`\r\n`>>> import pyarrow.dataset as ds`\r\n`>>> pa.__version__`\r\n`'2.0.0'`\r\n`>>> schema = pa.schema([pa.field(\"utf8\", pa.utf8())])`\r\n`>>> table = pa.Table.from_pydict(\\{\"utf8\": [\"foo\", \"bar\"]}, schema)`\r\n`>>> pq.write_table(table, \"/tmp/example.parquet\")`\r\n`>>> large_schema = pa.schema([pa.field(\"utf8\", pa.large_utf8())])`\r\n`>>> ds.dataset(\"/tmp/example.parquet\", schema=large_schema,`\r\n`format=\"parquet\").to_table()`\r\n`Traceback (most recent call last):`\r\n`\u00a0 File \"<stdin>\", line 1, in <module>`\r\n`\u00a0 File \"pyarrow/_dataset.pyx\", line 405, in`\r\n`pyarrow._dataset.Dataset.to_table`\r\n`\u00a0 File \"pyarrow/_dataset.pyx\", line 2262, in`\r\n`pyarrow._dataset.Scanner.to_table`\r\n`\u00a0 File \"pyarrow/error.pxi\", line 122, in`\r\n`pyarrow.lib.pyarrow_internal_check_status`\r\n`\u00a0 File \"pyarrow/error.pxi\", line 107, in pyarrow.lib.check_status`\r\n`pyarrow.lib.ArrowTypeError: fields had matching names but differing types.`\r\n`From: utf8: string To: utf8: large_string`",
        "created_at": "2021-01-23T03:48:08.000Z",
        "updated_at": "2021-02-06T23:21:38.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-01-25T09:23:47.709Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11353?focusedCommentId=17271190) by Joris Van den Bossche (jorisvandenbossche):*\nNote that in general, we don't have any functionality exposed in the python parquet bindings to override the type used when reading specific columns (I don't know to what extent this actually exists in the C++ layer). So this is not an issue specific to the large types. Now for the large types, it might be that this can be done more efficiently in the C++ layer than \"just\" casting afterwards?\r\n\r\nFor the Dataset API (what the example above is using): this is a known limitation right now that the schema has to match exactly, and almost no schema evolution is allowed (only from null -> any type). See ARROW-11003 for an umbrella issue for this (eg we also want to allow to read int32 columns as int64)."
        },
        {
            "created_at": "2021-02-06T23:21:38.933Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11353?focusedCommentId=17280330) by Micah Kornfield (emkornfield):*\nChanged the title to make this more general.\u00a0 I think doing this at load time would save work.\u00a0 Not sure how much of a performance impact it would have vs casting."
        }
    ]
}