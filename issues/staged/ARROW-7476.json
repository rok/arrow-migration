{
    "issue": {
        "title": "[Python] Arrow error: IOError: Error reading bytes from file: No error",
        "body": "***Note**: This issue was originally created as [ARROW-7476](https://issues.apache.org/jira/browse/ARROW-7476). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nwhen I try to read a parquet file using either Pandas or dask, I get error following error:\r\n\r\nArrow error: IOError: Error reading bytes from file: No error. However, when I try again to read the file, sometime I'm able to read the file. Below are the command I used to read the parquet file.\r\n\r\nwith dask\r\n\r\ndd.read_parquet('my.parquet', engine='pyarrow',compression='snappy').compute()\r\n\r\n<font color=\"#172b4d\">pd.read_parquet('my.parquet', engine='pyarrow',compression='snappy')</font>\r\n\r\n\u00a0",
        "created_at": "2019-12-30T13:28:32.000Z",
        "updated_at": "2020-04-27T02:44:30.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-04-27T02:44:30.000Z"
    },
    "comments": [
        {
            "created_at": "2019-12-30T15:50:24.409Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7476?focusedCommentId=17005411) by Neal Richardson (npr):*\nThanks for the report. Can you provide a file that reproduces this issue?"
        },
        {
            "created_at": "2020-01-07T18:55:11.961Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7476?focusedCommentId=17009987) by Gaurav vashisth (grv1207):*\nHi, The file quite big to share around which has 12 million records having 11 columns. What I have seen is that this error happens only with a large set of records(>1millions) as I'm also working with a small dataset(1k,10k,100k), where it works fine. However, if I try again after some time I can read in the same file with 12 million again."
        },
        {
            "created_at": "2020-01-08T07:50:01.630Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7476?focusedCommentId=17010445) by gaurav vashisth (gaurav.vashisth1207@gmail.com):*\nUPDATE: This error can occur in the file having having 1 million records as well.\u00a0"
        },
        {
            "created_at": "2020-01-08T18:17:16.152Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7476?focusedCommentId=17010891) by Wes McKinney (wesm):*\nThat doesn't seem so big. If the data is not sensitive can you share it?"
        },
        {
            "created_at": "2020-04-27T02:44:30.856Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7476?focusedCommentId=17092949) by Wes McKinney (wesm):*\nClosing. If you can provide a way for us to reproduce the issue (such as a sample file) please reopen the issue. Thanks!"
        }
    ]
}