{
    "issue": {
        "title": "[Rust] [Parquet] Extend arrow schema conversion to projected fields",
        "body": "***Note**: This issue was originally created as [ARROW-10168](https://issues.apache.org/jira/browse/ARROW-10168). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen writing Arrow data to Parquet, we serialise the schema's IPC representation. This schema is then read back by the Parquet reader, and used to preserve the array type information from the original Arrow data.\r\n\r\nWe however do not rely on the above mechanism when reading projected columns from a Parquet file; i.e. if we have a file with 3 columns, but we only read 2 columns, we do not yet rely on the serialised arrow schema; and can thus lose type information.\r\n\r\nThis behaviour was deliberately left out, as the function\u00a0\r\n**parquet_to_arrow_schema_by_columns** does not check for the existence of arrow schema in the metadata.",
        "created_at": "2020-10-03T07:33:47.000Z",
        "updated_at": "2021-01-16T21:38:59.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Rust",
            "Type: task"
        ],
        "closed": true,
        "closed_at": "2020-10-07T22:17:03.000Z"
    },
    "comments": [
        {
            "created_at": "2020-10-07T22:17:03.539Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10168?focusedCommentId=17209899) by Neville Dipale (nevi_me):*\nIssue resolved by pull request 8354\n<https://github.com/apache/arrow/pull/8354>"
        }
    ]
}