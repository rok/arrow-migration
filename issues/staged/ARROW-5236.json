{
    "issue": {
        "title": "[Python] hdfs.connect() is trying to load libjvm in windows",
        "body": "***Note**: This issue was originally created as [ARROW-5236](https://issues.apache.org/jira/browse/ARROW-5236). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThis issue was originally reported at <https://github.com/apache/arrow/issues/4215>\u00a0. Raising a Jira as per\u00a0Wes McKinney's request.\r\n\r\nSummary:\r\n The following script\r\n```Java\n\r\n$ cat expt2.py\r\nimport pyarrow as pa\r\nfs = pa.hdfs.connect()\r\n```\r\ntries to load libjvm in windows 7 which is not expected.\r\n```\n\r\n$ python ./expt2.py\r\nTraceback (most recent call last):\r\n  File \"./expt2.py\", line 3, in <module>\r\n    fs = pa.hdfs.connect()\r\n  File \"C:\\ProgramData\\Continuum\\Anaconda\\envs\\scratch_py36_pyarrow\\lib\\site-packages\\pyarrow\\hdfs.py\", line 183, in connect\r\n    extra_conf=extra_conf)\r\n  File \"C:\\ProgramData\\Continuum\\Anaconda\\envs\\scratch_py36_pyarrow\\lib\\site-packages\\pyarrow\\hdfs.py\", line 37, in __init__\r\n    self._connect(host, port, user, kerb_ticket, driver, extra_conf)\r\n  File \"pyarrow\\io-hdfs.pxi\", line 89, in pyarrow.lib.HadoopFileSystem._connect\r\n  File \"pyarrow\\error.pxi\", line 83, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowIOError: Unable to load libjvm\r\n```\r\nThere is no libjvm file in Windows Java installation.\r\n```\n\r\n$ echo $JAVA_HOME\r\nC:\\Progra~1\\Java\\jdk1.8.0_141\r\n\r\n$ find $JAVA_HOME -iname '*libjvm*'\r\n<returns nothing.>\r\n```\r\nI see the libjvm error with both 0.11.1 and 0.13.0 versions of pyarrow.\r\n\r\nSteps to reproduce the issue (with more details):\r\n\r\nCreate the environment\r\n```\n\r\n$ cat scratch_py36_pyarrow.yml\r\nname: scratch_py36_pyarrow\r\nchannels:\r\n  - defaults\r\ndependencies:\r\n  - python=3.6.8\r\n  - pyarrow\r\n```\r\n```\n\r\n$ conda env create -f scratch_py36_pyarrow.yml\r\n```\r\nApply the following patch to lib/site-packages/pyarrow/hdfs.py . I had to do this since the Hadoop installation that comes with MapR <<https://mapr.com/>> windows client only has $HADOOP_HOME/bin/hadoop.cmd . There is no file named $HADOOP_HOME/bin/hadoop and so the subsequent subprocess.check_output call fails with FileNotFoundError if this patch is not applied.\r\n```\n\r\n$ cat ~/x/patch.txt\r\n131c131\r\n<         hadoop_bin = '{0}/bin/hadoop'.format(os.environ['HADOOP_HOME'])\r\n---\r\n>         hadoop_bin = '{0}/bin/hadoop.cmd'.format(os.environ['HADOOP_HOME'])\r\n\r\n$ patch /c/ProgramData/Continuum/Anaconda/envs/scratch_py36_pyarrow/lib/site-packages/pyarrow/hdfs.py ~/x/patch.txt\r\npatching file /c/ProgramData/Continuum/Anaconda/envs/scratch_py36_pyarrow/lib/site-packages/pyarrow/hdfs.py\r\n```\r\nActivate the environment\r\n```\n\r\n$ source activate scratch_py36_pyarrow\r\n```\r\nSample script\r\n```\n\r\n$ cat expt2.py\r\nimport pyarrow as pa\r\nfs = pa.hdfs.connect()\r\n```\r\nExecute the script\r\n```\n\r\n$ python ./expt2.py\r\nTraceback (most recent call last):\r\n  File \"./expt2.py\", line 3, in <module>\r\n    fs = pa.hdfs.connect()\r\n  File \"C:\\ProgramData\\Continuum\\Anaconda\\envs\\scratch_py36_pyarrow\\lib\\site-packages\\pyarrow\\hdfs.py\", line 183, in connect\r\n    extra_conf=extra_conf)\r\n  File \"C:\\ProgramData\\Continuum\\Anaconda\\envs\\scratch_py36_pyarrow\\lib\\site-packages\\pyarrow\\hdfs.py\", line 37, in __init__\r\n    self._connect(host, port, user, kerb_ticket, driver, extra_conf)\r\n  File \"pyarrow\\io-hdfs.pxi\", line 89, in pyarrow.lib.HadoopFileSystem._connect\r\n  File \"pyarrow\\error.pxi\", line 83, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowIOError: Unable to load libjvm\r\n```",
        "created_at": "2019-04-29T15:25:32.000Z",
        "updated_at": "2021-06-22T15:11:20.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-06-22T15:11:20.000Z"
    },
    "comments": [
        {
            "created_at": "2019-06-04T13:06:13.094Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5236?focusedCommentId=16855674) by Urmila (urmilarv):*\nHi, I am also facing same issue. I have conda and spark installed on my local windows machine and trying to connect HDFS (unix) as mentioned below\r\n\r\nimport pyarrow as pa\r\nfs = pa.hdfs.connect('hostname.xx.xx.com', port_number, user='abc@xyx.COM', kerb_ticket='local machine path')\r\nTraceback (most recent call last):\r\nFile \"\", line 1, in \r\nFile \"C:\\Users\\vishurm\\opt\\miniconda3\\lib\\site-packages\\pyarrow\\hdfs.py\", line\r\n183, in connect\r\nextra_conf=extra_conf)\r\nFile \"C:\\Users\\vishurm\\opt\\miniconda3\\lib\\site-packages\\pyarrow\\hdfs.py\", line\r\n37, in init\r\nself._connect(host, port, user, kerb_ticket, driver, extra_conf)\r\nFile \"pyarrow\\io-hdfs.pxi\", line 89, in pyarrow.lib.HadoopFileSystem._connect\r\nFile \"pyarrow\\error.pxi\", line 83, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowIOError: Unable to load libjvm"
        },
        {
            "created_at": "2019-11-18T05:28:14.978Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5236?focusedCommentId=16976293) by Sujeet-A (sujeet-a.hinge@db.com):*\nI am also facing the same issue on Windows 7 Professional.\r\n\r\nDo we have any update on the resolution ?\r\n\r\n\u00a0"
        },
        {
            "created_at": "2020-05-14T04:49:17.760Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5236?focusedCommentId=17106888) by lifan (vgoah):*\nI looked the hdfs_internal.cc file and find out the bug beacuse it using #ifdef __WIN32 define but maybe failure on win64 platform, bynow if you do not want to rebuild arrow cpp, you can mkdir %JAVA_HOME%\\lib\\server , and copy jvm.dll to there then renmae it to libjvm.so , also you must rename hdfs.dll to libhdfs.so in %HADOOP_HOME%\\bin dir or cp hdfs.dll to %HADOOP_HOME%\\lib\\native\\ and rename it to libhdfs.so\r\n\r\nI use this method to success using pyarrow.hdfs.connect()"
        },
        {
            "created_at": "2020-07-30T13:58:25.345Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5236?focusedCommentId=17167943) by Michael Peleshenko (mpeleshenko):*\nI've been having trouble connecting to HDFS even with the 1.0.0 pyarrow build as I run into the below error when running:\r\n\r\n```python\n\r\npa.hdfs.connect(host=\"host\", port=port, user=\"user\", kerb_ticket=\"kerb_ticket\")\r\n```\r\n\r\n```\n\r\n  File \"C:\\ProgramData\\Continuum\\Anaconda\\envs\\pyarrow-test\\lib\\site-packages\\pyarrow\\hdfs.py\", line 210 in connect\r\n    extra_conf=extra_conf)\r\n  File \"C:\\ProgramData\\Continuum\\Anaconda\\envs\\pyarrow-test\\lib\\site-packages\\pyarrow\\hdfs.py\", line 40, in __init__\r\n    self._connect(host, port, user, kerb_ticket, extra_conf)\r\n  File \"pyarrow\\io-hdfs.pxi\", line 75, in pyarrow.lib.HadoopFileSystem._connect\r\n  File \"pyarrow\\error.pxi\", line 99, in pyarrow.lib.check_status\r\nOSError: Unable to load libjvm: The specified module could not be found.\r\n```\r\n\r\nI tried the workaround mentioned [here](https://issues.apache.org/jira/browse/ARROW-5236?focusedCommentId=17106888&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17106888) and got it working by copying jvm.dll into %JAVA_HOME%\\lib\\server\\libjvm.so. It seems the logic to find libjvm is following a Linux path for some reason.\r\n\r\nLooking into the arrow internals, I came across this:\r\nhttps://github.com/apache/arrow/blob/b0d623957db820de4f1ff0a5ebd3e888194a48f0/cpp/src/arrow/io/hdfs_internal.cc#L176-L180\r\n\r\nThis looks like the same issue observed in ARROW-1003, except that one was for libhdfs. In my situation, libhdfs is found as expected as hdfs.dll, so Windows logic is definitely followed there.\r\nhttps://github.com/apache/arrow/blob/b0d623957db820de4f1ff0a5ebd3e888194a48f0/cpp/src/arrow/io/hdfs_internal.cc#L144-L145\r\n\r\nI suspect a similar fix is needed here to change `__WIN32` to `_WIN32`."
        },
        {
            "created_at": "2021-06-22T15:07:14.159Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5236?focusedCommentId=17367436) by Antoine Pitrou (apitrou):*\nSorry, I hadn't noticed this issue. `[~mpeleshenko]`, thanks for the find. I agree `__WIN32` (with two underscores) looks like a typo..."
        },
        {
            "created_at": "2021-06-22T15:10:04.146Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5236?focusedCommentId=17367440) by Antoine Pitrou (apitrou):*\nAh, looks like this was already fixed in ARROW-11642."
        },
        {
            "created_at": "2021-06-22T15:11:20.128Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5236?focusedCommentId=17367441) by Antoine Pitrou (apitrou):*\nI **think** this is just a duplicate of ARROW-11642 and am closing as such.\r\n\r\nIf it still doesn't work with Arrow 4.0.1 or later, feel free to ping on this issue."
        }
    ]
}