{
    "issue": {
        "title": "[C++][Python] Regression reading partition keys of large batches.",
        "body": "***Note**: This issue was originally created as [ARROW-15318](https://issues.apache.org/jira/browse/ARROW-15318). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIn a partitioned dataset with chunks larger than the default 1Mi batch size, reading _only_ the partition keys is hanging, and consuming unbounded memory. The bug first appeared in nightly build `7.0.0.dev468`.\r\n```python\n\r\nIn [1]: import pyarrow as pa, pyarrow.parquet as pq, numpy as np\r\n\r\nIn [2]: pa.__version__\r\nOut[2]: '7.0.0.dev468'\r\n\r\nIn [3]: table = pa.table({'key': pa.repeat(0, 2 ** 20 + 1), 'value': np.arange(2 ** 20 + 1)})\r\n\r\nIn [4]: pq.write_to_dataset(table[:2 ** 20], 'one', partition_cols=['key'])\r\n\r\nIn [5]: pq.write_to_dataset(table[:2 ** 20 + 1], 'two', partition_cols=['key'])\r\n\r\nIn [6]: pq.read_table('one', columns=['key'])['key'].num_chunks\r\nOut[6]: 1\r\n\r\nIn [7]: pq.read_table('two', columns=['key', 'value'])['key'].num_chunks\r\nOut[7]: 2\r\n\r\nIn [8]: pq.read_table('two', columns=['key'])['key'].num_chunks\r\nzsh: killed     ipython # hangs; kllled\r\n```",
        "created_at": "2022-01-13T05:09:38.000Z",
        "updated_at": "2022-01-14T20:41:37.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-01-13T20:45:13.000Z"
    },
    "comments": [
        {
            "created_at": "2022-01-13T20:45:13.924Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15318?focusedCommentId=17475726) by David Li (lidavidm):*\nIssue resolved by pull request 12147\n<https://github.com/apache/arrow/pull/12147>"
        }
    ]
}