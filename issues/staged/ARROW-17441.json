{
    "issue": {
        "title": "[Python] Memory kept after del and pool.released_unused()",
        "body": "***Note**: This issue was originally created as [ARROW-17441](https://issues.apache.org/jira/browse/ARROW-17441). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI was trying reproduce another issue involving memory pools not releasing memory, but encountered this confusing behavior: if I create a table, then call `{}del table{`}, and then `{}pool.release_unused(){`}, I still see significant memory usage. On mimalloc in particular, I see no meaningful drop in memory usage on either call.\r\n\r\nAm I missing something? My understanding prior has been that memory will be held onto by a memory pool, but will be forced free by release_unused; and that system memory pool should release memory immediately. But neither of those seem true.\r\n```python\n\r\nimport os\r\nimport psutil\r\nimport time\r\nimport gc\r\nprocess = psutil.Process(os.getpid())\r\nimport numpy as np\r\nfrom uuid import uuid4\r\n\r\n\r\nimport pyarrow as pa\r\n\r\ndef gen_batches(n_groups=200, rows_per_group=200_000):\r\n    for _ in range(n_groups):\r\n        id_val = uuid4().bytes\r\n        yield pa.table({\r\n            \"x\": np.random.random(rows_per_group), # This will compress poorly\r\n            \"y\": np.random.random(rows_per_group),\r\n            \"a\": pa.array(list(range(rows_per_group)), type=pa.int32()), # This compresses with delta encoding\r\n            \"id\": pa.array([id_val] * rows_per_group), # This compresses with RLE\r\n        })\r\n\r\ndef print_rss():\r\n    print(f\"RSS: {process.memory_info().rss:,} bytes\")\r\n\r\nprint(f\"memory_pool={pa.default_memory_pool().backend_name}\")\r\nprint_rss()\r\nprint(\"reading table\")\r\ntab = pa.concat_tables(list(gen_batches()))\r\nprint_rss()\r\nprint(\"deleting table\")\r\ndel tab\r\ngc.collect()\r\nprint_rss()\r\nprint(\"releasing unused memory\")\r\npa.default_memory_pool().release_unused()\r\nprint_rss()\r\nprint(\"waiting 10 seconds\")\r\ntime.sleep(10)\r\nprint_rss()\r\n```\r\n```none\n\r\n> ARROW_DEFAULT_MEMORY_POOL=mimalloc python test_pool.py && \\\r\n    ARROW_DEFAULT_MEMORY_POOL=jemalloc python test_pool.py && \\\r\n    ARROW_DEFAULT_MEMORY_POOL=system python test_pool.py\r\nmemory_pool=mimalloc\r\nRSS: 44,449,792 bytes\r\nreading table\r\nRSS: 1,819,557,888 bytes\r\ndeleting table\r\nRSS: 1,819,590,656 bytes\r\nreleasing unused memory\r\nRSS: 1,819,852,800 bytes\r\nwaiting 10 seconds\r\nRSS: 1,819,852,800 bytes\r\nmemory_pool=jemalloc\r\nRSS: 45,629,440 bytes\r\nreading table\r\nRSS: 1,668,677,632 bytes\r\ndeleting table\r\nRSS: 698,400,768 bytes\r\nreleasing unused memory\r\nRSS: 699,023,360 bytes\r\nwaiting 10 seconds\r\nRSS: 699,023,360 bytes\r\nmemory_pool=system\r\nRSS: 44,875,776 bytes\r\nreading table\r\nRSS: 1,713,569,792 bytes\r\ndeleting table\r\nRSS: 540,311,552 bytes\r\nreleasing unused memory\r\nRSS: 540,311,552 bytes\r\nwaiting 10 seconds\r\nRSS: 540,311,552 bytes\r\n```",
        "created_at": "2022-08-16T20:48:31.000Z",
        "updated_at": "2022-08-17T21:02:05.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-08-16T20:57:23.178Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17580468) by Antoine Pitrou (apitrou):*\nI must admit I don't understand the references to compression in your comments. Were you planning to use Parquet at some point?\r\n\r\nOther than that, Numpy-allocated memory does not use the Arrow memory pool, so I'm not sure those stats are very indicative. "
        },
        {
            "created_at": "2022-08-16T21:00:05.707Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17580471) by Will Jones (willjones127):*\n> I must admit I don't understand the references to compression in your comments. Were you planning to use Parquet at some point?\r\n\r\nSorry, I was testing memory usage from Parquet reads and seeing something like this, but decided to take Parquet out of the picture to simplify.\r\n\r\n> Other than that, Numpy-allocated memory does not use the Arrow memory pool, so I'm not sure those stats are very indicative.\r\n\r\nAh I think you are likely right there."
        },
        {
            "created_at": "2022-08-16T21:00:57.204Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17580472) by Will Jones (willjones127):*\nI reran this in PyArrow 7.0.0 and got results where mimalloc is more in line with the others, so I think mimalloc 2 is actually worse rather than better at releasing unused memory:\r\n\r\n```Java\n\r\n> ARROW_DEFAULT_MEMORY_POOL=mimalloc python test_pool.py && \\\r\n    ARROW_DEFAULT_MEMORY_POOL=jemalloc python test_pool.py && \\\r\n    ARROW_DEFAULT_MEMORY_POOL=system python test_pool.py\r\nmemory_pool=mimalloc\r\nRSS: 43,958,272 bytes\r\nreading table\r\nRSS: 1,728,200,704 bytes\r\ndeleting table\r\nRSS: 1,600,585,728 bytes\r\nreleasing unused memory\r\nRSS: 549,797,888 bytes\r\nwaiting 10 seconds\r\nRSS: 549,797,888 bytes\r\nmemory_pool=jemalloc\r\nRSS: 43,663,360 bytes\r\nreading table\r\nRSS: 1,663,483,904 bytes\r\ndeleting table\r\nRSS: 693,682,176 bytes\r\nreleasing unused memory\r\nRSS: 694,304,768 bytes\r\nwaiting 10 seconds\r\nRSS: 694,304,768 bytes\r\nmemory_pool=system\r\nRSS: 44,220,416 bytes\r\nreading table\r\nRSS: 1,667,072,000 bytes\r\ndeleting table\r\nRSS: 697,171,968 bytes\r\nreleasing unused memory\r\nRSS: 697,171,968 bytes\r\nwaiting 10 seconds\r\nRSS: 697,171,968 bytes\r\n```"
        },
        {
            "created_at": "2022-08-16T21:05:29.357Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17580473) by Weston Pace (westonpace):*\nMy suspicion would be that pa.total_allocated_bytes would be 0 (as @pitrou said, we are not using the Arrow memory pools here) and that remaining 500MB is fragmented data leftover in the system allocator.\r\n\r\nThat being said, it does beg the question why the system allocator isn't able to release the memory.  In other words, what's making up the fragments occupying those pages?  I'd guess it's some kind of python thing but it could possibly be some kind of global.  It's also maybe possible that the system allocator just doesn't try that hard to return data pages to the OS."
        },
        {
            "created_at": "2022-08-16T21:06:23.724Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17580474) by Weston Pace (westonpace):*\n{blockquote}\r\nI reran this in PyArrow 7.0.0 and got results where mimalloc is more in line with the others, so I think mimalloc 2 is actually worse rather than better at releasing unused memory:\r\n{blockquote}\r\n\r\nCan you print `pa.total_allocated_bytes` at the end to confirm it is zero?"
        },
        {
            "created_at": "2022-08-16T21:07:12.801Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17580475) by Will Jones (willjones127):*\nGoing back to my original test with Parquet, it does seem like there some long-standing issue with Parquet reads and mimalloc. And a regression with the system allocator on MacOS?\r\n\r\nHere is the original Parquet read test (so all buffers are allocated within Arrow, no numpy):\r\n```python\n\r\nimport os\r\nimport psutil\r\nimport time\r\nimport gc\r\nprocess = psutil.Process(os.getpid())\r\n\r\n\r\nimport pyarrow.parquet as pq\r\nimport pyarrow as pa\r\n\r\ndef print_rss():\r\n    print(f\"RSS: {process.memory_info().rss:,} bytes\")\r\n\r\npq_path = \"tall.parquet\"\r\n\r\nprint(f\"memory_pool={pa.default_memory_pool().backend_name}\")\r\nprint_rss()\r\nprint(\"reading table\")\r\ntab = pq.read_table(pq_path)\r\nprint_rss()\r\nprint(\"deleting table\")\r\ndel tab\r\ngc.collect()\r\nprint_rss()\r\nprint(\"releasing unused memory\")\r\npa.default_memory_pool().release_unused()\r\nprint_rss()\r\nprint(\"waiting 10 seconds\")\r\ntime.sleep(10)\r\nprint_rss()\r\nprint(f\"Total allocated bytes: {pa.total_allocated_bytes():,}\") \n```\r\nResult in PyArrow 7.0.0:\r\n```none\n\r\nARROW_DEFAULT_MEMORY_POOL=mimalloc python test_pool2.py && \\\r\n    ARROW_DEFAULT_MEMORY_POOL=jemalloc python test_pool2.py && \\\r\n    ARROW_DEFAULT_MEMORY_POOL=system python test_pool2.py\r\nmemory_pool=mimalloc\r\nRSS: 47,906,816 bytes\r\nreading table\r\nRSS: 2,077,507,584 bytes\r\ndeleting table\r\nRSS: 2,071,887,872 bytes\r\nreleasing unused memory\r\nRSS: 2,064,875,520 bytes\r\nwaiting 10 seconds\r\nRSS: 1,862,352,896 bytes\r\nTotal allocated bytes: 0\r\nmemory_pool=jemalloc\r\nRSS: 47,415,296 bytes\r\nreading table\r\nRSS: 2,704,965,632 bytes\r\ndeleting table\r\nRSS: 70,746,112 bytes\r\nreleasing unused memory\r\nRSS: 71,663,616 bytes\r\nwaiting 10 seconds\r\nRSS: 71,663,616 bytes\r\nTotal allocated bytes: 0\r\nmemory_pool=system\r\nRSS: 47,857,664 bytes\r\nreading table\r\nRSS: 2,705,408,000 bytes\r\ndeleting table\r\nRSS: 71,106,560 bytes\r\nreleasing unused memory\r\nRSS: 71,106,560 bytes\r\nwaiting 10 seconds\r\nRSS: 71,106,560 bytes\r\nTotal allocated bytes: 0 \n```\r\nResult in PyArrow 9.0.0:\r\n```none\n\r\n> ARROW_DEFAULT_MEMORY_POOL=mimalloc python test_pool2.py && \\\r\n    ARROW_DEFAULT_MEMORY_POOL=jemalloc python test_pool2.py && \\\r\n    ARROW_DEFAULT_MEMORY_POOL=system python test_pool2.py\r\nmemory_pool=mimalloc\r\nRSS: 48,037,888 bytes\r\nreading table\r\nRSS: 2,140,487,680 bytes\r\ndeleting table\r\nRSS: 2,149,711,872 bytes\r\nreleasing unused memory\r\nRSS: 2,142,273,536 bytes\r\nwaiting 10 seconds\r\nRSS: 1,710,981,120 bytes\r\nTotal allocated bytes: 0\r\nmemory_pool=jemalloc\r\nRSS: 48,136,192 bytes\r\nreading table\r\nRSS: 2,681,274,368 bytes\r\ndeleting table\r\nRSS: 71,942,144 bytes\r\nreleasing unused memory\r\nRSS: 72,908,800 bytes\r\nwaiting 10 seconds\r\nRSS: 72,908,800 bytes\r\nTotal allocated bytes: 0\r\nmemory_pool=system\r\nRSS: 48,005,120 bytes\r\nreading table\r\nRSS: 2,847,965,184 bytes\r\ndeleting table\r\nRSS: 1,440,071,680 bytes\r\nreleasing unused memory\r\nRSS: 1,440,071,680 bytes\r\nwaiting 10 seconds\r\nRSS: 1,440,071,680 bytes\r\nTotal allocated bytes: 0 \n```"
        },
        {
            "created_at": "2022-08-16T21:10:35.275Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17580476) by Antoine Pitrou (apitrou):*\n`ReleaseUnused()` for the system allocator is only implemented on glibc, it's a no-op on macOS. So no surprise you're not seeing any effect here."
        },
        {
            "created_at": "2022-08-16T21:17:50.500Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17580477) by Antoine Pitrou (apitrou):*\nApparently you can use the macOS `footprint` command-line utility to get interesting information about the memory heap of a process."
        },
        {
            "created_at": "2022-08-17T20:44:55.881Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17581015) by Weston Pace (westonpace):*\nReleaseUnused is also only going to apply to pool-allocated memory.  It appears here we are NOT dealing with pool-allocated memory since \"Total Allocated Bytes\" is 0.  So we shouldn't focus too much on mimalloc.  I suspect the culprit is plain old malloc.  However, a change in behavior in mimalloc **could** cause a change in behavior in malloc.  When reading parquet the pattern is roughly:\r\n\r\nLots of small flatbuffers allocations\r\nLarge buffer allocations\r\nLots of small flatbuffers allocations\r\nLarge buffer allocations\r\n\r\nSo if the \"Large buffer allocations\" changed in behavior it's possible for the interleaved non-buffer allocations to end up with different fragmentation.  Although this seems unlikely.  Maybe there are other things that changed between 8 and 9 like clang / glibc version / etc?\r\n\r\nThis theory is maybe reinforced by the fact that this only happens on Mac (is this correct?  I can't get this to reproduce on Ubuntu.  Maybe it is clang specific?).  Since mimalloc is probably fairly similar between mac and linux but the system allocator might not be so similar.  Debugging (and fixing) fragmentation is going to be pretty tricky.\r\n\r\nFirst, we should prove this is indeed a fragmentation issue.  I think it would be very helpful for our memory investigation efforts to have some kind of way to visualize or calculate the amount of fragmentation.  Sadly, I tried some brief googling and it looks like that might be a tricky task.  Maybe the simplest thing to do is replace the global allocator with jemalloc which has APIs that can dump a lot more detailed statistics.  However, doing this might itself fix the fragmentation since you're no longer using the standard allocator.\r\n"
        },
        {
            "created_at": "2022-08-17T21:02:05.829Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17441?focusedCommentId=17581027) by Weston Pace (westonpace):*\nI see now the original example was using numpy so there would be no such thing as \"flatbuffers allocations\" so maybe my reasoning isn't quite right.  Still, I think a good next step would be to measure the RAM used by the global allocator (i.e. the one that isn't managed by pyarrow)."
        }
    ]
}