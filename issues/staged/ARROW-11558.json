{
    "issue": {
        "title": "[C++] Push down projection and selection to S3 Select",
        "body": "***Note**: This issue was originally created as [ARROW-11558](https://issues.apache.org/jira/browse/ARROW-11558). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAmazon S3 Select [1], an S3 feature generally available since April 2018 [2], can improve S3 read performance by allowing S3 clients to use a limited subset of SQL to specify projection and selection [3] on data in some formats [4]. It would be interesting to try using this in Arrow and to measure its effects on S3 read performance under various conditions.\r\n\r\n[1]\u00a0<https://aws.amazon.com/blogs/aws/s3-glacier-select/>\r\n\r\n[2] <https://aws.amazon.com/about-aws/whats-new/2018/04/amazon-s3-select-is-now-generally-available/>\r\n\r\n[3]\u00a0<https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-glacier-select-sql-reference-select.html>\r\n\r\n[4]<https://docs.aws.amazon.com/cli/latest/reference/s3api/select-object-content.html>",
        "created_at": "2021-02-08T18:02:47.000Z",
        "updated_at": "2021-03-18T20:45:03.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-02-19T05:34:17.390Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11558?focusedCommentId=17286849) by Will Jones (willjones127):*\nI am also interested to see what situations s3 select is beneficial.\r\n\r\nHowever, I wonder which parts do you think should be part of the Arrow library?\r\n\r\nFrom what I can tell, the S3 Select endpoints give back a stream of JSON or CSV, which you could probably deserialize with the existing Arrow JSON and CSV readers. So this might be functionality you could build _using_ Arrow, rather than need to build _into_ Arrow. In fact, much of this might be more appropriate to have in [AWS Data Wrangler](https://github.com/awslabs/aws-data-wrangler), which already uses the Arrow library for reading parquet from S3."
        },
        {
            "created_at": "2021-02-26T15:06:49.521Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11558?focusedCommentId=17291696) by Ian Cook (icook):*\nThanks `[~willjones127]` \u2014yep, apparently the S3 Select output serialization formats are currently limited to CSV and JSON. I followed this chain of links to confirm this:\r\n1. S3 Select user guide:\u00a0<https://docs.aws.amazon.com/AmazonS3/latest/userguide/selecting-content-from-objects.html>\n1. SelectObjectContent API reference page:\u00a0<https://docs.aws.amazon.com/AmazonS3/latest/API/API_SelectObjectContent.html>\n1. OutputSerialization API reference page:\u00a0<https://docs.aws.amazon.com/AmazonS3/latest/API/API_OutputSerialization.html>\u00a0(see only CSV and JSON listed there)\n   \n   This combined with the limited set of object data file formats, encodings, and compression formats that S3 Select supports\u00a0certainly makes the practical applications of S3 Select within Arrow fairly narrow. However it might still be worth considering whether there are some cases in which it could improve the speed and cost of retrieving data from S3 in cases where Arrow is running outside AWS\u2014for example, in cases where the user wants to use Arrow to select very small numbers of records/fields from very large sets of data files. But it might be that the complexity of implementing this in Arrow is not warranted given the narrow range of practical applications.\n   \n   \u00a0"
        },
        {
            "created_at": "2021-03-18T20:45:03.094Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11558?focusedCommentId=17304441) by Ian Cook (icook):*\nAmazon S3 Object Lambda (announced today at https://aws.amazon.com/blogs/aws/introducing-amazon-s3-object-lambda-use-your-code-to-process-data-as-it-is-being-retrieved-from-s3/) seems like a better way to achieve the goals described here."
        }
    ]
}