{
    "issue": {
        "title": "[Python] Reading a dictionary column from Parquet results in disproportionate memory usage",
        "body": "***Note**: This issue was originally created as [ARROW-5993](https://issues.apache.org/jira/browse/ARROW-5993). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI'm using pyarrow to read a 40MB parquet file.\r\n\r\nWhen reading all of the columns besides the \"body\" columns, the process peaks at 170MB.\r\n\r\nReading only the \"body\" column results in over 6GB of memory used.\r\n\r\nI made the file publicly accessible: s3://dhavivresearch/pyarrow/demofile.parquet\r\n\r\n\u00a0\r\n\r\n\u00a0",
        "created_at": "2019-07-21T11:44:50.000Z",
        "updated_at": "2019-08-22T16:53:31.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-08-20T16:50:27.000Z"
    },
    "comments": [
        {
            "created_at": "2019-07-22T17:00:08.900Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5993?focusedCommentId=16890312) by Wes McKinney (wesm):*\nThis isn't actually a bug but it's a symptom of fully materializing a densely dictionary-encoded column.\r\n\r\nI'm addressing this in my patch for ARROW-3772 and follow up patches which will allow this data to be read directly as dictionary-encoded without blowing up memory. I'll leave this issue open so we can validate the the patch once I get it submitted"
        },
        {
            "created_at": "2019-08-19T22:34:11.229Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5993?focusedCommentId=16910801) by Wes McKinney (wesm):*\n`[~danielil]` can you make this file publicly accessible again? I'm getting \"Access Denied\" at that URL. I think you are probably hitting ARROW-6060 which was fixed but I can confirm by checking the file"
        },
        {
            "created_at": "2019-08-20T16:39:27.546Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5993?focusedCommentId=16911533) by Wes McKinney (wesm):*\nI was able to get the file from https://dhavivresearch.s3.amazonaws.com/pyarrow/demofile.parquet"
        },
        {
            "created_at": "2019-08-20T16:50:27.439Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5993?focusedCommentId=16911551) by Wes McKinney (wesm):*\nI confirmed that this is ARROW-6060. On master peak memory use reading _the entire file_ is 85MB. In 0.14.1 it's a little under 6GB. This code can be used to reproduce\r\n\r\n```Java\n\r\nimport pandas as pd\r\nfrom pandas.util.testing import rands\r\n\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\n\r\nimport gc\r\nclass memory_use:\r\n    \r\n    def __init__(self):\r\n        self.start_use = pa.total_allocated_bytes()        \r\n        self.pool = pa.default_memory_pool()\r\n        self.start_peak_use = self.pool.max_memory()\r\n        \r\n    def __enter__(self):\r\n        return\r\n    \r\n    def __exit__(self, type, value, traceback):\r\n        gc.collect()\r\n        print(\"Change in memory use: {}\"\r\n              .format(pa.total_allocated_bytes() - self.start_use))\r\n        print(\"Change in peak use: {}\"\r\n              .format(self.pool.max_memory() - self.start_peak_use))\r\n\r\nwith memory_use():\r\n    table = pq.read_table('/home/wesm/Downloads/demofile.parquet')        \r\n```"
        },
        {
            "created_at": "2019-08-22T08:30:13.634Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5993?focusedCommentId=16913128) by Daniel Haviv (danielil):*\nThanks Wes, amazing work :)\r\n\r\nIs there an estimated release date for 0.15?\r\n\r\n\u00a0"
        },
        {
            "created_at": "2019-08-22T16:53:31.191Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5993?focusedCommentId=16913497) by Neal Richardson (npr):*\n0.15 is probably still a couple weeks away. You can follow the issue burndown at\u00a0<https://cwiki.apache.org/confluence/display/ARROW/Arrow+0.15.0+Release>"
        }
    ]
}