{
    "issue": {
        "title": "[Python] Writing Parquet file with flavor='spark' loses pandas schema metadata",
        "body": "***Note**: This issue was originally created as [ARROW-1961](https://issues.apache.org/jira/browse/ARROW-1961). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nYou can see the issue in the `_sanitize_schema` method\r\n\r\nhttps://github.com/apache/arrow/blob/master/python/pyarrow/parquet.py#L201\r\n\r\nsee https://github.com/apache/arrow/issues/1452",
        "created_at": "2018-01-02T18:38:04.000Z",
        "updated_at": "2018-01-25T22:17:56.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2018-01-25T22:17:56.000Z"
    },
    "comments": [
        {
            "created_at": "2018-01-25T22:17:56.420Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1961?focusedCommentId=16340193) by Uwe Korn (uwe):*\nIssue resolved by pull request 1511\n<https://github.com/apache/arrow/pull/1511>"
        }
    ]
}