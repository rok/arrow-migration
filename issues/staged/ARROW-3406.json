{
    "issue": {
        "title": "[C++] Create a caching memory pool implementation",
        "body": "***Note**: This issue was originally created as [ARROW-3406](https://issues.apache.org/jira/browse/ARROW-3406). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nA caching memory pool implementation would be able to recycle freed memory blocks instead of returning them to the system immediately. Two different policies may be chosen:\r\n- either an unbounded cache\n- or a size-limited cache, perhaps with some kind of LRU mechanism\n  \n  Such a feature might help e.g. for CSV parsing, when reading and parsing data into temporary memory buffers.",
        "created_at": "2018-10-02T15:29:47.000Z",
        "updated_at": "2021-08-05T09:12:31.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-08-05T09:12:31.000Z"
    },
    "comments": [
        {
            "created_at": "2018-10-02T17:36:30.103Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3406?focusedCommentId=16635865) by Wes McKinney (wesm):*\nNot really related, but on the subject of other kinds of allocators wanted to make you aware of the chunked allocator that's used (I think) in the Parquet encoding routines https://github.com/apache/parquet-cpp/blob/master/src/parquet/util/memory.h#L100"
        },
        {
            "created_at": "2019-08-29T13:19:46.790Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3406?focusedCommentId=16918622) by Antoine Pitrou (apitrou):*\nModern allocators actually have their own internal freelists or other memory block reuse schemes. So I'm not sure this is really necessary, unless perhaps if we know which sizes we're gonna reuse exactly."
        },
        {
            "created_at": "2021-02-19T23:29:42.237Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3406?focusedCommentId=17287421) by Wes McKinney (wesm):*\nThis would probably better be a \"buffer pool\" in the context of query processing (if at all), where many smallish-buffers are allocated and discarded. Curious what other systems do"
        },
        {
            "created_at": "2021-08-04T10:35:23.660Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3406?focusedCommentId=17393009) by Antoine Pitrou (apitrou):*\ncc `[~westonpace]`"
        },
        {
            "created_at": "2021-08-04T19:46:58.221Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3406?focusedCommentId=17393423) by Weston Pace (westonpace):*\nThis is often done during packet processing.  Chapter 5 of https://fast.dpdk.org/doc/pdf-guides-2.2/prog_guide-2.2.pdf explains how one such pool works.  Although packet processing is a bit of a different field.  Packets are usually very small (a few kB) and arrive at a very fast rate.  I agree with Antoine that this would only be useful (not redundant with jemalloc/mimalloc) if you are using fixed size blocks and this is fairly common with I/O.  Although for disk I/O I would guess the I/O time will swamp any allocation time.  For memory mapped I/O this is a non-issue.  For network I/O via Flight I think this kind of optimization would be covered by gRPC.  I think the same is true of S3 where we receive the buffer from the AWS SDK.\r\n\r\n  Without any kind of evidence that memory pressure/allocation is becoming a bottleneck I'm not sure it makes sense to work on this."
        },
        {
            "created_at": "2021-08-05T09:12:31.170Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3406?focusedCommentId=17393736) by Antoine Pitrou (apitrou):*\nOk, closing.\r\n"
        }
    ]
}