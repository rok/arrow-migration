{
    "issue": {
        "title": "[C++][Dataset] num_rows method for Dataset/Scanner",
        "body": "***Note**: This issue was originally created as [ARROW-9697](https://issues.apache.org/jira/browse/ARROW-9697). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nSomething like Scanner::ToTable except first Project to keep 0 columns, and for each record batch, grab the num_rows. Then sum the resulting vector.",
        "created_at": "2020-08-11T21:21:27.000Z",
        "updated_at": "2021-05-05T20:58:53.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-05-05T20:58:53.000Z"
    },
    "comments": [
        {
            "created_at": "2020-08-13T08:19:23.532Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9697?focusedCommentId=17176829) by Joris Van den Bossche (jorisvandenbossche):*\nIt might be worth adding some method for this to the format-specific fragments, as some formats can know this from metadata, instead of producing empty record batches to get the num_rows?  \r\n(of course if the empty record batch is efficiently created based on this metadata, it might actually not matter performance wise)"
        },
        {
            "created_at": "2020-08-13T14:42:23.279Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9697?focusedCommentId=17177065) by Neal Richardson (npr):*\nThere are a few cases I see that we could optimize like that. In R we have a method for FileSystemDataset when it has parquet files that it can iterate over the files themselves and get the num_rows from each without reading any rows in. That's really fast (on local filesystem) even not multithreaded. `csv::TableReader` doesn't expose a num_rows method so we can't there (though you'd think something like `wc -l` minus the number of skipped rows could do that quickly); likewise I don't think that IPC format includes summary stats like that.\r\n\r\nBut I still want to be able to get the num_rows with a filter applied, i.e. from a Scanner, and so even with Parquet I won't be able to go with file-level stats unless the filter is only hitting partition keys."
        },
        {
            "created_at": "2020-08-13T20:41:03.243Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9697?focusedCommentId=17177312) by Joris Van den Bossche (jorisvandenbossche):*\nAh, yes, I didn't consider the \"filtered dataset\" case, that's indeed also very useful and requires more than potenial metadata."
        },
        {
            "created_at": "2021-04-08T18:24:18.439Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9697?focusedCommentId=17317406) by David Li (lidavidm):*\nI'm taking a swing at this and it'll be up once ARROW-11797 lands. Note that Joris correctly guesses that the Parquet reader indeed implements the optimization internally; there's no need for a special method as the Parquet reader will just fabricate a batch if it notices you aren't reading any columns."
        },
        {
            "created_at": "2021-05-05T20:58:53.444Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9697?focusedCommentId=17339894) by Ben Kietzman (bkietz):*\nIssue resolved by pull request 10060\n<https://github.com/apache/arrow/pull/10060>"
        }
    ]
}