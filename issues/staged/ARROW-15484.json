{
    "issue": {
        "title": "[Python] kwargs fails for pyarrow.parquet.write_to_dataset()",
        "body": "***Note**: This issue was originally created as [ARROW-15484](https://issues.apache.org/jira/browse/ARROW-15484). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen supplying `kwargs` such as `basename_template` or `existing_data_behavior` to `pyarrow.parquet.write_to_dataset()`, it fails as below.\r\n\u00a0\r\n```python\n\r\nimport pandas as pd\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport pyarrow.dataset as ds\r\n\r\ndf = pd.DataFrame({\r\n    'int': [1, 2],\r\n    'str': ['a', 'b']\r\n})\r\n\r\ntable = pa.Table.from_pandas(df)\r\n\r\n\"\"\"\r\n**kwargs : dict,\r\n    Additional kwargs for write_table function. See docstring for write_table or ParquetWriter for more information.\r\n\"\"\"\r\npq.write_to_dataset(table, root_path='foo',\r\n                    use_legacy_dataset=False,\r\n# kwargs:\r\n                    basename_template=\"prefix-{i}.parquet\",\r\n                    existing_data_behavior=\"error\"\r\n                    )\r\n```\r\n```\n\r\nTypeError                                 Traceback (most recent call last)\r\n...test.py in <module>\r\n     16     Additional kwargs for write_table function. See docstring for write_table or ParquetWriter for more information.\r\n     17 \"\"\"\r\n---> 18 pq.write_to_dataset(table, root_path='foo',\r\n     19                     use_legacy_dataset=False,\r\n     20                     # kwargs:\r\n\r\n...lib/python3.8/site-packages/pyarrow/parquet.py in write_to_dataset(table, root_path, partition_cols, partition_filename_cb, filesystem, use_legacy_dataset, **kwargs)\r\n   2144         # map format arguments\r\n   2145         parquet_format = ds.ParquetFileFormat()\r\n-> 2146         write_options = parquet_format.make_write_options(**kwargs)\r\n   2147 \r\n   2148         # map old filesystems to new one\r\n\r\n...lib/python3.8/site-packages/pyarrow/_dataset.pyx in pyarrow._dataset.ParquetFileFormat.make_write_options()\r\n\r\n...lib/python3.8/site-packages/pyarrow/_dataset.pyx in pyarrow._dataset.ParquetFileWriteOptions.update()\r\n\r\nTypeError: unexpected parquet write option: basename_template\r\n```",
        "created_at": "2022-01-27T15:55:02.000Z",
        "updated_at": "2022-08-27T14:42:08.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Parquet",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-01-28T12:38:35.000Z"
    },
    "comments": [
        {
            "created_at": "2022-01-27T21:03:52.600Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15484?focusedCommentId=17483435) by Martin Th\u00f8gersen (th0ger):*\nSeems related to the latest fix ARROW-14620 of release-6.0.1"
        },
        {
            "created_at": "2022-01-27T23:56:23.263Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15484?focusedCommentId=17483475) by Weston Pace (westonpace):*\n`basename_template` and `existing_data_behavior` are valid args for `pyarrow.dataset.write_dataset` but they are not valid args to `pyarrow.parquet.write_to_dataset`.  The latter (a parquet specific interface kept mostly for backwards compatibility) tries to interpret any extra arguments as arguments to `pyarrow.parquet.write_table` which doesn't accept those arguments either.\r\n\r\nI think the error message is correct with respect to the docstring for the method.\r\n\r\n```\n\r\n        Additional kwargs for write_table function. See docstring for\r\n        `write_table` or `ParquetWriter` for more information.\r\n        Using `metadata_collector` in kwargs allows one to collect the\r\n        file metadata instances of dataset pieces. The file paths in the\r\n        ColumnChunkMetaData will be set relative to `root_path`.\r\n```\r\n\r\nand the error message is `unexpected parquet write option: basename_template`\r\n\r\nI agree the error stack trace is a little misleading.  Arguments to `pyarrow.parquet.write_table` are enveloped into a `ParquetFileFormat` object which informs the dataset how, specifically, it should be writing parquet files (e.g. what compression to use, whether or not to use dictionaries, etc.)"
        },
        {
            "created_at": "2022-01-28T12:35:00.254Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15484?focusedCommentId=17483746) by Martin Th\u00f8gersen (th0ger):*\nThanks `[~westonpace]` , that solved my issue.\r\nI think the reference to `write_table` in the docstring confused me, because it's quite overloaded in various sub-modules.\r\n\r\nWorking code:\r\n\r\n```python\n\r\nimport pyarrow.dataset as ds\r\nds.write_dataset(data=table,\r\n                 base_dir='foo',\r\n                 basename_template=\"prefix-{i}.parquet\",\r\n                 format=\"parquet\",\r\n                 existing_data_behavior=\"error\"\r\n                 )\r\n```\r\n"
        },
        {
            "created_at": "2022-08-27T14:42:08.916Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15484?focusedCommentId=17586067) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}