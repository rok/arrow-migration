{
    "issue": {
        "title": "[C++][Python] FileNotFound with Scality accessed through S3 APIs",
        "body": "***Note**: This issue was originally created as [ARROW-14930](https://issues.apache.org/jira/browse/ARROW-14930). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen using dataset.Dataset with S3FileSystem with compatible S3 object sotrage, get an FileNotFoundError.\r\n\r\n\u00a0\r\n\r\nMy code:\r\n\r\n\u00a0\r\n\r\nscality = fs.S3FileSystem(access_key='accessKey1', secret_key='verySecretKey1', endpoint_override=\"http://localhost:8000\", region=\"\")\r\n\r\ndata = ds.dataset(\"dasynth/parquet/taxies/2019_june/\", format=\"parquet\", partitioning=\"hive\", filesystem=scality)",
        "created_at": "2021-11-30T16:46:26.000Z",
        "updated_at": "2022-03-30T21:05:53.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-12-20T11:42:25.000Z"
    },
    "comments": [
        {
            "created_at": "2021-11-30T16:48:58.213Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17451244) by Luis Morales (luis_morales):*\ndasynth -> bucket\r\n\r\nparquet, taxies -> folders\r\n\r\n2019_june -> root dir for partitioned parquet"
        },
        {
            "created_at": "2021-12-02T14:48:20.177Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17452453) by Joris Van den Bossche (jorisvandenbossche):*\nA few questions to help diagnose the problem. Could you first try to see if the filesystem object itself can find the directories/files (so whether the problem lies there, or in the dataset code). For example, could you try:\r\n\r\n```python\n\r\nscality.get_file_info(\"dasynth\")\r\nscality.get_file_info(\"dasynth/parquet/taxies\")\r\n```\r\n\r\nIf the parameters for the S3FileSystem are correct, it should normally be able to give some basic information about the bucket."
        },
        {
            "created_at": "2021-12-02T17:05:13.588Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17452514) by Luis Morales (luis_morales):*\nTried three things:\r\n\r\n\u00a0\r\n\r\n(the bucket as a FileSelector object and recursively. OK)\r\n\r\n**scality.get_file_info(fs.FileSelector(\"dasynth/\", recursive=True))**\r\n\r\n<it gives me every folder and file under dasynth bucket>\u00a0\r\n\r\n\u00a0\r\n\r\n(the bucket as a path. OK)\r\n\r\n**scality.get_file_info(\"dasynth/\")**\r\n\r\n<FileInfo for 'dasynth/': type=FileType.Directory>\r\n\r\n\u00a0\r\n\r\n(a folder under the bucket as a path. KO)\r\n\r\n**scality.get_file_info(\"dasynth/parquet/\")**\r\n\r\n<FileInfo for 'dasynth/parquet/': type=FileType.NotFound>\r\n\r\n\u00a0\r\n\r\n(a folder under the bucket as a FIleSelector object. OK)\r\n\r\n**scality.get_file_info(fs.FileSelector(\"dasynth/parquet/\"))**\r\n\r\n[<FileInfo for 'dasynth/parquet/': type=FileType.Directory>]"
        },
        {
            "created_at": "2021-12-02T17:06:07.419Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17452516) by Luis Morales (luis_morales):*\n(they were four tests sorry, not three)\r\n\r\n:)"
        },
        {
            "created_at": "2021-12-04T12:39:33.924Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17453384) by Luis Morales (luis_morales):*\nAdditional info. Logs from S3 compatible server (scality):\r\n\r\n**scality.get_file_info(\"dasynth/parquet/\")**\r\n```Java\n\r\n{\"name\":\"S3\",\"clientIP\":\"::ffff:172.17.0.1\",\"clientPort\":47954,\"httpCode\":200,\"httpMethod\":\"HEAD\",\"httpURL\":\"/dasynth/parquet\",\"time\":1638621462882,\"req_id\":\"b01ebf5fc0409fbced02\",\"level\":\"info\",\"message\":\"received request\",\"hostname\":\"33938e405ca2\",\"pid\":78}\r\n{\"name\":\"S3\",\"bucketName\":\"dasynth\",\"objectKey\":\"parquet\",\"bytesReceived\":0,\"bodyLength\":0,\"service\":\"s3\",\"action\":\"HeadObject\",\"accountDisplayName\":\"Bart\",\"accountName\":\"Bart\",\"bytesSent\":191,\"clientIP\":\"::ffff:172.17.0.1\",\"clientPort\":47954,\"httpCode\":404,\"httpMethod\":\"HEAD\",\"httpURL\":\"/dasynth/parquet\",\"time\":1638621462887,\"req_id\":\"b01ebf5fc0409fbced02\",\"elapsed_ms\":5.076007,\"level\":\"info\",\"message\":\"responded with error XML\",\"hostname\":\"33938e405ca2\",\"pid\":78}\r\n{\"name\":\"S3\",\"clientIP\":\"::ffff:172.17.0.1\",\"clientPort\":47954,\"httpCode\":200,\"httpMethod\":\"HEAD\",\"httpURL\":\"/dasynth/parquet\",\"time\":1638621462888,\"req_id\":\"e02c3e47bd4d83c64b45\",\"level\":\"info\",\"message\":\"received request\",\"hostname\":\"33938e405ca2\",\"pid\":78}\r\n{\"name\":\"S3\",\"bucketName\":\"dasynth\",\"objectKey\":\"parquet\",\"bytesReceived\":0,\"bodyLength\":0,\"service\":\"s3\",\"action\":\"HeadObject\",\"accountDisplayName\":\"Bart\",\"accountName\":\"Bart\",\"bytesSent\":191,\"clientIP\":\"::ffff:172.17.0.1\",\"clientPort\":47954,\"httpCode\":404,\"httpMethod\":\"HEAD\",\"httpURL\":\"/dasynth/parquet\",\"time\":1638621462892,\"req_id\":\"e02c3e47bd4d83c64b45\",\"elapsed_ms\":3.876694,\"level\":\"info\",\"message\":\"responded with error XML\",\"hostname\":\"33938e405ca2\",\"pid\":78}\r\n{\"name\":\"S3\",\"clientIP\":\"::ffff:172.17.0.1\",\"clientPort\":47954,\"httpCode\":200,\"httpMethod\":\"GET\",\"httpURL\":\"/dasynth?delimiter=%2F&list-type=2&max-keys=1&prefix=parquet%2F\",\"time\":1638621462893,\"req_id\":\"44a5115f184a8ff86f54\",\"level\":\"info\",\"message\":\"received request\",\"hostname\":\"33938e405ca2\",\"pid\":78}\r\n{\"name\":\"S3\",\"bucketName\":\"dasynth\",\"bytesReceived\":0,\"bodyLength\":0,\"service\":\"s3\",\"action\":\"ListObjectsV2\",\"accountDisplayName\":\"Bart\",\"accountName\":\"Bart\",\"bytesSent\":361,\"clientIP\":\"::ffff:172.17.0.1\",\"clientPort\":47954,\"httpCode\":200,\"httpMethod\":\"GET\",\"httpURL\":\"/dasynth?delimiter=%2F&list-type=2&max-keys=1&prefix=parquet%2F\",\"time\":1638621462913,\"req_id\":\"44a5115f184a8ff86f54\",\"elapsed_ms\":20.228346,\"level\":\"info\",\"message\":\"responded with XML\",\"hostname\":\"33938e405ca2\",\"pid\":78}\r\n```\r\n\u00a0\r\n\r\n**scality.get_file_info(fs.FileSelector(\"dasynth/parquet/\"))**\r\n\r\n```Java\n\r\n{\"name\":\"S3\",\"clientIP\":\"::ffff:172.17.0.1\",\"clientPort\":47956,\"httpCode\":200,\"httpMethod\":\"GET\",\"httpURL\":\"/dasynth?delimiter=%2F&list-type=2&max-keys=1000&prefix=parquet%2F\",\"time\":1638621506540,\"req_id\":\"efc897c4c849927a7de2\",\"level\":\"info\",\"message\":\"received request\",\"hostname\":\"33938e405ca2\",\"pid\":78}\r\n{\"name\":\"S3\",\"bucketName\":\"dasynth\",\"bytesReceived\":0,\"bodyLength\":0,\"service\":\"s3\",\"action\":\"ListObjectsV2\",\"accountDisplayName\":\"Bart\",\"accountName\":\"Bart\",\"bytesSent\":364,\"clientIP\":\"::ffff:172.17.0.1\",\"clientPort\":47956,\"httpCode\":200,\"httpMethod\":\"GET\",\"httpURL\":\"/dasynth?delimiter=%2F&list-type=2&max-keys=1000&prefix=parquet%2F\",\"time\":1638621506562,\"req_id\":\"efc897c4c849927a7de2\",\"elapsed_ms\":22.359362,\"level\":\"info\",\"message\":\"responded with XML\",\"hostname\":\"33938e405ca2\",\"pid\":78}\r\n```\r\n\u00a0\r\n\r\nThose HEAD requests seem to be the problem, they are answering with 404 http code. Why arn't they in the fs.FileSelector case?"
        },
        {
            "created_at": "2021-12-04T12:41:03.770Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17453385) by Luis Morales (luis_morales):*\nThe same kind of problem arises when trying to build a dataset:\r\n\r\n\u00a0\r\n\r\ndatos = ds.dataset(\"dasynth/parquet/taxies/2019/\", filesystem=scality)\r\n\r\n\u00a0\r\n\r\nThe logs are the same as in the **scality.get_file_info(\"dasynth/parquet/\")** use case. The HEAD operations appear again."
        },
        {
            "created_at": "2021-12-06T15:42:18.949Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17454093) by Joris Van den Bossche (jorisvandenbossche):*\nLooking at the implemenation for `get_file_info` with a string passed (https://github.com/apache/arrow/blob/e903a214525dd6dcd8e57b20958a65dc678be47d/cpp/src/arrow/filesystem/s3fs.cc#L2135-L2198), this does indeed do HEAD requests, while the `get_file_info` with a FileSelector (https://github.com/apache/arrow/blob/e903a214525dd6dcd8e57b20958a65dc678be47d/cpp/src/arrow/filesystem/s3fs.cc#L2200-L2223) is implemented differently.\r\n\r\nNow, the fact that those HEAD requests fail, is that an issue on your side?"
        },
        {
            "created_at": "2021-12-08T17:14:08.150Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17455884) by Luis Morales (luis_morales):*\nI would say there is no problem in the server side. My thoughts on this:\r\n\r\n\u00a0\r\n\r\n**scality.get_file_info(\"dasynth/parquet/\")**\u00a0\r\n\r\nThis method through HEAD opeartions is asking for buckets or objects, but in this case dasynth/parquet is none of them, it's just a prefix (or folder or tag... name it here the way you want). That's the reason why the server answers with object not found.\r\n\r\n\u00a0\r\n\r\nWhen using FileSelector is not asking previously if the object exists, it just asks for the contents with a GET method and in that case it works properly.\r\n\r\n\u00a0\r\n\r\nMaybe with a new parameter with object_type = [bucket, object, tag] and apply a different logic on each case:\r\n\r\nbucket, object - > HEAD methods\r\n\r\ntag -> the same logic as if it would use FileSelector.\r\n\r\n\u00a0\r\n\r\nwould solve the problem\u00a0\r\n\r\n\u00a0\r\n\r\nadditionally in the dataset() method things should be changed too according to this idea.\r\n\r\n\u00a0\r\n\r\nan additional\u00a0 example. if you use get_file_info with a file like this:\r\n\r\n\u00a0\r\n\r\nscality.get_file_info(\"dasynth/parquet/taxies/2019/month_year=2001-01/payment_type=1/9ccd9d4ae28a41e1acaf40ea594b61da.snappy.parquet\")\r\n\r\n\u00a0\r\n\r\nit works despite of the folders parquet, taxies, 2019..."
        },
        {
            "created_at": "2021-12-08T19:26:20.136Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17455947) by Luis Morales (luis_morales):*\njust as a reference... awsdatawrangler works perfectly, with methods like:\r\n\r\n\u00a0\r\n\r\nwr.s3.list_objects(path='s3://dasynth/parquet', boto3_session=sesion)\r\n\r\n\u00a0\r\n\r\nreturning objects (parquet files)\r\n\r\n\u00a0\r\n\r\nfor chunk in wr.s3.read_parquet('s3://dasynth/parquet/taxies/2019/', dataset=True, boto3_session=sesion, use_threads=True, chunked=True):\r\n\u00a0 \u00a0 chunks+=1\r\n\r\n\u00a0\r\n\r\nmy_second_filter = lambda x: True if x[\"payment_type\"].startswith(\"2\") and x[\"month_year\"].startswith(\"2019-06\") else False\r\nfor chunk in wr.s3.read_parquet(path=\"s3://dasynth/parquet/taxies/2019/\", dataset=True, partition_filter=my_second_filter,\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 boto3_session=sesion, use_threads=True, chunked=True):\r\n\u00a0 \u00a0 chunks+=1\r\n\r\n\u00a0\r\n\r\nworking properly with filters...\r\n\r\n\u00a0\r\n\r\nthis is what I want to get from pyarrow, as it's going to be a lighter library and not coupled to AWS open source initiatives.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2021-12-09T13:05:45.998Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456430) by Joris Van den Bossche (jorisvandenbossche):*\ncc `[~apitrou]`"
        },
        {
            "created_at": "2021-12-09T13:13:55.097Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456436) by Antoine Pitrou (apitrou):*\n[~luis_morales] Is there some kind of public Scality test server that we can try testing against?"
        },
        {
            "created_at": "2021-12-09T14:09:10.224Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456461) by Luis Morales (luis_morales):*\nThe product i'm using is scality (scality.com). They have a public docker image that is basically their S3 Connector (they call it zenko cloud server).\r\n\r\n\u00a0\r\n\r\nYou can find the image here:\r\n\r\n\u00a0\r\n\r\n<https://hub.docker.com/r/zenko/cloudserver/>\r\n\r\n\u00a0\r\n\r\ni'm using this docker run (with ssl activated, the docker generates its own self-certificate and ca each time you run it):\r\n\r\n\u00a0\r\n\r\ndocker run -v <local_data_folder>:/usr/src/app/localData -v <local_metadata_folder>:/usr/src/app/localMetadata -p 8000:8000 -e SSL=TRUE -e ENDPOINT=s3.scality.test -e LOG_LEVEL=trace -e REMOTE_MANAGEMENT_DISABLE=1 zenko/cloudserver\r\n\r\n\u00a0\r\n\r\nThe endpoint is needed when using SSL.\r\n\r\nI'll tell scality support guys to have a look at this too."
        },
        {
            "created_at": "2021-12-09T15:23:02.750Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456500) by Antoine Pitrou (apitrou):*\nHmm, I tried the in-memory backed:\r\n```Java\n\r\n$ docker run -d --name cloudserver -p 8000:8000 -e S3BACKEND=mem -e REMOTE_MANAGEMENT_DISABLE=1 zenko/cloudserver\r\n```\r\n\r\nAnd it seems to work properly with our S3 filesystem:\r\n```python\n\r\n>>> from pyarrow import fs\r\n>>> f = fs.S3FileSystem(scheme='http', access_key='accessKey1', secret_key='verySecretKey1', endpoint_override='localhost:8000')\r\n>>> f.get_file_info('/')\r\n<FileInfo for '/': type=FileType.Directory>\r\n>>> f.get_file_info(fs.FileSelector('/', recursive=True))\r\n[]\r\n>>> f.create_dir('bucket')\r\n>>> f.get_file_info(fs.FileSelector('/', recursive=True))\r\n[<FileInfo for 'bucket': type=FileType.Directory>]\r\n>>> f.create_dir('bucket/foo/bar')\r\n>>> f.get_file_info(fs.FileSelector('/', recursive=True))\r\n[<FileInfo for 'bucket': type=FileType.Directory>,\r\n <FileInfo for 'bucket/foo': type=FileType.Directory>,\r\n <FileInfo for 'bucket/foo/bar': type=FileType.Directory>]\r\n>>> f.get_file_info(fs.FileSelector('bucket/', recursive=True))\r\n[<FileInfo for 'bucket/foo': type=FileType.Directory>,\r\n <FileInfo for 'bucket/foo/bar': type=FileType.Directory>]\r\n>>> f.get_file_info(fs.FileSelector('bucket/foo', recursive=True))\r\n[<FileInfo for 'bucket/foo/bar': type=FileType.Directory>]\r\n>>> f.get_file_info(fs.FileSelector('bucket/foo/bar', recursive=True))\r\n[]\r\n>>> f.get_file_info('bucket/')\r\n<FileInfo for 'bucket/': type=FileType.Directory>\r\n>>> f.get_file_info('bucket/foo')\r\n<FileInfo for 'bucket/foo': type=FileType.Directory>\r\n>>> f.get_file_info('bucket/foo/')\r\n<FileInfo for 'bucket/foo/': type=FileType.Directory>\r\n>>> f.get_file_info('bucket/foo/bar')\r\n<FileInfo for 'bucket/foo/bar': type=FileType.Directory>\r\n>>> f.get_file_info('bucket/foo/bar/')\r\n<FileInfo for 'bucket/foo/bar/': type=FileType.Directory>\r\n```\r\n"
        },
        {
            "created_at": "2021-12-09T15:23:40.565Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456502) by Antoine Pitrou (apitrou):*\nShould I try something else?"
        },
        {
            "created_at": "2021-12-09T16:29:59.320Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456546) by Luis Morales (luis_morales):*\ntry with local filesystem, with the -v options, something like this:\r\n\r\n```Java\n\r\ndocker run -v /cto/ring/data:/usr/src/app/localData -v /cto/ring/metadata:/usr/src/app/localMetadata -p 8000:8000 -e SSL=TRUE -e ENDPOINT=s3.scality.test -e LOG_LEVEL=trace -e REMOTE_MANAGEMENT_DISABLE=1 zenko/cloudserver\r\n```\r\n\r\n\u00a0\r\n\r\nwhen running\u00a0\r\n```Java\n\r\nf.create_dir('bucket')\r\n```\r\n\u00a0i get this error:\r\n\r\n```Java\n\r\nOSError: When creating bucket 'bucket': AWS Error [code 100]: Unable to parse ExceptionName: MalformedXML Message: The XML you provided was not well-formed or did not validate against our published schema.\r\n```\r\n"
        },
        {
            "created_at": "2021-12-09T17:48:51.197Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456603) by Antoine Pitrou (apitrou):*\nHmm, but what should the \"data directory\" and \"metadata directory\" contain? Just empty directories?"
        },
        {
            "created_at": "2021-12-09T18:01:33.802Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456620) by Luis Morales (luis_morales):*\nthose folders are for scality. it uses it own internal structure to store both the data and the metadata. it's the S3 layer that translates that structures to S3-like structure of buckets and files...\r\n\r\n\u00a0\r\n\r\nin my use case i create the buckets and store the parquets using s3cmd."
        },
        {
            "created_at": "2021-12-09T18:03:49.599Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17456624) by Luis Morales (luis_morales):*\nThe thing is that Im not using pyarrow to create dir's as in your use case... in my test I use s3cmd to create folders and move files, in our production use case I'll use parquet files generated with Apache Spark with Hive partitioning\r\n\r\n\u00a0"
        },
        {
            "created_at": "2021-12-13T10:24:21.831Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17458257) by Antoine Pitrou (apitrou):*\nI tried reproducing by creating a single file in an empty bucket using `s3cmd`:\r\n\r\n```bash\n\r\n$ s3cmd --no-ssl --host=localhost:8000 --host-bucket=\"%(bucket)s.localhost:8000\" --access_key=accessKey1 --secret_key=verySecretKey1 put setup.cfg s3://bucket/foo/bar.txt\r\nupload: 'setup.cfg' -> 's3://bucket/foo/bar.txt'  [1 of 1]\r\n 1075 of 1075   100% in    0s   109.75 kB/s  done\r\n```\r\n\r\nAnd it still works properly with PyArrow:\r\n```python\n\r\n>>> f = fs.S3FileSystem(scheme='http', access_key='accessKey1', secret_key='verySecretKey1', endpoint_override='localhost:8000')\r\n>>> f.get_file_info(fs.FileSelector('/', recursive=True))\r\n[<FileInfo for 'bucket': type=FileType.Directory>,\r\n <FileInfo for 'bucket/foo': type=FileType.Directory>,\r\n <FileInfo for 'bucket/foo/bar.txt': type=FileType.File, size=1075>]\r\n>>> f.get_file_info('bucket')\r\n<FileInfo for 'bucket': type=FileType.Directory>\r\n>>> f.get_file_info('bucket/foo')\r\n<FileInfo for 'bucket/foo': type=FileType.Directory>\r\n>>> f.get_file_info('bucket/foo/bar.txt')\r\n<FileInfo for 'bucket/foo/bar.txt': type=FileType.File, size=1075>\r\n```\r\n\r\neven though s3cmd itself doesn't see the \"directory\":\r\n```bash\n\r\n$ s3cmd --no-ssl --host=localhost:8000 --host-bucket=\"%(bucket)s.localhost:8000\" --access_key=accessKey1 --secret_key=verySecretKey1 info s3://bucket/foo\r\nERROR: S3 error: 404 (Not Found)\r\n```\r\n"
        },
        {
            "created_at": "2021-12-15T14:19:19.964Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17459982) by Luis Morales (luis_morales):*\nI've tried your tests but with local storage, not memory (and with SSL).\r\n\r\ndocker run -v /cto/ring/data:/usr/src/app/localData -v /cto/ring/metadata:/usr/src/app/localMetadata -p 8000:8000 -e SSL=TRUE -e ENDPOINT=s3.scality.test -e LOG_LEVEL=trace -e REMOTE_MANAGEMENT_DISABLE=1 zenko/cloudserver\r\n\r\nI create bucket with s3cmd:\r\n\r\ns3cmd mb s3://bucket\r\n\r\n\u00a0\r\n\r\nThen put the file with folders:\r\n\r\ns3cmd put hola.txt s3://bucket/foo/bar.txt\r\n\r\n\u00a0\r\n\r\nNow with pyarrow:\r\n\r\nscality = fs.S3FileSystem(access_key='accessKey1', secret_key='verySecretKey1', endpoint_override=\"https://s3.scality.test:8000\", scheme='https')\r\n\r\n**scality.get_file_info(fs.FileSelector('/', recursive=True)). OK.**\r\n\r\n[<FileInfo for 'bucket': type=FileType.Directory>,\r\n<FileInfo for 'bucket/foo': type=FileType.Directory>,\r\n\r\n<FileInfo for 'bucket/foo/bar.txt': type=FileType.File, size=11>]\r\n\r\n\u00a0\r\n\r\n**scality.get_file_info('bucket'). OK.**\r\n\r\n<FileInfo for 'bucket': type=FileType.Directory>\r\n\r\n\u00a0\r\n\r\n**scality.get_file_info('bucket/foo'). OK.**\r\n\r\n<FileInfo for 'bucket/foo/bar': type=FileType.Directory>\r\n\r\n\u00a0\r\n\r\nI think this works because foo has a file inside. Lets try a more parquet-oriented use case (the first folder has no file, just the folders that correspond to partitions, hive style)\r\n\r\n\u00a0\r\n\r\ns3cmd put hola.txt s3://bucket/foo/bar/hello.txt\r\n\r\n**scality.get_file_info(fs.FileSelector('bucket', recursive=True)). OK**\r\n\r\n[<FileInfo for 'bucket/foo': type=FileType.Directory>,\r\n\r\n<FileInfo for 'bucket/foo/bar': type=FileType.Directory>,\r\n\r\n<FileInfo for 'bucket/foo/bar/hola.txt': type=FileType.File, size=11>]\r\n\r\n\u00a0\r\n\r\n<font color=\"#ff0000\">**scality.get_file_info('bucket/foo'). KO**</font>\r\n\r\n<font color=\"#ff0000\">**<FileInfo for 'bucket/foo': type=FileType.NotFound>**</font>\r\n\r\n\u00a0\r\n\r\n**scality.get_file_info('bucket/foo/bar'). OK**\r\n\r\n<FileInfo for 'bucket/foo/bar': type=FileType.Directory>\r\n\r\n\u00a0\r\n\r\nThe point is that from a parquet perspective when I create a dataset I have to ask for the \"foo\" folder (the one that has all the partitions inside), not the \"bar\" one (will be equivalent to one particular partition).\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2021-12-15T15:56:53.262Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17460057) by Antoine Pitrou (apitrou):*\nWhat does `-e ENDPOINT=s3.scality.test` do?"
        },
        {
            "created_at": "2021-12-15T16:36:07.687Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17460078) by Luis Morales (luis_morales):*\nIf SSL activated you need to use this kind of url (it's what the docker uses to create the certificates and CAs). I think you can work without SSL for the tests we are doing."
        },
        {
            "created_at": "2021-12-16T15:40:15.127Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17460823) by Antoine Pitrou (apitrou):*\nOk, I've managed to reproduce now and I think it's really a bug in CloudServer."
        },
        {
            "created_at": "2021-12-16T16:05:02.335Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17460830) by Antoine Pitrou (apitrou):*\nIt seems there's a workaround, though."
        },
        {
            "created_at": "2021-12-20T11:42:25.317Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14930?focusedCommentId=17462558) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 11977\n<https://github.com/apache/arrow/pull/11977>"
        }
    ]
}