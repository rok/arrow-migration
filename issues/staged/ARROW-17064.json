{
    "issue": {
        "title": "[Python] Python hangs when use pyarrow.fs.copy_files with \"used_threads=True\"",
        "body": "***Note**: This issue was originally created as [ARROW-17064](https://issues.apache.org/jira/browse/ARROW-17064). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen try to copy a local path to s3 remote filesystem using `pyarrow.fs.copy_files` and using default parameter `use_threads=True`, the system hangs. If use \"use_threads=False` the operation must complete ok (but more slow).\r\n\r\n\u00a0\r\n\r\nMy code is:\r\n```java\n\r\n>>> import pyarrow as pa\r\n>>> s3fs=pa.fs.S3FileSystem(endpoint_override=\"http://xxxxxx\")\r\n>>> pa.fs.copy_files(\"tests/data/payments\", \"bucket/payments\", destination_filesystem=s3fs)\r\n... (don't return)\n```\r\nIf check remote s3, all files appear, but the function don't return\r\n\r\n\u00a0\r\n\r\nPlatform: Windows",
        "created_at": "2022-07-13T08:21:18.000Z",
        "updated_at": "2022-07-13T19:29:24.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": []
}