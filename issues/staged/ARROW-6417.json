{
    "issue": {
        "title": "[C++][Parquet] Non-dictionary BinaryArray reads from Parquet format have slowed down since 0.11.x",
        "body": "***Note**: This issue was originally created as [ARROW-6417](https://issues.apache.org/jira/browse/ARROW-6417). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIn doing some benchmarking, I have found that binary reads seem to be slower from Arrow 0.11.1 to master branch. It would be a good idea to do some basic profiling to see where we might improve our memory allocation strategy (or whatever the bottleneck turns out to be)",
        "created_at": "2019-09-02T17:59:06.000Z",
        "updated_at": "2019-10-14T20:50:54.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2019-10-14T20:50:54.000Z"
    },
    "comments": [
        {
            "created_at": "2019-09-03T03:09:37.427Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16921131) by Wes McKinney (wesm):*\nI updated the results plot to use gcc 8.3 in both v0.11.1 and master branch as of 9/2/2019"
        },
        {
            "created_at": "2019-09-03T05:03:12.477Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16921164) by Wes McKinney (wesm):*\nThe dreaded `\\_\\_memmove_avx_unaligned_erms` has showed up again. I'll have a poke at this to see what could be done\r\n\r\n\u00a0\r\n```java\n\r\n+   60.85%     0.01%  python   libparquet.so.15.0.0                               [.] parquet::internal::TypedRecordReader<parquet::PhysicalType<(parquet::Type::ty\u2592\r\n+   58.16%     0.00%  python   libparquet.so.15.0.0                               [.] parquet::internal::ByteArrayChunkedRecordReader::ReadValuesSpaced            \u2592\r\n+   57.54%     0.00%  python   libparquet.so.15.0.0                               [.] parquet::PlainByteArrayDecoder::DecodeArrow                                  \u2592\r\n+   57.52%     5.57%  python   libparquet.so.15.0.0                               [.] parquet::PlainByteArrayDecoder::DecodeArrow<arrow::internal::ChunkedBinaryBui\u2592\r\n+   49.99%     4.80%  python   libparquet.so.15.0.0                               [.] arrow::internal::ChunkedBinaryBuilder::Append                                \u2592\r\n+   44.66%     9.74%  python   libarrow.so.15.0.0                                 [.] arrow::BaseBinaryBuilder<arrow::BinaryType>::Append                          \u2592\r\n+   30.62%     9.64%  python   libarrow.so.15.0.0                                 [.] arrow::BufferBuilder::Append                                                 \u2592\r\n+   23.51%    10.91%  python   libc-2.27.so                                       [.] __memmove_avx_unaligned_erms                                                 \u2592\r\n+   21.23%     0.00%  python   [unknown]                                          [.] 0xffffffffffffffff                                                           \u2592\r\n+   18.58%     0.01%  python   libparquet.so.15.0.0                               [.] parquet::ColumnReaderImplBase<parquet::PhysicalType<(parquet::Type::type)6> >\u2592\r\n+   18.45%    14.80%  python   libsnappy.so.1.1.7                                 [.] snappy::RawUncompress                                                        \u2592\r\n+   18.42%     0.02%  python   libparquet.so.15.0.0                               [.] parquet::SerializedPageReader::NextPage                                      \u2592\r\n+   18.27%     0.00%  python   libarrow.so.15.0.0                                 [.] arrow::util::SnappyCodec::Decompress                                         \u2592\r\n+   18.27%     0.00%  python   libarrow.so.15.0.0                                 [.] arrow::util::SnappyCodec::Decompress                                         \u2592\r\n+   18.27%     0.00%  python   libsnappy.so.1.1.7                                 [.] snappy::RawUncompress                                                        \u2592\r\n+   14.99%     0.00%  python   libarrow.so.15.0.0                                 [.] arrow::PoolBuffer::Resize                                                    \u2592\r\n+   14.99%     0.00%  python   libarrow.so.15.0.0                                 [.] arrow::PoolBuffer::Reserve                                                   \u2592\r\n+   14.99%     0.00%  python   libarrow.so.15.0.0                                 [.] arrow::DefaultMemoryPool::Reallocate                                         \u2592\r\n+   14.98%     0.01%  python   libarrow.so.15.0.0                                 [.] je_arrow_rallocx                                                             \u2592\r\n+   14.97%     0.00%  python   libarrow.so.15.0.0                                 [.] je_arrow_private_je_arena_ralloc                                             \u2592\r\n+   14.96%     0.00%  python   libarrow.so.15.0.0                                 [.] je_arrow_private_je_large_ralloc                                             \u2592\r\n+   14.64%     0.00%  python   libarrow.so.15.0.0                                 [.] arrow::BufferBuilder::Resize                                                 \u2592\r\n+   12.82%    12.82%  python   [unknown]                                          [k] 0xffffffff98e00a67                                                           \u2592\r\n+   11.74%     3.73%  python   libarrow.so.15.0.0                                 [.] arrow::BaseBinaryBuilder<arrow::BinaryType>::AppendNextOffset  \n```"
        },
        {
            "created_at": "2019-09-03T05:14:59.215Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16921168) by Wes McKinney (wesm):*\nOK, I think to make things faster we need to be more careful about pre-allocating with `BinaryBuilder` and calling `BaseBinaryBuilder<T>::UnsafeAppend` instead of `Append`. It's a bit tricky because we have `ChunkedBinaryBuilder` in the mix, so we may have to manage the creation of chunks in the Parquet value decoder. I think this is worth the effort given how much of a hot path this is for reading Parquet files. I'll spend a little time on it tomorrow"
        },
        {
            "created_at": "2019-09-04T18:57:32.448Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16922758) by Wes McKinney (wesm):*\nSo on closer inspection, in v0.11.1 we weren't yet handling chunked binary reads at all, so the comparison is not really apples to oranges. v0.12.x was the first release series to include chunking support, so could be the more appropriate comparison. \r\n\r\nThis performance issue is really vexing. We also changed jemalloc versions between 0.12.x and 0.15.x so I wonder if the allocator version could be impacting performance"
        },
        {
            "created_at": "2019-09-04T19:36:29.770Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16922791) by Wes McKinney (wesm):*\nFurther down the rabbit hole\r\n\r\n0.12.1 perf profile\r\n\r\n```Java\n\r\n   - parquet::arrow::FileReader::Impl::ReadSchemaField                                                                                                             \r\n      - 66.24% parquet::arrow::ColumnReader::NextBatch                                                                                                             \r\n         - parquet::arrow::PrimitiveImpl::NextBatch                                                                                                                \r\n            - 66.23% parquet::internal::RecordReader::ReadRecords                                                                                                  \r\n               - 41.51% parquet::internal::TypedRecordReader<parquet::DataType<(parquet::Type::type)6> >::ReadRecordData                                           \r\n                  - 38.62% parquet::internal::TypedRecordReader<parquet::DataType<(parquet::Type::type)6> >::ReadValuesSpaced                                      \r\n                     - 26.97% arrow::internal::ChunkedBinaryBuilder::Append                                                                                        \r\n                        - 24.06% arrow::BinaryBuilder::Append                                                                                                      \r\n                           + 12.78% arrow::BufferBuilder::Append                                                                                                   \r\n                             1.99% arrow::ArrayBuilder::Reserve                                                                                                    \r\n                             1.16% arrow::BufferBuilder::Append@plt                                                                                                \r\n                             0.52% arrow::ArrayBuilder::Reserve@plt                                                                                                                          0.57% arrow::BinaryBuilder::Append@plt                                                                                                   \r\n                     + 8.34% parquet::Decoder<parquet::DataType<(parquet::Type::type)6> >::DecodeSpaced                                                            \r\n                       0.53% arrow::internal::ChunkedBinaryBuilder::Append@plt                                                                                     \r\n                    2.02% parquet::internal::DefinitionLevelsToBitmap                                                                                              \r\n                  + 0.86% parquet::internal::RecordReader::RecordReaderImpl::ReserveValues                                                                        \r\n               + 24.31% parquet::internal::TypedRecordReader<parquet::DataType<(parquet::Type::type)6> >::ReadNewPage \r\n```\r\n\r\nmaster / my ARROW-6417 branch\r\n\r\n```Java\n\r\n   - 74.04% parquet::internal::TypedRecordReader<parquet::PhysicalType<(parquet::Type::type)6> >::ReadRecords                                                      \r\n      - 49.00% parquet::internal::TypedRecordReader<parquet::PhysicalType<(parquet::Type::type)6> >::ReadRecordData                                                \r\n         - 45.82% parquet::internal::ByteArrayChunkedRecordReader::ReadValuesSpaced                                                                                \r\n            - 45.19% parquet::PlainByteArrayDecoder::DecodeArrow                                                                                                   \r\n               + 20.92% arrow::BaseBinaryBuilder<arrow::BinaryType>::ReserveData                                                                                   \r\n                 7.61% __memmove_avx_unaligned_erms                                                                                                                \r\n               + 2.59% arrow::BaseBinaryBuilder<arrow::BinaryType>::Resize                                                                                         \r\n                 0.77% memcpy@plt                                                                                                                                  \r\n            + 0.63% parquet::DictByteArrayDecoderImpl::DecodeArrow                                                                                                 \r\n           2.09% parquet::internal::DefinitionLevelsToBitmap                                                                                                       \r\n         + 1.07% parquet::internal::TypedRecordReader<parquet::PhysicalType<(parquet::Type::type)6> >::ReserveValues                                               \r\n      + 24.32% parquet::SerializedPageReader::NextPage                                                                                                             \r\n```\r\n\r\nFurthermore, jemalloc is show up as taking a lot more time on 5.2.x versus the older version we had before\r\n\r\nmaster\r\n\r\n```Java\n\r\n+   24.59%     0.00%  python   libarrow.so.15.0.0                                 [.] je_arrow_rallocx                                                             \r\n+   24.58%     0.00%  python   libarrow.so.15.0.0                                 [.] je_arrow_private_je_arena_ralloc                                             \r\n+   24.57%     0.00%  python   libarrow.so.15.0.0                                 [.] je_arrow_private_je_large_ralloc                                             \r\n```\r\n\r\n0.12.1\r\n\r\n```Java\n\r\n+    8.30%     0.01%  python   libarrow.so.12.1.0                                 [.] je_arrow_rallocx                                                             \r\n+    8.28%     0.01%  python   libarrow.so.12.1.0                                 [.] je_arrow_private_je_arena_ralloc \r\n```\r\n\r\nSo it seems like the difference in jemalloc versions may be accounting for some of the performance difference. The other thing that strikes me is that the UBSAN changes (`SafeLoadAs`) are likely introducing performance degradation because the Parquet BYTE_ARRAY encoding results in mostly unaligned lengths.\r\n\r\ncc `[~pitrou]` [~emkornfield@gmail.com] for any thoughts..."
        },
        {
            "created_at": "2019-09-05T12:23:27.058Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923360) by Antoine Pitrou (apitrou):*\nHave you tried to measure the same jemalloc version for the two Arrow versions (or, conversely, the two jemalloc versions for the same Arrow version)?"
        },
        {
            "created_at": "2019-09-05T14:20:25.051Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923474) by Wes McKinney (wesm):*\nI will try that next. I'm going to merge my current patch in the meantime and leave this JIRA open"
        },
        {
            "created_at": "2019-09-05T15:29:12.122Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923534) by Micah Kornfield (emkornfield@gmail.com):*\nFor SafeLoadAs, you could try changing the implementation to dereference instead of memcpy, which should be equivalent to the old code (assuming it is getting inlined correctly).\u00a0 IIRC, we saw very comparable numbers for the existing parquet benchmarks when I made those changes.\u00a0"
        },
        {
            "created_at": "2019-09-05T16:02:11.946Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923566) by Wes McKinney (wesm):*\nOK, it appears that the jemalloc version is causing the perf difference\r\n\r\ncurrent master branch with vendored jemalloc version (4.something with patches)\r\n\r\n```Java\n\r\n$ python 20190903_parquet_benchmark.py \r\ndense-random 100000\r\n({'case': 'read-dense-random-single-thread'}, 0.6065331888198853)\r\n```\r\n\r\nmaster with jemalloc 5.2.0\r\n\r\n```Java\n\r\n$ python 20190903_parquet_benchmark.py \r\ndense-random 100000\r\n({'case': 'read-dense-random-single-thread'}, 1.2143790817260742)\r\n```\r\n\r\nTo reproduce these results yourself\r\n\r\n- Get the old jemalloc tarball from here https://github.com/apache/arrow/tree/maint-0.12.x/cpp/thirdparty/jemalloc\n- Set `$ARROW_JEMALLOC_URL` to the path of that before building\n- Use this branch which has the old EP configuration https://github.com/wesm/arrow/tree/use-old-jemalloc\n  \n  Here's the benchmark script that I'm running above\n  \n  https://gist.github.com/wesm/7e5ae1d41981cfdd20415faf71e5f57e\n  \n  I'm interested if other benchmarks are affected or if this is a peculiarity of this particular benchmark"
        },
        {
            "created_at": "2019-09-05T16:49:32.801Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923607) by Wes McKinney (wesm):*\nThe benchmark results in arrow-builder-benchmark are pretty damning...\r\n\r\nmaster\r\n\r\n```Java\n\r\n---------------------------------------------------------------------------\r\nBenchmark                                    Time           CPU Iterations\r\n---------------------------------------------------------------------------\r\nBufferBuilderTinyWrites/real_time    264925407 ns  264925189 ns          2    966.31MB/s\r\nBufferBuilderSmallWrites/real_time   178721490 ns  178720664 ns          4   1.39882GB/s\r\nBufferBuilderLargeWrites/real_time   192722520 ns  192720335 ns          4   1.29027GB/s\r\nBuildBooleanArrayNoNulls              61622618 ns   61620052 ns         11   4.05712GB/s\r\nBuildIntArrayNoNulls                 159926782 ns  159919611 ns          4   1.56329GB/s\r\nBuildAdaptiveIntNoNulls               34141484 ns   34141072 ns         20   7.32256GB/s\r\nBuildAdaptiveIntNoNullsScalarAppend  118671966 ns  118669726 ns          6   2.10669GB/s\r\nBuildBinaryArray                     646172067 ns  646165509 ns          1   396.183MB/s\r\nBuildChunkedBinaryArray              629538527 ns  629517882 ns          1    406.66MB/s\r\nBuildFixedSizeBinaryArray            319843478 ns  319421997 ns          2   801.448MB/s\r\nBuildDecimalArray                    613258571 ns  613249404 ns          1   834.897MB/s\r\nBuildInt64DictionaryArrayRandom      265489567 ns  265479003 ns          3   964.295MB/s\r\nBuildInt64DictionaryArraySequential  256461735 ns  256454103 ns          3   998.229MB/s\r\nBuildInt64DictionaryArraySimilar     436497455 ns  436496161 ns          2   586.489MB/s\r\nBuildStringDictionaryArray           737468427 ns  737429710 ns          1   463.142MB/s\r\nArrayDataConstructDestruct               38895 ns      38895 ns      18067\r\n```\r\n\r\nmaster with the older jemalloc\r\n\r\n```Java\n\r\n---------------------------------------------------------------------------\r\nBenchmark                                    Time           CPU Iterations\r\n---------------------------------------------------------------------------\r\nBufferBuilderTinyWrites/real_time    139816022 ns  139814056 ns          5   1.78806GB/s\r\nBufferBuilderSmallWrites/real_time    35215592 ns   35214766 ns         19   7.09912GB/s\r\nBufferBuilderLargeWrites/real_time    32460612 ns   32456001 ns         21   7.66046GB/s\r\nBuildBooleanArrayNoNulls              33690068 ns   33688611 ns         21   7.42091GB/s\r\nBuildIntArrayNoNulls                  49988970 ns   49987507 ns         14   5.00125GB/s\r\nBuildAdaptiveIntNoNulls               23878665 ns   23876703 ns         29   10.4705GB/s\r\nBuildAdaptiveIntNoNullsScalarAppend  116140426 ns  116137665 ns          6   2.15262GB/s\r\nBuildBinaryArray                     593711307 ns  593699295 ns          1   431.195MB/s\r\nBuildChunkedBinaryArray              538185849 ns  538185876 ns          1   475.672MB/s\r\nBuildFixedSizeBinaryArray            218638403 ns  218631191 ns          3   1.14348GB/s\r\nBuildDecimalArray                    294477232 ns  294474155 ns          2   1.69794GB/s\r\nBuildInt64DictionaryArrayRandom      248790745 ns  248788395 ns          3   1028.99MB/s\r\nBuildInt64DictionaryArraySequential  238954386 ns  238949356 ns          3   1071.36MB/s\r\nBuildInt64DictionaryArraySimilar     422484600 ns  422471016 ns          2   605.959MB/s\r\nBuildStringDictionaryArray           716507144 ns  716487471 ns          1    476.68MB/s\r\nArrayDataConstructDestruct               38406 ns      38406 ns      18229\r\n```\r\n\r\nSo it seems that performance in realloc-heavy workloads is degraded"
        },
        {
            "created_at": "2019-09-05T16:57:00.860Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923612) by Wes McKinney (wesm):*\nI opened an issue with jemalloc to see if we're doing something wrong https://github.com/jemalloc/jemalloc/issues/1621"
        },
        {
            "created_at": "2019-09-05T17:20:55.409Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923630) by Antoine Pitrou (apitrou):*\nWow that's massive.\r\n\r\nRe `SafeLoadAs`, I'm with Micah: it shouldn't make a difference on a x86 CPU with a decent compiler. Worth checking anyway."
        },
        {
            "created_at": "2019-09-05T17:29:40.840Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923639) by Antoine Pitrou (apitrou):*\nFTR, similar issues with jemalloc seem to have happened in the past, I wonder if it's a regression:\r\nhttps://github.com/jemalloc/jemalloc/issues/335\r\nhttps://github.com/jemalloc/jemalloc/issues/126\r\n"
        },
        {
            "created_at": "2019-09-05T22:30:47.453Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16923778) by Wes McKinney (wesm):*\nAfter reverting the jemalloc version, the benchmarks show that master is faster than v0.12.1, which is certainly what I was **hoping for** after all the work we put in refactoring stuff the last few months. So the SafeLoadAs issue is no longer a concern"
        },
        {
            "created_at": "2019-10-14T20:50:54.783Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6417?focusedCommentId=16951350) by Wes McKinney (wesm):*\nThis was fixed in 0.15.0 by the jemalloc toolchain work and other optimizations"
        }
    ]
}