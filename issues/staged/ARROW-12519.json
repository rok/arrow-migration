{
    "issue": {
        "title": "[C++] Create/document better characterization of jemalloc/mimalloc",
        "body": "***Note**: This issue was originally created as [ARROW-12519](https://issues.apache.org/jira/browse/ARROW-12519). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe following script reads in a large dataset 10 times in a loop.\u00a0 The dataset being referred to is from Ursa benchmarks here (<https://github.com/ursacomputing/benchmarks).>\u00a0 However, any sufficiently large db should be sufficient.\u00a0 The dataset is ~5-6 GB when deserialized into an Arrow table.\u00a0 The conversion to a dataframe is not zero-copy and so the loop requires about 8.6GB.\r\n\r\nRunning this code 10 times with mimalloc consumes 27GB of RAM.\u00a0 It is pretty deterministic.\u00a0 Even putting a 1 second sleep in between each run yields the same result.\u00a0 On the other hand if I put the read into its own method (second version below) then it uses only 14 GB.\r\n\r\nOur current rule of thumb seems to be \"as long as the allocators stabilize to some number at some point then it is not a bug\" so technically both 27GB and 14GB are valid.\r\n\r\nIf we can't put any kind of bound whatsoever on the RAM that Arrow needs then it will eventually become a problem for adoption.\u00a0 I think we need to develop some sort of characterization around how much mimalloc/jemalloc should be allowed to over-allocate before we consider it a bug and require changing the code to avoid the situation (or documenting that certain operations are not valid).\r\n\r\n\u00a0\r\n\r\n---~~CODE~~---\r\n\r\n\u00a0\r\n\r\n// First version (uses ~27GB)\r\n```java\n\r\nimport time\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport psutil\r\nimport os\r\n\r\npa.set_memory_pool(pa.mimalloc_memory_pool())\r\nprint(pa.default_memory_pool().backend_name)\r\n\r\nfor _ in range(10):\r\n    table = pq.read_table('/home/pace/dev/benchmarks/benchmarks/data/temp/fanniemae_2016Q4.uncompressed.parquet')\r\n    df = table.to_pandas()\r\n    print(pa.total_allocated_bytes())\r\n    proc = psutil.Process(os.getpid())\r\n    print(proc.memory_info())\r\n```\r\n// Second version (uses ~14GB)\r\n```java\n\r\nimport time\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport psutil\r\nimport os\r\n\r\npa.set_memory_pool(pa.mimalloc_memory_pool())\r\nprint(pa.default_memory_pool().backend_name)\r\n\r\ndef bm():\r\n    table = pq.read_table('/home/pace/dev/benchmarks/benchmarks/data/temp/fanniemae_2016Q4.uncompressed.parquet')\r\n    df = table.to_pandas()\r\n    print(pa.total_allocated_bytes())\r\n    proc = psutil.Process(os.getpid())\r\n    print(proc.memory_info())\r\n\r\nfor _ in range(10):\r\n    bm()\r\n\r\n```",
        "created_at": "2021-04-23T13:14:33.000Z",
        "updated_at": "2021-11-10T19:23:39.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-11-10T19:23:39.000Z"
    },
    "comments": [
        {
            "created_at": "2021-04-23T13:33:59.305Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17330466) by Jonathan Keane (jonkeane):*\nInteresting! I've definitely noticed this with the fanniemae csv but never uncovered what was going on with it.\r\n\r\nIf you look in the fanniemae columns of plots and especially the arrow_table rows of plots (where we only read into arrow and not then into a dataframe) you can see that the durations on those increase over time (which IME in situations like these correlate with memory (over)allocation / leakiness / what you describe). \r\n\r\nhttps://ursalabs.org/blog/2021-r-benchmarks-part-1/memory-allocators-full.png\r\n\r\nInterestingly, this seems to happen with all datasets with jemalloc (there's some exploration of this though no real conclusion in ARROW-11433)."
        },
        {
            "created_at": "2021-04-23T13:40:07.158Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17330472) by Jonathan Keane (jonkeane):*\nI've also attached some more recent R benchmarks (the 7 April HEAD uses mimalloc 2.0 and 6 April uses 1.6 \u2014 we are now using 1.6 because we saw some regressions in the c++ microbenchmarks with 2.0)\r\n\r\nWe see the same increase in durection for fanniemae here, but not for the other datasets (well, except for with 3.0 which used jemalloc, but that's the same as ^^^)\r\n\r\nOddly(?) the files that are individual types don't seem to exhibit this pattern anywhere (though those files are much smaller / quicker so maybe this only impacts larger files somehow?)"
        },
        {
            "created_at": "2021-04-23T14:44:16.502Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17330828) by Antoine Pitrou (apitrou):*\nWhen you say \"consumes 27GB of RAM\", it's the RSS number?"
        },
        {
            "created_at": "2021-04-23T17:29:20.227Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17330948) by Weston Pace (westonpace):*\n`[~apitrou]` Yes, the RSS number.\u00a0 Here is the output of the script run with MIMALLOC_SHOW_STATS=1\r\n```java\n\r\nmimalloc\r\n8609028224\r\npmem(rss=11891290112, vms=16666406912, shared=45887488, text=2023424, lib=0, data=16011034624, dirty=0)\r\n8609028224\r\npmem(rss=17924034560, vms=25525309440, shared=47259648, text=2023424, lib=0, data=24869982208, dirty=0)\r\n8609028224\r\npmem(rss=19656933376, vms=25793744896, shared=47259648, text=2023424, lib=0, data=25138417664, dirty=0)\r\n8609028224\r\npmem(rss=21644206080, vms=26062180352, shared=47259648, text=2023424, lib=0, data=25406853120, dirty=0)\r\n8609028224\r\npmem(rss=22500700160, vms=26330615808, shared=47259648, text=2023424, lib=0, data=25675292672, dirty=0)\r\n8609028224\r\npmem(rss=23115137024, vms=26330615808, shared=46972928, text=2023424, lib=0, data=25675296768, dirty=0)\r\n8609028224\r\npmem(rss=23457878016, vms=26330615808, shared=47063040, text=2023424, lib=0, data=25675296768, dirty=0)\r\n8609028224\r\npmem(rss=23734255616, vms=26330615808, shared=45867008, text=2023424, lib=0, data=25675296768, dirty=0)\r\n8609028224\r\npmem(rss=23847768064, vms=26330615808, shared=45510656, text=2023424, lib=0, data=25675300864, dirty=0)\r\n8609028224\r\npmem(rss=23974707200, vms=26330615808, shared=45461504, text=2023424, lib=0, data=25675300864, dirty=0)\r\nheap stats:     peak      total      freed       unit      count  \r\n  reserved:    51.1 gb    53.7 gb    53.7 gb       1 b              ok\r\n committed:    51.1 gb    53.7 gb    53.5 gb       1 b              not all freed!\r\n     reset:    84.1 mb     1.8 gb     1.8 gb       1 b              not all freed!\r\n   touched:       0 b        0 b    150.1 gb       1 b              ok\r\n  segments:     166       36.6 k     36.6 k                         ok\r\n-abandoned:       0          0          0                           ok\r\n   -cached:       0          0          0                           ok\r\n     pages:     7.8 k     39.7 k     39.7 k                         ok\r\n-abandoned:       0          0          0                           ok\r\n -extended:       0   \r\n -noretire:       0   \r\n     mmaps:       0   \r\n   commits:     100   \r\n   threads:       8          8          8                           ok\r\n  searches:     0.0 avg\r\nnuma nodes:       1\r\n   elapsed:      57.660 s\r\n   process: user: 169.387 s, system: 30.217 s, faults: 7, reclaims: 19183835, rss: 27.4 gb\r\n\r\n```"
        },
        {
            "created_at": "2021-04-23T17:42:12.141Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17330954) by Weston Pace (westonpace):*\nAnd here is a run using the NYC dataset which is half as large but still requires >3X the required amount of RAM...\r\n```java\n\r\nmimalloc\r\n8609028224\r\npmem(rss=11891290112, vms=16666406912, shared=45887488, text=2023424, lib=0, data=16011034624, dirty=0)\r\n8609028224\r\npmem(rss=17924034560, vms=25525309440, shared=47259648, text=2023424, lib=0, data=24869982208, dirty=0)\r\n8609028224\r\npmem(rss=19656933376, vms=25793744896, shared=47259648, text=2023424, lib=0, data=25138417664, dirty=0)\r\n8609028224\r\npmem(rss=21644206080, vms=26062180352, shared=47259648, text=2023424, lib=0, data=25406853120, dirty=0)\r\n8609028224\r\npmem(rss=22500700160, vms=26330615808, shared=47259648, text=2023424, lib=0, data=25675292672, dirty=0)\r\n8609028224\r\npmem(rss=23115137024, vms=26330615808, shared=46972928, text=2023424, lib=0, data=25675296768, dirty=0)\r\n8609028224\r\npmem(rss=23457878016, vms=26330615808, shared=47063040, text=2023424, lib=0, data=25675296768, dirty=0)\r\n8609028224\r\npmem(rss=23734255616, vms=26330615808, shared=45867008, text=2023424, lib=0, data=25675296768, dirty=0)\r\n8609028224\r\npmem(rss=23847768064, vms=26330615808, shared=45510656, text=2023424, lib=0, data=25675300864, dirty=0)\r\n8609028224\r\npmem(rss=23974707200, vms=26330615808, shared=45461504, text=2023424, lib=0, data=25675300864, dirty=0)\r\nheap stats:     peak      total      freed       unit      count  \r\n  reserved:    51.1 gb    53.7 gb    53.7 gb       1 b              ok\r\n committed:    51.1 gb    53.7 gb    53.5 gb       1 b              not all freed!\r\n     reset:    84.1 mb     1.8 gb     1.8 gb       1 b              not all freed!\r\n   touched:       0 b        0 b    150.1 gb       1 b              ok\r\n  segments:     166       36.6 k     36.6 k                         ok\r\n-abandoned:       0          0          0                           ok\r\n   -cached:       0          0          0                           ok\r\n     pages:     7.8 k     39.7 k     39.7 k                         ok\r\n-abandoned:       0          0          0                           ok\r\n -extended:       0   \r\n -noretire:       0   \r\n     mmaps:       0   \r\n   commits:     100   \r\n   threads:       8          8          8                           ok\r\n  searches:     0.0 avg\r\nnuma nodes:       1\r\n   elapsed:      57.660 s\r\n   process: user: 169.387 s, system: 30.217 s, faults: 7, reclaims: 19183835, rss: 27.4 gb\r\n\r\n```"
        },
        {
            "created_at": "2021-04-23T17:57:12.621Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17330960) by Antoine Pitrou (apitrou):*\nThat's a bit disconcerting. It may be worthwhile opening an issue on the mimalloc issue tracker to gather opinions and seek for guidance."
        },
        {
            "created_at": "2021-04-23T18:07:10.707Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17330967) by Weston Pace (westonpace):*\nI will do so."
        },
        {
            "created_at": "2021-04-23T18:36:48.663Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17330984) by Weston Pace (westonpace):*\nhttps://github.com/microsoft/mimalloc/issues/393"
        },
        {
            "created_at": "2021-11-10T16:20:01.107Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17441823) by Antoine Pitrou (apitrou):*\n`[~westonpace]` Should we do something with this JIRA? (sorry, edited: \"JIRA\" not \"PR\")"
        },
        {
            "created_at": "2021-11-10T19:23:12.645Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12519?focusedCommentId=17441916) by Weston Pace (westonpace):*\nI'll close it.\u00a0 I think this issue in particular turned out to be python holding onto the memory (something to do with exceptions or for loops).\u00a0 I'm not aware of any real world, obvious and egregious jemalloc misbehavior at the moment."
        }
    ]
}