{
    "issue": {
        "title": "[R] Weird R error: Error in fs___FileSystem__GetTargetInfos_FileSelector(self, x) :    ignoring SIGPIPE signal",
        "body": "***Note**: This issue was originally created as [ARROW-16680](https://issues.apache.org/jira/browse/ARROW-16680). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nOkay apologies, this is a bit of a weird error but is annoying the heck out of me.\u00a0 The following block of all R code, when run with Rscript (or embedded into any form of Rmd, quarto, knitr doc) produces the error below (at least most of the time):\r\n\r\n\u00a0\r\n```java\n\r\nlibrary(arrow)\r\nlibrary(dplyr)\n```\r\n```java\n\r\nSys.setenv(AWS_EC2_METADATA_DISABLED = \"TRUE\")\r\nSys.unsetenv(\"AWS_ACCESS_KEY_ID\")\r\nSys.unsetenv(\"AWS_SECRET_ACCESS_KEY\")\r\nSys.unsetenv(\"AWS_DEFAULT_REGION\")\r\nSys.unsetenv(\"AWS_S3_ENDPOINT\")s3 <- arrow::s3_bucket(bucket = \"scores/parquet\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0endpoint_override = \"data.ecoforecast.org\")\r\nds <- arrow::open_dataset(s3, partitioning = c(\"theme\", \"year\"))\r\nds |> dplyr::filter(theme == \"phenology\") |> dplyr::collect()\r\n```\r\nGives the error\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n```java\n\r\nError in fs___FileSystem__GetTargetInfos_FileSelector(self, x) : \r\n  ignoring SIGPIPE signal\r\nCalls: %>% ... <Anonymous> -> fs___FileSystem__GetTargetInfos_FileSelector \n```\r\nBut only when run as a script! When run interactively in an R console, this code runs just fine.\u00a0 Even as a script the code seems to run fine, but erroneously seems to be attempting this sigpipe I don't understand.\u00a0\u00a0\r\n\r\nIf the script is executed with litter (<https://dirk.eddelbuettel.com/code/littler.html)> then it runs fine, since littler handles sigpipe but Rscripts don't.\u00a0 But I have no idea why the above code throws a pipe in the first place.\u00a0 Worse, if I choose a different filter for the above, like \"aquatics\", it (usually) works without the error.\u00a0\u00a0\r\n\r\nI have no idea why `fs___FileSystem__GetTargetInfos_FileSelector` results in this, but would really appreciate any hints on how to avoid this as it makes it very hard to use arrow in workflows right now!\u00a0\r\n\r\n\u00a0\r\n\r\nthanks for all you do!\r\n\r\n\u00a0",
        "created_at": "2022-05-27T21:06:18.000Z",
        "updated_at": "2022-11-11T17:33:05.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-05-31T11:03:46.236Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17544320) by Nicola Crane (thisisnic):*\nThanks for reporting this `[~cboettig]`.\u00a0 Not sure what's going on here, looks like it could be similar to another issue we have open which is currently unresolved: <https://github.com/apache/arrow/issues/12118#issuecomment-1027823802>\r\n\r\nI've seen something here about a completely different use case (not using Arrow); someone reading from a TSV file and it not having finished reading causes a similar error: <https://www.mail-archive.com/r-help@r-project.org/msg261632.html>\r\n\r\nOut of interest, how many rows does the query return that causes the issue versus a couple that don't?\r\n\r\n`[~apitrou]` - does anything come to mind here?"
        },
        {
            "created_at": "2022-05-31T11:40:34.510Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17544341) by Antoine Pitrou (apitrou):*\nIntuitively, this does not seem to be a problem with Arrow, especially if it happens to other people in unrelated use cases."
        },
        {
            "created_at": "2022-05-31T11:41:42.651Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17544342) by Antoine Pitrou (apitrou):*\nIs this reproducible using the snippet above? `[~paleolimbot]`"
        },
        {
            "created_at": "2022-05-31T14:28:45.325Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17544422) by Nicola Crane (thisisnic):*\n`[~apitrou]` Perhaps not an Arrow issue, though I'm wondering if there's something about running it in a script and the reading from S3 being incomplete which is causing the issue."
        },
        {
            "created_at": "2022-05-31T14:53:05.499Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17544440) by Dewey Dunnington (paleolimbot):*\nHmm...I get a few things depending on what I try. I can get this to run without error, and I also got the below error once:\r\n\r\n```R\n\r\ncode <- '\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\n\r\nSys.setenv(AWS_EC2_METADATA_DISABLED = \"TRUE\")\r\nSys.unsetenv(\"AWS_ACCESS_KEY_ID\")\r\nSys.unsetenv(\"AWS_SECRET_ACCESS_KEY\")\r\nSys.unsetenv(\"AWS_DEFAULT_REGION\")\r\nSys.unsetenv(\"AWS_S3_ENDPOINT\")\r\ns3 <- arrow::s3_bucket(\r\n  bucket = \"scores/parquet\",\r\n  endpoint_override = \"data.ecoforecast.org\"\r\n)\r\nds <- arrow::open_dataset(s3, partitioning = c(\"theme\", \"year\"))\r\nprint(ds |> dplyr::filter(theme == \"phenology\") |> dplyr::collect())\r\n'\r\n\r\ntf <- tempfile()\r\nwrite(code, tf)\r\n\r\ncallr::rscript(tf)\r\n```\r\n\r\n\r\n```\n\r\nError in `dplyr::collect()`:\r\n! Invalid: Could not open Parquet input source 'scores/parquet/phenology/2022/phenology-2022-05-05-PEG_FUSION_0.parquet': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\r\n/Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/compute/exec/exec_plan.cc:470  iterator_.Next()\r\n/Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/record_batch.cc:337  ReadNext(&batch)\r\n/Users/deweydunnington/Desktop/rscratch/arrow/cpp/src/arrow/record_batch.cc:351  ToRecordBatches()\r\nBacktrace:\r\n    \u2586\r\n 1. \u251c\u2500base::print(dplyr::collect(dplyr::filter(ds, theme == \"phenology\")))\r\n 2. \u251c\u2500dplyr::collect(dplyr::filter(ds, theme == \"phenology\"))\r\n 3. \u2514\u2500arrow:::collect.arrow_dplyr_query(...)\r\n 4.   \u2514\u2500base::tryCatch(...) at r/R/dplyr-collect.R:22:2\r\n 5.     \u2514\u2500base tryCatchList(expr, classes, parentenv, handlers)\r\n 6.       \u2514\u2500base tryCatchOne(expr, names, parentenv, handlers[[1L]])\r\n 7.         \u2514\u2500value[[3L]](cond)\r\n 8.           \u2514\u2500arrow:::handle_csv_read_error(e, x$.data$schema, call) at r/R/dplyr-collect.R:27:6\r\n 9.             \u2514\u2500rlang::abort(msg, call = call) at r/R/util.R:212:2\r\nExecution halted\r\n* Closing connection 0\r\n* Closing connection 0\r\n* Closing connection 0\r\n* Closing connection 0\r\n* Closing connection 0\r\n* Closing connection 0\r\n* Closing connection 0\r\n* Closing connection 0\r\n* Closing connection 0\r\nError in (function (command = NULL, args = character(), error_on_status = TRUE,  : \r\n  System command 'Rscript' failed, exit status: 1, stdout & stderr were printed\r\nType .Last.error.trace to see where the error occurred\r\n```\r\n\r\n"
        },
        {
            "created_at": "2022-05-31T17:01:37.801Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17544504) by Carl Boettiger (cboettig):*\nHi folks, thanks for testing, I know this is a weird issue.\u00a0 It does not reproduce for me every time either, but most of the time.\u00a0\r\n\r\nSome machines reproduce the error more frequently for me than others (I think ones with slightly lower-speed network connections).\u00a0 If I remove the filter in the last command, it is a bit easier to reproduce the error.\u00a0 (with no filter, the data has ~ 4M rows)\r\n\r\nI think the error above about magic bytes is unrelated; I have seen that occasionally too, and I think it might just be some kind of chance lost packet / network error?\u00a0\r\n\r\n\u00a0\r\n\r\nThe error trace from the SIGPIPE error is thrown by the arrow function, https://github.com/apache/arrow/blob/master/r/R/filesystem.R#L204\r\n\r\n\u00a0\r\n\r\nAnyway, I appreciate you taking a look at all at this weird issue.\u00a0 Any other pointers on how to trace this down, or why fs___FileSystem__GetTargetInfos_FileSelector might involve a sigpipe in the first place?\u00a0 (really tricky without being able to reproduce in an interactive session!)"
        },
        {
            "created_at": "2022-07-23T18:03:05.649Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17570344) by Vitalie Spinu (vspinu):*\nI am not seeing this from `fs__FileSystem_GetTargetInfos_FileSelector`. In fact all I see is `Error: ignoring SIGPIPE signal Execution halted` which pops after my my entire R script completes.\u00a0\r\n\r\n\r\nTo my eye this comes from aws-> curl. This is dbg backtrace:\r\n```java\n\r\nThread 12 \"R\" received signal SIGPIPE, Broken pipe.\r\n[Switching to Thread 0x7fffd37fe700 (LWP 207327)]\r\n__libc_write (nbytes=31, buf=0x7fffc05828a3, fd=15) at ../sysdeps/unix/sysv/linux/write.c:26\r\n26 \u00a0 \u00a0 \u00a0../sysdeps/unix/sysv/linux/write.c: No such file or directory.\r\n(gdb) backtrace\r\n#0 \u00a0__libc_write (nbytes=31, buf=0x7fffc05828a3, fd=15) at ../sysdeps/unix/sysv/linux/write.c:26\r\n#1 \u00a0__libc_write (fd=15, buf=0x7fffc05828a3, nbytes=31) at ../sysdeps/unix/sysv/linux/write.c:24\r\n#2 \u00a00x00007fffec3ad459 in ?? () from /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n#3 \u00a00x00007fffec3a863e in ?? () from /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n#4 \u00a00x00007fffec3a7654 in ?? () from /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n#5 \u00a00x00007fffec3a7b17 in BIO_write () from /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n#6 \u00a00x00007fffec113dde in ?? () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#7 \u00a00x00007fffec114cd9 in ?? () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#8 \u00a00x00007fffec11e88e in ?? () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#9 \u00a00x00007fffec11ca65 in ?? () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#10 0x00007fffec127ec3 in SSL_shutdown () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#11 0x00007fffec2d37c5 in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#12 0x00007fffec2d3835 in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#13 0x00007fffec2918ce in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#14 0x00007fffec294216 in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#15 0x00007fffec2a6ecf in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#16 0x00007fffec2a7d31 in curl_multi_perform () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#17 0x00007fffec29e1bb in curl_easy_perform () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#18 0x00007fffee3e247b in Aws::Http::CurlHttpClient::MakeRequest(std::shared_ptr<Aws::Http::HttpRequest> const&, Aws::Utils::RateLimits::RateLimiterInterface*, Aws::Utils::RateLimits::RateLimiterInterface*) const ()\r\n\u00a0 \u00a0from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#19 0x00007fffee1a721a in Aws::Client::AWSClient::AttemptOneRequest(std::shared_ptr<Aws::Http::HttpRequest> const&, Aws::AmazonWebServiceRequest const&, char const*, char const*, char const*) const ()\r\n\u00a0 \u00a0from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#20 0x00007fffee1bc1a3 in Aws::Client::AWSClient::AttemptExhaustively(Aws::Http::URI const&, Aws::AmazonWebServiceRequest const&, Aws::Http::HttpMethod, char const*, char const*, char const*) const ()\r\n\u00a0 \u00a0from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#21 0x00007fffee1bd448 in Aws::Client::AWSClient::MakeRequestWithUnparsedResponse(Aws::Http::URI const&, Aws::AmazonWebServiceRequest const&, Aws::Http::HttpMethod, char const*, char const*, char const*) const ()\r\n\u00a0 \u00a0from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#22 0x00007fffee2e5933 in Aws::S3::S3Client::GetObject(Aws::S3::Model::GetObjectRequest const&) const () from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#23 0x00007fffedfb6234 in arrow::fs::(anonymous namespace)::ObjectInputFile::ReadAt(long, long, void*) () from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#24 0x00007fffedfb6931 in arrow::fs::(anonymous namespace)::ObjectInputFile::ReadAt(long, long) () from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#25 0x00007fffed378474 in arrow::internal::FnOnce<void ()>::FnImpl<std::_Bind<arrow::detail::ContinueFuture (arrow::Future<std::shared_ptr<arrow::Buffer> >, arrow::io::RandomAccessFile::ReadAsync(arrow::io::IOContext const&, long, long)::{lambda()#1})> >::invoke() () from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#26 0x00007fffed402ca7 in std::thread::_State_impl<std::thread::_Invoker<std::tuple<arrow::internal::ThreadPool::LaunchWorkersUnlocked(int)::{lambda()#1}> > >::_M_run() ()\r\n\u00a0 \u00a0from /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/arrow/libs/arrow.so\r\n#27 0x00007ffff59d0de4 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#28 0x00007ffff77c7609 in start_thread (arg=<optimized out>) at pthread_create.c:477\r\n#29 0x00007ffff76ec133 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n \n```\r\nI am using arrow's dataset on a S3 location and as the error does not occur on a specific call, I cannot apply the\u00a0 catch-retry strategy.\u00a0\r\n\r\n\u00a0\r\n\r\nI have also seen this error when using Athena odbc driver from R.\u00a0"
        },
        {
            "created_at": "2022-07-23T23:40:32.483Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17570394) by Vitalie Spinu (vspinu):*\nSome more digging with more debug symbols reveals that the error happens in the finalizer.\r\n\r\nI am a complete nob around these topics but it looks to me that at some point the finalizer is triggered and when `Aws::S3::S3Client::S3Client` is destructed curl still attempts to write to a disconnected socket in `curl_easy_cleanup`.\u00a0\r\n\r\n\u00a0\r\n```java\n\r\nThread 1 \"R\" received signal SIGPIPE, Broken pipe.\r\n__libc_write (nbytes=31, buf=0x555576a55b83, fd=43) at ../sysdeps/unix/sysv/linux/write.c:26\r\n26 \u00a0 \u00a0 \u00a0../sysdeps/unix/sysv/linux/write.c: No such file or directory.\r\n(gdb) break\r\nbreak \u00a0 \u00a0 \u00a0 \u00a0break-range \u00a0\r\n(gdb) backtrace\u00a0\r\n#0 \u00a0__libc_write (nbytes=31, buf=0x555576a55b83, fd=43) at ../sysdeps/unix/sysv/linux/write.c:26\r\n#1 \u00a0__libc_write (fd=43, buf=0x555576a55b83, nbytes=31) at ../sysdeps/unix/sysv/linux/write.c:24\r\n#2 \u00a00x00007fffe92b1459 in ?? () from /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n#3 \u00a00x00007fffe92ac63e in ?? () from /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n#4 \u00a00x00007fffe92ab654 in ?? () from /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n#5 \u00a00x00007fffe92abb17 in BIO_write () from /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n#6 \u00a00x00007fffe90f7dde in ?? () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#7 \u00a00x00007fffe90f8cd9 in ?? () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#8 \u00a00x00007fffe910288e in ?? () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#9 \u00a00x00007fffe9100a65 in ?? () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#10 0x00007fffe910bec3 in SSL_shutdown () from /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n#11 0x00007fffe91cc7c5 in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#12 0x00007fffe91cc835 in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#13 0x00007fffe918a8ce in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#14 0x00007fffe91b795b in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#15 0x00007fffe919f336 in curl_multi_cleanup () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#16 0x00007fffe918ab43 in ?? () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#17 0x00007fffe91972ed in curl_easy_cleanup () from /usr/lib/x86_64-linux-gnu/libcurl.so.4\r\n#18 0x00007fffec96aa14 in Aws::Http::CurlHandleContainer::~CurlHandleContainer (this=0x55556bd25ff8, __in_chrg=<optimized out>)\r\n\u00a0 \u00a0 at ~/vc/arrow/cpp/build/awssdk_ep-prefix/src/awssdk_ep/aws-cpp-sdk-core/source/http/curl/CurlHandleContainer.cpp:31\r\n#19 0x00007fffec952377 in Aws::Http::CurlHttpClient::~CurlHttpClient (this=0x55556bd25f90, __in_chrg=<optimized out>) at /usr/include/c++/9/ext/new_allocator.h:89\r\n#20 0x00007fffeabde0f2 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x55556bd25f80) at /usr/include/c++/9/bits/shared_ptr_base.h:155\r\n#21 0x00007fffec7f4ba5 in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count (this=0x5555758352d0, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:1169\r\n#22 std::__shared_ptr<Aws::Http::HttpClient, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr (this=0x5555758352c8, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:1169\r\n#23 std::shared_ptr<Aws::Http::HttpClient>::~shared_ptr (this=0x5555758352c8, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr.h:103\r\n#24 Aws::Client::AWSClient::~AWSClient (this=0x5555758352a0, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/build/awssdk_ep-prefix/src/awssdk_ep/aws-cpp-sdk-core/include/aws/core/client/AWSClient.h:106\r\n#25 Aws::Client::AWSXMLClient::~AWSXMLClient (this=0x5555758352a0, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/build/awssdk_ep-prefix/src/awssdk_ep/aws-cpp-sdk-core/include/aws/core/client/AWSClient.h:401\r\n#26 Aws::S3::S3Client::~S3Client (this=0x5555758352a0, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/build/awssdk_ep-prefix/src/awssdk_ep/aws-cpp-sdk-s3/source/S3Client.cpp:160\r\n#27 0x00007fffec52daf4 in arrow::fs::(anonymous namespace)::S3Client::~S3Client (this=0x5555758352a0, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/src/arrow/filesystem/s3fs.cc:554\r\n#28 0x00007fffec52eefd in __gnu_cxx::new_allocator<arrow::fs::(anonymous namespace)::S3Client>::destroy<arrow::fs::(anonymous namespace)::S3Client> (this=0x5555758352a0, __p=0x5555758352a0)\r\n\u00a0 \u00a0 at /usr/include/c++/9/ext/new_allocator.h:152\r\n#29 0x00007fffec52eb6f in std::allocator_traits<std::allocator<arrow::fs::(anonymous namespace)::S3Client> >::destroy<arrow::fs::(anonymous namespace)::S3Client> (__a=..., __p=0x5555758352a0)\r\n\u00a0 \u00a0 at /usr/include/c++/9/bits/alloc_traits.h:496\r\n#30 0x00007fffec52e4e1 in std::_Sp_counted_ptr_inplace<arrow::fs::(anonymous namespace)::S3Client, std::allocator<arrow::fs::(anonymous namespace)::S3Client>, (__gnu_cxx::_Lock_policy)2>::_M_dispose (this=0x555575835290)\r\n\u00a0 \u00a0 at /usr/include/c++/9/bits/shared_ptr_base.h:557\r\n#31 0x00007fffeabde0f2 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x555575835290) at /usr/include/c++/9/bits/shared_ptr_base.h:155\r\n#32 0x00007fffeabda9bb in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count (this=0x5555685ba510, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:730\r\n#33 0x00007fffec511cc4 in std::__shared_ptr<arrow::fs::(anonymous namespace)::S3Client, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr (this=0x5555685ba508, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:1169\r\n#34 0x00007fffec511ce0 in std::shared_ptr<arrow::fs::(anonymous namespace)::S3Client>::~shared_ptr (this=0x5555685ba508, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr.h:103\r\n#35 0x00007fffec57c38e in arrow::fs::S3FileSystem::Impl::~Impl (this=0x5555685ba0d0, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/src/arrow/filesystem/s3fs.cc:1647\r\n#36 0x00007fffec57c3e0 in __gnu_cxx::new_allocator<arrow::fs::S3FileSystem::Impl>::destroy<arrow::fs::S3FileSystem::Impl> (this=0x5555685ba0d0, __p=0x5555685ba0d0) at /usr/include/c++/9/ext/new_allocator.h:152\r\n#37 0x00007fffec57aff5 in std::allocator_traits<std::allocator<arrow::fs::S3FileSystem::Impl> >::destroy<arrow::fs::S3FileSystem::Impl> (__a=..., __p=0x5555685ba0d0) at /usr/include/c++/9/bits/alloc_traits.h:496\r\n#38 0x00007fffec57995f in std::_Sp_counted_ptr_inplace<arrow::fs::S3FileSystem::Impl, std::allocator<arrow::fs::S3FileSystem::Impl>, (__gnu_cxx::_Lock_policy)2>::_M_dispose (this=0x5555685ba0c0)\r\n\u00a0 \u00a0 at /usr/include/c++/9/bits/shared_ptr_base.h:557\r\n#39 0x00007fffeabde0f2 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x5555685ba0c0) at /usr/include/c++/9/bits/shared_ptr_base.h:155\r\n#40 0x00007fffeabda9bb in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count (this=0x555568408930, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:730\r\n#41 0x00007fffec536ec6 in std::__shared_ptr<arrow::fs::S3FileSystem::Impl, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr (this=0x555568408928, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:1169\r\n#42 0x00007fffec536ee6 in std::shared_ptr<arrow::fs::S3FileSystem::Impl>::~shared_ptr (this=0x555568408928, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr.h:103\r\n#43 0x00007fffec51b3da in arrow::fs::S3FileSystem::~S3FileSystem (this=0x5555684088e0, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/src/arrow/filesystem/s3fs.cc:2206\r\n#44 0x00007fffec51b406 in arrow::fs::S3FileSystem::~S3FileSystem (this=0x5555684088e0, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/src/arrow/filesystem/s3fs.cc:2206\r\n#45 0x00007fffec57ab32 in std::_Sp_counted_ptr<arrow::fs::S3FileSystem*, (__gnu_cxx::_Lock_policy)2>::_M_dispose (this=0x555565dc4cb0) at /usr/include/c++/9/bits/shared_ptr_base.h:377\r\n#46 0x00007fffee754ed8 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x555565dc4cb0) at /usr/include/c++/9/bits/shared_ptr_base.h:148\r\n#47 std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x555565dc4cb0) at /usr/include/c++/9/bits/shared_ptr_base.h:148\r\n#48 0x00007fffee35eba9 in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count (this=0x555570637880, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:730\r\n#49 0x00007fffee37b412 in std::__shared_ptr<arrow::fs::FileSystem, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr (this=0x555570637878, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:1169\r\n#50 0x00007fffee37b45c in std::shared_ptr<arrow::fs::FileSystem>::~shared_ptr (this=0x555570637878, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr.h:103\r\n#51 0x00007fffec49b75a in arrow::fs::SubTreeFileSystem::~SubTreeFileSystem (this=0x555570637810, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/src/arrow/filesystem/filesystem.cc:276\r\n#52 0x00007fffee754ed8 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x555570637800) at /usr/include/c++/9/bits/shared_ptr_base.h:148\r\n#53 std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x555570637800) at /usr/include/c++/9/bits/shared_ptr_base.h:148\r\n#54 0x00007fffee35eba9 in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count (this=0x555568218770, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:730\r\n#55 0x00007fffee37b412 in std::__shared_ptr<arrow::fs::FileSystem, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr (this=0x555568218768, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:1169\r\n#56 0x00007fffee37b45c in std::shared_ptr<arrow::fs::FileSystem>::~shared_ptr (this=0x555568218768, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr.h:103\r\n#57 0x00007fffee3c23d4 in arrow::dataset::FileSystemDataset::~FileSystemDataset (this=0x555568218720, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/src/arrow/dataset/file_base.h:222\r\n#58 0x00007fffee3c2410 in arrow::dataset::FileSystemDataset::~FileSystemDataset (this=0x555568218720, __in_chrg=<optimized out>) at ~/vc/arrow/cpp/src/arrow/dataset/file_base.h:222\r\n#59 0x00007fffee3d19e2 in std::_Sp_counted_ptr<arrow::dataset::FileSystemDataset*, (__gnu_cxx::_Lock_policy)2>::_M_dispose (this=0x55556a3ca000) at /usr/include/c++/9/bits/shared_ptr_base.h:377\r\n#60 0x00007fffee7ad357 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x55556a3ca000) at /usr/include/c++/9/bits/shared_ptr_base.h:148\r\n#61 std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release (this=0x55556a3ca000) at /usr/include/c++/9/bits/shared_ptr_base.h:148\r\n#62 std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count (this=0x555568170738, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:730\r\n#63 std::__shared_ptr<arrow::dataset::Dataset, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr (this=0x555568170730, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr_base.h:1169\r\n#64 std::shared_ptr<arrow::dataset::Dataset>::~shared_ptr (this=0x555568170730, __in_chrg=<optimized out>) at /usr/include/c++/9/bits/shared_ptr.h:103\r\n#65 cpp11::default_deleter<std::shared_ptr<arrow::dataset::Dataset> > (obj=0x555568170730) at /path/to/renv/library/R-4.2/x86_64-pc-linux-gnu/cpp11/include/cpp11/external_pointer.hpp:17\r\n#66 cpp11::external_pointer<std::shared_ptr<arrow::dataset::Dataset>, &cpp11::default_deleter<std::shared_ptr<arrow::dataset::Dataset> > >::r_deleter (p=<optimized out>) at /renv/library/R-4.2/x86_64-pc-linux-gnu/cpp11/include/cpp11/external_pointer.hpp:47\r\n#67 cpp11::external_pointer<std::shared_ptr<arrow::dataset::Dataset>, &cpp11::default_deleter<std::shared_ptr<arrow::dataset::Dataset> > >::r_deleter (p=<optimized out>) at /renv/library/R-4.2/x86_64-pc-linux-gnu/cpp11/include/cpp11/external_pointer.hpp:36\r\n#68 0x00005555556dcb77 in R_RunWeakRefFinalizer (w=<optimized out>) at memory.c:1500\r\n#69 0x00005555556dcde3 in RunFinalizers () at memory.c:1567\r\n#70 0x00005555556dcf85 in R_RunPendingFinalizers () at memory.c:1603\r\n#71 0x00005555556937ba in bc_check_sigint () at eval.c:5550\r\n#72 bcEval (body=<optimized out>, rho=<optimized out>, useCache=<optimized out>) at eval.c:6744\r\n#73 0x000055555569cd58 in Rf_eval (e=0x5555678ed528, rho=rho@entry=0x55557677c728) at eval.c:748\r\n#74 0x000055555569ea8f in R_execClosure (call=call@entry=0x555567b579f8, newrho=newrho@entry=0x55557677c728, sysparent=<optimized out>, rho=rho@entry=0x5555767b7008, arglist=arglist@entry=0x55557677c6b8, op=op@entry=0x5555678ed1a8) at eval.c:1918\r\n \n```"
        },
        {
            "created_at": "2022-08-03T20:22:12.794Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17574916) by Carl Boettiger (cboettig):*\nHi arrow devs, apologies that this one is hard to write a reprex for, but this issue is still killing me.\u00a0 The issue happens when running as an external command \u2013 RScript, knit, now quarto as well, for most non-trivial scripts that touches S3 using arrow.\u00a0 At the moment, the only successful workaround I've found has been using littler, `r` instead of `RScript`, which understands sigpipes and thus doesn't error under these conditions.\u00a0 Unfortunately that does not help for standard workflows that rely on things like quarto or blogdown or the many other tools in the RStudio markdown ecosystem that all interpret this as an error.\u00a0 \r\n\r\nHere's another attempt at a reprex:\r\n```java\n\r\ndownload.file(\"https://github.com/cboettig/forecasts-darts-framework/raw/main/weather-covariates.qmd\", \"sigpipe.qmd\")\r\nquarto::quarto_render(\"sigpipe.qmd\")\r\n# ...\r\n#> \u00a0$ include: logi FALSE\r\n#>\u00a0\r\n#>\u00a0\r\n#> [31moutput file: sigpipe.knit.md\r\n#>\u00a0\r\n#> [39m[31mError: ignoring SIGPIPE signal\r\n#> Execution halted\r\n#> [39m\r\n#> Error in \"processx::run(quarto_bin, args, echo = TRUE)\": ! System command 'quarto' failed\r\n```\r\n\r\n\r\n<sup>Created on 2022-08-03 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>\u00a0"
        },
        {
            "created_at": "2022-08-03T23:53:41.541Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17574968) by Carl Boettiger (cboettig):*\nAdditional note \u2013 the behavior seems to be specific to Linux.\u00a0 Here's a GH-Actions task that runs the identical script on Linux, Mac, and Windows, reproducing this error on Linux but succeeding with the same script on Windows: <https://github.com/cboettig/scratch/runs/7662520931?check_suite_focus=true> .\u00a0 \r\nEven then the issue is slightly difficult to reproduce, it occurs frequently but not every time, as visible in the GH-Actions log there.\u00a0 Apologies, I realize that makes it hard to reproduce and debug."
        },
        {
            "created_at": "2022-08-04T02:10:00.278Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17574990) by Carl Boettiger (cboettig):*\nFWIW, the sigpipe error also appears more likely in larger data \u2013 e.g. If I add an additional `filter` to run the same code but on a smaller subset of the data I can almost always avoid the error. Definitely a nuisance to debug.\u00a0 Feels to me like there is some kind of race conditions behavior occurring, where the finalizer is closing a task before curl is done listening.\u00a0 (maybe the discussion here is relevant: https://stackoverflow.com/questions/28915838/piping-rscript-gives-error-after-output, but I'm well out of my depth).\u00a0"
        },
        {
            "created_at": "2022-08-04T13:14:39.507Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17575261) by Dewey Dunnington (paleolimbot):*\nThanks for keeping on this!\r\n\r\nFWIW, the deletion that seems to cause the sigpipe happens here: https://github.com/aws/aws-sdk-cpp/blob/main/aws-cpp-sdk-core/source/http/curl/CurlHandleContainer.cpp#L25-L33\r\n\r\n...and there is a way to disable sigpipe errors that was broken at one point: https://github.com/curl/curl/issues/3138 . That issue described a race condition that happens when objects get deleted that triggers a sigpipe, which seems consistent with what you're seeing (intermittent failure coming from a deleter).\r\n\r\nThat fix looks like it was in CURL 7.62.0, and Ubuntu focal is at 7.68.0 at least (and you're running on newer Ubuntu than that).\r\n\r\nIt **seems** like adding `curl_easy_setopt(curl, CURLOPT_NOSIGNAL);` right here https://github.com/aws/aws-sdk-cpp/blob/main/aws-cpp-sdk-core/source/http/curl/CurlHandleContainer.cpp#L89 might work?"
        },
        {
            "created_at": "2022-08-04T13:27:11.042Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17575264) by Neal Richardson (npr):*\nIs it possible for `[~cboettig]` to set that curl option outside of the aws-sdk (like the curl timeout issue) and prove out that it works?\r\n\r\nIf so, at a minimum we could introduce a patch step in our aws-sdk-cpp build to add that in, as well as upstream the fix (IDK when we'll upgrade to the latest aws-sdk-cpp even if they do accept the PR)."
        },
        {
            "created_at": "2022-08-22T20:56:33.768Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17583194) by Vitalie Spinu (vspinu):*\nAWS does set the option <https://github.com/aws/aws-sdk-cpp/blob/main/aws-cpp-sdk-core/source/http/curl/CurlHandleContainer.cpp#L142> to 1. The curl [doc](https://curl.se/libcurl/c/CURLOPT_NOSIGNAL.html)\u00a0 is a bit confusing though:\r\n\r\n\u00a0\r\n```\n\r\nSetting CURLOPT_NOSIGNAL to 1 makes libcurl NOT ask the system to\r\nignore SIGPIPE signals, which otherwise are sent by the system\r\nwhen trying to send data to a socket which is closed in the\r\nother end. libcurl makes an effort to never cause such SIGPIPEs\r\nto trigger, but some operating systems have no way to avoid them\r\nand even on those that have there are some corner cases when\r\nthey may still happen, contrary to our desire. In addition,\r\nusing CURLAUTH_NTLM_WB authentication could cause a SIGCHLD\r\nsignal to be raised.\n```\r\nIt looks like there is no way to reliably avoid shose sigpipes. Hence, maybe the right approach would be to handle sigpies like [plasma code does it](https://github.com/apache/arrow/blob/3c7a0cad0e25ed66e4c555d9da49f320f803573c/cpp/src/plasma/plasma.h#L52-L67) ?"
        },
        {
            "created_at": "2022-11-09T05:05:26.270Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17630753) by Carl Boettiger (cboettig):*\nHi folks, not to nag but this issue is still killing us.\u00a0 It seems only to occur when accessing relatively large remote S3 data, and even then isn't 100% repeatable, but I can't avoid it by setting CURLOPT_NOSIGNAL.\u00a0 This prevents us from using arrow in large automated workflows...\r\n\r\nWe can avoid it by running using littler instead of R / RScript, as littler can accept the sigpipe, but that is of no use in other tools that control how R is called,\u00a0 such as quarto notebooks.\u00a0 We reported this to the quarto team (<https://github.com/quarto-dev/quarto-cli/issues/1667#issuecomment-1204554958)> but after some trial mechanisms to avoid it JJ suggested it really needs to be resolved upstream instead..."
        },
        {
            "created_at": "2022-11-10T18:20:47.912Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17631842) by Dewey Dunnington (paleolimbot):*\nIt sounds like ignoring sigpipe unconditionally (i.e., in Arrow C++ or AWS SDK C++ code) is generally considered a bad idea; however, ignoring it within the session where you're running into this problem is probably fine. I can't reproduce this locally but you could try something like this as a workaround:\r\n\r\n```R\n\r\ncpp11::cpp_source(code = '\r\n#include <csignal>\r\n#include <cpp11.hpp>\r\n\r\n[[cpp11::register]] void ignore_sigpipes() {\r\n  signal(SIGPIPE, SIG_IGN);\r\n}\r\n')\r\n\r\nignore_sigpipes()\r\n```"
        },
        {
            "created_at": "2022-11-11T17:33:05.137Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16680?focusedCommentId=17632484) by Carl Boettiger (cboettig):*\nWow, thanks Dewey!\u00a0 That looks like black magic to me but I can definitely confirm that it works!\r\n\r\n\u00a0\r\n\r\nStill a bit stuck on the right thing to do in cases where we are providing user-facing packages that rely on arrow functions to access large external data, like you say I don't mind doing this in my scripts but it seems poor form to invisibly impose this on users where it may have side-effects with their other stuff?"
        }
    ]
}