{
    "issue": {
        "title": "[Python] org/apache/hadoop/fs/FileSystem class not found when pyarrow FileSystem used in spark",
        "body": "***Note**: This issue was originally created as [ARROW-5049](https://issues.apache.org/jira/browse/ARROW-5049). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nwhen i init pyarrow filesystem to connect hdfs clusfter in spark,the libhdfs throws error:\r\n```java\n\r\norg/apache/hadoop/fs/FileSystem class not found\u00a0\r\n```\r\nI print out the CLASSPATH, the classpath value is wildcard mode\u00a0\u00a0\r\n```java\n\r\n../share/hadoop/hdfs;spark/spark-2.0.2-bin-hadoop2.7/jars...\r\n```\r\nThe value is set by spark,but libhdfs must load class from jar files.\r\n\r\n\u00a0\r\n\r\nRoot cause is:\r\n\r\nIn hdfs.py we just check the string\u00a0 ''hadoop\"\u00a0 in classpath,but not jar file\r\n```java\n\r\ndef _maybe_set_hadoop_classpath():\r\n    if 'hadoop' in os.environ.get('CLASSPATH', ''):\r\n        return\n```",
        "created_at": "2019-03-28T02:36:19.000Z",
        "updated_at": "2019-04-25T20:08:40.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-04-25T20:08:40.000Z"
    },
    "comments": [
        {
            "created_at": "2019-04-25T20:08:40.910Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5049?focusedCommentId=16826427) by Micah Kornfield (emkornfield@gmail.com):*\nIssue resolved by pull request 4081\n<https://github.com/apache/arrow/pull/4081>"
        }
    ]
}