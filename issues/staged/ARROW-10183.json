{
    "issue": {
        "title": "[C++] Create a ForEach library function that runs on an iterator of futures",
        "body": "***Note**: This issue was originally created as [ARROW-10183](https://issues.apache.org/jira/browse/ARROW-10183). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThis method should take in an iterator of futures and a callback and\u00a0pull an item off the iterator, \"await\" it, run the callback on it, and then fetch the next item from the iterator.",
        "created_at": "2020-10-05T22:34:31.000Z",
        "updated_at": "2021-02-16T14:45:53.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-02-16T14:45:46.000Z"
    },
    "comments": [
        {
            "created_at": "2020-10-06T10:01:25.839Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17208626) by Antoine Pitrou (apitrou):*\nSo it's spawning a dedicated thread pool? Is there a desired use case for this feature?"
        },
        {
            "created_at": "2020-10-06T19:47:13.533Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17209101) by Weston Pace (westonpace):*\nNot spawning a thread pool, it would take a thread pool as an argument.\u00a0 The current use case I'm looking at is the CSV reader.\r\n\r\nThe current implementation is:\r\n \\* One thread (outside the thread pool, let's call it the I/O thread) reads from an input stream, up to X blocks in advance, and places the blocks in a blocking queue.\r\n \\* Another thread (calling thread, may be a thread pool thread, let's call it the parse thread) takes blocks off of the blocking queue (which it sees as an iterator) and creates thread pool tasks for conversion.\u00a0 This step will block if I/O is slow.\r\n \\* The thread pool threads (conversion tasks) then do the conversion, possibly making new conversion tasks which are added to the thread pool.\r\n \\* Once the parsing thread is done reading the iterator it blocks until the conversion tasks have finished.\r\n\r\nThe goal is to change the parsing thread so it is no longer blocking, as it may be a thread pool thread, and if it is blocking it shouldn't tie up the thread.\u00a0 I can keep the dedicated I/O thread since it is outside the thread pool.\r\n\r\nThis changes the I/O thread from an iterator of Block to an iterator of Future<Block>.\r\n\r\nConverting the parse thread is a little trickier.\u00a0 It currently is...\r\n\r\n`\u00a0 \u00a0 iterator = StartIterator();`\r\n\r\n`\u00a0 \u00a0 for each block in iterator:`\r\n\r\n`\u00a0 \u00a0 \u00a0 \u00a0\u00a0``ParseBlockAndCreateConversionTasks();`\r\n\r\n`\u00a0 \u00a0 WaitForConversionTasks();`\r\n\r\nThe \"for each\" part is a little trickier with a generator that returns promises.\u00a0 This task is aiming to replace that bit.\r\n\r\nNow that I think it all through like this I suppose the \"parallel for each\" and \"N threads\" wording is not needed.\u00a0 This is a natural point to allow for concurrency (e.g. allowing up to N parse threads).\u00a0 However, the original implementation had only the single parse thread so I don't need to introduce it here.\u00a0 I'll go ahead and strip that from the task and start with just a basic serial for each.\u00a0 Even with a serial for-each there is a need for a common library function that, given an iterator of futures, and a function, applies the function to each of the items in the iterator.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2020-10-06T19:50:33.217Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17209104) by Weston Pace (westonpace):*\nThis is also a bit of a mental investigation on my part to be sure this can be done without exploding the stack.\u00a0 Since this is essentially iterator.next().then(iterator.next().then(iterator.next().then(...\u00a0 My understanding is that it can, and there are numerous articles on continuations and avoiding stack busting while doing this kind of thing.\u00a0 I have yet to synthesize all that knowledge and put it into practice."
        },
        {
            "created_at": "2020-10-06T20:01:05.686Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17209110) by Antoine Pitrou (apitrou):*\nJust for the record, we already have a `AsCompleted` iterator. We could have a variant that takes an iterator of futures rather than a vector of futures."
        },
        {
            "created_at": "2020-10-07T11:55:12.125Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17209498) by Weston Pace (westonpace):*\nI had not quite come across that class so I appreciate the mention.\u00a0 It will not satisfy in this case though.\u00a0 There is a back pressure problem that is difficult to explain but will make more sense in code.\r\n\r\nMore significantly though, the AsCompletedIterator still does waits, which is what I'm trying to avoid.\u00a0 I'm attaching a diagram to this sub task that will hopefully provide a bit more explanation."
        },
        {
            "created_at": "2021-01-14T19:44:45.509Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17265168) by Weston Pace (westonpace):*\nLatest round of benchmarks (5 iterations on each)\r\n       |\u00a0|2.0.0 (Mean)|2.0.0 (StdDev)|Async (Mean)|Async (StdDev)|Async (Tasks)|Threaded (Mean)|Threaded (StdDev)|Threaded (Tasks)|\r\n\n|gzip/cache|6.291222|0.095669|6.467804|0.035468|6229|6.262252|0.056097|4149|\r|\n|-|-|-|-|-|-|-|-|-|-|\n|gzip/none|9.292271|0.251346|9.494446|0.273585|6229|9.22652|0.254951|4149|\r|\n|none/cache|1.226155|0.086003|1.245934|0.077262|6229|1.238495|0.073567|4149|\r|\n|none/none|34.326746|0.392563|35.091284|0.833403|6222|36.270428|2.033464|4149|\r<br>\r<br>gzip means the source file was compressed with gzip and cache means the source file was cached in the OS cache.\u00a0 For cache=None the benchmark is high.\u00a0 We have to make a file copy to ensure we are reading from the disk and this copy time is included in the benchmark.\u00a0 However, this overhead is consistent.\r<br>\r<br>The 2.0.0 numbers come from using the conda pyarrow (and thus the threaded table reader).\r<br>\r<br>Results are fairly noisy but I think there is some consistent minor degredation in the async case.\u00a0 It could be a result of there being a higher number of tasks, the high number of futures, using submit instead of spawn, or could just be noise.|\n"
        },
        {
            "created_at": "2021-01-16T01:47:32.354Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17266471) by Weston Pace (westonpace):*\nSome good news.\u00a0 I figured out my CSV reading benchmark was flawed (had the wrong separator).\u00a0 New results...\r\n\n|\u00a0|2.0.0 (Mean)|2.0.0 (StdDev)|Async (Mean)|Async (StdDev)|\r|\n|-|-|-|-|-|-|\n|gzip/cache|6.62|0.12|6.70|0.16|\r|\n|gzip/none|9.89|0.43|9.06|0.21|\r|\n|none/cache|4.05|0.09|3.95|0.11|\r|\n|none/none|34.57|1.15|32.25|1.22|\r<br>\r<br>I also realized at least one possible situation where the async reader could fall behind the threaded reader.\u00a0 If the I/O is running slower (e.g. zip case) then sometimes the parse task will find the I/O promise unfulfilled (finished parsing but next decompressed block not ready).\u00a0 In the threaded case the outer parsing thread will block here while in the async case a new task will get added to the pool to run when the I/O finishes.\u00a0 That task will get added in the pool **behind** all the conversion tasks.\u00a0 So then the parsing will be delayed and it is possible the readahead queue will fill up, delaying the I/O.\r<br>\r<br>\u00a0\r<br>\r<br>The timing has to be just right so that parsing & I/O are similar in performance.\u00a0 The I/O has to be slow enough to sometimes not be ready but not so slow that the task pool completely drains between each block.\r<br>\r<br>\u00a0\r<br>\r<br>I've tested the gzip/cache case quite often and this is the only case where the async version consistently unperformed.\u00a0 I think the I/O in the \\*/none cases are too slow and the I/O in the none/cache case is too fast.\r<br>\r<br>\u00a0\r<br>\r<br>A prioritized thread queue would allow working around this situation.\u00a0 The conversion tasks should be marked lower priority than the parsing tasks.|\n"
        },
        {
            "created_at": "2021-01-27T08:43:33.617Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17272684) by Weston Pace (westonpace):*\n`[~apitrou]` `[~bkietz]` I wanted to add a note about the parallelism of the AsyncGenerator.\u00a0 This is not so much a question as it is an update on my brain trying to wrap my head around all of this.\u00a0 I will confess that I have not yet fully internalized all of what can go on.\u00a0 For the purposes of discussion I will consider a chain (graph where each node has 1 or 2 edges and there are no cycles) of async generators, each node in the chain mutates the stream in some way.\u00a0 For example, in the CSV case there is the original Buffer generator (a background generator), the CSV block reader, the chunker, and then the \"parse & convert scheduler\" (a Visitor which terminates the chain).\u00a0 The \"fan-out\" in the CSV is still delegated to the task group so that parallelism need hasn't been fully explored, although it could remain a chain (I think).\r\n\r\nAn AsyncGenerator's Next() function should never have to be called by more than one thread at once in the way you might do with an iterator.\u00a0 Instead, the question comes down to whether you can call a generator's Next() function before the promise returned by the previous call has completed.\u00a0 It is similar and different.\u00a0 So it's not so much a question of \"thread safe\" as it is a question of \"reentrant\".\r\n\r\nAsyncGenerators come in both flavors.\u00a0 A decompressing node (or the CSV block reader and the CSV chunker) are all quite stateful and must finish processing a block before they can begin consuming the next.\u00a0 So you should not call Next() until the future returned is resolved.\u00a0 The parsing and converting on the other hand is free to run in parallel.\u00a0 In addition, any queuing stage (AddReadahead and BackgroundIterator) can be called in parallel, thus allowing for pipeline parallelism.\u00a0 Since everything is pull driven this \"parallel pull\" is driven from the AddReadahead nodes and could be driven from a \"visit\" or \"collect\" sink as well.\r\n\r\nSo just summarizing what we have today...\r\n\r\nSources:\r\nBackgroundGenerator - Reentrant, Does not pull\r\n\r\nIntermediate Nodes:\r\nTransformer - Not reentrant (by necessity of has_next), Does not pull\r\nAddReadahead - Reentrant, Pulls reentrantly\r\n\r\nSinks:\r\nVisit - Pulls serially (could be reentrantly in the future)\r\nCollect - Pulls serially (could be reentrantly in the future)\r\n\r\nToday we have...\r\n\r\nBackgroundGenerator -> AddReadahead -> Transformer -> Transformer -> Visit(1)\r\n\r\nIt would be an error for example to do...\r\n\r\nBackgroundGenerator -> AddReadahead -> Transformer -> Transformer -> Visit(N)\r\n\r\n...or...\r\n\r\nBackgroundGenerator -> AddReadahead -> Transformer -> Transformer -> AddReadahead -> Visit(1)\r\n\r\n...both of those would cause Transformer (which is not reentrant) to be pulled reentrantly.\u00a0 I am wondering if there is some merit in encoding these rules somehow into the types themselves so that something like that would fail to compile."
        },
        {
            "created_at": "2021-01-27T09:00:27.838Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17272696) by Weston Pace (westonpace):*\nAs maybe more food for though one could consider a classic map-reduce style summation task.\u00a0 A buffer comes in with 1024 elements, it is split into 8 sum tasks of 128 and then reduced with 7 reduce tasks.\u00a0 This \"fan-out\" could be implemented as a fully reentrant pipeline...\r\n\r\nMapper (Just a flatMap, fits Transformer model, but should be able to be made reentrant, emits 8 times for each input)\r\n Summer (Takes in a buffer and computes the sum, fits transformer model, but should be reentrant)\r\n Reducer (Consumes two numbers and outputs the sum, would NOT fit transformer model (even with skip), curiously though it should also be reentrant)\r\n\r\nAll of these could be \"transformers\" but the existing transform model would make them non-reentrant.\u00a0 However, all of them \"should\" be able to be reentrant.\u00a0 I think this argues somewhat to gaps in the transformer model.\u00a0 I have an improved model in mind, but it is was not compatible with synchronous iterators so I abandoned it.\u00a0 I may have to revisit."
        },
        {
            "created_at": "2021-02-16T14:45:46.335Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10183?focusedCommentId=17285235) by Ben Kietzman (bkietz):*\nIssue resolved by pull request 9095\n<https://github.com/apache/arrow/pull/9095>"
        }
    ]
}