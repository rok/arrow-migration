{
    "issue": {
        "title": "[R] DatasetFactory could sniff file formats",
        "body": "***Note**: This issue was originally created as [ARROW-12792](https://issues.apache.org/jira/browse/ARROW-12792). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI was running the following code:\r\n```java\n\r\ntf <- tempfile()\r\ndir.create(tf)\r\non.exit(unlink(tf))\r\nwrite_csv_arrow(mtcars[1:5,], file.path(tf, \"file1.csv\"))\r\nwrite_csv_arrow(mtcars[6:11,], file.path(tf, \"file2.csv\"))\r\n# ds <- open_dataset(c(file.path(tf, \"file1.csv\"), file.path(tf, \"file2.csv\")))\r\nds <- open_dataset(c(file.path(tf, \"file1.csv\"), file.path(tf, \"file2.csv\")), \r\n                   schema = Table$create(mtcars)$schema\r\n                   )\r\n```\r\nBut when I print the ds object, it reports that the files are Parquet files not CSVs\r\n```java\n\r\n> ds\r\n FileSystemDataset with 2 Parquet files\r\n mpg: double\r\n cyl: double\r\n disp: double\r\n hp: double\r\n drat: double\r\n wt: double\r\n qsec: double\r\n vs: double\r\n am: double\r\n gear: double\r\n carb: double\n```",
        "created_at": "2021-05-14T13:30:29.000Z",
        "updated_at": "2022-08-27T14:42:05.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-05-17T11:14:57.000Z"
    },
    "comments": [
        {
            "created_at": "2021-05-14T13:48:13.497Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12792?focusedCommentId=17344608) by Nicola Crane (thisisnic):*\nThis is because in open_dataset(), there is a call to DatasetFactory$create, which has argument format, for which the default argument is parquet. I think a reasonable solution is to add a function to open_dataset() which detects the format of the inputs and is called if sources are character vectors and no \"format\" parameter has been passed in."
        },
        {
            "created_at": "2021-05-14T14:49:17.151Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12792?focusedCommentId=17344636) by Neal Richardson (npr):*\nI'm not sure we want to go down this path (though not sure we don't). If I understand what you're proposing, if you provide file paths (and possibly only local file system paths, not S3/cloud), we sniff their file type, but if you provide a reference to a directory, we don't. I wonder if that step alone just adds confusion."
        },
        {
            "created_at": "2021-05-14T14:51:58.046Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12792?focusedCommentId=17344638) by Nicola Crane (thisisnic):*\nAh, didn't know it could be created with a reference to a directory.\r\n\r\nI suppose an alternative might be that DataSetFactor$create doesn't have a default value for format and it should instead be specified in the code?\u00a0 Sounds like it'd also help solve ARROW-12791 though I guess that expediancy isn't necessarily the reason to implement something."
        },
        {
            "created_at": "2021-05-17T11:14:41.946Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12792?focusedCommentId=17346084) by Nicola Crane (thisisnic):*\nAfter thinking about this, there are no sensible code-based changes - instead, I will add examples to the documentation on loading in non-parquet files."
        },
        {
            "created_at": "2022-08-27T14:42:05.194Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12792?focusedCommentId=17586031) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}