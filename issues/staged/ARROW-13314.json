{
    "issue": {
        "title": "[Python] JSON parsing segment fault on long records (block_size) dependent",
        "body": "***Note**: This issue was originally created as [ARROW-13314](https://issues.apache.org/jira/browse/ARROW-13314). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHello,\r\n\r\n\u00a0\r\n\r\nI have a big JSON file (~300MB) with complex records (nested json, nested lists of jsons). When I try to read this with pyarrow I am getting a segmentation fault. I tried then couple of things from read options, please see the code below (I developed this code on an example file that was attached here: https://issues.apache.org/jira/browse/ARROW-9612):\r\n\r\n\u00a0\r\n```python\n\r\n    from pyarrow import json\r\n    from pyarrow.json import ReadOptions\r\n    import tqdm\r\n\r\n    if __name__ == '__main__':\r\n\r\n         source = 'wiki_04.jsonl'\r\n\r\n         ro = ReadOptions(block_size=2**20)\r\n\r\n         with open(source, 'r') as file:\r\n             for i, line in tqdm.tqdm(enumerate(file)):\r\n                 with open('temp_file_arrow_3.ndjson', 'a') as file2:\r\n                     file2.write(line)\r\n                 json.read_json('temp_file_arrow_3.ndjson', read_options=ro)\r\n```\r\nFor both the example file and my file, this code will return the straddling object exception (or seg fault) once the file reach the block_size. Increasing the block_size will make the code fail later.\r\n\r\nThen I tried, on my file, to put an explicit schema:\r\n```python\n\r\n    from pyarrow import json\r\n    from pyarrow.json import ReadOptions\r\n    import pandas as pd\r\n\r\n    if __name__ == '__main__':\r\n\r\n         source = 'my_file.jsonl'\r\n\r\n         df = pd.read_json(source, lines=True) \r\n         table_schema = pa.Table.from_pandas(df).schema\r\n         \r\n         ro = ReadOptions(explicit_schema = table_schema)\r\n         table = json.read_json(source, read_options=ro)         \r\n\r\n```\r\nThis works, which may suggest that this issue, and the issue of the linked JIRA issue, are only appearing when an explicit schema is not provided. Additionally the following code works as well:\r\n```python\n\r\n    from pyarrow import json\r\n    from pyarrow.json import ReadOptions\r\n    import pandas as pd\r\n\r\n    if __name__ == '__main__':\r\n\r\n         source = 'my_file.jsonl'\r\n         \r\n         ro = ReadOptions(block_size = 2**30)\r\n         table = json.read_json(source, read_options=ro)         \r\n\r\n```\r\nThe block_size is bigger than my file in this case. Is it possible that the schema is defined in the first block and then if the schema changes, I get a seg fault?\r\n\r\nI cannot share my json file, however, I hope that someone could add some clarity on what I am seeing and maybe suggest a workaround.\r\n\r\nThank you,\r\n Guido",
        "created_at": "2021-07-12T16:52:01.000Z",
        "updated_at": "2022-04-08T13:02:55.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-07-19T14:32:53.605Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13314?focusedCommentId=17383377) by Alessandro Molina (amol-):*\nI was able to reproduce the issue locally. I seem to get the abort/segfault only when arrow is built in debug mode by the way. Otherwise it seems to freeze waiting for some thread.\r\n\r\nThis is the mentioned exception\r\n```Java\n\r\nTraceback (most recent call last):\r\n  File \"/home/amol/ARROW/tries/read.py\", line 5, in <module>\r\n    json.read_json('temp_file_arrow_3.ndjson', read_options=ro)\r\n  File \"pyarrow/_json.pyx\", line 247, in pyarrow._json.read_json\r\n  File \"pyarrow/error.pxi\", line 143, in pyarrow.lib.pyarrow_internal_check_status\r\n  File \"pyarrow/error.pxi\", line 99, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowInvalid: straddling object straddles two block boundaries (try to increase block size?)\r\n```\r\n\r\nIn debug mode I also get those two extra errors\r\n```Java\n\r\npure virtual method called\r\nterminate called without an active exception\r\n```\r\n\r\nand the traceback I could get from gdb looks like\r\n```Java\n\r\n#4  0x00007ffff39a5567 in std::terminate() () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#5  0x00007ffff39a62e5 in __cxa_pure_virtual () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#6  0x00007ffff5ed13f0 in arrow::json::ChunkedStructArrayBuilder::InsertChildren (this=0xb89ae0, block_index=0, \r\n    unconverted=...) at src/arrow/json/chunked_builder.cc:396\r\n#7  0x00007ffff5ed0321 in arrow::json::ChunkedStructArrayBuilder::Insert (this=0xb89ae0, block_index=0, \r\n    unconverted=std::shared_ptr<arrow::Array> (use count 1, weak count 0) = {...})\r\n    at src/arrow/json/chunked_builder.cc:320\r\n#8  0x00007ffff5f2ba61 in arrow::json::TableReaderImpl::ParseAndInsert (this=0xc489b0, \r\n    partial=std::shared_ptr<arrow::Buffer> (use count 1, weak count 0) = {...}, \r\n    completion=std::shared_ptr<arrow::Buffer> (use count 1, weak count 0) = {...}, \r\n    whole=std::shared_ptr<arrow::Buffer> (use count 1, weak count 0) = {...}, block_index=0)\r\n    at src/arrow/json/reader.cc:158\r\n#9  0x00007ffff5f2a331 in arrow::json::TableReaderImpl::Read()::{lambda()#1}::operator()() const (__closure=0xca6cb8)\r\n    at src/arrow/json/reader.cc:104\r\n...\r\n```"
        },
        {
            "created_at": "2022-04-08T13:02:55.955Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13314?focusedCommentId=17519565) by Jacob Wujciak-Jens (assignUser):*\nThe same exception still happen in pyarrow 7.0.0\u00a0"
        }
    ]
}