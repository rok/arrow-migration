{
    "issue": {
        "title": "Reading a StructArray column with an ExtensionType causes segfault",
        "body": "***Note**: This issue was originally created as [ARROW-17539](https://issues.apache.org/jira/browse/ARROW-17539). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWe can make nested columns in a Parquet file by putting a `pa.StructArray` in a `pa.Table` and writing that Table to Parquet. We can selectively read back that nested column by specifying it with dot syntax:\r\n\r\n`pq.ParquetFile(\"f.parquet\").read_row_groups([0], [\"table_column.struct_field\"])`\r\n\r\nBut if the Arrow types are ExtensionTypes, then the above causes a segfault. The segfault depends both on the nested struct field and the ExtensionTypes.\r\n\r\nHere is a minimally reproducing example of reading a nested struct field without extension types, which does not raise a segfault. (I'm building the `pa.StructArray` manually with `from_buffers` because I'll have to add the ExtensionTypes in the next example.)\r\n```python\n\r\nimport numpy as np\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\n\r\none = pa.Array.from_buffers(\r\n    pa.int64(),\r\n    3,\r\n    [None, pa.py_buffer(np.array([10, 20, 30], dtype=np.int64))],\r\n)\r\ntwo = pa.Array.from_buffers(\r\n    pa.float64(),\r\n    3,\r\n    [None, pa.py_buffer(np.array([1.1, 2.2, 3.3], dtype=np.float64))],\r\n)\r\nrecord = pa.Array.from_buffers(\r\n    pa.struct([\r\n        pa.field(\"one\", one.type, False),\r\n        pa.field(\"two\", two.type, False),\r\n    ]),\r\n    3,\r\n    [None],\r\n    children=[one, two],\r\n)\r\nassert record.to_pylist() == [\r\n    {\"one\": 10, \"two\": 1.1},\r\n    {\"one\": 20, \"two\": 2.2},\r\n    {\"one\": 30, \"two\": 3.3},\r\n]\r\n\r\ntable = pa.Table.from_arrays([record], names=[\"column\"])\r\npq.write_table(table, \"record.parquet\")\r\ntable2 = pq.ParquetFile(\"record.parquet\").read_row_groups([0], [\"column.one\"])\r\nassert table2.to_pylist() == [\r\n    {\"column\": {\"one\": 10}},\r\n    {\"column\": {\"one\": 20}},\r\n    {\"column\": {\"one\": 30}},\r\n]\r\n```\r\nSo far, so good; no segfault. Next, we define and register an ExtensionType,\r\n```python\n\r\nimport json\r\n\r\nclass AnnotatedType(pa.ExtensionType):\r\n    def __init__(self, storage_type, annotation):\r\n        self.annotation = annotation\r\n        super().__init__(storage_type, \"my:app\")\r\n    def __arrow_ext_serialize__(self):\r\n        return json.dumps(self.annotation).encode()\r\n    @classmethod\r\n    def __arrow_ext_deserialize__(cls, storage_type, serialized):\r\n        annotation = json.loads(serialized.decode())\r\n        print(storage_type, annotation)\r\n        return cls(storage_type, annotation)\r\n    @property\r\n    def num_buffers(self):\r\n        return self.storage_type.num_buffers\r\n    @property\r\n    def num_fields(self):\r\n        return self.storage_type.num_fields\r\n\r\npa.register_extension_type(AnnotatedType(pa.null(), None))\r\n```\r\nbuild the `pa.StructArray` again,\r\n```python\n\r\none = pa.Array.from_buffers(\r\n    AnnotatedType(pa.int64(), {\"annotated\": \"one\"}),\r\n    3,\r\n    [None, pa.py_buffer(np.array([10, 20, 30], dtype=np.int64))],\r\n)\r\ntwo = pa.Array.from_buffers(\r\n    AnnotatedType(pa.float64(), {\"annotated\": \"two\"}),\r\n    3,\r\n    [None, pa.py_buffer(np.array([1.1, 2.2, 3.3], dtype=np.float64))],\r\n)\r\nrecord = pa.Array.from_buffers(\r\n    AnnotatedType(\r\n        pa.struct([\r\n            pa.field(\"one\", one.type, False),\r\n            pa.field(\"two\", two.type, False),\r\n        ]),\r\n        {\"annotated\": \"record\"},\r\n    ),\r\n    3,\r\n    [None],\r\n    children=[one, two],\r\n)\r\nassert record.to_pylist() == [\r\n    {\"one\": 10, \"two\": 1.1},\r\n    {\"one\": 20, \"two\": 2.2},\r\n    {\"one\": 30, \"two\": 3.3},\r\n]\r\n```\r\nNow when we write and read this back, there's a segfault:\r\n```python\n\r\ntable = pa.Table.from_arrays([record], names=[\"column\"])\r\npq.write_table(table, \"record_annotated.parquet\")\r\n\r\nprint(\"before segfault\")\r\n\r\ntable2 = pq.ParquetFile(\"record_annotated.parquet\").read_row_groups([0], [\"column.one\"])\r\n\r\nprint(\"after segfault\")\r\n```\r\nThe output, which prints each annotation as the ExtensionType is deserialized, is\r\n```java\n\r\nbefore segfault\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\nSegmentation fault (core dumped)\r\n```\r\nNote that if we read back that file, `{}record_annotated.parquet{`}, without the ExtensionType, everything is fine:\r\n```java\n\r\nPython 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \r\n[GCC 10.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import pyarrow as pa\r\n>>> import pyarrow.parquet as pq\r\n>>> table2 = pq.ParquetFile(\"record_annotated.parquet\").read_row_groups([0], [\"column.one\"])\r\n>>> assert table2.to_pylist() == [\r\n...     {\"column\": {\"one\": 10}},\r\n...     {\"column\": {\"one\": 20}},\r\n...     {\"column\": {\"one\": 30}},\r\n... ]\r\n```\r\nand if we register the ExtensionType but don't select a column, everything is fine:\r\n```java\n\r\nPython 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \r\n[GCC 10.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import pyarrow as pa\r\n>>> import pyarrow.parquet as pq\r\n>>> import json\r\n>>> \r\n>>> class AnnotatedType(pa.ExtensionType):\r\n...     def __init__(self, storage_type, annotation):\r\n...         self.annotation = annotation\r\n...         super().__init__(storage_type, \"my:app\")\r\n...     def __arrow_ext_serialize__(self):\r\n...         return json.dumps(self.annotation).encode()\r\n...     @classmethod\r\n...     def __arrow_ext_deserialize__(cls, storage_type, serialized):\r\n...         annotation = json.loads(serialized.decode())\r\n...         print(storage_type, annotation)\r\n...         return cls(storage_type, annotation)\r\n...     @property\r\n...     def num_buffers(self):\r\n...         return self.storage_type.num_buffers\r\n...     @property\r\n...     def num_fields(self):\r\n...         return self.storage_type.num_fields\r\n... \r\n>>> pa.register_extension_type(AnnotatedType(pa.null(), None))\r\n>>> \r\n>>> table2 = pq.ParquetFile(\"record_annotated.parquet\").read_row_groups([0])\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\n>>> assert table2.to_pylist() == [\r\n...     {\"column\": {\"one\": 10, \"two\": 1.1}},\r\n...     {\"column\": {\"one\": 20, \"two\": 2.2}},\r\n...     {\"column\": {\"one\": 30, \"two\": 3.3}},\r\n... ]\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\nstruct<one: extension<my:app<AnnotatedType>> not null, two: extension<my:app<AnnotatedType>> not null> {'annotated': 'record'}\r\nint64 {'annotated': 'one'}\r\ndouble {'annotated': 'two'}\r\n```\r\nIt's just the case of doing both that causes the segfault.",
        "created_at": "2022-08-26T20:34:22.000Z",
        "updated_at": "2022-08-26T20:34:22.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": []
}