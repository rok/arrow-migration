{
    "issue": {
        "title": "Partition column dissappear when reading dataset",
        "body": "***Note**: This issue was originally created as [ARROW-14938](https://issues.apache.org/jira/browse/ARROW-14938). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAppending CSV to parquet dataset with partitioning on \"code\".\r\n```python\n\r\ntable = pa.Table.from_pandas(chunk)\r\n\u00a0 \u00a0 \u00a0 \u00a0 pa.dataset.write_dataset(\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 table,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 output_path,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 basename_template=f\"chunk_\\{y}_\\{{i}}\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 format=\"parquet\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 partitioning=[\"code\"],\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 existing_data_behavior=\"overwrite_or_ignore\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 )\r\n```\r\nLoading the dataset again and expecting code to be in the dataframe.\r\n```python\n\r\nimport pyarrow.dataset as ds\r\ndataset = ds.dataset(\"../data/interim/2020_elements_parquet/\", format=\"parquet\",)\r\ndf = dataset.to_table().to_pandas()\r\n\r\n>>>df[\"code\"]\r\n```\r\nTrace\r\n```python\n\r\n--------------------------------------------------------------------------- KeyError Traceback (most recent call last) ~/.local/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)  3360 try: -> 3361 return self._engine.get_loc(casted_key)  3362 except KeyError as err: ~/.local/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc() ~/.local/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc() pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item() pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item() KeyError: 'code' The above exception was the direct cause of the following exception: KeyError Traceback (most recent call last) /tmp/ipykernel_24875/4149106129.py in <module> ----> 1 df[\"code\"] ~/.local/lib/python3.9/site-packages/pandas/core/frame.py in __getitem__(self, key)  3456 if self.columns.nlevels > 1:  3457 return self._getitem_multilevel(key) -> 3458 indexer = self.columns.get_loc(key)  3459 if is_integer(indexer):  3460 indexer = [indexer] ~/.local/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)  3361 return self._engine.get_loc(casted_key)  3362 except KeyError as err: -> 3363 raise KeyError(key) from err  3364  3365 if is_scalar(key) and isna(key) and not self.hasnans: KeyError: 'code'\r\n```",
        "created_at": "2021-12-01T10:33:25.000Z",
        "updated_at": "2021-12-02T02:40:30.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-12-01T11:38:33.556Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14938?focusedCommentId=17451752) by Lance Dacey (ldacey):*\nIf you add the partitioning argument to ds.dataset(source, format, partitioning) that should fix it.\r\n\r\nFor example, partitioning=\"hive\" or specify it with a partitioning object partitioning=ds.partitioning(pa.schema([\"code\", pa.string()]), flavor=\"hive\"). I used hive in those examples but there is directory partitioning as well."
        },
        {
            "created_at": "2021-12-01T12:37:49.700Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14938?focusedCommentId=17451777) by Martin Gran (martgra):*\n`[~ldacey]` - thanks. Setting to hive did not work however passing as following:\r\n```python\n\r\ndataset = ds.dataset(path, format=\"parquet\", partitioning=[,\"code\"])\r\n```\r\n\r\nWould be great with an explanation :-)"
        },
        {
            "created_at": "2021-12-01T13:22:55.898Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14938?focusedCommentId=17451813) by Lance Dacey (ldacey):*\nSure - refer to this section: https://arrow.apache.org/docs/python/dataset.html#different-partitioning-schemes\r\n\r\n\"hive\" is a shortcut which will infer the data type of the partition column when it gets added back to the table, but you can specify the schema of your partitioned columns too using ds.partitioning().\r\n\r\n"
        },
        {
            "created_at": "2021-12-02T02:40:30.264Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14938?focusedCommentId=17452138) by Weston Pace (westonpace):*\nI added some info on the GH issues ticket too.  My guess is that \"hive\" didn't work because you were specifying it on the read only and not the write."
        }
    ]
}