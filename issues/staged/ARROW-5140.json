{
    "issue": {
        "title": "[Bug?][Parquet] Can write a jagged array column of strings to disk, but hit `ArrowNotImplementedError` on read",
        "body": "***Note**: This issue was originally created as [ARROW-5140](https://issues.apache.org/jira/browse/ARROW-5140). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n# Description\r\n\r\nI encountered an issue on a proprietary dataset where we have a schema that looks roughly like:\r\n\r\n{\\{ |-- ids: array (nullable = true) | |-- element: string (containsNull = true) }}\r\n\r\nI was able to write this dataset to parquet no problem (using\u00a0`pq.write_table`), but upon reading it (using\u00a0`pq.read_table`) I encountered the following error:\u00a0`ArrowNotImplementedError: Nested data conversions not implemented for chunked array outputs`\u00a0(a full stacktrace is attached below)\r\n\r\nI believe that this is pretty confusing because I was able to serialize but not deserialize this table. I was able to also find that this does not happen with all sizes of the dataset - a smaller sample did not encounter this issue! So I built a small reproduction harness and checked out where this could happen:\r\n## Further investigation\r\n \\* If I set the maximum number of elements per row of\u00a0`ids`, I found that reducing it allows me to serialize/deserialize more rows\r\n \\* At a setting of maximum 15 elements per row, each element being at most 20 characters, I fail at about 1.3e5 rows\r\n \\* At the limit of my willingness to spend time building giant dataframes to investigate this, I haven't been able to reproduce this issue for e.g. longs instead of strings\r\n \\* Another column in this dataset consists of much longer strings than this column's strings (when concatenated), and the total sum of all characters is ~3x in\u00a0_that_\u00a0column versus this trouble column (when the strings in each row are just simply concatenated). I have no issue serializing / deserializing that column.\r\n \\* The fact that each array is of a different length doesn't seem to matter - if I change it so as to force everything to be ~14 elements, it fails with the same error even at 1e5 rows.\r\n\r\n# Reproduction code\r\n\r\nThis\u00a0[gist](https://gist.github.com/zmjjmz/1bf738966d2df147a4fae7268ee3d812) should have both a stacktrace and reproduction code.\r\n## Version info\r\n\r\n{\\{pyarrow==0.12.0 parquet==1.2 }}\r\n# Mea culpa\r\n\r\nI copy-pasted this from Github on request (<https://github.com/apache/arrow/issues/4115>), and Jira formatting is a nightmare compared to markdown, so I apologize.",
        "created_at": "2019-04-08T15:20:50.000Z",
        "updated_at": "2022-08-27T14:41:56.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-08-12T21:55:19.000Z"
    },
    "comments": [
        {
            "created_at": "2019-07-23T12:22:00.947Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5140?focusedCommentId=16890944) by Takuya Kato (Ktakuya):*\nOn macOS with pyarrow == 0.14.0, I could not reproduce the issue\r\n```java\n\r\n$ vim repro.py // copy the gist\r\n$ mkdir jaggedbug_testpath\r\n$ python repro.py\r\n$ echo $?\r\n0\r\n$ find jaggedbug_testpath -type f -name '*.parquet'\r\njaggedbug_testpath/160000_rows_maxsize_15_str.parquet\r\n...\r\njaggedbug_testpath/170000_rows_maxsize_15_str.parquet\n```\r\nThis problem might be platform or version specific."
        },
        {
            "created_at": "2019-07-23T14:50:47.885Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5140?focusedCommentId=16891100) by Zachary Jablons (zmjjmz):*\nHey there,\r\n\r\nI tested it on Deb8 with pyarrow 0.14.0 and couldn't reproduce it \u2013 so it seems like this issue has been fixed.\u00a0"
        },
        {
            "created_at": "2022-08-27T14:41:56.757Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5140?focusedCommentId=17585943) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}