{
    "issue": {
        "title": "[Python] Add Azure Datalake Filesystem Gen1 Wrapper for pyarrow",
        "body": "***Note**: This issue was originally created as [ARROW-5131](https://issues.apache.org/jira/browse/ARROW-5131). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe current pyarrow package can only read parquet files that have been written to Gen1 Azure Datalake using the fastparquet engine.  This only works if the dask-adlfs package is explicitly installed and imported.  I've added a method to the dask-adlfs package, found [here](https://github.com/dask/dask-adlfs), and issued a PR for that change.  To support this capability, added an ADLFSWrapper to filesystem.py file.",
        "created_at": "2019-04-06T15:08:58.000Z",
        "updated_at": "2019-09-20T00:57:57.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2019-09-18T15:23:48.000Z"
    },
    "comments": [
        {
            "created_at": "2019-08-10T19:33:00.086Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5131?focusedCommentId=16904502) by Gregory Hayes (hayesgb):*\nWanted to touch base on this.  I\u2019ve been looking at rewriting and cleaning up the dask-adlfs package.  Wanted to get input on making it the AzureDatalakeFileSystem class a  subclass of both the AbstractFileSystem and the AzureDLFileSystem, using multiple inheritance.  This allows us to pull in all of the methods from both classes and utilize the Azure library that already exists.\n\nIf that seems reasonable, then I\u2019ll proceed along those lines.\n\n"
        },
        {
            "created_at": "2019-08-22T22:20:07.009Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5131?focusedCommentId=16913741) by Wes McKinney (wesm):*\nOur medium/long-term plan in Apache Arrow is to support cloud filesystems in C++. See initial steps in this direction to support Amazon S3 https://github.com/apache/arrow/pull/5167"
        },
        {
            "created_at": "2019-08-27T15:29:54.635Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5131?focusedCommentId=16916809) by Gregory Hayes (hayesgb):*\nThanks.  We can close this, knowing that\u2019s the strategic direction. "
        },
        {
            "created_at": "2019-09-18T15:23:48.899Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5131?focusedCommentId=16932553) by Antoine Pitrou (apitrou):*\nClosing as suggested."
        }
    ]
}