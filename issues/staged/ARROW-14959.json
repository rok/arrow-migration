{
    "issue": {
        "title": "[Python] Reading Hive-style partitioned parquet files from GCS",
        "body": "***Note**: This issue was originally created as [ARROW-14959](https://issues.apache.org/jira/browse/ARROW-14959). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nTrying to read a spark-generated hive-style partitioned parquet dataset with **gcsfs** and {**}pyarrow{**}, but getting a **FileNotFoundError** if I try to read from the base directory or even if try to read directly from one of the partitions. Not sure if I am doing something wrong or it is not supported.\r\n\r\nNote that I have successfully read this hive-style partitioned parquet dataset using other methods to rule out any other issues, including:\r\n \\* Successful read with pyspark by using spark.read.parquet\r\n \\* Successful read of a specific partition by passing list of paths to `ParquetDataset`\r\n \\* Also, tested reading another spark-generated parquet dataset with no Hive-style partitions from GCS and that worked as well.\r\n\r\nBelow is what I am trying:\r\n\r\n\u00a0\r\n```python\n\r\nimport gcsfs\r\nimport pyarrow as pa\r\n\u00a0\r\ngcs = gcsfs.GCSFileSystem()\r\n\u00a0\r\npartitions = pa.dataset.partitioning(\r\n\u00a0 \u00a0 pa.schema([(\"partition_var\", pa.string())]), dictionaries=\"infer\", flavor=\"hive\"\r\n)\r\n\u00a0\r\npartitioned_dataset = pa.dataset.dataset(\r\n\u00a0 \u00a0 \"path/to/partitioned/dataset/base/dir\",\r\n\u00a0 \u00a0 filesystem=gcs,\r\n\u00a0 \u00a0 format=\"parquet\",\r\n\u00a0 \u00a0 partitioning=partitions,\r\n)\r\n\u00a0\r\npartition_of_dataset = pa.dataset.dataset(\r\n\u00a0 \u00a0 \"path/to/partitioned/dataset/base/dir/partition_var=some_value\",\r\n\u00a0 \u00a0 filesystem=gcs,\r\n\u00a0 \u00a0 format=\"parquet\",\r\n)\n```\r\n\u00a0\r\n\r\nThe errors returned for both are below:\r\n```java\n\r\nFileNotFoundError: path/to/partitioned/dataset/base/dir/\r\nFileNotFoundError: path/to/partitioned/dataset/base/dir/partition_var=some_value/\n```\r\n\u00a0",
        "created_at": "2021-12-01T19:42:52.000Z",
        "updated_at": "2021-12-02T14:43:13.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-12-02T14:42:50.157Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14959?focusedCommentId=17452448) by Joris Van den Bossche (jorisvandenbossche):*\nJust to confirm, if you read a specific file then it works?  For example with:\r\n\r\n```Java\n\r\nimport pyarrow.parquet as pq\r\npq.read_table(\"path/to/partitioned/dataset/base/dir/partition_var=some_value/<data file>.parquet\", filesystem=gcs)\r\n```\r\n\r\nCan you try some things with the filesystem object and show what those return?\r\n\r\n```Java\n\r\ngcs.isdir(\"path/to/partitioned/dataset/base/dir/\")\r\ngcs.exists(\"path/to/partitioned/dataset/base/dir/\")\r\ngcs.info(\"path/to/partitioned/dataset/base/dir/\")\r\ngcs.find(\"path/to/partitioned/dataset/base/dir/\", maxdepth=None, withdirs=True, detail=True)\r\n```"
        }
    ]
}