{
    "issue": {
        "title": "[C++][Compute] Support tagging ExecBatches with arbitrary extra information",
        "body": "***Note**: This issue was originally created as [ARROW-12873](https://issues.apache.org/jira/browse/ARROW-12873). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIdeally, ExecBatches could be tagged with arbitrary optional objects for tracing purposes and to transmit execution hints from one ExecNode to another.\r\n\r\nThese should **not** be explicit members like ExecBatch::selection_vector is, since they may not originate from the arrow library. For an example within the arrow project: `libarrow_dataset` will be used to produce ScanNodes and a WriteNodes and it's useful to tag scanned batches with their `Fragment` of origin. However adding `ExecBatch::fragment` would result in a cyclic dependency.\r\n\r\nTo facilitate this tagging capability, we would need a type erased container something like\r\n```Java\n\r\nstruct AnySet {\r\n  void* Get(tag_t tag);\r\n  void Set(tag_t tag, void* value, FnOnce<void(void*)> destructor);\r\n};\r\n```\r\n\r\n",
        "created_at": "2021-05-25T14:53:04.000Z",
        "updated_at": "2022-05-10T17:16:39.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-05-25T16:59:06.090Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17351200) by Ben Kietzman (bkietz):*\nIn the longer term: distributed execution will require that batches be serializable, which would transitively apply to `AnySet`"
        },
        {
            "created_at": "2021-05-25T18:17:57.713Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17351266) by Weston Pace (westonpace):*\nIs this something that you could use the record batch's metadata for?\u00a0 I suspect no but it would be good to state the reasoning."
        },
        {
            "created_at": "2021-05-26T16:22:30.593Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17351915) by Ben Kietzman (bkietz):*\nRecord batch metadata is attached to the schema, while ExecBatches do not have a schema.\r\n\r\nThe intention of ExecBatches is to provide a lighter weight, non-owning, even-more-cheaply slicable unit for chunks of data moving through the execution graph."
        },
        {
            "created_at": "2021-05-26T16:25:04.982Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17351918) by Ben Kietzman (bkietz):*\nIt's worth noting that without some support for tagging we won't be able to maintain batch order for simple filter+project workflows, which is currently required by ParquetDataset. Currently this is handled in dataset:: by tagging batches with the indices of their origin fragment and their index within that fragment, then stitching batches back into a table which maintains the original batch order. If we don't provide any way to propagate such tags through an ExecPlan then there will be no way to reconstruct an ordered table"
        },
        {
            "created_at": "2021-05-26T17:13:23.980Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17351945) by Ben Kietzman (bkietz):*\nAdditionally, we'll have performance regressions in expression evaluation since we have no way to attach known guarantees to batches. Currently (for example) when filtering batches from the file `/a=3/dat.parquet` with `a == 3 and b == 2` we will only do the work associated with `b == 2`. However if a FilterNode is receiving batches from a ScanNode it has no way to safely skip the work associated with `a == 3` since it can't detect the partition of origin\r\n"
        },
        {
            "created_at": "2021-05-26T17:41:46.119Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17351969) by Antoine Pitrou (apitrou):*\nI agree this is probably desirable. I hope we can find a type-safe way of doing this, though :) `void*` isn't really terrific."
        },
        {
            "created_at": "2021-05-26T18:36:21.883Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17352013) by Weston Pace (westonpace):*\nI agree we will need metadata to travel with the batches.\u00a0 I'll agree with\u00a0 `[~apitrou]` I'm not sufficiently convince we can't know it all ahead of time.\u00a0 You mention \"since they may not originate from the arrow library\".\u00a0 Do you have an example of that?\u00a0 I think `void\\*` is clearly justified if it is pass-thru information.\u00a0 In other words if A) The source is external to Arrow AND B) The consumption / use of the metadata is external to Arrow.\u00a0 I'm not sure that is the case here.\r\n\r\nMy only concern with void\\* is that it communicates nothing about what information should be put in there.\u00a0 For example, if Arrow is going to use this information to optimize query plans then it would be useful for data producers to know exactly what format they should be creating so that they can have their data optimized appropriately.\u00a0 Abstractions can be built up and simplified and refined.\r\n\r\nWith regards to filtering we already have the concept of expressions and simplification.\u00a0 It seems pretty straightforward that an exec batch would have a partition expression associated with it.\u00a0 If \"partition expression\" is not the right word than maybe \"guarantee expression\" or something of the sort.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2021-05-26T19:28:24.840Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17352033) by Felipe Aramburu (felipearamburu):*\nThat metadata should travel with batches is indeed important specially when we start planning for things like joins where knowing statistical information about each batch will allow us to avoid many useless comparisons.\r\n\r\nWhen it comes to specifying metadata that can vary greatly between different use cases. Different algorithms need different information and different sources of information can provide varying degrees of statistical information or execution hints.\u00a0\r\n\r\nWould something that uses dynamic dispatching. Where users basically construct metadata that is suitable for different purposes with different properties can be instantiated and passed around as unique or shared pointers of their base class and the thread performing execution can dynamically dispatch to fill in the information it needs from the metadata. Or it can require that this metadata be of a certain derived type and cast it during execution returning an error status if it was instantiated in the wrong way.\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2021-05-26T20:19:27.089Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17352050) by Eduardo Ponce (edponce):*\nI think discussing examples of ExecNode metadata will help drive the design. I assume that Arrow may consume ExecNode metadata in more than one place (for example, different hints will be used by different steps), and this makes generalization and extensibility a bit more complex. A key aspect is on how the metadata will be consumed in Arrow (not so much the transferring of such). Having objects with different data members and methods will require custom consumption mechanisms for each one.\r\n\r\nIs it possible to categorize the different types of metadata? For example, tracing information may depend on a specific tracing tool for particular measurements (hardware counters) and export format but this can be solved via polymorphism. Hints for the execution plan may depend on the data source and using an opaque structure may suffice or even a key-value map. And other considerations are required for other metadata.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2021-05-26T22:55:08.883Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17352115) by Michal Nowakiewicz (michalno):*\nI don't have anything against adding arbitrary tags to batches. In my experience working in query execution I didn't have a need for such a functionality, which can mean that either I didn't face the specific problems (likely) or that there are other ways of solving some of the problems that require tags.\u00a0\r\n\r\nOne thing I am wondering about, which is maybe a bit academic, is what are the rules of preserving tags that operators (ExecNodes) must follow. Let's say I implement a new one that splits rows from input ExecBatch into two new ExecBatches. Would I know what to do with the tags? Or do we say that tags are for pass-through operators only (operators that do not generate new ExecBatches)?"
        },
        {
            "created_at": "2021-06-01T16:20:20.156Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17355203) by Ben Kietzman (bkietz):*\n> You mention \"since they may not originate from the arrow library\".  Do you have an example of that?\r\n\r\nlibarrow_dataset is currently separate from libarrow\r\n\r\n> It seems pretty straightforward that an exec batch would have a partition expression associated with it.\r\n\r\nThat seems reasonable, and since Expression is in the compute:: namespace these days we can attach `Expression ExecBatch::guarantee` without much trouble.\r\n\r\n> One thing I am wondering about, which is maybe a bit academic, is what are the rules of preserving tags that operators (ExecNodes) must follow.\r\n\r\nThat's an excellent point; it's not at all clear what nodes should do with batch-level tags if the node doesn't have a straightforward 1-in-1-out process. For now in https://github.com/apache/arrow/pull/10397 I'm pursuing a workaround of augmenting scanned batches with virtual columns which encode their fragment and batch indices, which can be used to reorder batches in a ToTable operation.\r\n\r\nPerhaps something similar could be more generally applicable to the problem of tagging batches: users who need to tag batches can augment with virtual columns containing keys into a table which they maintain."
        },
        {
            "created_at": "2021-08-05T20:38:06.941Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17394284) by David Li (lidavidm):*\nDo we have a consensus on using virtual columns vs explicit metadata? In ARROW-13540 I've put up an OrderByNode that is a sink node to sidestep this (as it can just push the batches to the generator immediately), but it would be nice to have it as a non-sink node to let us implement more types of aggregations (ones which depend on ordering but do not need to keep large amounts of state)."
        },
        {
            "created_at": "2021-08-06T20:59:29.251Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17394991) by David Li (lidavidm):*\nSo I tried implementing an arg_min_max node as part of ARROW-13540, using virtual columns to tag batches with their relative order ([see the PR](https://github.com/apache/arrow/pull/10863/commits/283a5c7e0c7541f28bf559cc66bf3d7a607b0db6)). This is an aggregation which needs to know its inputs are ordered in some way.\r\n\r\nHaving the metadata as actual columns makes some things difficult: we need to branch when looking up the aggregate kernels, we have to register kernels with different arities (and hence duplicate or refactor some of the utilities used there), and we need to branch when feeding data into the kernels. Also, the GroupByNode and OrderByNode have to hardcode the position of the virtual column and ensure that they are consistent with each other (and any possible intermediate node needs to pass it forward) - this is **very** brittle, especially if/when we want to go back and add more metadata. In effect, virtual columns mean all node implementations are tightly coupled.\r\n\r\nHowever, I don't think having separate metadata improves this much, as it instead carries the risk that the metadata isn't correctly updated as batches are manipulated. In effect, I don't think the metadata can feasibly be runtime extensible, and having any metadata will end up coupling node implementations in some way. So I agree with Antoine and Weston, and might go further and say that we necessarily have to know all the possible categories of metadata ahead of time, since nodes have to know what to do with it anyways, and this discussion might be moot (everything can just be explicit fields in ExecBatch). If there is format- or backend- specific information to carry (Felipe's point), an extension point in ExecBatch might be useful still, but it's hard to imagine how a generic ExecNode could know what to do with that metadata safely - I would say that custom metadata needs to be accompanied by custom ExecNodes, which pass the metadata around themselves and can't 'leak' it outside a subgraph consisting solely of these nodes."
        },
        {
            "created_at": "2021-08-06T22:04:01.114Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17395001) by Weston Pace (westonpace):*\nWith the caveat that I haven't been following this super closely, what if the virtual columns are passed as separate inputs / outputs?  Hardcoding the meaning of an input/output seems safer than hardcoding the meaning of a particular column index."
        },
        {
            "created_at": "2021-08-06T22:07:44.845Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17395002) by David Li (lidavidm):*\nI think that's just a different way of encoding what was originally proposed, right (explicit separate metadata)? I'm not sure I follow."
        },
        {
            "created_at": "2021-08-06T22:24:54.729Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17395006) by Weston Pace (westonpace):*\nI thought the original proposal was tagging record batches with arbitrary void\\* pointers.  It's possible I'm not explaining myself well.\r\n\r\nIf you'll allow some psuedocode here to avoid the complexity of exec plan...\r\n\r\nWhat we have today is:\r\n```python\n\r\nexec_batch_with_order_at_back = order_by_node(in_batch)\r\ngrouped_output = group_by_node(exec_batch_with_order_at_back, kernel_that_can_use_order)\r\n\r\ndef group_by_node(batch, agg_kernel):\r\n  group_ids = grouper(batch)\r\n  mashed_together_batch = {group_ids, batch}\r\n  if can_use_order(agg_kernel):\r\n    agg_kernel(mashed_together_batch, mashed_together_batch[-1])\r\n  else:\r\n    agg_kernel(mashed_together_batch)\r\n```\r\n\r\nI'm proposing (and this may not make any sense at all):\r\n```python\n\r\nexec_batch, order = order_by_node(in_batch)\r\ngrouped_output = group_by_node(exec_batch, kernel_that_can_use_order, extra_inputs=[order])\r\n\r\ndef group_by_node(batch, agg_kernel, extra_inputs=[]):\r\n  group_ids = grouper(batch)\r\n  mashed_together_batch = {group_ids, batch}\r\n  agg_kernel(mashed_together_batch, *extra_inputs)\r\n```\r\n\r\nThe kernels still need different arities which I think is ok, but you don't have to do the branching.\r\n\r\nAlso, is there a reason (there probably is) we don't require aggregate kernels to be 2+ arity:\r\n```python\n\r\ndef group_by_node(batch, agg_kernel, extra_inputs=[]):\r\n  group_ids = grouper(batch)\r\n  agg_kernel(batch, group_ids, *extra_inputs)\r\n```"
        },
        {
            "created_at": "2021-08-09T12:11:04.849Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17396011) by David Li (lidavidm):*\nTo me this is mostly isomorphic to the original proposal, except using Datum instead of void\\*. You could imagine attaching the secondary vector<Datum> to ExecBatch. This also still has the issue that we need to preserve some global ordering of metadata and/or know which metadata go with which types of kernels, something that using a map-like interface as originally proposed would at least avoid.\r\n\r\nTo your last point, until relatively recently, there was no way to define \"VarArgs with at least N\" parameters without jumping through some hoops. But even with that support, there's still the issue of ordering the output metadata/parameters between different kinds of kernels."
        },
        {
            "created_at": "2021-08-09T19:25:23.269Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17396229) by Weston Pace (westonpace):*\nIf we want strings would it be sufficient to be able to index node inputs / function inputs by name?  For example:\r\n\r\n```cpp\n\r\n// In a node, retrieving inputs\r\nauto group_ids = inputs_[\"group_ids_in\"]\r\nauto batch = inputs_[\"batch_in\"]\r\n```\r\n\r\n```cpp\n\r\n// In a node, sending outputs\r\noutputs[\"group_ids_out\"]->InputReceived(this, seq, group_ids);\r\noutputs[\"batch_out\"]->InputReceived(this, seq, batch);\r\n```\r\n\r\n```cpp\n\r\n// Building the graph\r\n// First argument is a vector of (input_name, node, output_name) for each input parameter\r\ncompute::MakeAggregateSumNode({{\"group_ids_in\", grouper, \"group_ids_out\"}, {\"batch_in\", grouper, \"batch_out\"}}, ...);\r\n```\r\n\r\nThen for compute functions you could do something like...\r\n\r\n```cpp\n\r\nCallFunction(\"aggregate_sum\", {{\"batch\", batch}, {\"group_ids\": group_ids}}, &options, ctx);\r\n```\r\n\r\n "
        },
        {
            "created_at": "2021-08-10T00:04:59.260Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12873?focusedCommentId=17396329) by David Li (lidavidm):*\nI think so, but I still think this is very close to the original proposal, just using Datums in place of void\\*. Also this requires nodes to know which metadata kernels can make use of (which I guess I argued they must know anyways) but it might not be as clean as just passing it implicitly as part of the ExecBatch (though implicit may not be what we want here!)\r\n\r\nIn any case: my main argument is that I think passing metadata as part of the values in the ExecBatch and as part of arguments is likely too brittle/inextensible to be what we want."
        }
    ]
}