{
    "issue": {
        "title": "io-hdfs-test failure",
        "body": "***Note**: This issue was originally created as [ARROW-1130](https://issues.apache.org/jira/browse/ARROW-1130). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHi,\n\nI have noticed that arrow-cpp's io-hdfs-test fails during compilation with GCC 4.8, but passes when compiled with GCC 5.4 (as it just skips all tests as it doesn't connect to the HDFS client).\n\nI went into the test output log and it seemed to want me to set the variable ARROW_HDFS_TEST_USER, so I set the variable to 'root' and ARROW_HDFS_TEST_PORT to '9000' (which is the port that I use to connect to my local hdfs) and the test passes.\n\nDo I need to configure the environment and the variables in a specific way to get it to work?\n\nI'm mainly asking as I am trying to use arrow and parquet c++ libraries in an external project and I continue to run into segfaults in the libhdfs jni_helper even though I successfully connect to HDFS on my local Hadoop cluster and even read in a single Parquet file and am hoping that somehow this will help me figure out the issue in my external project as well.\n\nThank you in advance for your help.\n",
        "created_at": "2017-06-19T19:30:51.000Z",
        "updated_at": "2017-06-24T16:25:56.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2017-06-24T16:25:41.000Z"
    },
    "comments": [
        {
            "created_at": "2017-06-20T17:49:47.043Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1130?focusedCommentId=16056168) by Wes McKinney (wesm):*\nSo, the test suite passes when you set the right environment variables, but you are getting a segfault when using the libraries in production? Do you have a backtrace or any other debugging information? Have you tried reading and/or writing a simple test file to your Hadoop cluster? \n\nThese are the env variables you can set for testing:\n\nhttps://github.com/apache/arrow/blob/master/cpp/src/arrow/io/io-hdfs-test.cc#L115\n\nThe only other configurable is the directory where libhdfs.so is located: https://github.com/apache/arrow/blob/master/cpp/src/arrow/io/hdfs-internal.cc#L90"
        },
        {
            "created_at": "2017-06-20T21:54:37.519Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1130?focusedCommentId=16056534) by Young Park (cyp):*\nHi Wes,\n\nYes, but the test passes when I set the env variables for testing hdfs (when built with GCC4.8) but when built with GCC5, the test passes as it just gracefully skips the io-hdfs-test tests. I am guessing that it may be the intended behavior for the tests, but I wanted to bring this up as when I traced the source of the error before I set the testing env variables, the error seemed to come from the jni_helper. And at the time, I suspected that my program was also running into issues with jni_helper, I was hoping that someone with more HDFS experience would have a better insight into what may be the root cause of the issue.\n\nWith respect to the project that I am working on, I am using the libraries(Arrow, Parquet) to connect to HDFS and read in Parquet files. \nMy program successfully connects to HDFS, calls ReadBatch while iterating through the columns in the Row Group, constructs and returns an arrow::RecordBatch, but it segfaults soon afterwards.\n\nI am suspecting an error in the use of shared_ptrs as the error log shows that it segfaults after calling destroy on arrow::PoolBuffer, but I wanted to rule out all possibilities along the way.\n\nAttached is a error log from running my program.\n\n```java\n#\n# A fatal error has been detected by the Java Runtime Environment:\n#\n#  SIGSEGV (0xb) at pc=0xffffffff748e3af0, pid=4149, tid=0x00007f316c1d1740\n#\n# JRE version: OpenJDK Runtime Environment (8.0_131-b11) (build 1.8.0_131-b11)\n# Java VM: OpenJDK 64-Bit Server VM (25.131-b11 mixed mode linux-amd64 compressed oops)\n# Problematic frame:\n# C  0xffffffff748e3af0\n#\n# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\n#\n# If you would like to submit a bug report, please visit:\n#   http://www.azulsystems.com/support/\n# The crash happened outside the Java Virtual Machine in native code.\n# See problematic frame for where to report the bug.\n#\n\n---------------  T H R E A D  ---------------\n\nCurrent thread (0x0000000004931800):  JavaThread \"main\" [_thread_in_native, id=4149, stack(0x00007ffe747eb000,0x00007ffe748eb000)]\n\nsiginfo: si_signo: 11 (SIGSEGV), si_code: 1 (SEGV_MAPERR), si_addr: 0xffffffff748e3af0\n\nRegisters:\nRAX=0xffffffff748e3af0, RBX=0x00000000066bb050, RCX=0x00007ffe748e3a90, RDX=0x0000000000000040\nRSP=0x00007ffe748e3788, RBP=0x00007ffe748e37a0, RSI=0x0000000006681880, RDI=0x00007ffe748e3a90\nR8 =0x00000000066815e0, R9 =0x00007f316c1d1700, R10=0x0000000000001041, R11=0x00007f3165c61f8a\nR12=0x00007ffe748e42df, R13=0x00007ffe748e4250, R14=0x00000000042cebd8, R15=0x0000000000000000\nRIP=0xffffffff748e3af0, EFLAGS=0x0000000000010202, CSGSFS=0x002b000000000033, ERR=0x0000000000000015\n  TRAPNO=0x000000000000000e\n\nTop of Stack: (sp=0x00007ffe748e3788)\n0x00007ffe748e3788:   00007f3165c84cec 0000000000000000\n0x00007ffe748e3798:   00000000066816f8 00007ffe748e37c0\n0x00007ffe748e37a8:   00007f316636a9ed 00000000066816f8\n0x00007ffe748e37b8:   00000000066816f0 00007ffe748e37e0\n0x00007ffe748e37c8:   00007f316636981c 00000000066816f8\n0x00007ffe748e37d8:   00000000066816f0 00007ffe748e3800\n0x00007ffe748e37e8:   00007f31663688f9 00000000066816f8\n0x00007ffe748e37f8:   00000000066816f0 00007ffe748e3820\n0x00007ffe748e3808:   00007f31663678cb ffffffff00000000\n0x00007ffe748e3818:   00000000066816e0 00007ffe748e3840\n0x00007ffe748e3828:   00007f3165c66490 0000000000000000\n0x00007ffe748e3838:   00000000066816e0 00007ffe748e3860\n0x00007ffe748e3848:   00007f3165c62497 0000000000000000\n0x00007ffe748e3858:   00000000066817e8 00007ffe748e3880\n0x00007ffe748e3868:   00007f3165c613c8 00007f3165f84250\n0x00007ffe748e3878:   00000000066817e0 00007ffe748e38a0\n0x00007ffe748e3888:   00007f3165c613e2 00007f316c1d1700\n0x00007ffe748e3898:   00000000066817e0 00007ffe748e38c0\n0x00007ffe748e38a8:   00007f3165c61fb8 00000000066bb050\n0x00007ffe748e38b8:   0000000006681798 00007ffe748e38e0\n0x00007ffe748e38c8:   00007f3165c804ca 00007f316c1d1700\n0x00007ffe748e38d8:   0000000006681798 00007ffe748e3900\n0x00007ffe748e38e8:   00007f31660239e1 0000000006681798\n0x00007ffe748e38f8:   0000000006681790 00007ffe748e3920\n0x00007ffe748e3908:   00007f3166023314 0000000006681798\n0x00007ffe748e3918:   0000000006681790 00007ffe748e3940\n0x00007ffe748e3928:   00007f3166022c24 0000000006681798\n0x00007ffe748e3938:   0000000006681790 00007ffe748e3960\n0x00007ffe748e3948:   00007f31660214d1 ffffffff00000000\n0x00007ffe748e3958:   0000000006681780 00007ffe748e3980\n0x00007ffe748e3968:   00000000016d38d6 0000000000000000\n0x00007ffe748e3978:   0000000006681780 00007ffe748e39a0 \n\nInstructions: (pc=0xffffffff748e3af0)\n0xffffffff748e3ad0:   \n[error occurred during error reporting (printing registers, top of stack, instructions near pc), id 0xb]\n\nRegister to memory mapping:\n\nRAX=0xffffffff748e3af0 is an unknown value\nRBX=0x00000000066bb050 is an unknown value\nRCX=0x00007ffe748e3a90 is pointing into the stack for thread: 0x0000000004931800\nRDX=0x0000000000000040 is an unknown value\nRSP=0x00007ffe748e3788 is pointing into the stack for thread: 0x0000000004931800\nRBP=0x00007ffe748e37a0 is pointing into the stack for thread: 0x0000000004931800\nRSI=0x0000000006681880 is an unknown value\nRDI=0x00007ffe748e3a90 is pointing into the stack for thread: 0x0000000004931800\nR8 =0x00000000066815e0 is an unknown value\nR9 =0x00007f316c1d1700 is an unknown value\nR10=0x0000000000001041 is an unknown value\nR11=0x00007f3165c61f8a: _ZN5arrow14PrimitiveArrayD1Ev+0 in /parquet-cpp/arrow_ep/src/arrow_ep-install/lib/libarrow.so.0 at 0x00007f3165b99000\nR12=0x00007ffe748e42df is pointing into the stack for thread: 0x0000000004931800\nR13=0x00007ffe748e4250 is pointing into the stack for thread: 0x0000000004931800\nR14=0x00000000042cebd8 is an unknown value\nR15=0x0000000000000000 is an unknown value\n\n\nStack: [0x00007ffe747eb000,0x00007ffe748eb000],  sp=0x00007ffe748e3788,  free space=993k\nNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\nC  0xffffffff748e3af0\nC  [libparquet.so.1+0xf49ed]  void __gnu_cxx::new_allocator<arrow::PoolBuffer>::destroy<arrow::PoolBuffer>(arrow::PoolBuffer*)+0x23\nC  [libparquet.so.1+0xf381c]  std::enable_if<std::allocator_traits<std::allocator<arrow::PoolBuffer> >::__destroy_helper<arrow::PoolBuffer>::value, void>::type std::allocator_traits<std::allocator<arrow::PoolBuffer> >::_S_destroy<arrow::PoolBuffer>(std::allocator<arrow::PoolBuffer>&, arrow::PoolBuffer*)+0x23\nC  [libparquet.so.1+0xf28f9]  void std::allocator_traits<std::allocator<arrow::PoolBuffer> >::destroy<arrow::PoolBuffer>(std::allocator<arrow::PoolBuffer>&, arrow::PoolBuffer*)+0x23\nC  [libparquet.so.1+0xf18cb]  std::_Sp_counted_ptr_inplace<arrow::PoolBuffer, std::allocator<arrow::PoolBuffer>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()+0x27\nC  [libarrow.so.0+0xcd490]  std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release()+0x42\nC  [libarrow.so.0+0xc9497]  std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count()+0x27\nC  [libarrow.so.0+0xc83c8]  std::__shared_ptr<arrow::Buffer, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr()+0x1c\nC  [libarrow.so.0+0xc83e2]  std::shared_ptr<arrow::Buffer>::~shared_ptr()+0x18\nC  [libarrow.so.0+0xc8fb8]  arrow::PrimitiveArray::~PrimitiveArray()+0x2e\nC  [libarrow.so.0+0xe74ca]  arrow::NumericArray<arrow::FloatType>::~NumericArray()+0x2a\nC  [libparquet_arrow.so.1+0x929e1]  void __gnu_cxx::new_allocator<arrow::NumericArray<arrow::FloatType> >::destroy<arrow::NumericArray<arrow::FloatType> >(arrow::NumericArray<arrow::FloatType>*)+0x23\nC  [libparquet_arrow.so.1+0x92314]  std::enable_if<std::allocator_traits<std::allocator<arrow::NumericArray<arrow::FloatType> > >::__destroy_helper<arrow::NumericArray<arrow::FloatType> >::value, void>::type std::allocator_traits<std::allocator<arrow::NumericArray<arrow::FloatType> > >::_S_destroy<arrow::NumericArray<arrow::FloatType> >(std::allocator<arrow::NumericArray<arrow::FloatType> >&, arrow::NumericArray<arrow::FloatType>*)+0x23\nC  [libparquet_arrow.so.1+0x91c24]  void std::allocator_traits<std::allocator<arrow::NumericArray<arrow::FloatType> > >::destroy<arrow::NumericArray<arrow::FloatType> >(std::allocator<arrow::NumericArray<arrow::FloatType> >&, arrow::NumericArray<arrow::FloatType>*)+0x23\nC  [libparquet_arrow.so.1+0x904d1]  std::_Sp_counted_ptr_inplace<arrow::NumericArray<arrow::FloatType>, std::allocator<arrow::NumericArray<arrow::FloatType> >, (__gnu_cxx::_Lock_policy)2>::_M_dispose()+0x27\nC  [cntk+0x12d38d6]  std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release()+0x42\nC  [cntk+0x126e1c7]  std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count()+0x27\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x989a6]  std::__shared_ptr<arrow::Array, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr()+0x1c\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x989c0]  std::shared_ptr<arrow::Array>::~shared_ptr()+0x18\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x9e1bc]  void std::_Destroy<std::shared_ptr<arrow::Array> >(std::shared_ptr<arrow::Array>*)+0x18\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x9d46c]  void std::_Destroy_aux<false>::__destroy<std::shared_ptr<arrow::Array>*>(std::shared_ptr<arrow::Array>*, std::shared_ptr<arrow::Array>*)+0x26\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x9c5eb]  void std::_Destroy<std::shared_ptr<arrow::Array>*>(std::shared_ptr<arrow::Array>*, std::shared_ptr<arrow::Array>*)+0x23\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x9afcd]  void std::_Destroy<std::shared_ptr<arrow::Array>*, std::shared_ptr<arrow::Array> >(std::shared_ptr<arrow::Array>*, std::shared_ptr<arrow::Array>*, std::allocator<std::shared_ptr<arrow::Array> >&)+0x27\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x99a9b]  std::vector<std::shared_ptr<arrow::Array>, std::allocator<std::shared_ptr<arrow::Array> > >::~vector()+0x35\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x9cbce]  arrow::RecordBatch::~RecordBatch()+0x1c\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0xa5568]  std::_Sp_counted_ptr<arrow::RecordBatch*, (__gnu_cxx::_Lock_policy)2>::_M_dispose()+0x22\nC  [cntk+0x12d38d6]  std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release()+0x42\nC  [cntk+0x126e1c7]  std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count()+0x27\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x99142]  std::__shared_ptr<arrow::RecordBatch, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr()+0x1c\nC  [Cntk.Deserializers.DF-2.0rc2d.so+0x9915c]  std::shared_ptr<arrow::RecordBatch>::~shared_ptr()+0x18\n```\n\n"
        },
        {
            "created_at": "2017-06-20T22:01:47.865Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1130?focusedCommentId=16056546) by Wes McKinney (wesm):*\nThe `io-hdfs-test` issue seems unrelated to me. It looks to me like you could be mixing C++ ABIs (going from gcc 4.8 to gcc5) \u2013 were all of the components in your application built with the same compiler? The libstdc++ that's loaded needs to also be compatible\n\nAnything else you can tell us about what versions of the libraries you are using? "
        },
        {
            "created_at": "2017-06-20T22:27:00.956Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1130?focusedCommentId=16056580) by Young Park (cyp):*\nHi Wes,\n\nThat's what I suspected. I just wanted to rule out all possibilities as I have been blocked on this for bit. \n\nI did build all the components using gcc4.8 except for libhdfs, but libhdfs is C code so it shouldn't cause C++ ABIs. \n\nWhat do you mean by libstdc++ compatibility? If I set the default gcc version and g++ version to 4.8, wouldn't that load the correct libstdc++?\n\nThanks for your help!"
        },
        {
            "created_at": "2017-06-20T22:50:25.673Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1130?focusedCommentId=16056603) by Wes McKinney (wesm):*\nYou should look at what libstdc++ is being loaded at runtime. Try putting the gcc 4.8 runtime libraries first in your LD_LIBRARY_PATH and see what happens. I've been burned by this quite a few times. See item 3 in https://gcc.gnu.org/onlinedocs/libstdc+/manual/abi.html; libraries are supposed to be **forward compatible** with NEWER {{libstdc }}, but if you use an OLDER {{libstdc+}}, then you could have problems\n"
        },
        {
            "created_at": "2017-06-21T18:53:09.480Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1130?focusedCommentId=16058019) by Young Park (cyp):*\nHi Wes,\n\nI looked at what libstc++ is loaded using ```java\n/sbin/ldconfig -p | grep stdc++\n``` and verified that my libraries are correctly linked to libstdc++.so.6.0.21. According to the gnu website, it should be compatible with gcc 4.8. \n\nDo you have any other intuition(s) as to what may be causing the libjvm to crash when calling ```java\narrow::io::HdfsClient::Connect(m_HDFSconf, &m_HDFSClient)\n```?\n"
        },
        {
            "created_at": "2017-06-21T19:30:13.396Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1130?focusedCommentId=16058068) by Wes McKinney (wesm):*\nCan you show me the CNTK code where this is used?"
        },
        {
            "created_at": "2017-06-22T22:09:15.578Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1130?focusedCommentId=16060093) by Wes McKinney (wesm):*\nI have been helping debug this. When debugging with JNI, it's necessary to set\n\n```Java\nhandle SIGSEGV nostop noprint pass\n```\n\nin gdb before starting the application\n\nsee \"Using GDB\" in https://cwiki.apache.org/confluence/display/IMPALA/Impala+Debugging+Tips\n\n\"Note that the JVM will generate segmentation faults that you should just continue from.\"\n\n"
        }
    ]
}