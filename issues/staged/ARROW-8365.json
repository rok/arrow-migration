{
    "issue": {
        "title": "[C++] Error when writing files to S3 larger than 5 GB",
        "body": "***Note**: This issue was originally created as [ARROW-8365](https://issues.apache.org/jira/browse/ARROW-8365). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen purely using the arrow-cpp library to write to S3, I get the following error when trying to write a large Arrow table to S3 (resulting in a file size larger than 5 GB):\r\n\r\n`../src/arrow/io/interfaces.cc:219: Error ignored when destroying file of type N5arrow2fs12_GLOBAL__N_118ObjectOutputStreamE: IOError: When uploading part for key 'test01.parquet/part-00.parquet' in bucket 'test': AWS Error [code 100]: Unable to parse ExceptionName: EntityTooLarge Message: Your proposed upload exceeds the maximum allowed size with address : 52.219.100.32`\r\n\r\nI have diagnosed the problem by looking at and modifying the code in **`s3fs.cc`**. The code uses multipart upload, and uses 5 MB chunks for the first 100 parts. After it has submitted the first 100 parts, it is supposed to increase the size of the chunks to 10 MB (the part upload threshold or `part_upload_threshold_`). The issue is that the threshold is increased inside `DoWrite`, and `DoWrite` can be called multiple times before the current part is uploaded, which ultimately causes the threshold to keep getting increased indefinitely, and the last part ends up surpassing the 5 GB part upload limit of AWS/S3.\r\n\r\nThis issue where the last part is much larger than it should I'm pretty sure can happen every time a multi-part upload exceeds 100 parts, but the error is only thrown if the last part is larger than 5 GB. Therefore this is only observed with very large uploads.\r\n\r\nI can confirm that the bug does not happen if I move this:\r\n\r\n`if (part_number_ % 100 == 0) {`\r\n\u00a0\u00a0 part_upload_threshold_ += kMinimumPartUpload;}}\r\n}\r\n\r\nand do it in a different method, right before the line that does: `++part_number_`\r\n\r\n\u00a0",
        "created_at": "2020-04-07T14:47:28.000Z",
        "updated_at": "2020-04-07T16:33:29.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-04-07T16:33:28.000Z"
    },
    "comments": [
        {
            "created_at": "2020-04-07T14:58:02.695Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8365?focusedCommentId=17077312) by Antoine Pitrou (apitrou):*\nThanks for the thorough report and diagnosis!"
        },
        {
            "created_at": "2020-04-07T15:13:04.742Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8365?focusedCommentId=17077326) by Antoine Pitrou (apitrou):*\n`[~jjgalvez]` I've submitted https://github.com/apache/arrow/pull/6864 . Can you check whether the diff looks good to you?"
        },
        {
            "created_at": "2020-04-07T15:21:52.026Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8365?focusedCommentId=17077335) by Juan Galvez (jjgalvez):*\nDone. Thanks!"
        },
        {
            "created_at": "2020-04-07T16:33:28.513Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8365?focusedCommentId=17077386) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 6864\n<https://github.com/apache/arrow/pull/6864>"
        }
    ]
}