{
    "issue": {
        "title": "[Rust] Create one standard DataFrame API",
        "body": "***Note**: This issue was originally created as [ARROW-9742](https://issues.apache.org/jira/browse/ARROW-9742). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n\u00a0There was a discussion in last Arrow sync call about the fact that there are numerous Rust DataFrame projects and it would be good to have one standard, in the Arrow repo.\r\n\r\nI do think it would be good to have a DataFrame trait in Arrow, with an implementation in DataFusion, and making it possible for other projects to extend/replace the implementation e.g. for distributed compute, or for GPU compute, as two examples.\u00a0\r\n\r\n`[~jhorstmann]` Does this capture what you were suggesting in the call?",
        "created_at": "2020-08-14T14:02:45.000Z",
        "updated_at": "2020-10-09T10:50:35.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Rust",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-08-16T16:21:13.000Z"
    },
    "comments": [
        {
            "created_at": "2020-08-16T16:21:13.372Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9742?focusedCommentId=17178521) by Andy Grove (andygrove):*\nIssue resolved by pull request 7972\n<https://github.com/apache/arrow/pull/7972>"
        },
        {
            "created_at": "2020-08-16T17:38:28.198Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9742?focusedCommentId=17178562) by J\u00f6rn Horstmann (jhorstmann):*\nHi `[~andygrove]` , in the call I was more thinking about the compute kernels which would be used by different dataframe implementations. I know of the following two projects, both seem to be implementing common arithmetic operations themselves instead of reusing functions defined inside arrow\r\n\r\nPolars: <https://github.com/ritchie46/polars/blob/master/polars/src/chunked_array/arithmetic.rs>\r\n\r\nRust Dataframe: <https://github.com/nevi-me/rust-dataframe/blob/master/src/functions/scalar.rs>\r\n\r\nI don't think this was done for performance reasons, as the current packed_simd implementations should be quite fast. Maybe it's more of a marketing problem and people do not know that the rust arrow implementation contains those kernels and not just the array data structures.\r\n\r\nNevertheless, I think having a common DataFrame implementation inside arrow makes sense, especially since the implementation can reuse all of the existing datafusion and logicalplan machinery."
        },
        {
            "created_at": "2020-08-17T23:45:23.403Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9742?focusedCommentId=17179274) by Neville Dipale (nevi_me):*\nHi `[~jhorstmann]`, the scalar functions on the rust-dataframe library mainly call the Arrow compute functions. As we have implemented compute functions with an array being the smallest unit, I iterate the chunked arrays and call scalar functions on the arrays, before grouping them again into a chunk.\r\n\r\nI explored usin Rayon for parallelising those compute functions, but it's not a priority (the project is really for me to explore ideas, with the goal being to create a lazy dataframe ala spark).\r\n\r\nThere's scope to add a lot of compute functions to Arrow so that downstream users can reuse them, and so we can optimise performance from one place. I haven't yet seen interest in functions like trig, temporal functions (I have a Jira open for this as I tend to do a lot of datetime conversions), and other functions beyond what we have. I think DF has some of these as UDFs, which probably makes sense to keep them there for now.\r\n\r\nRegarding performance, we've found some patterns that help with autovectorisation when writing compute functions, I think at the least we could write them up so that downstream users can at least follow them.\r\n\r\nOne common mistake I've seen is that we iterate through array values, checking if a slot is valid or null, and computing the function if valid. An approach that works is to ignore nulls and calculate them from the validty mask."
        }
    ]
}