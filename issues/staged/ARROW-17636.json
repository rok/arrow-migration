{
    "issue": {
        "title": "[Python] Converting Table to pandas raises NotImplementedError (when table previously saved as partitioned parquet dataset)",
        "body": "***Note**: This issue was originally created as [ARROW-17636](https://issues.apache.org/jira/browse/ARROW-17636). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen converting a table in which one of the column's type is of DictionaryType (values=int32, indices=int32, ordered=0) the conversion to pandas DataFrame fails with:\r\n\r\nNotImplementedError: dictionary<values=int32, indices=int32, ordered=0>\r\n\r\nThe dictionary has this conversion not implmented yet.\r\n\r\nThis DictionaryType is used as type when using one of the columns (Int64) as one of the parquet's dataset partition columns.",
        "created_at": "2022-09-06T18:15:29.000Z",
        "updated_at": "2022-10-19T03:10:44.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-09-06T19:07:15.538Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17636?focusedCommentId=17600947) by Roberto Lobo (rhlobo):*\nUsing an workaround:\r\n```java\n\r\n        conversion_options['types_mapper'] = _TYPE_MAPPINGS.get\r\n        try:\r\n            data = table.to_pandas(**conversion_options)\r\n        except NotImplementedError:\r\n            for tcolumn in list(table.columns):\r\n                if isinstance(tcolumn.type, pa.DictionaryType):\r\n                    problematic_columns.append((tcolumn._name, tcolumn, pa.int64()))\r\n\r\n            for tcolumn_name, tcolumn, tcolumn_type in problematic_columns:\r\n                table = table.drop([tcolumn_name])\r\n                table = table.append_column(\r\n                    pa.field(tcolumn._name,tcolumn_type),\r\n                    [tcolumn.to_pylist()]\r\n                )\r\n\r\n            data = table.to_pandas(**conversion_options)\r\n```"
        },
        {
            "created_at": "2022-09-07T07:31:08.262Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17636?focusedCommentId=17601174) by Joris Van den Bossche (jorisvandenbossche):*\n`[~rhlobo]` could you provide a reproducible example? (or a traceback might be helpful as well)\r\n\r\nI don't directly any problem with the following simple example converting a dictionary column with in32 indices and dictionary to a pandas categorical:\r\n\r\n```Java\n\r\nIn [2]: table = pa.table({'col': pa.DictionaryArray.from_arrays(pa.array([0, 1, 0], pa.int32()), pa.array([10, 11], pa.int32()))})\r\n\r\nIn [3]: table\r\nOut[3]: \r\npyarrow.Table\r\ncol: dictionary<values=int32, indices=int32, ordered=0>\r\n----\r\ncol: [  -- dictionary:\r\n[10,11]  -- indices:\r\n[0,1,0]]\r\n\r\nIn [4]: table.to_pandas()\r\nOut[4]: \r\n  col\r\n0  10\r\n1  11\r\n2  10\r\n\r\nIn [5]: table.to_pandas().dtypes\r\nOut[5]: \r\ncol    category\r\ndtype: object\r\n```"
        },
        {
            "created_at": "2022-09-25T15:59:07.460Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17636?focusedCommentId=17609217) by Roberto Lobo (rhlobo):*\nSorry for the long delay in responding `[~jorisvandenbossche]` .\r\n\r\nHere is an reproductible example: [bug.py](bug.py)"
        },
        {
            "created_at": "2022-09-27T09:29:27.530Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17636?focusedCommentId=17609932) by Joris Van den Bossche (jorisvandenbossche):*\nThanks, that's very useful!\r\n\r\nSo the issue here is that when using a nullable integer data type in pandas, which is a pandas extension type, pyarrow tries to recreate that data type on the \"to_pandas()\" conversion based on the information that we store in the table's metadata. \r\nNow, because the write/read operation with partitioning, the data that is being read again now has a dictionary type, while we do preserve the metadata. As a result, we get metadata and actual data that are no longer fully matching (the metadata says the type was an integer extension dtype, the actual data is now dictionary type), and this currently fails in the conversion. \r\n\r\nReproducing this in another way (explicitly changing this type in the table to get such a table with out-of-sync metadata and actual types):\r\n\r\n```python\n\r\ndf = pd.DataFrame({\"col\": pd.array([1, 2, 3, 1, 2], dtype=\"Int64\")})\r\ntable = pa.table(df)\r\ntable2 = table.set_column(0, \"col\", table[\"col\"].dictionary_encode())\r\n\r\n>>> table2.schema\r\ncol: dictionary<values=int64, indices=int32, ordered=0>\r\n-- schema metadata --\r\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 390\r\n\r\n>>> table2.to_pandas()\r\n....\r\n~/scipy/repos/arrow/python/pyarrow/pandas_compat.py in _reconstruct_block(item, columns, extension_columns)\r\n    778             raise ValueError(\"This column does not support to be converted \"\r\n    779                              \"to a pandas ExtensionArray\")\r\n--> 780         pd_ext_arr = pandas_dtype.__from_arrow__(arr)\r\n    781         block = _int.make_block(pd_ext_arr, placement=placement)\r\n    782     else:\r\n\r\n~/miniconda3/envs/arrow-dev/lib/python3.8/site-packages/pandas/core/arrays/numeric.py in __from_arrow__(self, array)\r\n     53             # test_from_arrow_type_error raise for string, but allow\r\n     54             #  through itemsize conversion GH#31896\r\n---> 55             rt_dtype = pandas_dtype(array.type.to_pandas_dtype())\r\n     56             if rt_dtype.kind not in [\"i\", \"u\", \"f\"]:\r\n     57                 # Could allow \"c\" or potentially disallow float<->int conversion,\r\n\r\n~/scipy/repos/arrow/python/pyarrow/types.pxi in pyarrow.lib.DataType.to_pandas_dtype()\r\n\r\nNotImplementedError: dictionary<values=int64, indices=int32, ordered=0>\r\n```\r\n\r\nThe error is indirectly being raised from the pandas code, but I have to check a bit whether we should fix this on the pyarrow or pandas side (we might need to catch this error on the pyarrow side, and in that case not try to convert to the pandas extension dtype but use the normal conversion path).\r\n\u00a0"
        },
        {
            "created_at": "2022-09-27T09:34:51.202Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17636?focusedCommentId=17609937) by Joris Van den Bossche (jorisvandenbossche):*\n`[~rhlobo]` one possible workaround on the short term could be to avoid using dictionary type for the partitioning fields, which case be done with:\r\n\r\n```Java\n\r\nresult_table = pq.read_table(source='xbug.pq', partitioning=ds.HivePartitioning.discover(infer_dictionary=False))\r\n```\r\n\r\nOr, alternatively, if you want to use dictionary / category dtype for those fields, you can remove the metadata before converting to pandas:\r\n\r\n```Java\n\r\nresult_table = pq.read_table(source='xbug.pq')\r\nresult_table = result_table.replace_schema_metadata()\r\nresult_table.to_pandas()\r\n```\r\n\r\nbut this way, also the other columns will not be converted to a pandas nullable data type, but to plain numpy (non-nullable) integer dtypes."
        }
    ]
}