{
    "issue": {
        "title": "[C++] Unrecognized filesystem type in URI: abfss://",
        "body": "***Note**: This issue was originally created as [ARROW-17672](https://issues.apache.org/jira/browse/ARROW-17672). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI am running the below commands in databricks.\r\n\r\nWhen I am trying to read a file which is stored in adls using pandas:\r\n```java\n\r\npip install adlfs \r\nimport pandas as pd\r\ndata = pd.read_parquet(\"abfss://data.parquet\", storage_options= {})\n```\r\nThen I got the below error:\u00a0\r\n```java\n\r\nFile \"/databricks/python/lib/python3.7/site-packages/pandas/io/parquet.py\", line 310, in read_parquet\r\nreturn impl.read(path, columns=columns, **kwargs)\r\nFile \"/databricks/python/lib/python3.7/site-packages/pandas/io/parquet.py\", line 125, in read\r\npath, columns=columns, **kwargs\r\nFile \"/databricks/python/lib/python3.7/site-packages/pyarrow/parquet.py\", line 1573, in read_table\r\nignore_prefixes=ignore_prefixes,\r\nFile \"/databricks/python/lib/python3.7/site-packages/pyarrow/parquet.py\", line 1434, in __init__\r\nignore_prefixes=ignore_prefixes)\r\nFile \"/databricks/python/lib/python3.7/site-packages/pyarrow/dataset.py\", line 667, in dataset\r\nreturn _filesystem_dataset(source, **kwargs)\r\nFile \"/databricks/python/lib/python3.7/site-packages/pyarrow/dataset.py\", line 424, in _filesystem_dataset\r\nfs, paths_or_selector = _ensure_single_source(source, filesystem)\r\nFile \"/databricks/python/lib/python3.7/site-packages/pyarrow/dataset.py\", line 371, in _ensure_single_source\r\nfilesystem, path = FileSystem.from_uri(path)\r\nFile \"pyarrow/_fs.pyx\", line 347, in pyarrow._fs.FileSystem.from_uri\r\nFile \"pyarrow/error.pxi\", line 122, in pyarrow.lib.pyarrow_internal_check_status\r\nFile \"pyarrow/error.pxi\", line 84, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowInvalid: Unrecognized filesystem type in URI: abfss://data.parquet \n```",
        "created_at": "2022-09-10T08:02:53.000Z",
        "updated_at": "2022-09-13T17:01:33.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Parquet",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-09-11T21:50:59.447Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17672?focusedCommentId=17602914) by Kouhei Sutou (kou):*\nWe need to implement a filesystem module for Azure Data Lake Storage in C++ like ARROW-2034 to support this case."
        },
        {
            "created_at": "2022-09-13T11:03:08.018Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17672?focusedCommentId=17603514) by Joris Van den Bossche (jorisvandenbossche):*\nYou are using `adlfs`, which is an fsspec-compatible filesystem, and so normally I expect that the pandas `read_parquet` call converts the \"abfss://data.parquet\" URI to an fsspec filesystem, passing that to the underlying pyarrow function, and we do have support for fsspec filesystems (and in that way we can support filesystems that don't have native support inside Arrow C++, such as Azure at the moment). \r\n\r\nSo something is going wrong here. As a starter, can you indicate which versions you are using for pyarrow, pandas, fsspec and adlfs? (eg a `pip list` or `conda list`)"
        },
        {
            "created_at": "2022-09-13T17:00:41.759Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17672?focusedCommentId=17603676) by Prakhar Sandhu (prakharsandhu):*\nPlease find the versions used below:\r\n\u00a0\r\npandas==1.3.5\r\npyarrow==4.0.0\r\npython==3.7.6\r\nadlfs==2022.2.0\r\nfsspec==2022.8.2"
        }
    ]
}