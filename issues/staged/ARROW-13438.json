{
    "issue": {
        "title": "[C++] Can't use StreamWriter with ToParquetSchema schema",
        "body": "***Note**: This issue was originally created as [ARROW-13438](https://issues.apache.org/jira/browse/ARROW-13438). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHi there,\r\n\r\nFirst of all, I'm not sure if I'm doing this correctly, as it took a bit of reverse engineering to figure this out.\u00a0\r\n\r\nI'm using Arrow 4.0.1 on Ubuntu with C++.\r\n\r\nI followed the streaming example and created:\r\n```cpp\n\r\n#include <cassert>\r\n#include <chrono>\r\n#include <cstdint>\r\n#include <cstring>\r\n#include <ctime>\r\n#include <iomanip>\r\n#include <iostream>\r\n#include <utility>\r\n\r\n#include \"arrow/io/file.h\"\r\n#include \"parquet/exception.h\"\r\n#include \"parquet/stream_reader.h\"\r\n#include \"parquet/stream_writer.h\"\r\n\r\nstd::shared_ptr<parquet::schema::GroupNode> GetSchema() {\r\n  parquet::schema::NodeVector fields;\r\n  fields.push_back(parquet::schema::PrimitiveNode::Make(\r\n      \"int64_field\", parquet::Repetition::OPTIONAL, parquet::Type::INT64,\r\n      parquet::ConvertedType::NONE));\r\n\r\n  return std::static_pointer_cast<parquet::schema::GroupNode>(\r\n      parquet::schema::GroupNode::Make(\"schema\", parquet::Repetition::REQUIRED, fields));\r\n}\r\n\r\nint main() {\r\n  std::shared_ptr<arrow::io::FileOutputStream> outfile;\r\n\r\n  PARQUET_ASSIGN_OR_THROW(\r\n      outfile,\r\n      arrow::io::FileOutputStream::Open(\"parquet-stream-api-example.parquet\"));\r\n\r\n  parquet::WriterProperties::Builder builder;\r\n  parquet::StreamWriter os{parquet::ParquetFileWriter::Open(outfile, GetSchema(), builder.build())};\r\n\r\n  os << int64_t(10);\r\n\r\n  return 0;\r\n}\r\n```\r\nThe code terminates with:\r\n```java\n\r\nterminate called after throwing an instance of 'parquet::ParquetException'\r\n  what():  Column converted type mismatch.  Column 'int64_field' has converted type[NONE] not 'INT_64' \n```\r\nWhat I'm not sure about is `parquet::ConvertedType::NONE` part. The example provides this value even for primitives, while it's my understanding that it's necessary? If I do provide it, the code works.\r\n\r\nNow, to the reverse engineering part.\u00a0I'm trying to write to Parquet using `StreamWriter`. `StreamWriter` requires\u00a0`parquet::schema::{{GroupNode`}} as the schema, but I begin with `arrow::Schema` I [found](https://github.com/apache/arrow/blob/e990d177b1f1dec962315487682f613d46be573c/cpp/src/parquet/arrow/writer.cc#L442)\u00a0that it can be converted to `{{parquet::SchemaDescriptor`}} using `parquet::arrow::ToParquetSchema `utility. Looking at the utility [implementation](https://github.com/apache/arrow/blob/85f192a45755b3f15653fdc0a8fbd788086e125f/cpp/src/parquet/arrow/schema.cc#L322) I can see that `logical_type` is set to `None` which equals to `parquet::ConvertedType::None` and hence the converted schema can't be used due to the issue I described above.\r\n1. Do we need to provide `ConvertedType` even for primitives?\n1. Is it a bug in the schema conversion utility or [ColumnCheck](https://github.com/apache/arrow/blob/8e43f23dcc6a9e630516228f110c48b64d13cec6/cpp/src/parquet/stream_writer.cc#L200) assert?\n1. Or is it expected behavior, in this case, what's a suggested approach? Build Parquet schema instead of Arrow Schema?\n   \n   Thank you,\n   \n   Vasily.",
        "created_at": "2021-07-22T19:38:27.000Z",
        "updated_at": "2022-09-01T10:09:56.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-09-01T10:07:40.672Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13438?focusedCommentId=17598859) by Laurent Erreca (Laurent Erreca):*\nHi,\r\n\r\nI had a similar issue with timestamp field :\r\n```c++\n\r\n...\r\n\r\n// Schema definition\r\n\r\nparquet::schema::NodeVector fields;\r\nfields.push_back(PrimitiveNode::Make(\"posdate\", Repetition::REQUIRED, LogicalType::Timestamp(false, LogicalType::TimeUnit::MICROS, false, false), Type::INT64));\r\n\r\nstd::shared_ptr<GroupNode> schema = std::static_pointer_cast<GroupNode>(GroupNode::Make(\"schema\", Repetition::REQUIRED, fields));\r\n\r\n...\r\n\r\n// Write\r\n\r\nparquet::StreamWriter out{\r\n\u00a0 \u00a0 parquet::ParquetFileWriter::Open(outfile, schema, builder.build())};\r\n\r\n// posdate is a timestamp converted to int64\r\n\r\nout << posdate; // fails here\r\n\r\n```\r\nException:\r\n\r\n```bash\n\r\n\r\nColumn converted type mismatch. \u00a0Column 'posdate' has converted type[NONE] not 'INT_64'\r\n\r\n```\r\n\r\nCould be a bug in [ColumnCheck](https://github.com/apache/arrow/blob/8e43f23dcc6a9e630516228f110c48b64d13cec6/cpp/src/parquet/stream_writer.cc#L200) as mentionned above?\r\n\r\n\u00a0\r\n\r\nI can bypass this issue by setting\u00a0isAdjustedToUTC to false and by letting posdate as type std::chrono::microseconds, but in this case the output parquet file metadata has converted_type set to TIMESTAMP_MICROS."
        }
    ]
}