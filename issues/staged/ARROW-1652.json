{
    "issue": {
        "title": "[JS] Separate Vector into BatchVector and CompositeVector",
        "body": "***Note**: This issue was originally created as [ARROW-1652](https://issues.apache.org/jira/browse/ARROW-1652). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nCompositeVector should have a `batch(..)` function that returns a BatchVector",
        "created_at": "2017-10-05T15:27:54.000Z",
        "updated_at": "2017-11-03T21:45:08.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: JavaScript",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2017-11-03T21:45:08.000Z"
    },
    "comments": [
        {
            "created_at": "2017-10-05T15:30:35.441Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1652?focusedCommentId=16193049) by Brian Hulette (bhulette):*\nI started working on implementing this change, I'll try to put up a PR for it tomorrow so that [~paul.e.taylor] can take a look"
        },
        {
            "created_at": "2017-10-09T22:18:07.417Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1652?focusedCommentId=16197777) by Paul Taylor (paul.e.taylor):*\n`[~bhulette]` yes, it's worth revisiting how the batch lookup happens.\r\n\r\nThe reason `get` doesn't take a batch hint currently is that without inspecting the loaded batches before iteration, the iterator would need to do the batch lookup on each item anyway:\r\n\r\n```Java\n\r\nfor (let index = 0; index < vector.length; ++index) {\r\n  vector.get(index, vector.findBatch(index)); // <-- hypothetical `get` that takes a batch hint\r\n}\r\n```\r\n\r\nAlso, I measured the cost of a variant of `get` that returns a tuple of `[value, batchIndex]`, and it was much slower than incurring the batch-lookup cost each time. The best we could do is expose the batches, so an external iterator could increment the batch hint based on the index being iterated:\r\n\r\n```Java\n\r\nlet batches = vector.batches();\r\nlet iterated = 0, index = -1, batch = -1;\r\nwhile (++index < vector.length) {\r\n  if (iterated >= index) {\r\n    iterated += batches[++batch].length;\r\n  }\r\n  vector.get(index - iterated, batch);\r\n}\r\n```\r\n\r\nBut this approach also has a number of drawbacks:\r\n\r\n1. Forcing the iterator to do this every time isn't very ergonomic\r\n2. It's only helpful for contiguous iterations (from `start` < `index` < `end`). Random lookups will still have to reverse-lookup the batch index from the item index each get call\r\n\r\nThe [Vector iterators](https://github.com/apache/arrow/blob/master/js/src/vector/typed.ts#L78) don't have to do the batch index lookup, since they always iterate in a defined order:\r\n\r\n```Java\n\r\n// Always iterates from 0 -> length, faster than calling `get()` in a loop\r\nfor (let x of vector) { }\r\n```\r\n\r\nAssuming contiguous iteration, we could add `skip()`/`skipLast()` and `take()`/`takeLast()` methods, which return a clone of the Vector with trimmed internal batches list. This would only require `subarray` calls on the first/last TypedArrays, so still zero-copy:\r\n\r\n```Java\n\r\nfor (let x of vector.skip(10).take(10)) { // <-- iterate indexes 10 through 20\r\n}\r\n```\r\n\r\nI also want to call out that `Vector.range()` taking a batch hint is a bit of slight-of-hand to accommodate the [ListVectorBase\\|(https://github.com/apache/arrow/blob/master/js/src/vector/list.ts#L43] offset lookups. The ListVector `from` and `to` offsets are relative to the RecordBatch they were introduced, so passing the batch index into the slice method causes slice to lookup the `from` and `to` offsets relative to the batch they're from, instead of adjusting them relative to all the batches:\r\n\r\n```Java\n\r\n[{   /* RecordBatch 0 */\r\n  offsets: [0, 5, 10],\r\n  values: \"hellobrian\"\r\n}, { /* RecordBatch 1 */\r\n  offsets: [0, 4, 8],\r\n  values: \"frompaul\"\r\n}]\r\n// vector.get(2) decomposes to:\r\n// vector.values.slice(0, 4, 1) <-- offsets 0, 4 in RecordBatch 1\r\n```"
        },
        {
            "created_at": "2017-10-10T00:14:41.218Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1652?focusedCommentId=16197919) by Brian Hulette (bhulette):*\n[~paul.e.taylor] all good points. My primary goal with this ticket (and ARROW-1651) is just to improve performance when iterating over multiple vectors simultaneously using a `Table`. Currently, the `*rows` iterator just defers to each Vector's `get(i)` function for every index, which makes for a lot of batch lookups when scanning all of the data. The Vector iterators don't help since they can't be used simultaneously across multiple Vectors (or can they? is there something like python's `zip` that we could use?)\r\n\r\nIf the `Table` required that each of it's vectors have the same batches, and stored that in a `batches` array, [`*rows`](https://github.com/apache/arrow/blob/master/js/src/table.ts#L50) could just iterate over each batch, and then over each index within it.\r\n```Java\n\r\n*rows() {\r\n    for (let batch of this.batches) {\r\n       for (idx = 0; idx < batch; ++idx) {\r\n          yield this._columns.map(function(c) { return c.get(idx, batch); });\r\n       }\r\n    }\r\n}\r\n```\r\nObviously there would need to be bounds-checking for `startRow` and `endRow` as well, but that wouldn't be hard to implement by tracking an overall index.\r\n\r\nThe batch hint could be an optional parameter on `Vector.get(..)`. That way no one is forced to use it, and random access would be more intuitive. Or it could be an entirely separate function `Vector.getFromBatch(i, batch)`.\r\n\r\nMy end goal here is just improving performance when iterating over multiple vectors, so if anyone has other ideas on how to do that I'd be happy to ditch this idea. Maybe there's some way to use multiple Vector iterators simultaneously that I'm missing?"
        },
        {
            "created_at": "2017-10-14T17:24:44.889Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1652?focusedCommentId=16204747) by Brian Hulette (bhulette):*\nFinally put up that PR I promised: https://github.com/apache/arrow/pull/1200"
        },
        {
            "created_at": "2017-10-15T19:40:33.293Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1652?focusedCommentId=16205278) by Paul Taylor (paul.e.taylor):*\n`[~bhulette]` \r\n> The Vector iterators don't help since they can't be used simultaneously across multiple Vectors (or can they? is there something like python's zip that we could use?)\r\n\r\nYeah totally. I've been using [IxJS](https://github.com/ReactiveX/IxJS) for this, it's basically a lazy version of `lodash` for Iterables and AsyncIterables from the team that did the Enumerable and Observable extension methods in C#. The Ix operators work on any JS Iterable type, so they work with the JS Vectors. You can use the operators in a functional style, or cast the Vectors to Iterables and work with a full prototype (which I find is easier with intellisense):\r\n\r\n```javascript\n\r\nimport * as fs from 'fs';\r\nimport { Table } from 'apache-arrow';\r\nimport { zip } from 'ix/iterable/zip';\r\nimport { AsyncSink, AsyncIterable } from 'ix';\r\n\r\nlet tables = AsyncIterable\r\n  .from(fs\r\n    .createReadStream('table.arrow')\r\n    .pipe(new AsyncSink()))\r\n  .toArray()\r\n  .map((buffers) => Table.from(...buffers));\r\n\r\nfor await (let table of tables) {\r\n  let colA = table.getColumn('A');\r\n  let colB = table.getColumn('B');\r\n  for (let [a, b] of zip(colA, colB)) {\r\n    console.log(a + b);\r\n  }\r\n}\r\n```\r\n\r\nIt's also helpful when you're working with a streaming source:\r\n\r\n```javascript\n\r\nimport { zip } from 'ix/iterable/zip';\r\nimport { readBuffers } from 'apache-arrow';\r\nimport { AsyncSink, AsyncIterable } from 'ix';\r\n\r\nlet vectors = AsyncIterable\r\n  .from(fetch('http://some-resource.arrow'))\r\n  .flatMap(({ body }) => await body.getReader().pipeTo(new AsyncSink()))\r\n  .toArray() // todo: `readBuffersAsync`, so we don't have to aggregate the stream here\r\n  .flatMap((buffers) => readBuffers(...buffers))\r\n\r\nfor await (let [colA, colB] of vectors) {\r\n  for (let sum of zip(([a, b]) => a + b, colA, colB)) {\r\n    console.log(sum);\r\n  }\r\n}\r\n```\r\n\r\nIn addition to zip, there's a ton of other useful columnar transforms like scan, map, filter, reduce, min/max/groupBy, inner/outer/groupJoin, distinctUntilChanged, and operations for converting between sync/async Iterables. Pretty slick.\r\n\r\n> If the Table required that each of it's vectors have the same batches, and stored that in a batches array, \\*rows could just iterate over each batch, and then over each index within it.\r\n\r\nYou're absolutely right, I threw the `*rows()` iterator in at the last minute b/c it looked good in a gist. Ideally it would zip the columns. The whole Table thing deserves a make over :-)\r\n\r\n> The most significant changes are in `ListVector` and `IndexVector`, because I removed the `returnWithBatchIndex` argument and made some tweaks to the way offset vectors are handled (Rather than subtracting batch when accessing data, use `length - 1` to reduce `index` while iterating)\r\n\r\nGod that's awesome, thanks for seeing that! I spent nearly a day debugging that until I noticed they were always off by `batch` many. It didn't even occur to me to subtract 1 while iterating \ud83d\ude02.\r\n\r\n> The batch hint could be an optional parameter on Vector.get(..). That way no one is forced to use it, and random access would be more intuitive. Or it could be an entirely separate function Vector.getFromBatch(i, batch).\r\n\r\nYeah sorry I forgot to mention in my previous comment that I [originally had a batch hint in get](https://github.com/graphistry/arrow/blame/05372ddf3be33847ebce9f7458ee59e7ada1b15a/src/vectors/typed.ts#L42), almost identical to your PR \ud83d\ude05. As I was working through the tests I realized the batch hint doesn't always compose across Vectors. Considering how heavily composition is employed in the Vector design, `get` should always be idempotent with respect to its iterator form.\r\n\r\nFor example, cloning a Vector and pairing it with a new validity Vector could result in the vectors having different internal batch structures. In this case the parent could call the ValidityVector's `get` with the wrong indexes, batch hints, or both. I could be mistaken, but I think applies to all the composed types (StructVector, ListVectorBase, DictionaryVector)? Unfortunately this tight coupling does exist between the ListVectorBase and its offset Vector. I didn't see an alternative given the memory layout, so I made it an internal implementation detail. It would be great to change that it if possible.\r\n\r\n> My end goal here is just improving performance when iterating over multiple vectors, so if anyone has other ideas on how to do that I'd be happy to ditch this idea. Maybe there's some way to use multiple Vector iterators simultaneously that I'm missing?\r\n\r\nI'm with you 100%, speed is the name of the game.\r\n\r\nLast weekend I benchmarked iterating 25MM Float32s across 22 batches (in turbofan) to see if I could make the reverse `index -> batch` lookup faster:\r\n\r\n- a for-loop with hint takes ~340ms\n- the way `get` works today takes ~750ms\n- regular iterators take ~700ms (avoiding intermediate `IteratorResult` allocations gets that down to ~640ms range)\n- a straight memcpy takes ~100ms\n- a special forward-only iterator function (that allows skipping ahead but not back) takes ~350ms\n- skip list and sparse array were both total disasters in the ~5-10s range\n  \n  These ratios seem in line with the Arrow performance tests. While I share your opinions on speed, the JIT is famously difficult to predict. I think our energy will be better applied writing Arrow-optimized iteration operators (filter/skip/take, sort, groupBy) that cleverly cache intermediate indexes and make liberal use of zero-copy slicing than attempting to micro-optimize the difference between `for` and `for...of` loops.\n  \n  Does that all sound reasonable or am I way off base?\n"
        },
        {
            "created_at": "2017-11-03T21:45:08.757Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1652?focusedCommentId=16238437) by Wes McKinney (wesm):*\nIssue resolved by pull request 1273\n<https://github.com/apache/arrow/pull/1273>"
        }
    ]
}