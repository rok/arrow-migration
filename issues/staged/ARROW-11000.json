{
    "issue": {
        "title": "[Python] Enable random access reading for Python file objects (if supported)",
        "body": "***Note**: This issue was originally created as [ARROW-11000](https://issues.apache.org/jira/browse/ARROW-11000). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n`arrow::py::PyReadableFile::ReadAt` is being commented as thread-safe (it puts a lock on the underlying python file) and should thus allow random access in parallel code (for example, reading a subset (eg column) of a parquet file). \r\n\r\nHowever, based on experimentation, it seems this doesn't work (eg with s3fs filesystem to read a specific parquet column",
        "created_at": "2020-12-21T16:10:08.000Z",
        "updated_at": "2020-12-21T19:02:49.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-12-21T16:33:34.533Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11000?focusedCommentId=17252954) by Joris Van den Bossche (jorisvandenbossche):*\nIt might also be an issue specific to `PyFileSystem` handlers. Because when adding some print statements in `PyReadableFile::ReadAt`, this is clearly called for a plain python file object:\r\n\r\n```Java\n\r\nIn [3]: with open(\"test.parquet\", \"rb\") as f:\r\n   ...:     pq.read_table(f)\r\n   ...: \r\nCalling PyReadableFile::ReadAt\r\nCalled seek successfully\r\n....\r\n```"
        },
        {
            "created_at": "2020-12-21T16:42:19.694Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11000?focusedCommentId=17252958) by Joris Van den Bossche (jorisvandenbossche):*\nThe reason I opened this issue is because I saw large download sizes when using `s3fs` to read a single column of a large parquet file (compared to using our own S3Filesystem, which downloaded only a little bit of data). \r\n\r\nSo the example basically is the following. But, with the mentioned print statements, it seems `PyReadableFile::ReadAt` also gets called in this case. So it might be rather an issue on s3fs side?\r\n\r\n```Java\n\r\nIn [7]: import s3fs\r\n\r\nIn [8]: fs2 = s3fs.S3FileSystem(anon=True)\r\n\r\nIn [9]: pq.read_table('ursa-labs-taxi-data/2016/01/data.parquet', filesystem=fs2, columns=[\"passenger_count\"])\r\nCalling PyReadableFile::ReadAt\r\nCalled seek successfully\r\n....\r\n```"
        },
        {
            "created_at": "2020-12-21T19:02:49.831Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11000?focusedCommentId=17253047) by Maarten Breddels (maartenbreddels):*\ndid you check with passing `default_fill_cache=False` and `default_block_size=1` to the s3fs ctor? I think it by default does too many smart things."
        }
    ]
}