{
    "issue": {
        "title": "[R] dim method for FileSystemDataset",
        "body": "***Note**: This issue was originally created as [ARROW-8118](https://issues.apache.org/jira/browse/ARROW-8118). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI been using this function enough that I wonder if a) would be useful in the package and b) whether this is something you think is worth working on. The basic problem is that if you have a hierarchical file structure that accommodates using open_dataset, it is definitely useful to know the amount of data you are dealing with. My idea is that 'FileSystemDataset' would have dim, nrow and ncol methods. Here is how I've been using it:\r\n```java\n\r\nlibrary(arrow)\r\nx <- open_dataset(\"data/rivers-data/\", partitioning = c(\"prov\", \"month\"))\r\ndim_arrow <- function(x) {\r\n rows <- sum(purrr::map_dbl(x$files, ~ParquetFileReader$create(.x)$ReadTable()$num_rows))\r\n cols <- x$schema$num_fields\r\n \r\n c(rows, cols)\r\n}\r\ndim_arrow(x)\r\n#> [1] 426929 7\r\n```\r\n\u00a0\r\n\r\nIdeally this would work on\u00a0arrow_dplyr_query objects as well but I haven't quite figured out how that filters based on the partitioning variables.",
        "created_at": "2020-03-13T22:20:28.000Z",
        "updated_at": "2020-03-19T19:09:58.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-03-19T19:09:57.000Z"
    },
    "comments": [
        {
            "created_at": "2020-03-13T22:45:20.450Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8118?focusedCommentId=17059118) by Neal Richardson (npr):*\nYeah, ncol is easy to get from the Dataset schema (and you can get it from arrow_dplyr_query too, incorporating any select statement). Your solution for nrow is clever, but you're right, that won't generalize to query objects, and looking ahead, you'd have to switch the behavior based on the FileFormat since Datasets can be based on other file types. \r\n\r\nI'd be happy to review a PR with nrow and ncol methods, and dim that wraps them, erroring gracefully where unsupported (i.e. if filtered). IMO the C++ library should be able to tell us nrow, and it may already have the relevant file/row group statistics in memory, but we can start with something that works in R and worry about pushing the work down to C++ later."
        },
        {
            "created_at": "2020-03-14T13:33:07.065Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8118?focusedCommentId=17059350) by Francois Saint-Jacques (fsaintjacques):*\nA small point, getting the number of rows can be a very expensive call, it can trigger a full parsing of the dataset."
        },
        {
            "created_at": "2020-03-14T16:58:51.491Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8118?focusedCommentId=17059410) by Neal Richardson (npr):*\nRight. If we're talking about with a filter, then yes, this is an aggregation over the whole dataset. But for the full dataset, at least for Parquet, in the discovery/inspect step of creating the dataset we've already grabbed the metadata from each file. Doesn't that tell us how many rows are in each file? "
        },
        {
            "created_at": "2020-03-19T19:09:57.161Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8118?focusedCommentId=17062875) by Ben Kietzman (bkietz):*\nIssue resolved by pull request 6635\n<https://github.com/apache/arrow/pull/6635>"
        }
    ]
}