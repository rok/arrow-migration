{
    "issue": {
        "title": "[C++] Allow the creation of future \"chains\" to better control parallelism",
        "body": "***Note**: This issue was originally created as [ARROW-13004](https://issues.apache.org/jira/browse/ARROW-13004). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThis is a bit tricky to explain.\u00a0 ShouldSchedule::Always works well for AddCallback but falls short for Transfer and Then.\u00a0 An example may explain best.\r\n\r\nConsider three operators, Source, Transform, and Sink.\u00a0 They are setup as...\r\n```java\n\r\nsource_fut = source(); // 1\r\ntransform_fut = source_fut.Then(Transform(), ScheduleAlways); // 2\r\nsink_fut = transform_fut.Then(Consume()); // 3\r\n```\r\nThe intent is to run Transform + Consume as a single thread task on each item generated by source().\u00a0 This is what happens if source() is slow.\u00a0 If source() is fast (let's pretend it's always finished) then this is not what happens.\r\n\r\nLine 2 causes a new thread task to be launched (since source_fut is finished).\u00a0 It is possible that new thread task can mark transform_fut finished before line 3 is executed by the original thread.\u00a0 This causes Consume() and Transform() to run on separate threads.\r\n\r\nThe solution (at least as best I can come up with) is unfortunately a little complex (though the complexity can be hidden in future/async_generator internals).\u00a0 Basically, it is worth waiting to schedule until the future chain has had a chance to finish connecting the pressure.\u00a0 This means a future created with ScheduleAlways is created in an \"unconsumed\" mode.\u00a0 Any callbacks that would normally be launched will not be launched until the future switches to \"consumed\".\u00a0 Future.Wait(), VisitAsyncGenerator, CollectAsyncGenerator, and some of the async_generator operators would cause the future to be \"consumed\".\u00a0 The \"consume\" signal will need to propagate backwards up the chain so futures will need to keep a reference to their antecedent future.\r\n\r\nThis work meshes well with some other improvements I have been considering, in particular, splitting future/promise and restricting futures to a single callback.\r\n\r\n\u00a0",
        "created_at": "2021-06-08T05:13:05.000Z",
        "updated_at": "2022-07-12T21:56:59.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2022-07-12T21:56:59.000Z"
    },
    "comments": [
        {
            "created_at": "2021-06-08T05:34:29.896Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13004?focusedCommentId=17359045) by Weston Pace (westonpace):*\n`[~bkietz]` `[~apitrou]` \u00a0There is potentially an analogous problem in a push-based model with back pressure.\u00a0 In both cases the problem arises when there is a slow sink and a fast source.\u00a0 Consider the same Source, Transform, Sink graph.\u00a0 If sink is slow enough then the graph will eventually pause.\r\n\r\n\u00a0\r\n\r\nConsider the following potential sequence:\r\n \\* Initial State: Source will be stopped, Transform will be stopped, and Sink will be running.\r\n \\* Sink finishes and unpauses Transform\r\n \\* Transform delivers an item immediately to Sink (if paused it will presumably have one in its buffer).\r\n \\* Transform unpauses Source\r\n \\* Sink pauses Transform\r\n \\* Source delivers an item immediately (again, it has a full buffer) to Transform\r\n \\* Transform pauses Sink\r\n \\* We have now returned to the initial state.\r\n\r\n\u00a0\r\n\r\nNotice that data locality is lost.\u00a0 Even if Transform is the stateless (and just forwards any extra items to Sink allowing a bit of overrun) I think care is still needed.\u00a0 I don't have enough a sense of the details to think it all the way through.\u00a0 Just a note to include this in any test cases (in a back-pressured situation ensure that each unpause runs an entire item through the chain without stopping at each node) when you get around to adding back pressure."
        },
        {
            "created_at": "2021-06-08T07:30:21.018Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13004?focusedCommentId=17359098) by Antoine Pitrou (apitrou):*\n> The intent is to run Transform + Consume as a single thread task on each item generated by source()\r\n\r\nThen why not just chain them directly?\r\n\r\n\u00a0"
        },
        {
            "created_at": "2021-06-08T19:25:37.909Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13004?focusedCommentId=17359536) by Weston Pace (westonpace):*\nSome of the async_generator.h operators (e.g. the merge or resequencing operators) aren't so easy to chain directly.\u00a0 That being said, I will hold off for the moment on working on this until the ExecPlan work is more stable.\u00a0 It's possible the scan node can just adopt the tools from ExecPlan and build up a graph instead of using async_generator.h."
        },
        {
            "created_at": "2022-07-12T14:04:18.977Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13004?focusedCommentId=17565523) by @toddfarmer:*\nThis issue was last updated over 90 days ago, which may be an indication it is no longer being actively worked. To better reflect the current state, the issue is being unassigned. Please feel free to re-take assignment of the issue if it is being actively worked, or if you plan to start that work soon."
        },
        {
            "created_at": "2022-07-12T21:56:59.606Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13004?focusedCommentId=17566030) by Weston Pace (westonpace):*\nThis is handled better by the exec plan and we are not likely to pursue this in futures"
        }
    ]
}