{
    "issue": {
        "title": "[Python] Timestamp metadata min/max stored as INT96 cannot be read in",
        "body": "***Note**: This issue was originally created as [ARROW-10444](https://issues.apache.org/jira/browse/ARROW-10444). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI am working with Parquet files produced by AWS Redshift's UNLOAD command. The schema has several timestamp columns stored as INT96. I have noticed their min/max values are omitted from the PyArrow's metadata\u00a0\r\n\r\ne.g. For this column in my table schema: `dv_startdateutc: timestamp[ns]`, the statistics section of the column metadata is None, i.e. not filled in with the min/max values present in the other non-timestamp columns:\r\n```python\n\r\n<pyarrow._parquet.ColumnChunkMetaData object at 0x7ff5000d1a10>\r\n file_offset: 1342723\r\n file_path: \r\n physical_type: INT96\r\n num_values: 150144\r\n path_in_schema: dv_startdateutc\r\n is_stats_set: False\r\n statistics: None\r\n compression: SNAPPY\r\n encodings: ('PLAIN_DICTIONARY', 'PLAIN', 'RLE')\r\n has_dictionary_page: True\r\n dictionary_page_offset: 1342659\r\n data_page_offset: 1342687\r\n total_compressed_size: 64\r\n total_uncompressed_size: 60\r\n```\r\nThis means PyArrow cannot use metadata to filter dataset reads by date/time.\r\n \u00a0\r\n I suspect this bug arises in `_cast_statistic_raw_min()`\u00a0and `_cast_statistic_raw_max()`\u00a0in `/python/pyarrow/_parquet.pyx` at L180. The code extracts below show there are casts for `ParquetType_INT32` and\u00a0`ParquetType_INT64`, but not for `ParquetType_INT96`.\r\n\r\nCan a case be added for `ParquetType_INT96` in both of these?\r\n\r\nNote that those raw `ParquetType_INT96` will be converted to the appropriate timestamp type in `_box_logical_type_value(raw, statistics.descr())`\r\n\r\n\u00a0\r\n\r\nThanks\r\n Stephen\r\n```python\n\r\n cdef\u00a0_cast_statistic_raw_min(CStatistics*\u00a0statistics):\r\n \u00a0\u00a0\u00a0\u00a0cdef\u00a0ParquetType\u00a0physical_type\u00a0=\u00a0statistics.physical_type()\r\n \u00a0\u00a0\u00a0\u00a0cdef\u00a0uint32_t\u00a0type_length\u00a0=\u00a0statistics.descr().type_length()\r\n \u00a0\u00a0\u00a0\u00a0if\u00a0physical_type\u00a0==\u00a0ParquetType_BOOLEAN:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CBoolStatistics*>\u00a0statistics).min()\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_INT32:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CInt32Statistics*>\u00a0statistics).min()\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_INT64:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CInt64Statistics*>\u00a0statistics).min()\r\n# ADD ParquetType_INT96 here!!! \u00a0\u00a0\u00a0\u00a0\r\n     elif\u00a0physical_type\u00a0==\u00a0ParquetType_FLOAT:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CFloatStatistics*>\u00a0statistics).min()\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_DOUBLE:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CDoubleStatistics*>\u00a0statistics).min()\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_BYTE_ARRAY:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0_box_byte_array((<CByteArrayStatistics*>\u00a0statistics).min())\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_FIXED_LEN_BYTE_ARRAY:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0_box_flba((<CFLBAStatistics*>\u00a0statistics).min(),\u00a0type_length)\r\n\r\ncdef\u00a0_cast_statistic_raw_max(CStatistics*\u00a0statistics):\r\n \u00a0\u00a0\u00a0\u00a0cdef\u00a0ParquetType\u00a0physical_type\u00a0=\u00a0statistics.physical_type()\r\n \u00a0\u00a0\u00a0\u00a0cdef\u00a0uint32_t\u00a0type_length\u00a0=\u00a0statistics.descr().type_length()\r\n \u00a0\u00a0\u00a0\u00a0if\u00a0physical_type\u00a0==\u00a0ParquetType_BOOLEAN:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CBoolStatistics*>\u00a0statistics).max()\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_INT32:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CInt32Statistics*>\u00a0statistics).max()\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_INT64:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CInt64Statistics*>\u00a0statistics).max()\r\n# ADD ParquetType_INT96 here!!!\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_FLOAT:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CFloatStatistics*>\u00a0statistics).max()\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_DOUBLE:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0(<CDoubleStatistics*>\u00a0statistics).max()\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_BYTE_ARRAY:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0_box_byte_array((<CByteArrayStatistics*>\u00a0statistics).max())\r\n \u00a0\u00a0\u00a0\u00a0elif\u00a0physical_type\u00a0==\u00a0ParquetType_FIXED_LEN_BYTE_ARRAY:\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return\u00a0_box_flba((<CFLBAStatistics*>\u00a0statistics).max(),\u00a0type_length)\r\n```",
        "created_at": "2020-10-31T02:23:12.000Z",
        "updated_at": "2020-11-02T22:27:21.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-10-31T04:34:44.763Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10444?focusedCommentId=17223998) by Micah Kornfield (emkornfield):*\nI think if you want to try to make a pull request, we can add it.\u00a0 I would guess the reason why it hasn't been added is int96 is considered deprecated (it might be bits are missing elsewhere to properly filter on int96 types as well)."
        },
        {
            "created_at": "2020-10-31T13:20:58.006Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10444?focusedCommentId=17224073) by Stephen Simmons (stevesimmons):*\nDeprecated is fine for writing, but when you're reading, you have the parquet files you're given!\r\n\r\nLooks like I'll also need to define a CInt96Statistics or maybe CTimestampStatistics class in `_parquet.pxd`.\r\n\r\nFor reference, the conversion from Int96 Impala timestamp to int64[ns] in `/parquet-cpp/parquet/arrow/reader.h`\u00a0has:\r\n```java\n\r\nconstexpr int64_t kJulianToUnixEpochDays = 2440588LL;\r\nconstexpr int64_t kMillisecondsInADay = 86400000LL;\r\nconstexpr int64_t kNanosecondsInADay = kMillisecondsInADay * 1000LL * 1000LL;\r\n\r\nstatic inline int64_t impala_timestamp_to_nanoseconds(const Int96& impala_timestamp) {\r\n  int64_t days_since_epoch = impala_timestamp.value[2] - kJulianToUnixEpochDays;\r\n  int64_t nanoseconds = *(reinterpret_cast<const int64_t*>(&(impala_timestamp.value)));\r\n  return days_since_epoch * kNanosecondsInADay + nanoseconds;\r\n} \n```"
        },
        {
            "created_at": "2020-11-02T16:19:18.802Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10444?focusedCommentId=17224782) by Joris Van den Bossche (jorisvandenbossche):*\nDo you have a small reproducer / parquet file with statistics included for int96 columns? \r\nBecause it seems the Arrow parquet writer does not write statistics for int96 columns. Not fully sure here, though, but a small test like this gives `is_stats_set=False`:\r\n\r\n```Java\n\r\nIn [8]: import pyarrow.parquet as pq\r\n\r\nIn [11]: table = pa.table({\"timestamp\": pa.array([\"2020-01-01\", \"2020-01-02\"]).cast(pa.timestamp(\"us\"))})\r\n\r\nIn [13]: pq.write_table(table, \"test.parquet\", use_deprecated_int96_timestamps=True)\r\n\r\nIn [16]: meta = pq.read_metadata(\"test.parquet\")\r\n\r\nIn [17]: meta.schema\r\nOut[17]: \r\n<pyarrow._parquet.ParquetSchema object at 0x7f597248cac8>\r\nrequired group field_id=0 schema {\r\n  optional int96 field_id=1 timestamp;\r\n}\r\n\r\nIn [18]: meta.schema.to_arrow_schema()\r\nOut[18]: \r\ntimestamp: timestamp[ns]\r\n  -- field metadata --\r\n  PARQUET:field_id: '1'\r\n\r\nIn [19]: meta.row_group(0).column(0)\r\nOut[19]: \r\n<pyarrow._parquet.ColumnChunkMetaData object at 0x7f5970706548>\r\n  file_offset: 70\r\n  file_path: \r\n  physical_type: INT96\r\n  num_values: 2\r\n  path_in_schema: timestamp\r\n  is_stats_set: False\r\n  statistics:\r\n    None\r\n  compression: SNAPPY\r\n  encodings: ('PLAIN_DICTIONARY', 'PLAIN', 'RLE')\r\n  has_dictionary_page: True\r\n  dictionary_page_offset: 4\r\n  data_page_offset: 40\r\n  total_compressed_size: 66\r\n  total_uncompressed_size: 66\r\n\r\n```\r\n\r\nSuch a reproducer will be needed to add a test for it."
        },
        {
            "created_at": "2020-11-02T22:23:59.459Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10444?focusedCommentId=17224991) by Stephen Simmons (stevesimmons):*\nHi Joris. I thought about investigating what's actually written in that field's metadata. My original parquet files are are dataset made up of 800 6GB files written by an AWS Redshift database that I don't have access to, saved into S3 buckets that are tightly permissioned, and which I can only access via a secure JupyterHub session. So it will take me some time to dig into whether Redshift writes INT96 min/max values or not.\r\n\r\nThanks for your example. I had traced though that code path in PyArrow earlier. The underlying reason why PyArrow does not write max/min statistics for timestamps as INT96 is because INT96 is defined as SORTORDER::UNSIGNED in cpp\\src\\parquet\\statistics.h|.cpp.\r\n\r\nSo assuming Redshift writes the INT96 statistics, it will need some more involved work on the arrow side to read it.\u00a0 \u00a0 \u00a0 \u00a0"
        }
    ]
}