{
    "issue": {
        "title": "[Python] ParquetDataset deadlock with different metadata_nthreads values",
        "body": "***Note**: This issue was originally created as [ARROW-7385](https://issues.apache.org/jira/browse/ARROW-7385). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n```Java\n\r\nimport pandas as pd\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\noutput_folder = \"C:\\scr\\tmp\"\r\nweather_df = pd.DataFrame({\"a\": [1, 1, 1, 2, 2, 2, 3, 3, 3], \"b\": [1, 1, 1, 1, 5, 1, 1, 1, 1], \"c\": [\"c1\", \"c1\", \"c1\", \"c10\", \"c20\", \"c30\", \"c1\", \"c1\", \"c1\"], \"d\": [32, 32, 32, 32, 32, 32, 32, 32, 32] })\r\ntable = pa.Table.from_pandas(weather_df)\r\npq.write_to_dataset(table, root_path=output_folder, partition_cols=[\"a\", \"b\", \"c\"])\r\n```\r\n\r\n# works for 1 thread\r\n\r\n```Java\n\r\ndataset = pq.ParquetDataset(output_folder, metadata_nthreads=1, validate_schema=False)\r\n```\r\n\r\n# stuck for 2~6 threads (but it may vary from time to time)\r\n\r\n```Java\n\r\ndataset = pq.ParquetDataset(output_folder, metadata_nthreads=2, validate_schema=False)\r\ndataset = pq.ParquetDataset(output_folder, metadata_nthreads=6, validate_schema=False)\r\n```\r\n\r\n# works for 60 thread\r\n\r\n```Java\n\r\ndataset = pq.ParquetDataset(output_folder, metadata_nthreads=60, validate_schema=False)\r\n```",
        "created_at": "2019-12-13T05:42:21.000Z",
        "updated_at": "2022-09-23T13:55:00.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2019-12-18T15:01:37.014Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7385?focusedCommentId=16999250) by Joris Van den Bossche (jorisvandenbossche):*\n`[~mrmathematica]` Thanks for the report! \r\nI can confirm this (on linux, with pyarrow master)"
        },
        {
            "created_at": "2019-12-18T15:05:09.684Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7385?focusedCommentId=16999253) by Joris Van den Bossche (jorisvandenbossche):*\ncc `[~rgruener]`"
        },
        {
            "created_at": "2020-04-14T15:47:05.966Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7385?focusedCommentId=17083361) by Chongkai Zhu (mrmathematica):*\n`[~jorisvandenbossche]` any updates? Or if you mind I create a PR for this on github? Thanks."
        },
        {
            "created_at": "2020-04-15T18:41:37.636Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7385?focusedCommentId=17084305) by Joris Van den Bossche (jorisvandenbossche):*\nNo specific update. A PR is certainly welcome. \r\n\r\nNote that we are working on a reimplementation of the ParquetDataset based on the general Dataset API (see https://github.com/apache/arrow/blob/master/docs/source/python/dataset.rst, and see the note I just added here https://github.com/apache/arrow/pull/6779/commits/24f72168dc52967e62451febd661ac1b5472dbb7). So while we might not be actively working on the existing ParquetDataset implementation any more, PRs fixing bugs in it are certainly still welcome (it's not yet going away on the short term).\r\n\r\nFeedback on the new implementation is also very welcome (but, it does not yet support multi-threaded discovery/reading of the metadata)."
        }
    ]
}