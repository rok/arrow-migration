{
    "issue": {
        "title": "[Python] Performance degradation parquet reading of wide dataframes",
        "body": "***Note**: This issue was originally created as [ARROW-11469](https://issues.apache.org/jira/browse/ARROW-11469). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI noticed a relatively big performance degradation in version 1.0.0+ when trying to load wide dataframes.\r\n\r\nFor example you should be able to reproduce by doing:\r\n```java\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\n\r\ndf = pd.DataFrame(np.random.rand(100, 10000))\r\ntable = pa.Table.from_pandas(df)\r\npq.write_table(table, \"temp.parquet\")\r\n\r\n%timeit pd.read_parquet(\"temp.parquet\")\n```\r\nIn version 0.17.0, this takes about 300-400 ms and for anything above and including 1.0.0, this suddenly takes around 2 seconds.\r\n\r\n\u00a0\r\n\r\nThanks for looking into this.",
        "created_at": "2021-02-02T09:08:28.000Z",
        "updated_at": "2021-05-14T14:59:00.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-02-02T16:26:52.785Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17277261) by Joris Van den Bossche (jorisvandenbossche):*\n`[~Axelg1]` Thanks for the report\r\n\r\nWe have had similar issues in the past (eg ARROW-9924, ARROW-9827), but it seems that some things deteriorated again. \r\n\r\nSo as a temporary workaround, you can specify `use_legacy_dataset=True` to use the old code path (another alternative is using the single-file `pq.ParquetFile` interface, this will never have overhead for dealing with potentially more complicated datasets).\r\n\r\ncc `[~bkietz]` There seems to be a lot of overhead being spent in the projection (`RecordBatchProjector`, and specifically `SetInputSchema`, `CheckProjectable`, `FieldRef` finding, see the attached profile [profile_wide300.svg](profile_wide300.svg) ), while in this case there is actually no projection happening.   \r\n\r\n\r\n"
        },
        {
            "created_at": "2021-05-03T21:32:32.818Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17338622) by Elena Henderson (elena@ursacomputing.com):*\nPerformance of reading wide dataframes degraded further in pyarrow 4.0.0:\r\n\r\n<https://conbench.ursa.dev/compare/runs/afbbfc387b314fb6886168225c29d3af...c30d6d188bc24aa2b319808446b8d0aa/>\r\n\r\n<https://conbench.ursa.dev/compare/runs/87781efdd9f940098f91cc8b50a32ca1...a54fde45cfa2406bab2ff0f5080f274d/>\r\n\r\n\u00a0\r\n\r\nBaseline = pyarrow 3.0.0\r\n\r\nContender = pyarrow 4.0.0\r\n\r\n\u00a0\r\n\r\n![image-2021-05-03-14-39-59-485.png](https://issues.apache.org/jira/secure/attachment/13024943/image-2021-05-03-14-39-59-485.png)\r\n\r\n\u00a0\r\n\r\nWe tracked down regression to this commit:\u00a0<https://github.com/apache/arrow/commit/c5c583b5d4290563332c653a0084c666ef232f0c>\u00a0\r\n\r\n<https://conbench.ursa.dev/compare/runs/d731c9100c6190566354a83dee2239ddb7be21d6...c5c583b5d4290563332c653a0084c666ef232f0c/>\r\n\r\n\u00a0\r\n\r\nBaseline = <https://github.com/apache/arrow/commit/d731c9100c6190566354a83dee2239ddb7be21d6>\r\n\r\nContender =\u00a0<https://github.com/apache/arrow/commit/c5c583b5d4290563332c653a0084c666ef232f0c>\u00a0\r\n\r\n\u00a0\r\n\r\n![image-2021-05-03-14-40-09-520.png](https://issues.apache.org/jira/secure/attachment/13024942/image-2021-05-03-14-40-09-520.png)\r\n\r\n\u00a0\r\n\r\ncc `[~bkietz]` `[~npr]` `[~dianaclarke]` `[~westonpace]`"
        },
        {
            "created_at": "2021-05-11T15:06:41.344Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17342631) by David Li (lidavidm):*\nI took a quick stab and looked with a profiler.\r\n\r\nTL;DR we're doing two things quadratically (copying shared_ptrs and looking up fields). This is the bulk of the runtime - not any actual computation!\r\n\r\nI tested a Parquet file with 10000 columns, 10000 rows, using the read options `use_threads=True, memory_map=True`.\r\n\r\nPyArrow 0.17, conda-forge: consistently ~550ms\r\nmaster 5.0.0: consistently ~5000-5500ms\r\n\r\nProfiler: <https://share.firefox.dev/3bffpI3>\r\n\r\nThe time spent falls in 3 buckets:\r\n1. ScanTask::SafeExecute takes ~500ms. This is actually reading the data - everything seems fine here.\n1. SetProjection takes ~1000ms. \n   \n   SetProjection takes each column and looks it up in the schema with FieldRef::GetOne. The lookup guards against duplicate field names, hence, it's iterating every column on each lookup - a quadratic operation. This is ~500ms of the runtime. Then, when we bind the projection, the same thing happens again - this is the other half. Most of the leaf time is spent in std::operator==<char>, i.e. in comparing column names.\n1. ProjectSingleBatch takes ~3300ms.\n   \n   Most of the time ends up in GetDatumField, which is yet again a lookup. Of the time herein, FieldRef::FindOneOrNone takes 730ms - this is the same problem as before (quadratic lookup). The method is sufficiently generic that we can't necessarily assume the field indices are the same (or can we?).\n   \n   The bulk of the remaining time - 2530ms - is in FieldPathGetDatumImpl which boils down to FieldPath::Get. This boils down to shared_ptr operations in SimpleRecordBatch::column_data (which is just a getter returning a vector<shared_ptr<ArrayData>>) - likely, since we're doing this once per field per record batch, we're creating a copy of 10000 shared_ptrs on every iteration!\n   \n   \n   \n   I tried two optimizations - if we make a simple lookup table in SetProjection, we can shave off those 500ms. (This will be harder if/when we support nested field refs.) And if we add a SimpleRecordBatch::column_data_ref which returns an const ArrayDataVector&, then we can shave about 2500ms off the runtime. Profile after making these changes: <https://share.firefox.dev/3tHsT5U>\n   \n   The rest of the time is in Bind/FindAll. We could probably eliminate or lessen this. We could add index-based field refs; this would make things much less flexible though. Or we could add careful use of lookup tables, e.g. lazily construct one on Schema. Since presumably all batches from a fragment share the same underlying schema, this would help a lot. (However, once we get beyond simple projections, preserving that property will be difficult.)\n   \n   The change to column_data is a very easy win and shouldn't pessimize any existing path (the implementation already operates on a vector& - so it was making a pointless copy), so I'll submit that as a PR while we decide what to do about the rest."
        },
        {
            "created_at": "2021-05-11T21:08:02.086Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17342868) by David Li (lidavidm):*\nAnd just to confirm, adding a cache of FieldRef->FieldPath lookups to projection trims another ~400ms off the runtime; at that point, the remaining overhead is in Expression::Bind (for which a similar cache would suffice), and in little things like (apparently) creating/moving/destroying futures that could then be tackled.\r\n\r\nProfile: <https://share.firefox.dev/3hhGBKj> \r\n (You can see the aforementioned Future overhead in `parquet::arrow::(anonymous namespace)::FileReaderImpl::GetRecordBatchReader`)"
        },
        {
            "created_at": "2021-05-12T19:09:39.279Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17343494) by David Li (lidavidm):*\nFinally, adding passing a fieldref-to-fieldpath cache to Bind() knocks out most of the rest of the slowdown, with the final result being 0.6s for a scan using Arrow 0.17 and 0.8s for the patched version here. (Note that master with use_legacy_dataset=True also takes about 0.8s so the difference may be in the Parquet reader itself.) Profile: <https://share.firefox.dev/33CGu3N>\r\n\r\n`[~bkietz]` what do you think about optionally passing an\u00a0`unordered_map<FieldRef, FieldPath>` cache to `ExecuteScalarExpression` and `Expression::Bind`? The invariant would have to be that the cache is not used with a schema that has the same fields but in a different order. However, I think we can maintain this easily enough, so long as we assume that all batches from the same fragment have the same schema. We can construct the cache when we start scanning a given fragment and isolate it to that fragment only. We could then visit the schema once to build the cache instead of visiting every field on every fieldref lookup.\r\n\r\n(Also note that filtering is untested here and may benefit from this optimization too, and I didn't try the async scanner.)"
        },
        {
            "created_at": "2021-05-14T13:16:03.860Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17344583) by David Li (lidavidm):*\nConbench does validate that the fix already committed improves runtime (it takes about 1/2 the time it did before): <https://conbench.ursa.dev/compare/batches/a74b919eba6a41288169b7637cd37ba2...4f26dd7a80004373b3afaff5853b0718/>"
        },
        {
            "created_at": "2021-05-14T13:35:07.389Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17344597) by Joris Van den Bossche (jorisvandenbossche):*\nThanks for those analyses!\r\n\r\nSomething else I am wondering: in this specific case, there is actually no projection to be done. Would it be worth to also add a special case for this, assuming that checking the exact equality of schemas is faster than reprojecting the batch to the same schema (although for many column, checking schema equality might also be slow?)"
        },
        {
            "created_at": "2021-05-14T13:42:44.749Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17344604) by David Li (lidavidm):*\nI also thought about that and am of two minds. This case (no projection, or perhaps only column selection) is presumably a very common case and could warrant some special treatment to ensure it's consistently fast, and of course doing no work is much better than doing work quickly. But if some relatively simple optimizations would help in all cases, then I think that's worth pursuing over a special case.\r\n\r\nMaybe it'd be worth benchmarking to ensure the optimizations here are enough of a speedup and don't slow down other cases (narrow schemas, selecting only a few columns, actual projections, etc.) and that'd both let us know about potential future regressions and help us decide if it's worth it.\r\n\r\nAs for schema equality, if we do special-case things: as with the optimizations described here, I think if we can assume that within a fragment, all batches will have the same schema, then that should reduce the overhead of checking schemas considerably since it'll be only O(fragments) (and, could be pipelined with other work)."
        },
        {
            "created_at": "2021-05-14T14:54:07.129Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17344639) by Neal Richardson (npr):*\nForgive me if I'm missing what the actual problem is, but would a solution be to solve this case (no projection, or perhaps only column selection) in the higher layers (Python, R, etc.)? ScannerBuilder->Project can either take a vector of Expressions or a vector of string column names. Python/R could choose to Project with strings if it is only selecting columns and not modifying/deriving anything (and not Project at all if selecting everything). "
        },
        {
            "created_at": "2021-05-14T14:59:00.165Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11469?focusedCommentId=17344643) by David Li (lidavidm):*\nUnfortunately no, projection is always 'active'; even if you don't set any projection, the Scanner sets a projection (of all columns using string names), which all ultimately flows through the same paths in C+. Of course, it could special-case that, but it'd be in C+."
        }
    ]
}