{
    "issue": {
        "title": "[Python] pyarrow hdfs reader overrequests  ",
        "body": "***Note**: This issue was originally created as [ARROW-5318](https://issues.apache.org/jira/browse/ARROW-5318). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI am using pyarrow's HdfsFilesystem interface. When I call a read on n bytes, I often get 0%-300% more data sent over the network. My suspicion is that pyarrow is reading ahead.\r\n\r\nThe pyarrow parquet reader doesn't have this behavior, and I am looking for a way to turn off read ahead for the general HDFS interface.\r\n\r\nI am running on ubuntu 14.04. This issue is present in pyarrow 0.10 - 0.13 (newest released version). I am on python 2.7\r\n\r\nI have been using wireshark to track the packets passed on the network.\r\n\r\nI suspect it is read ahead since the time for the 1st read is much greater than the time for 2nd read.\r\n\r\n\u00a0\r\n\r\nThe regular pyarrow reader\r\n```java\n\r\nimport pyarrow as pa \r\nfs = pa.hdfs.connect(hostname, driver='libhdfs') \r\nfile_path = 'dataset/train/piece0000' \r\nf = fs.open(file_path) \r\nf.seek(0) \r\nn_bytes = 3000000 \r\nf.read(n_bytes)\r\n```\r\n\u00a0\r\n\r\nParquet code without the same issue\r\n```java\n\r\nparquet_file = 'dataset/train/parquet/part-22e3' \r\npf = fs.open(parquet_path) \r\npqf = pa.parquet.ParquetFile(pf)\r\ndata = pqf.read_row_group(0, columns=['col_name'])\r\n\u00a0\n```\r\n\u00a0\r\n\r\n\u00a0",
        "created_at": "2019-05-14T19:08:56.000Z",
        "updated_at": "2022-08-27T14:41:52.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-06-27T06:36:00.000Z"
    },
    "comments": [
        {
            "created_at": "2019-05-14T19:13:36.935Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5318?focusedCommentId=16839714) by Ivan Dimitrov (dimitrov):*\nMaybe this is some eager caching?"
        },
        {
            "created_at": "2019-05-15T18:36:28.291Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5318?focusedCommentId=16840647) by Ivan Dimitrov (dimitrov):*\n@[pitrou](https://github.com/apache/arrow/commits?author=pitrou)\u00a0any thoughts"
        },
        {
            "created_at": "2019-05-16T21:20:16.196Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5318?focusedCommentId=16841732) by Ivan Dimitrov (dimitrov):*\n`[~wesmckinn]` Hey thanks for responding on stack overflow (<https://stackoverflow.com/questions/56176192/pyarrow-hdfs-reads-more-data-than-requested>)\u00a0\r\n\r\n\u00a0\r\n\r\nDo you have any ideas on what I should explore\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2019-05-17T22:14:15.162Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5318?focusedCommentId=16842663) by Ivan Dimitrov (dimitrov):*\nUpdate on the ticket.\r\n\r\nWhen using pyhdfs (a wrapper for webhdfs), I am able to specify the length I want to read in the `open` function. (<https://github.com/jingw/pyhdfs>). This prevents over-reading, unfortunately, webhdfs is probably too slow for my use case.\u00a0"
        },
        {
            "created_at": "2019-05-22T18:12:28.431Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5318?focusedCommentId=16846106) by Ivan Dimitrov (dimitrov):*\nTicket Resolution:\u00a0\r\n\r\nThe culprit was caching.\u00a0The driver has functionality for pread that isn't exposed in the pyarrow api. The solution is to add a method for NativeFile to read_at at a specific offset. The function will make an underlying pread call that does not cache.\u00a0"
        },
        {
            "created_at": "2019-05-28T22:10:51.724Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5318?focusedCommentId=16850190) by Ivan Dimitrov (dimitrov):*\nResolution at\u00a0https://issues.apache.org/jira/browse/ARROW-5432"
        },
        {
            "created_at": "2022-08-27T14:41:52.457Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5318?focusedCommentId=17585898) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}