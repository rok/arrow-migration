{
    "issue": {
        "title": "Arrow-Parquet c++ - Parquet files show inconsistent data ",
        "body": "***Note**: This issue was originally created as [ARROW-17453](https://issues.apache.org/jira/browse/ARROW-17453). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nFiles generated from Athena using Iceberg and read via arrow-parquet c++ show inconsistent data, with row information missing.\u00a0\r\n\r\nTo repro, create athena iceberg table with parquet as below.\u00a0\r\n\r\n\r\n\r\n\u00a0\r\n```java\n\r\ncreate table datatypes_helper (d_int1 int, d_bigint1 bigint, d_float1 float, d_double1 double, d_decimal38_0_1 decimal(38,0), d_decimal19_10_1 decimal(19,10), d_date1 date, d_timestamp1 timestamp, d_string1 string, d_binary1 binary, d_decimal1 decimal, d_array1 array<string>, d_map1 map<string, int>)\r\nLOCATION 's3:/'\u00a0\r\nTBLPROPERTIES (\r\n\u00a0 'table_type'='ICEBERG',\r\n\u00a0 'format'='parquet'\r\n);\r\ninsert into \u00a0datatypes_helper VALUES (11, CAST(11 as bigint), CAST(12.222222222100001 as real), 12.222222222222223, cast(11.0 as decimal(38,0)), cast(12.358024679 as decimal(19,10)), date('2022-01-12'), timestamp '2022-03-31 18:53:43', cast('IX1KNXR6KPF' as varchar), cast(X'0000011100' as varbinary), cast(11 as decimal(10,0)), array[cast('11' as varchar), cast('11' as varchar)], map(array[cast('rowNum' as varchar)], array[CAST(11 AS INT)]));\r\ninsert into \u00a0datatypes_helper VALUES (12, CAST(12 as bigint), CAST(13.3333333332 as real), 13.333333333333334, cast(12.0 as decimal(38,0)), cast(13.481481468 as decimal(19,10)), date('2022-01-13'), timestamp '2022-03-31 18:53:43', cast('WDJC5KD74I0B' as varchar), cast(X'000101111100' as varbinary), cast(12 as decimal(10,0)), array[cast('12' as varchar), cast('12' as varchar)], map(array[cast('rowNum' as varchar)], array[CAST(12 AS INT)]));\r\ninsert into \u00a0datatypes_helper VALUES (13, CAST(13 as bigint), CAST(14.4444444443 as real), 14.444444444444445, cast(13.0 as decimal(38,0)), cast(14.604938257 as decimal(19,10)), date('2022-01-14'), timestamp '2022-03-31 18:53:43', cast('Y8S9T7QOIWPS0' as varchar), cast(X'110011111110' as varbinary), cast(13 as decimal(10,0)), \u00a0array[cast('13' as varchar), cast('13' as varchar)], map(array[cast('rowNum' as varchar)], array[CAST(13 AS INT)]));\r\ninsert into \u00a0datatypes_helper(d_int1) VALUES (null);\r\ncreate table datatypes (d_int1 int, d_bigint1 bigint, d_float1 float, d_double1 double, d_decimal38_0_1 decimal(38,0), d_decimal19_10_1 decimal(19,10), d_date1 date, d_timestamp1 timestamp, d_string1 string, d_binary1 binary, d_decimal1 decimal, d_array1 array<string>, d_map1 map<string, int>)\r\nLOCATION 's3://'\u00a0\r\nTBLPROPERTIES (\r\n\u00a0 'table_type'='ICEBERG',\r\n\u00a0 'format'='parquet'\r\n\u00a0 );\r\ninsert into \u00a0datatypes select * from datatypes_helper;\r\n\u00a0\r\n```\r\n\r\nThe above inserts 4 rows. However querying the data using pyarrow return only 2 rows for some columns. Others parquet tools (parquet-tools-mr do not show this behavior)\r\n\r\n``\r\n```java\n\r\n>>> parquet_file.read_row_group(0)\r\npyarrow.Table\r\nd_int1: int32\r\nd_bigint1: int64\r\nd_float1: float\r\nd_double1: double\r\nd_decimal38_0_1: decimal128(38, 0)\r\nd_decimal19_10_1: decimal128(19, 10)\r\nd_date1: date32[day]\r\nd_timestamp1: timestamp[us]\r\nd_string1: string\r\nd_binary1: binary\r\nd_decimal1: decimal128(10, 0)\r\nd_array1: list<element: string>\r\n\u00a0 child 0, element: string\r\nd_map1: map<string, int32 ('d_map1')>\r\n\u00a0 child 0, d_map1: struct<key: string not null, value: int32> not null\r\n\u00a0 \u00a0 \u00a0 child 0, key: string not null\r\n\u00a0 \u00a0 \u00a0 child 1, value: int32\r\n----\r\nd_int1: [[12,11,null,null]]\r\nd_bigint1: [[12,11,null,null]]\r\nd_float1: [[13.333333,12.222222,null,null]]\r\nd_double1: [[13.333333333333334,12.222222222222223,null,null]]\r\nd_decimal38_0_1: [[12,11,null,null]]\r\nd_decimal19_10_1: [[13.4814814680,12.3580246790,null,null]]\r\nd_date1: [[2022-01-13,2022-01-12,null,null]]\r\nd_timestamp1: [[2022-03-31 18:53:43.000000,2022-03-31 18:53:43.000000,null,null]]\r\nd_string1: [[\"WDJC5KD74I0B\",\"IX1KNXR6KPF\",null,null]]\r\nd_binary1: [[000101111100,0000011100,null,null]]\n```\r\nThe parquet file queried is attached to the JIRA.\u00a0",
        "created_at": "2022-08-17T18:45:30.000Z",
        "updated_at": "2022-08-26T22:51:50.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Go",
            "Component: Parquet",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-08-26T20:54:30.000Z"
    },
    "comments": [
        {
            "created_at": "2022-08-26T14:54:36.110Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17453?focusedCommentId=17585430) by Matthew Topol (zeroshade):*\nThe Go library is also exhibiting this issue, I'll take a look and see if i can pinpoint the issue seeing as the Go impl is based on the C++ impl anyways."
        },
        {
            "created_at": "2022-08-26T15:53:50.257Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17453?focusedCommentId=17585470) by Matthew Topol (zeroshade):*\nI've Identified the issue and am creating a PR for the fix."
        },
        {
            "created_at": "2022-08-26T20:54:30.638Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17453?focusedCommentId=17585615) by Matthew Topol (zeroshade):*\nIssue resolved by pull request 13982\n<https://github.com/apache/arrow/pull/13982>"
        }
    ]
}