{
    "issue": {
        "title": "C++: Logical chunked arrays / columns: conforming to fixed chunk sizes",
        "body": "***Note**: This issue was originally created as [ARROW-39](https://issues.apache.org/jira/browse/ARROW-39). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nImplementing algorithms on large arrays assembled in physical chunks is problematic if:\n\n- The chunks are not all the same size (except possibly the last chunk, which can be less). Otherwise, retrieving a particular element is in general a O(log num_chunks) operation\n\n- The chunk size is not a power of 2. Computing integer modulus with a non-multiple of 2 requires more clock cycles (in other words, `i % p` is much more expensive to compute than `i & (p - 1)`, but the latter only works if p is a power of 2)\n\nMost of the Arrow data adapters will either feature contiguous data (1 chunk, so chunking is not an issue) or a regular chunk size, so this isn't as much of an immediate concern, but we should consider making it a contract of any data structures dealing in multiple arrays. \n\nIn general, it would be preferable to reorganize memory into either a regular chunksize (like 64K values per chunk) or a contiguous memory region. I would prefer for the moment to not to invest significant energy in writing algorithms for data with irregular chunk sizes. ",
        "created_at": "2016-03-04T22:55:29.000Z",
        "updated_at": "2022-08-27T14:41:42.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2017-03-22T21:03:41.000Z",
        "milestone": 28
    },
    "comments": [
        {
            "created_at": "2016-04-08T05:46:42.832Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-39?focusedCommentId=15231675) by Jacques Nadeau (jnadeau):*\nCan you expound here? I'm not sure what you mean by \"chunk\". If you're speaking about batches of records, I don't think fixed record batch sizes should be a requirement."
        },
        {
            "created_at": "2016-04-08T14:56:36.843Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-39?focusedCommentId=15232285) by Wes McKinney (wesm):*\nThis JIRA isn't about IPC; this is about writing in-memory algorithms for manipulating tables consisting of multiple chunks (multiple record batches). For example: performing a merge-sort in-memory on a table consisting of many row batches. The only point here was that, computationally, there's probably not much benefit in implementing algorithms that deal with tables with irregular chunk sizes (where random access in general requires a binary search) or chunk sizes that are not a power of two (since arithmetic with non-powers-of-2 requires a lot more CPU cycles).\n\nThe context for this JIRA originally was this data structure: https://github.com/apache/arrow/blob/master/cpp/src/arrow/column.h#L37\n\nIt's fine as a data container, but as soon as you start writing analytics (think: pandas, dplyr, and things like that) these things become a problem. "
        },
        {
            "created_at": "2016-04-08T20:09:59.554Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-39?focusedCommentId=15232838) by Kai Zheng (drankye):*\nThe rational makes sense. A general chunk in the current codes can be there, and we can add to have `FixedChunkedArray` of chunks of regular chunk size (32k, 64k and etc.)? For fixed size chunk, we need to ensure its unused buffer region allocated for the size to be clear."
        },
        {
            "created_at": "2017-03-22T21:03:41.137Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-39?focusedCommentId=15937119) by Wes McKinney (wesm):*\nThis is an application-level concern that's out of scope for Arrow for the moment, and applications utilizing chunked arrays will have various requirements that may make a general solution difficult."
        },
        {
            "created_at": "2022-08-27T14:41:42.527Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-39?focusedCommentId=17585797) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}