{
    "issue": {
        "title": "[Python] Allow HDFS FileSystem to be created without Hadoop present",
        "body": "***Note**: This issue was originally created as [ARROW-7486](https://issues.apache.org/jira/browse/ARROW-7486). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI would like to be able to construct an HDFS FileSystem object on a machine without Hadoop installed.  I don't need it to be able to actually do anything.  I just need creating it to not fail.\r\n\r\nThis would enable Dask users to run computations on an HDFS enabled cluster from outside of that cluster.  This almost works today.  We send a small computation to a worker (which has HDFS access) to generate the task graph for loading data, and then we bring that task graph back to the local machine, continue building on it, and then finally submit everything off to the workers for execution.\r\n\r\nThe flaw here is when we bring back the task graph from the worker back to the client.  It contains a reference to a PyArrow HDFSFileSystem object, which upon de-serialization calls _maybe_set_hadoop_classpath().  I suspect that if this was allowed to fail that things would work out ok for us.  \r\n\r\nDownstream issue originally reported here: https://github.com/dask/dask/issues/5758",
        "created_at": "2019-12-31T22:17:17.000Z",
        "updated_at": "2021-05-12T17:17:44.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-01-07T18:43:38.951Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7486?focusedCommentId=17009967) by Wes McKinney (wesm):*\nSeems reasonable, this is likely not that difficult to fix"
        },
        {
            "created_at": "2020-01-23T21:46:05.194Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7486?focusedCommentId=17022526) by Ben Schreck (bschreck):*\n`[~wesm]` \u00a0Any updates on this? If you provide me with some direction I may be able to submit a PR"
        },
        {
            "created_at": "2020-01-27T05:13:07.362Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7486?focusedCommentId=17024086) by Wes McKinney (wesm):*\nYou will have to alter the implementation to lazily connect to HDFS (i.e. invoking the code in `__init__` on the first actual filesystem operation) rather than eagerly like it does now. \r\n\r\nhttps://github.com/apache/arrow/blob/master/python/pyarrow/hdfs.py#L35\r\n\r\n`[~kszucs]` do you have further advice about this since you have worked on the HDFS code more recently than I have?"
        },
        {
            "created_at": "2021-05-12T17:17:44.888Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7486?focusedCommentId=17343378) by Antoine Pitrou (apitrou):*\n`[~mrocklin]` Is this desirable on your side?"
        }
    ]
}