{
    "issue": {
        "title": "[Python] Allow custom reader/writer implementation for arrow dataset read/write path",
        "body": "***Note**: This issue was originally created as [ARROW-18275](https://issues.apache.org/jira/browse/ARROW-18275). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWe're implementing a \"versionable\" data format where the read/write path has some metadata handling which we currently can't plug into the native pyarrow write_dataset and pa.dataset.dataset mechanism.\r\n\r\nWhat we've done currently is have our own `lance.write_dataset` and `lance.dataset` interfaces which knows about the versioning. And if you use the native arrow ones, it reads/writes an unversioned dataset.\r\n\r\nIt would be great if:\r\n\r\n1. the arrow interfaces provided a way for custom data formats to provide their own Arrow compliant reader/writer implementations, so we can delete our custom interface and stick with native pyarrow interface.\r\n\r\n2. the pyarrow interface can support custom kwargs like \"version=5\" or \"as_of=<timestamp>\" or \"version='latest'\"\r\n\r\nfor reference, this is what our custom C++ dataset implementation looks like: https://github.com/eto-ai/lance/blob/main/cpp/include/lance/arrow/dataset.h",
        "created_at": "2022-11-07T20:41:42.000Z",
        "updated_at": "2022-11-14T17:52:59.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-11-14T11:10:27.396Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-18275?focusedCommentId=17633701) by Miles Granger (milesgranger):*\nDoes this overlap with [ARROW-18163 \\| https://issues.apache.org/jira/browse/ARROW-18163]?  To me it sounds like if that were implemented, this could be accomplished by the implementation of the custom dataset format?"
        },
        {
            "created_at": "2022-11-14T16:14:00.022Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-18275?focusedCommentId=17633917) by Chang She (changhiskhan):*\nYeah, it would largely be sufficient. I created this issue after some\nprevious discussions with Weston. For example, when I created ARROW-18275,\nI was not aware that Dataset wasn\u2019t meant to be an extension point.\n\nBut basically, the goal is the same:\n\n1. Custom formats can tell pa.dataset.dataset to use the correct FileFormat\nbased on the filename / extension (instead of requiring the user to pass a\ncustom FileFormat subclass instance every time).\n\n2. Custom formats can provide custom read/write behavior to handle:\n- more complex metadata (eg versioning)\n- more complex scan options (eg offset, limit)\n- (planned) indexes\n\nCurrently we\u2019ve extended Arrow FilesystemDataset/Scanner in C++ then\nwrapped it in a custom cython class inheriting from pyarrow Dataset so the\nresulting user API is still fully Arrow compatible \u2014 but the user has to do\n\u201clance.dataset\u201d and \u201clance.write_dataset\u201d instead of just being able to go\nthrough native pyarrow APIs.\n\nThanks!\n\nOn Mon, Nov 14, 2022 at 3:11 AM Miles Granger (Jira) <jira@apache.org>\n\n"
        },
        {
            "created_at": "2022-11-14T17:52:59.752Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-18275?focusedCommentId=17633977) by Weston Pace (westonpace):*\n> 1. Custom formats can tell pa.dataset.dataset to use the correct FileFormat\n> based on the filename / extension (instead of requiring the user to pass a\n> custom FileFormat subclass instance every time).\r\n\r\nWe might be able to do this by creating a \"ExtensionGuessingFileFormat\" which could be the new default.  It would construct the appropriate formats as needed and delegate work to them.  It could even perhaps take a map from extension to format.  This way, if users did need to fine-tune the formats (e.g. specify a custom delimiter for CSV) it would still be possible.\r\n\r\n"
        }
    ]
}