{
    "issue": {
        "title": "[proposal] Arrow Intermediate Representation to facilitate the transformation of row-oriented data sources into Arrow columnar representation",
        "body": "***Note**: This issue was originally created as [ARROW-17220](https://issues.apache.org/jira/browse/ARROW-17220). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIn the context of this [OTEP](https://github.com/lquerel/oteps/blob/main/text/0156-columnar-encoding.md) (OpenTelemetry Enhancement Proposal) I developed an integration layer on top of Apache Arrow (Go and Rust) to {**}facilitate the translation of row-oriented data stream into an arrow-based columnar representation{**}. In this particular case the goal was to translate all OpenTelemetry entities (metrics, logs, or traces) into Apache Arrow records. These entities can be quite complex and their corresponding Arrow schema must be defined on the fly. IMO, this approach is not specific to my particular needs but could be used in many other contexts where there is a need to simplify the integration between a row-oriented source of data and Apache Arrow. The trade-off is to have to perform the additional step of conversion to the intermediate representation, but this transformation does not require to understand the arcana of the Arrow format and allows to potentially benefit from functionalities such as the encoding of the dictionary \"for free\", the automatic generation of Arrow schemas, the batching, the multi-column sorting, etc.\u00a0\r\n\r\nI know that JSON can be used as a kind of intermediate representation in the context of Arrow. I think current JSON integrations are insufficient to cover the most complex scenarios; e.g. support for most of the Arrow data type, various optimizations (string|binary dictionaries, multi-column sorting), batching, integration with Arrow IPC, compression ratio optimization, ... The object of this proposal is to progressively cover these gaps.\r\n\r\nI am looking to see if the community would be interested in such a contribution. Below are some additional details on the current implementation. All feedback is welcome.\r\n\r\n10K ft overview of the current implementation:\r\n1. Developers convert their row oriented stream into records based on the Arrow Intermediate Representation (AIR). At this stage the translation can be quite mechanical but if needed developers can decide for example to translate a map into a struct if that makes sense for them. The current implementation support the following arrow data types: bool, all uints, all ints, all floats, string, binary, list of any supported types, and struct of any supported types. Additional Arrow types could be added progressively.\n1. The row oriented record (i.e. AIR record) is then added to a RecordRepository. This repository will first compute a schema signature and will route the record to a RecordBatcher based on this signature.\n1. The RecordBatcher is responsible for collecting all the compatible AIR records and, upon request, the \"batcher\" is able to build an Arrow Record representing a batch of compatible inputs. In the current implementation, the batcher is able to convert string columns to dictionary based on a configuration. Another configuration allows to evaluate which columns should be sorted to optimize the compression ratio. The same optimization process could be applied to binary columns.\n1. Steps 1 through 3 can be repeated on the same RecordRepository instance to build new sets of arrow record batches. Subsequent iterations will be slightly faster due to different techniques used (e.g. object reuse, dictionary reuse and sorting, ...)\n   \n   The current [Go implementation](https://github.com/lquerel/otel-arrow-adapter)\u00a0(WIP) is currently part of this repo (see pkg/air package). If the community is interested, I could do a PR in the Arrow Go and Rust sub-projects.\n   \n   \u00a0\n   \n   EDIT 1: updated the original description based on David Li's feedback\n   \n   EDIT 2: A conversation on this topic is ongoing on the dev mailing list (see this [thread](https://lists.apache.org/thread/b3nt8kzfonnjy0hcxrlm1phcfxogqygl)).",
        "created_at": "2022-07-26T19:31:43.000Z",
        "updated_at": "2022-07-28T19:08:08.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Integration",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-07-26T20:38:12.432Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17220?focusedCommentId=17571610) by David Li (lidavidm):*\nI haven't read through everything yet, but there was also some likely related discussion on the C++ side about row conversions and whether there is something more general to pull out: https://github.com/apache/arrow/pull/12775 So this comes at a great time.\r\n\r\nI suppose the tradeoff here is having to take the extra step of converting to the intermediate representation, but potentially being able to get features like dictionary encoding \"for free\", transfer rows between systems, etc.? Is this an in-memory/library-level convenience, or a formal format that might eventually be serialized, etc.? Is there a link to the AIR implementation itself (looks like <https://github.com/lquerel/otel-arrow-adapter>)?\r\n\r\nI don't think there is a real Arrow/JSON encoding in any case. There's support for parsing JSONL in the C++ library, but that doesn't deal with the full range of Arrow types, schemas, etc. There's a semi-consistent JSON format for integration test data, but it's columnar and not intended for outside consumption. And the C+\\+ library has another testing-only format for quickly embedding test data into source code, but that's also not meant for outside usage.\r\n\r\nFinally, you may want to email [dev@](https://arrow.apache.org/community/) to get some more attention here. "
        },
        {
            "created_at": "2022-07-26T20:58:04.644Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17220?focusedCommentId=17571616) by Laurent Querel (lquerel):*\nThanks for this fast feedback.\u00a0\r\n\r\nI will take a look at the PR 12775.\r\n\r\nRegarding the go implementation you found the right link (see air package), the Rust implementation is currently a private repo.\u00a0\r\n\r\nBased on your advice I will send an email to dev@."
        }
    ]
}