{
    "issue": {
        "title": "[Python] Overriding Parquet schema when loading to SageMaker to inspect bad data",
        "body": "***Note**: This issue was originally created as [ARROW-10862](https://issues.apache.org/jira/browse/ARROW-10862). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nFollowing SO post: <https://stackoverflow.com/questions/53725691/pyarrow-lib-schema-vs-pyarrow-parquet-schema>\r\n\r\nI am attempting to find a way to override a parquet schema for a parquet file stored in S3. One date column has some bad dates which causes the load of the entire parquet file to fail.\r\n\r\nI have tried defining a schema, but get AttributeError: 'pyarrow.lib.schema' object has no attribute 'to_arrow_schema'. Same error as in SO post above,\r\n\r\nI have attempted to use the workaround suggested by Wes McKinney above by creating a dummy df, saving that to parquet, reading the schema from it and replacing the embedded schema in the parquet file with my replacement:\r\n\r\npq.ParquetDataset(my_filepath,filesystem = s3, schema=dummy_schema).read_pandas().to_pandas()\r\n\r\nI get an error message telling me that me schema is different! (It was supposed to be!)\r\n\r\n\u00a0\r\n\r\nCan you either allow schemas to be overridden or, even better, suggest a way to load a Parquet file where some of the dates in a date column are ='0001-01-01'\r\n\r\n\u00a0\r\n\r\nThanks,\r\n\r\nJames Kelly\r\n\r\n\u00a0",
        "created_at": "2020-12-09T12:45:12.000Z",
        "updated_at": "2020-12-22T14:26:36.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-12-10T10:42:40.796Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10862?focusedCommentId=17247158) by Joris Van den Bossche (jorisvandenbossche):*\nHi [~jimmy_ds], thanks for the report. Would you be able to provide a reproducible example? For example, could you share a (subset of) parquet file that shows the issue? Or, provide some code that generates a dummy parquet file that has the same behaviour?\r\n\r\n> Can you either allow schemas to be overridden or, even better, suggest a way to load a Parquet file where some of the dates in a date column are ='0001-01-01'\r\n\r\nCurrently when passing a `schema` to ParquetDataset, this schema is actually (I think) only used to _validate_ that the parquet files indeed have this schema, i.e. as a safety check, and not to be able to \"override\" the schema (and doing this safety check can be controlled by `validate_schema=False`). \r\n\r\nNow, I wondering for your specific case, what is the schema incompatibility precisely? You mention some dates being \"0001-01-01\"? But generally speaking, both parquet and pyarrow should be able to handle such dates:\r\n\r\n```python\n\r\n# workaround to create an array of dates from a string\r\n>>> arr = pa.array([\"0001-01-01\"]).cast(pa.timestamp('s')).cast(pa.date32())\r\n>>> table = pa.table({\"a\": arr})\r\n>>> import pyarrow.parquet as pq\r\n>>> pq.write_table(table, \"test_date.parquet\")\r\n>>> pq.read_metadata(\"test_date.parquet\").schema\r\n<pyarrow._parquet.ParquetSchema object at 0x7ff3f3e90e00>\r\nrequired group field_id=0 schema {\r\n  optional int32 field_id=1 a (Date);\r\n}\r\n>>> pq.read_table(\"test_date.parquet\")\r\npyarrow.Table\r\na: date32[day]\r\n```\r\n\r\n"
        }
    ]
}