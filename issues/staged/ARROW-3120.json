{
    "issue": {
        "title": "[C++] Parallelize execution of ScalarAggregateFunction",
        "body": "***Note**: This issue was originally created as [ARROW-3120](https://issues.apache.org/jira/browse/ARROW-3120). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAfter ARROW-8972, we have a generic chunk-based executor for aggregate functions. It should be relatively straightforward now to parallelize the execution loop of the executor. ",
        "created_at": "2018-08-26T21:47:19.000Z",
        "updated_at": "2021-08-04T12:04:50.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2019-02-11T16:30:26.267Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3120?focusedCommentId=16765129) by Wes McKinney (wesm):*\nRemoved from 0.13. The current Sum kernel implementation is not stateful. I suggest we wait to determine how parallel execution / synchronization will be managed for now (until we have more aggregations implemented, and begin to develop a runtime execution environment)"
        },
        {
            "created_at": "2021-08-04T10:38:31.902Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3120?focusedCommentId=17393014) by Antoine Pitrou (apitrou):*\ncc `[~lidavidm]`. It's still not obvious to me whether parallelization should occur inside the kernel machinery, rather than be orchestrated from the outside."
        },
        {
            "created_at": "2021-08-04T12:04:50.999Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3120?focusedCommentId=17393073) by David Li (lidavidm):*\nWith the current implementations of ExecNodes, it seems we are leaning towards the latter for now (e.g. ScalarAggregateNode manually maintains one state per thread and merges them at the end). That might change if and when we have a work-stealing scheduler as described on the mailing list."
        }
    ]
}