{
    "issue": {
        "title": "[R] Support for HTTPS Filesystem access",
        "body": "***Note**: This issue was originally created as [ARROW-14998](https://issues.apache.org/jira/browse/ARROW-14998). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThanks for such an amazing project. I've been entirely blown away by the S3 Filesystem access in the latest release; and excited to see other backends like Azure being discussed in the issues.\u00a0 As you know, many https clients also permit range requests, meaning (I think) that it should be possible to access public data (parquet, csv files) over generic HTTPS connections too.\r\n\r\nAs you probably know, duckdb already has support for https based remote file access, e.g. [https://github.com/duckdb/duckdb/blob/master/test/sql/copy/parquet/test_parquet_remote.test](https://github.com/duckdb/duckdb/blob/master/test/sql/copy/parquet/test_parquet_remote.test.)\r\n\r\n\u00a0(though it is not available out-of-the-box in the R client there either).\r\n\r\n\u00a0\r\n\r\nIt would be wonderful to have a similar remote filesystem access that could work over HTTPS like that in arrow.\u00a0 (I gather on the python side, fsspec already gives access to a wide number of such abstractions, but we're more limited in R so far, except for the geospatial data, where bindings to GDAL mean we can access GDAL's rather amazing virtual file systems over https, S3, FTP, etc, <https://gdal.org/user/virtual_file_systems.html> \u2013 a nice array-data complement to the more database-oriented workflow of arrow...).\r\n\r\n\u00a0\r\n\r\nThanks for considering!",
        "created_at": "2021-12-06T20:06:36.000Z",
        "updated_at": "2022-10-03T08:17:26.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-12-06T20:39:55.154Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14998?focusedCommentId=17454233) by David Li (lidavidm):*\nThis seems pretty similar to ARROW-7594 - does that sound right to you?"
        },
        {
            "created_at": "2021-12-06T20:48:13.055Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14998?focusedCommentId=17454236) by Carl Boettiger (cboettig):*\nI think so, thanks for sharing the link!\r\n\r\n\u00a0\r\n\r\nReally though it depends how it's implemented!\u00a0 e.g. a comment there notes other libraries in R that can take URLs, but some of these download the data first to /tmp, which isn't really the same thing.\u00a0 I see you already have some nice discussion over in that thread on implementation \u2013 it's a bit over my head, but I think it would be worth comparing notes on how this is done already in other major/widely used projects like duckdb, fsspec, and gdal?"
        },
        {
            "created_at": "2021-12-06T21:12:04.206Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14998?focusedCommentId=17454242) by David Li (lidavidm):*\nThe comment there is only pointing out that there are things in R/Python that are analogous, I think, we would not implement it on top of that. If you have ideas or experience with other systems, it would be much appreciated in the other thread - I'm going to leave this one open for any R-specific things that might need to happen and link them."
        },
        {
            "created_at": "2022-10-03T08:17:26.552Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14998?focusedCommentId=17612210) by Zac Davies (zacdav):*\nThis would be great, as far as I can tell, this is required to access pre-signed S3 URL's as a Dataset without the need to download/sync all files so the Dataset is on the local filesystem."
        }
    ]
}