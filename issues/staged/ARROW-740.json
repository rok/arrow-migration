{
    "issue": {
        "title": "FileReader fails for large objects",
        "body": "***Note**: This issue was originally created as [ARROW-740](https://issues.apache.org/jira/browse/ARROW-740). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nTrying to serialize a large arrow array (around 2\\*\\*30 entries) I get a non-success status when trying to use the FileReader to read the array:\n\n\"Bad status: Invalid: flatbuffer size 0 invalid. File offset: 660, metadata length: 0\"\n\nHow to reproduce:\n\nCheck out the branch arrow-large-objects from https://github.com/pcmoritz/ray-1, and follow http://ray.readthedocs.io/en/latest/install-on-ubuntu.html with that branch.\n\nThen run\n`python test/jenkins_tests/multi_node_tests/large_memory_test.py`\nin the ray root directory.\n\nMost likely there is some int32_t somewhere that overflows, but I haven't been able to track it down. The only int32_ts that are used by the FileReader seem to be for the flatbuffer metadata size, which should be small.\n",
        "created_at": "2017-03-30T01:50:17.000Z",
        "updated_at": "2017-03-30T19:02:50.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2017-03-30T19:02:50.000Z"
    },
    "comments": [
        {
            "created_at": "2017-03-30T01:58:56.252Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-740?focusedCommentId=15948265) by Wes McKinney (wesm):*\nI'm surprised that you were able to write the file, see ARROW-698. "
        },
        {
            "created_at": "2017-03-30T02:16:00.714Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-740?focusedCommentId=15948282) by Wes McKinney (wesm):*\nYou aren't checking the Status of `writer->WriteRecordBatch(*(*batch));` \u2013 it is most likely failing. I'll put up a patch for ARROW-698, but you should set an exception if that fails"
        },
        {
            "created_at": "2017-03-30T03:08:13.226Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-740?focusedCommentId=15948332) by Philipp Moritz (pcmoritz):*\nThanks! You are right, that is the problem. I'm putting in the checks."
        },
        {
            "created_at": "2017-03-30T15:02:27.274Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-740?focusedCommentId=15949239) by Wes McKinney (wesm):*\n`[~pcmoritz]` this should be fixed in master now, you will have to do `writer->WriteRecordBatch(batch, true)` to permit sizes over INT32_MAX"
        },
        {
            "created_at": "2017-03-30T19:02:50.136Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-740?focusedCommentId=15949616) by Wes McKinney (wesm):*\nresolved in https://github.com/apache/arrow/commit/642b753a49a3fcb5d53946c773cd70ab2a3ece88"
        }
    ]
}