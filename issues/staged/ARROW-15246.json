{
    "issue": {
        "title": "[Python] Automatic conversion of low-cardinality string array to Dictionary Array",
        "body": "***Note**: This issue was originally created as [ARROW-15246](https://issues.apache.org/jira/browse/ARROW-15246). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nUsers who convert Pandas string arrays to Arrow arrays may be surprised to see the Arrow ones use far more memory when the cardinality is low. The solution is for them to first convert to a Pandas Categorical, but it might save some headaches if we can automatically (or possibly with an option) detect when it's appropriate to use a Dictionary type over a String type.\r\n\r\nHere's an example of what I'm talking about:\r\n\r\n```python\n\r\nimport pyarrow as pa\r\nimport pandas as pd\r\n\r\nx_str = \"x\" * 30\r\ndf = pd.DataFrame({\"col\": [x_str] * 1_000_000})\r\n\r\n%memit tab1 = pa.Table.from_pandas(df)\r\n# peak memory: 269.44 MiB, increment: 121.62 MiB\r\n\r\ndf['col'] = df['col'].astype('category')\r\n%memit tab2 = pa.Table.from_pandas(df)\r\n# peak memory: 286.14 MiB, increment: 1.20 MiB\r\n```\r\n\r\nOne bad consequence of inferring this automatically is if there is a sequence of Pandas DataFrames that are being converted, it's possible they may end up with differing schemas. For that reason it's likely this behavior should be optional.",
        "created_at": "2022-01-04T19:01:38.000Z",
        "updated_at": "2022-01-04T19:01:38.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": []
}