{
    "issue": {
        "title": "[C++] Make RecordBatch interface virtual to permit record batches that lazy-materialize columns",
        "body": "***Note**: This issue was originally created as [ARROW-1808](https://issues.apache.org/jira/browse/ARROW-1808). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThis should be looked at soon to prevent having to define a different virtual interface for record batches. There are places where we are using the record batch constructor directly, and in some third party code (like MapD), so this might be good to get done for 0.8.0",
        "created_at": "2017-11-14T03:07:53.000Z",
        "updated_at": "2017-11-22T00:17:10.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2017-11-22T00:02:17.000Z"
    },
    "comments": [
        {
            "created_at": "2017-11-14T16:10:49.250Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1808?focusedCommentId=16251621) by Wes McKinney (wesm):*\n`[~kou]` I am going to start looking at this soon, since it may cause a little bit of disruption in the glib bindings. This is a moderately disruptive API change, but long-term it will be for the best. The idea is that the current `arrow::RecordBatch` is a \"simple in-memory record batch\". But the object-boxing requirements to produce a vector of `std::shared_ptr<arrow::ArrayData>` can be quite expensive for large record batches. \r\n\r\nInstead, we could have `arrow::RecordBatch` as an abstract interface with virtual function for column access, with the current incarnation of RecordBatch as a subclass. So we could also create an `arrow::IpcRecordBatch` that does late-materialization of the `arrow::Array` objects. So if you have 1000 columns, you do not pay the cost of creating array objects for all of them if you only end up accessing a few columns in some analytics algorithm"
        },
        {
            "created_at": "2017-11-14T16:16:44.560Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1808?focusedCommentId=16251633) by Wes McKinney (wesm):*\nAn alternative to changing the current `arrow::RecordBatch` implementation is to create a new `arrow::VirtualRecordBatch` class as the base class, but then we would need to change various APIs for classes that return `std::shared_ptr<RecordBatch>` (like the IPC loaders). "
        },
        {
            "created_at": "2017-11-15T07:41:13.425Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1808?focusedCommentId=16253069) by Kouhei Sutou (kou):*\nThanks for notifying it. It's very useful information.\r\nI like your idea. GLib bindings will follow the API changes soon when they are done.\r\n\r\nI'm not sure that the following is related to this topic but I share:\r\n\r\nIt may be useful that we can use arrow::ipc modules such as RecordBatchStreamReader and RecordBatchStreamWriter for RecordBatch on GPU.\r\n"
        },
        {
            "created_at": "2017-11-15T15:54:07.185Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1808?focusedCommentId=16253681) by Wes McKinney (wesm):*\nYes, that would be useful. We should create a separate JIRA about this"
        },
        {
            "created_at": "2017-11-16T05:10:41.082Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1808?focusedCommentId=16254767) by Kouhei Sutou (kou):*\nOK. I created ARROW-1824."
        },
        {
            "created_at": "2017-11-22T00:01:57.016Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1808?focusedCommentId=16261711) by Wes McKinney (wesm):*\nIssue resolved by pull request 1337\n<https://github.com/apache/arrow/pull/1337>"
        }
    ]
}