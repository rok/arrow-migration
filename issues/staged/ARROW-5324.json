{
    "issue": {
        "title": "[Plasma] API requests",
        "body": "***Note**: This issue was originally created as [ARROW-5324](https://issues.apache.org/jira/browse/ARROW-5324). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nCopied from\u00a0<https://github.com/apache/arrow/issues/4318>\u00a0(it's easier to read there, sorry hate Jira formatting)\r\n\r\nRelated to https://issues.apache.org/jira/browse/ARROW-3444\u00a0\r\n\r\nWhile working with the plasma API to create/seal an object for a table, using a custom object-ID, it would help to have a convenience API to get the size of the table.\r\n\r\nThe following code might help to illustrate the request and notes below:\r\n```java\n\r\n    if not parquet_path:\r\n        parquet_path = f\"./data/dataset_{size}.parquet\"\r\n\r\n    if not plasma_path:\r\n        plasma_path = f\"./data/dataset_{size}.plasma\"\r\n\r\n    try:\r\n        plasma_client = plasma.connect(plasma_path)\r\n    except:\r\n        plasma_client = None\r\n\r\n    if plasma_client:\r\n        table_id = plasma.ObjectID(bytes(parquet_path[:20], encoding='utf8'))\r\n        try:\r\n            table = plasma_client.get(table_id, timeout_ms=4000)\r\n            if table.__name__ == 'ObjectNotAvailable':\r\n                raise ValueError('Failed to get plasma object')\r\n        except ValueError:\r\n            table = pq.read_table(parquet_path, use_threads=True)\r\n            plasma_client.create_and_seal(table_id, table)\r\n```\r\n\u00a0\r\n\r\nThe use case is a workflow something like this:\r\n - process-A\r\n \\*\\* generate a pandas DataFrame `df`\r\n \\*\\* save the `df` to parquet, using pyarrow.parquet, with a unique parquet path\r\n \\*\\* (this process will not save directly to plasma)\r\n - process-B\r\n \\*\\* get the data from plasma or load it into plasma from the parquet file\r\n \\*\\* use the unique parquet path to generate a unique object-ID\r\n\r\nNotes:\r\n - `plasma_client.put` for the same data-table is not idempotent, it generates unique object-ID values that are not based on any hash of the data payload, so every put saves a new object-ID; could it use a data hash for idempotent puts? e.g.\r\n - \r\n```java\n\r\nIn : plasma_client.put(table)\r\nObjectID(666625fcb60959d23b6bfc739f88816da29e04d6)\r\nIn : plasma_client.put(table)\r\nObjectID(d2a4662999db30177b090f9fc2bf6b28687d2f8d)\r\nIn : plasma_client.put(table)\r\nObjectID(b2928ad786de2fdb74d374055597f6e7bd97fd61)\r\n\r\nIn : hash(table)\r\nTypeError: unhashable type: 'pyarrow.lib.Table'\n```\r\n\r\n - In process-B, when the data is not already in plasma, it reads data from a parquet file into a pyarrow.Table and then needs an object-ID and the table size to use plasma `client.create_and_seal` but it's not easy to get the table size - this might be related to github issue #2707 (#3444) - it might be ideal if the `client.create_and_seal` accepts responsibility for the size of the object to be created when given a pyarrow data object like a table.\r\n - when the plasma store does not have the object, it could have a default timeout rather than hang indefinitely, and it's a bit clumsy to return an object that is not easily checked with `isinstance` and it could be better to have an exception handling pattern (or something like the requests 404 patterns and options?)",
        "created_at": "2019-05-15T16:07:33.000Z",
        "updated_at": "2021-02-20T03:37:16.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++ - Plasma",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-02-20T03:37:16.000Z"
    },
    "comments": [
        {
            "created_at": "2019-05-15T16:57:25.576Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5324?focusedCommentId=16840569) by Darren Weber (dazza):*\nAn attempt to use unique object-IDs saved in a JSON file bumped into a serializing exception, i.e.\r\n\r\n```\n\r\nTypeError: Object of type ObjectID is not JSON serializable\r\n```\r\n\r\n```python\n\r\n        plasma_objects_file = Path(\"./data/plasma_objects.json\")\r\n        if plasma_objects_file.exists():\r\n            plasma_objects = json.load(plasma_objects_file.read())\r\n        else:\r\n            plasma_objects = {}\r\n\r\n        try:\r\n            table_id = plasma_objects[parquet_path]\r\n            table = plasma_client.get(table_id, timeout_ms=4000)\r\n            if table.__name__ == 'ObjectNotAvailable':\r\n                raise ValueError('Failed to get plasma object')\r\n        except (KeyError, ValueError):\r\n            table = pq.read_table(parquet_path, use_threads=True)\r\n            table_id = plasma_client.put(table)\r\n            plasma_objects[parquet_path] = table_id\r\n            plasma_objects_file.write_text(json.dumps(plasma_objects))\r\n\r\n        df = table.to_pandas()\r\n```\r\n\r\nIt might help if the object-ID has some API enhancements to help with serializing/deserializing it.  While exploring the current object:\r\n\r\n```python\n\r\nipdb> plasma_objects                                                                                                                                              \r\n{'./data/dataset_10.parquet': ObjectID(0ddf993d6b8e2914d9a0ae9a0b4b0eced7397549)}\r\nipdb> table_id                                                                                                                                                    \r\nObjectID(0ddf993d6b8e2914d9a0ae9a0b4b0eced7397549)\r\nipdb> str(table_id)                                                                                                                                               \r\n'ObjectID(0ddf993d6b8e2914d9a0ae9a0b4b0eced7397549)'\r\nipdb> dir(table_id)                                                                                                                                               \r\n['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'binary', 'from_random']\r\nipdb> table_id.binary                                                                                                                                             \r\n<built-in method binary of pyarrow._plasma.ObjectID object at 0x7f1974cbca58>\r\nipdb> table_id.binary()                                                                                                                                           \r\nb'\\r\\xdf\\x99=k\\x8e)\\x14\\xd9\\xa0\\xae\\x9a\\x0bK\\x0e\\xce\\xd79uI'\r\nipdb> table_id.from_random()                                                                                                                                      \r\nObjectID(0434422c7cd08e3c9fafc2ffd3f7234784ec0d49)\r\nipdb> table_id                                                                                                                                                    \r\nObjectID(0ddf993d6b8e2914d9a0ae9a0b4b0eced7397549)\r\nipdb> type(table_id.binary())                                                                                                                                     \r\n<class 'bytes'>\r\nipdb> bytes(table_id)                                                                                                                                             \r\n*** TypeError: cannot convert 'pyarrow._plasma.ObjectID' object to bytes\r\nipdb> interact\r\nIn : b = table_id.binary()\r\nIn : b\r\nb'\\r\\xdf\\x99=k\\x8e)\\x14\\xd9\\xa0\\xae\\x9a\\x0bK\\x0e\\xce\\xd79uI'\r\nIn : plasma.ObjectID\r\n<class 'pyarrow._plasma.ObjectID'>\r\nIn : plasma.ObjectID(b)\r\nObjectID(0ddf993d6b8e2914d9a0ae9a0b4b0eced7397549)\r\n```\r\n\r\nA pickled persistence for mapping parquet-files to object-IDs works OK, e.g. something like:\r\n```python\n\r\n        plasma_objects_file = Path(\"./data/plasma_objects.pickle\")\r\n        if plasma_objects_file.exists():\r\n            with plasma_objects_file.open(mode='rb') as fp:\r\n                plasma_objects = pickle.load(fp)\r\n        else:\r\n            plasma_objects = {}\r\n\r\n        try:\r\n            table_id = plasma.ObjectID(plasma_objects[parquet_path])\r\n            table = plasma_client.get(table_id, timeout_ms=4000)\r\n            if not isinstance(table, pyarrow.lib.Table):\r\n                raise ValueError('Failed to get plasma object')\r\n        except (KeyError, ValueError):\r\n            table = pq.read_table(parquet_path, use_threads=True)\r\n            table_id = plasma_client.put(table)\r\n            plasma_objects[parquet_path] = table_id.binary()\r\n            with plasma_objects_file.open(mode='wb') as fp:\r\n                pickle.dump(plasma_objects, fp)\r\n\r\n        df = table.to_pandas()\r\n```\r\n\r\n"
        }
    ]
}