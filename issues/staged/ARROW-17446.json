{
    "issue": {
        "title": "[R] Allow unrecognized R expressions to be callable as compute::Functions",
        "body": "***Note**: This issue was originally created as [ARROW-17446](https://issues.apache.org/jira/browse/ARROW-17446). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nCurrently, if an R expression is not entirely supported by the arrow compute engine, the entire input will be pulled into memory for native R to operate on. It would be possible to instead provide add a custom compute function to the registry (inside `R_init_arrow`, probably) which evaluates any sub expressions which couldn't be translated to native arrow compute expressions.\r\n\r\nThis would for example allow a filter expression including a call to an R function `baz` to evaluate on a dataset larger than memory and with predicate and projection pushdown as normal using the expressions which **are** translatable. The resulting expression might look something like this in c++:\r\n\r\n```Java\n\r\ncall(\"and_kleene\", {\r\n  call(\"greater\", {field_ref(\"a\"), scalar(1)}),\r\n  call(\"r_expr\", {field_ref(\"b\")},\r\n      /*options=*/RexprOptions{cpp11::function(baz_sexp)}),\r\n});\r\n```\r\n\r\nIn this case although the \"r_expr\" function is opaque to compute and datasets, we would still recognize that only fields \"a\" and \"b\" need to be materialized. Furthermore, the first member of the filter's conjunction is `a > 1`, which **is** translatable and could be used for predicate pushdown, for checking against parquet statistics, etc.\r\n\r\nSince R is not multithreaded, the compute function would need to take a global lock to ensure only a single thread of R execution. This would also block the interpreter, so it's not a high-performance solution... but it **would** block the interpreter less than doing everything in pure native R (since at least **some** of the work could be offloaded to worker threads and we could take advantage of batched input). Still, it seems like a worthwhile option to consider",
        "created_at": "2022-08-17T14:43:20.000Z",
        "updated_at": "2022-08-17T18:48:17.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-08-17T15:18:03.536Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17446?focusedCommentId=17580838) by Drago\u0219 Moldovan-Gr\u00fcnfeld (dragosmg):*\nThis looks very promising, as it would be able to solve cases that won't be handled after we solve ARROW-14071."
        },
        {
            "created_at": "2022-08-17T16:24:34.500Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17446?focusedCommentId=17580869) by Ben Kietzman (bkietz):*\nA difficulty with this approach is currently only scalar functions can be used in a filter, which would mean that we'd need to fallback to pure r if baz() depended on batch order in any way. See also ARROW-12632, ongoing work to support ordering between exec nodes"
        },
        {
            "created_at": "2022-08-17T17:43:59.327Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17446?focusedCommentId=17580910) by Dewey Dunnington (paleolimbot):*\nThis is something like auto-generating a user-defined scalar function in R, correct? (In the same way that Dragos' PR is auto-generating an expression). Another approach is to use the `map_batches(..., .lazy = TRUE)`, which would be slightly less efficient but wouldn't pull everything into memory or do unnecessary conversions from Arrays that aren't used."
        },
        {
            "created_at": "2022-08-17T18:48:17.967Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17446?focusedCommentId=17580948) by Dewey Dunnington (paleolimbot):*\nMaybe something like:\r\n\r\n```R\n\r\nlibrary(arrow, warn.conflicts = FALSE)\r\n#> Some features are not enabled in this build of Arrow. Run `arrow_info()` for more information.\r\nlibrary(rlang)\r\n#> \r\n#> Attaching package: 'rlang'\r\n#> The following object is masked from 'package:arrow':\r\n#> \r\n#>     string\r\n\r\n# I'm sure there's an easier way to do this\r\nmake_dummy_array <- function(type) {\r\n  reader <- RecordBatchReader$create(batches = list(), schema = schema(.x = type))\r\n  as_arrow_array(as_arrow_table(reader)[[1]], type = type)\r\n}\r\n\r\nmake_dummy_array(int8())\r\n#> Array\r\n#> <int8>\r\n#> []\r\n\r\nadd_udfs_from_expr <- function(x, mask, env = caller_env(), \r\n                               registry = new.env(parent = emptyenv()), schema = NULL) {\r\n  if (is_call(x)) {\r\n    if (is_symbol(x[[1]]) && !exists(as.character(x[[1]]), registry)) {\r\n      temp_fun_name <- paste0(\"r_temp_udf_\", hash(x))\r\n      arg_values <- lapply(x[-1], eval_tidy, mask, env)\r\n      arg_is_expression <- vapply(arg_values, inherits, logical(1), \"Expression\")\r\n      \r\n      args_that_were_not_expressions <- arg_values[!arg_is_expression]\r\n      arg_mapping <- c(which(arg_is_expression), which(!arg_is_expression))\r\n      \r\n      expression_as_types <- lapply(\r\n        arg_values[arg_is_expression],\r\n        function(e) e$type(schema)\r\n      )\r\n      expression_as_fields <- lapply(\r\n        expression_as_types,\r\n        function(t) field(\"\", t)\r\n      )\r\n      expression_as_dummy_arrays <- lapply(\r\n        expression_as_types,\r\n        make_dummy_array\r\n      )\r\n      \r\n      in_schema <- schema(!!!expression_as_fields)\r\n      \r\n      wrapper_fun <- function(context, ...) {\r\n        args_that_were_expressions <- lapply(list(...), as.vector)\r\n        args <- c(args_that_were_expressions, args_that_were_not_expressions)[arg_mapping]\r\n        expr <- call2(x[[1]], !!! args)\r\n        eval_tidy(expr, env = env)\r\n      }\r\n      \r\n      dummy_output <- exec(wrapper_fun, list(), !!!expression_as_dummy_arrays)\r\n      out_type <- infer_type(dummy_output)\r\n      \r\n      register_scalar_function(\r\n        temp_fun_name,\r\n        wrapper_fun,\r\n        in_type = in_schema,\r\n        out_type = out_type,\r\n        auto_convert = TRUE\r\n      )\r\n      \r\n      args <- as.list(x[-1])[arg_is_expression]\r\n      call2(temp_fun_name, !!!args)\r\n    } else {\r\n      x[] <- lapply(x, add_udfs_from_expr, mask, env)\r\n      x\r\n    }\r\n  } else {\r\n    x\r\n  }\r\n}\r\n\r\nsome_unknown_function <- function(x, y, z) {\r\n  x + y / z\r\n}\r\n\r\nsome_variable <- 1\r\n\r\nresult <- add_udfs_from_expr(\r\n  quote(some_unknown_function(some_variable, some_col, 3)),\r\n  mask = list(\r\n    some_col = Expression$field_ref(\"some_col\")\r\n  ),\r\n# I forget why we have to do this\r\n  schema = schema(some_col = float64())\r\n)\r\n\r\nresult\r\n#> r_temp_udf_9835e6872b8d3b41297ffc264389487d(some_col)\r\n\r\ncall_function(as.character(result[[1]]), as_arrow_array(1))\r\n#> Array\r\n#> <double>\r\n#> [\r\n#>   1.3333333333333333\r\n#> ]\r\n```\r\n"
        }
    ]
}