{
    "issue": {
        "title": "[Python] java.io.IOException: No FileSystem for scheme: hdfs [On AWS EMR]",
        "body": "***Note**: This issue was originally created as [ARROW-6389](https://issues.apache.org/jira/browse/ARROW-6389). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI can't access hdfs through pyarrow ( from inside a yarn container created by skein)\r\n\r\nThis code works in a jupyter notebook running on the master node, or in an ipython terminal on a worker when given the ARROW_LIBHDFS_DIR env var:\r\n\r\n````import pyarrow; pyarrow.hdfs.connect()````\r\n\r\n\u00a0\r\n\r\nHowever, when running on yarn by submitting the following skein application, I get a Java error.\r\n\r\n\u00a0\r\n\r\n{{name: test_conn\r\nqueue: default\r\n\r\nmaster:\r\n  env:\r\n    ARROW_LIBHDFS_DIR: /usr/lib/hadoop/lib/native\r\n    JAVA_HOME: /etc/alternatives/jre\r\n  resources:\r\n    vcores: 1\r\n    memory: 10 GiB\r\n  files:\r\n    conda_env: /home/hadoop/environment.tar.gz\r\n  script: |\r\n    echo $HADOOP_HOME\r\n    echo $JAVA_HOME\r\n    echo $HADOOP_CLASSPATH\r\n    echo $ARROW_LIBHDFS_DIR\r\n    source conda_env/bin/activate\r\n    python -c \"import pyarrow; pyarrow.hdfs.connect(); print(fs.open('test.txt').read())\"\r\n    echo \"Hello World!\"}}\r\n\r\nFYI I tried with/without all those extra env vars, to no effect. I also tried modifying the EMR cluster with any of the following\r\n\r\n\u00a0\r\n\r\n{{\"fs.hdfs.impl\": \"org.apache.hadoop.fs.Hdfs\"\r\n\"fs.AbstractFileSystem.hdfs.impl\": \"org.apache.hadoop.hdfs.DistributedFileSystem\"\r\n\"fs.hdfs.impl\": \"org.apache.hadoop.hdfs.DistributedFileSystem\"}}\r\n\r\nThe\u00a0`fs.AbstractFileSystem.hdfs.impl`\u00a0one gave a slightly different error- it was able to find which class by name to use for the \"hdfs://\" prefix, namely\u00a0`org.apache.hadoop.hdfs.DistributedFileSystem`, but not able to find that class.\r\n\r\nLogs:\r\n\r\n\u00a0\r\n\r\n{{=========================================================================================\r\nLogType:application.driver.log\r\nLog Upload Time:Thu Aug 29 20:51:59 +0000 2019\r\nLogLength:2635\r\nLog Contents:\r\n/usr/lib/hadoop\r\n/usr/lib/jvm/java-openjdk\r\n:/usr/lib/hadoop-lzo/lib/**:/usr/share/aws/aws-java-sdk/**:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/**:/usr/share/aws/emr/emrfs/auxlib/**:/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar:/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar:/usr/share/aws/emr/kinesis/lib/emr-kinesis-hadoop.jar:/usr/share/aws/emr/cloudwatch-sink/lib/**:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/**:/usr/lib/hadoop-lzo/lib/**:/usr/share/aws/aws-java-sdk/**:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/**:/usr/share/aws/emr/emrfs/auxlib/**:/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar:/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar:/usr/share/aws/emr/kinesis/lib/emr-kinesis-hadoop.jar:/usr/share/aws/emr/cloudwatch-sink/lib/**:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/**\r\n\r\nhdfsBuilderConnect(forceNewInstance=1, nn=default, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:\r\njava.io.IOException: No FileSystem for scheme: hdfs\r\n        at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2846)\r\n        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2857)\r\n        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)\r\n        at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2896)\r\n        at org.apache.hadoop.fs.FileSystem$Cache.getUnique(FileSystem.java:2884)\r\n        at org.apache.hadoop.fs.FileSystem.newInstance(FileSystem.java:439)\r\n        at org.apache.hadoop.fs.FileSystem$2.run(FileSystem.java:414)\r\n        at org.apache.hadoop.fs.FileSystem$2.run(FileSystem.java:411)\r\n        at java.security.AccessController.doPrivileged(Native Method)\r\n        at javax.security.auth.Subject.doAs(Subject.java:422)\r\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)\r\n        at org.apache.hadoop.fs.FileSystem.newInstance(FileSystem.java:411)\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/mnt2/yarn/usercache/hadoop/appcache/application_1567110830725_0001/container_1567110830725_0001_01_000001/conda_env/lib/python3.7/site-packages/pyarrow/hdfs.py\", line 215, in connect\r\n    extra_conf=extra_conf)\r\n  File \"/mnt2/yarn/usercache/hadoop/appcache/application_1567110830725_0001/container_1567110830725_0001_01_000001/conda_env/lib/python3.7/site-packages/pyarrow/hdfs.py\", line 40, in __init__\r\n    self._connect(host, port, user, kerb_ticket, driver, extra_conf)\r\n  File \"pyarrow/io-hdfs.pxi\", line 105, in pyarrow.lib.HadoopFileSystem._connect\r\n  File \"pyarrow/error.pxi\", line 87, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowIOError: HDFS connection failed\r\nHello World!\r\nEnd of LogType:application.driver.log\r\n\r\nLogType:application.master.log\r\nLog Upload Time:Thu Aug 29 20:51:59 +0000 2019\r\nLogLength:1588\r\nLog Contents:\r\n19/08/29 20:51:55 INFO skein.ApplicationMaster: Starting Skein version 0.8.0\r\n19/08/29 20:51:55 INFO skein.ApplicationMaster: Running as user hadoop\r\n19/08/29 20:51:55 INFO skein.ApplicationMaster: Application specification successfully loaded\r\n19/08/29 20:51:56 INFO client.RMProxy: Connecting to ResourceManager at IP.ec2.internal/IP:8030\r\n19/08/29 20:51:56 INFO impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0\r\n19/08/29 20:51:56 INFO skein.ApplicationMaster: gRPC server started at IP.ec2.internal:39361\r\n19/08/29 20:51:57 INFO skein.ApplicationMaster: WebUI server started at IP.ec2.internal:36511\r\n19/08/29 20:51:57 INFO skein.ApplicationMaster: Registering application with resource manager\r\n19/08/29 20:51:57 INFO client.RMProxy: Connecting to ResourceManager at IP.ec2.internal/IP:8032\r\n19/08/29 20:51:57 INFO skein.ApplicationMaster: Starting application driver\r\n19/08/29 20:51:57 INFO skein.ApplicationMaster: Shutting down: Application driver completed successfully.\r\n19/08/29 20:51:57 INFO skein.ApplicationMaster: Unregistering application with status SUCCEEDED\r\n19/08/29 20:51:57 INFO impl.AMRMClientImpl: Waiting for application to be successfully unregistered.\r\n19/08/29 20:51:58 INFO skein.ApplicationMaster: Deleted application directory hdfs://IP.ec2.internal:8020/user/hadoop/.skein/application_1567110830725_0001\r\n19/08/29 20:51:58 INFO skein.ApplicationMaster: WebUI server shut down\r\n19/08/29 20:51:58 INFO skein.ApplicationMaster: gRPC server shut down\r\nEnd of LogType:application.master.log}}",
        "created_at": "2019-08-30T00:53:06.000Z",
        "updated_at": "2021-08-04T09:05:59.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Java",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-08-04T09:05:59.000Z"
    },
    "comments": [
        {
            "created_at": "2019-09-01T21:20:26.510Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6389?focusedCommentId=16920517) by Ben Schreck (bschreck):*\nI fixed it by making HADOOP_HOME=/usr in the worker environment. Pyarrow for some reason sets the hadoop executable to $HADOOP_HOME/bin/hadoop on python/pyarrow/hdfs.py:L137. $HADOOP_HOME on my system was already /usr/bin/hadoop, so this resulted in /usr/bin/hadoop/bin/hadoop, which resulted in a wrong $CLASSPATH."
        },
        {
            "created_at": "2021-08-04T09:05:59.658Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6389?focusedCommentId=17392896) by Antoine Pitrou (apitrou):*\nProblem fixed / worked around as per the comment."
        }
    ]
}