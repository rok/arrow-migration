{
    "issue": {
        "title": "[R] Allow all file writers to write from a RecordBatchReader",
        "body": "***Note**: This issue was originally created as [ARROW-15405](https://issues.apache.org/jira/browse/ARROW-15405). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAfter ARROW-15040 we will be able to use a RecordBatchReader as input to a CSV file writer. It would be similarly helpful to be able to use a RecordBatchReader as input to write Parquet, IPC, and Feather files. The RecordBatchReader is important because it can be imported from C/Python/database results (e.g., DuckDB).\r\n\r\nThere is a workaround (at least for Parquet), but it's quite verbose:\r\n\r\n```R\n\r\ntf <- tempfile(fileext = \".parquet\")\r\ndf <- data.frame(a = 1:1e6)\r\narrow::write_parquet(df, tf)\r\n\r\ndbdir <- \":memory:\"\r\nsink <- tempfile(fileext = \".parquet\")\r\n\r\ncon <- DBI::dbConnect(duckdb::duckdb(dbdir = dbdir))\r\nres <- DBI::dbSendQuery(con, glue::glue_sql(\"SELECT * FROM { tf }\", .con = con), arrow = TRUE)\r\n\r\nreader <- duckdb::duckdb_fetch_record_batch(res)\r\n\r\n# write_parquet() doesn't *quite* support a record batch reader yet\r\n# and we want to stream to the writer to support possibly\r\n# bigger-than-memory results\r\nfs <- arrow::LocalFileSystem$create()\r\nstream <- fs$OpenOutputStream(sink)\r\n\r\nchunk_size <- asNamespace(\"arrow\")$calculate_chunk_size(1e6, 1)\r\nbatch <- arrow::Table$create(reader$read_next_batch())\r\nwriter <- arrow::ParquetFileWriter$create(\r\n  reader$schema,\r\n  stream,\r\n  properties = arrow::ParquetWriterProperties$create(batch)\r\n)\r\nwriter$WriteTable(batch, chunk_size = chunk_size)\r\n\r\nwhile (!is.null(batch <- reader$read_next_batch())) {\r\n  writer$WriteTable(arrow::Table$create(batch), chunk_size = chunk_size)\r\n}\r\n\r\nwriter$Close()\r\nstream$close()\r\nDBI::dbDisconnect(con, shutdown = TRUE)\r\n\r\ndf2 <- dplyr::arrange(arrow::read_parquet(sink), a)\r\nidentical(df2$a, df$a)\r\n#> [1] TRUE\r\n```\r\n",
        "created_at": "2022-01-21T13:27:53.000Z",
        "updated_at": "2022-02-01T18:07:15.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": []
}