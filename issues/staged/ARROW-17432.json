{
    "issue": {
        "title": "[R] messed up rows when importing large csv into parquet",
        "body": "***Note**: This issue was originally created as [ARROW-17432](https://issues.apache.org/jira/browse/ARROW-17432). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThis is a weird issue that creates new rows when importing a large csv (56 GB) into parquet in R. It occurred with both R Arrow 8.0.0 and 9.0.0 BUT didn't occur with the Python Arrow library 9.0.0. Due to the large size of the original csv it's difficult to create a reproducible example, but I share the code and outputs.\r\n\r\nThe code I use in R to import the csv:\r\n```java\n\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\n \r\ncsv_file <- \"/ebird_erd2021/full/obs.csv\"\r\ndest <- \"/ebird_erd2021/full/obs_parquet/\" \r\n\r\nsch = arrow::schema(checklist_id = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 species_code = string(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 exotic_category = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 obs_count = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 only_presence_reported = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 only_slash_reported = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 valid = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 reviewed = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 has_media = float32()\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 )\r\n\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0schema = sch, skip_rows = 1)\r\n\r\nwrite_dataset(csv_stream, dest, format = \"parquet\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 max_rows_per_file=1000000L,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 hive_style = TRUE,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 existing_data_behavior = \"overwrite\")\n```\r\nWhen I load the dataset and check one random _checklist_id_ I get rows that are not part of the _obs.csv_ file. There shouldn't be duplicated species in a checklist but there are ({_}amerob{_} for example)...\u00a0 also note that the duplicated species have different {_}obs_count{_}. 50 species in total in that specific {_}checklist_id{_}.\r\n```java\n\r\nparquet_arrow <- open_dataset(dest, format = \"parquet\")\r\n\r\nparquet_arrow |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 collect() \r\n\r\n# A tibble: 50 \u00d7 3\r\n   checklist_id species_code obs_count\r\n          <dbl> <chr>            <dbl>\r\n 1     18543372 altori               3\r\n 2     18543372 amekes               1\r\n 3     18543372 amered              40\r\n 4     18543372 amerob              30\r\n 5     18543372 amerob               9\r\n 6     18543372 balori               9\r\n 7     18543372 blkter               9\r\n 8     18543372 blkvul              20\r\n 9     18543372 buggna               1\r\n10     18543372 buwwar               1\r\n# \u2026 with 40 more rows\r\n# \u2139 Use `print(n = ...)` to see more rows\n```\r\nIf I use awk to query the csv file with that same checklist id, I get something different:\r\n```java\n\r\n$ awk -F \",\" '{ if ($1 == 18543372) { print } }' obs.csv\r\n\r\n18543372.0,rewbla,,60.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,amerob,,30.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,robgro,,2.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,eastow,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,sedwre1,,2.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,ovenbi1,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,buggna,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,reshaw,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,turvul,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,gowwar,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,balori,,9.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,buwwar,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,grycat,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,cangoo,,6.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,houwre,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,amered,,40.0,0.0,0.0,1.0,1.0,0.0\r\n18543372.0,norwat,,2.0,0.0,0.0,1.0,0.0,0.0\n```\r\n17 different species and no repetitions... Look _amerob_ on the 2nd line only, with 30 _obs_count_\r\n\r\n\u00a0\r\n\r\nIf I import the csv into parquet using the Python Arrow library as:\r\n```java\n\r\nimport pyarrow as pa\r\nimport pyarrow.dataset as ds\r\nimport pyarrow.compute as pc\r\nimport pandas as pd \r\n\r\ntest_rows_csv = pd.read_csv(\"/ebird_erd2021/full/obs.csv\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nrows = 1000)\r\n\r\nsch = pa.Schema.from_pandas(test_rows_csv)\r\n\r\ncsv_file = ds.dataset(\"/ebird_erd2021/full/obs.csv\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 schema = sch,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 format = \"csv\")\r\n\r\nds.write_dataset(csv_file,\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"ebird_erd2021/full/obs_parquet_py/\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0format = \"parquet\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0schema = sch,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0use_threads = True,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0max_rows_per_file = 1000000,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0max_rows_per_group = 1000000,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0existing_data_behavior = \"error\")\n```\r\nAnd then load it in R doing the same checklist search:\r\n```java\n\r\nparquet_py <- \"/ebird_erd2021/full/obs_parquet_py/\"\r\n\r\nparquet_arrow <- open_dataset(parquet_py, format = \"parquet\")\r\n\r\nparquet_arrow |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 select(checklist_id, species_code, obs_count) |>\u00a0\r\n\u00a0 collect()\r\n\r\n# A tibble: 17 \u00d7 3\r\n   checklist_id species_code obs_count\r\n          <dbl> <chr>            <dbl>\r\n 1     18543372 amered              40\r\n 2     18543372 amerob              30\r\n 3     18543372 balori               9\r\n 4     18543372 buggna               1\r\n 5     18543372 buwwar               1\r\n 6     18543372 cangoo               6\r\n 7     18543372 eastow               1\r\n 8     18543372 gowwar               1\r\n 9     18543372 grycat               1\r\n10     18543372 houwre               1\r\n11     18543372 norwat               2\r\n12     18543372 ovenbi1              1\r\n13     18543372 reshaw               1\r\n14     18543372 rewbla              60\r\n15     18543372 robgro               2\r\n16     18543372 sedwre1              2\r\n17     18543372 turvul               1\n```\r\nI get exactly what I should. No _species_code_ repeated and 17 different species.\r\n\r\n\u00a0\r\n\r\nDue to these differences I guess something weird must be happening in the R arrow library.",
        "created_at": "2022-08-16T14:01:07.000Z",
        "updated_at": "2022-10-17T02:33:25.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-10-17T02:33:25.000Z"
    },
    "comments": [
        {
            "created_at": "2022-08-25T15:32:22.859Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17432?focusedCommentId=17584903) by SHIMA Tatsuya (eitsupi):*\nHi, how about passing the schema to the `col_types` argument?\r\n\r\n```r\n\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\", \r\n                           col_types = sch)\r\n```\r\n\r\nOr, using `readr::read_csv()`?\r\n\r\nI also wonder if the number of rows in the dataset fetched is the same in all cases."
        },
        {
            "created_at": "2022-09-14T15:20:50.469Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17432?focusedCommentId=17604804) by Guillermo Duran (gds506):*\nThanks for your comments `[~eitsupi]` .\r\n\r\nI tried using _col_types_ instead of _schema_ as arguments of the _open_dataset_ function but the issue is still present.\r\n\r\n\u00a0\r\n\r\nI also did the \"query\" straight with the _csv_stream_ object and got the same issue, so I guess the bug is in the **_open_dataset_** function. Take a look:\r\n```java\n\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0col_types = sch)\r\n\r\ncsv_stream |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 collect()\r\n\r\n# A tibble: 50 \u00d7 9\r\n   checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n          <dbl> <chr>                  <dbl>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n 1     18543372 altori                    NA         3                      0                   0     1        0         0\r\n 2     18543372 amekes                    NA         1                      0                   0     1        0         0\r\n 3     18543372 amered                    NA        40                      0                   0     1        1         0\r\n 4     18543372 amerob                    NA        30                      0                   0     1        0         0\r\n 5     18543372 amerob                    NA         9                      0                   0     1        0         0\r\n 6     18543372 balori                    NA         9                      0                   0     1        0         0\r\n 7     18543372 blkter                    NA         9                      0                   0     1        0         0\r\n 8     18543372 blkvul                    NA        20                      0                   0     1        0         0\r\n 9     18543372 buggna                    NA         1                      0                   0     1        0         0\r\n10     18543372 buwwar                    NA         1                      0                   0     1        0         0\r\n# \u2026 with 40 more rows\r\n# \u2139 Use `print(n = ...)` to see more rows\n```\r\n\u00a0\r\n\r\nIn regard to the number of rows, I check the csv file:\r\n```java\n\r\n$ wc -l obs.csv\r\n\r\n739629150 obs.csv\n```\r\n\u00a0\r\n\r\nand the csv_stream read by arrow:\r\n```java\n\r\n> csv_stream$num_rows\r\n[1] 739629149\r\n\r\n```\r\nI get them right (without taking into account the header).\r\n\r\n\u00a0\r\n\r\nSo it seems the open_dataset is reading the right number of rows, but making a mess with the information on each row."
        },
        {
            "created_at": "2022-10-14T09:30:39.082Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17432?focusedCommentId=17617597) by Fran\u00e7ois Michonneau (fmic):*\nI'm wondering if you have a floating point issue. Your checklist ID is being imported as double and you filter with `==`. Can you parse your checklist ID as int32 when importing in Arrow? (as a related question why do you have decimal notation for integers in your CSV file?)"
        },
        {
            "created_at": "2022-10-14T13:53:07.212Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17432?focusedCommentId=17617742) by Guillermo Duran (gds506):*\nThanks for your suggestion `[~fmic]` \u00a0\r\n\r\nAs why we have a decimal notation on the checklists ID column... that's a good question, but basically that's how the data is exported from the eBird db.\r\n\r\n\u00a0\r\n```java\n\r\n$ head obs.csv\r\nchecklist_id,species_code,exotic_category,obs_count,only_presence_reported,only_slash_reported,valid,reviewed,has_media\r\n771514.0,comgra,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,grycat,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,bkcchi,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,sonspa,,3.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,bnhcow,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,amegfi,,4.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,rewbla,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771515.0,yelwar,,4.0,0.0,0.0,1.0,0.0,0.0\r\n771515.0,amecro,,1.0,0.0,0.0,1.0,0.0,0.0\r\n```\r\nI can do some regex trickery to remove the \".0\" from the csv before _open_dataset()_ but in any case it's weird that I have the issue only when importing the csv with the R Arrow library. If I change the type for that column to int32 on the _open_dataset()_ schema,\u00a0 I get a conversion error due to the mismatch.\r\n\r\n\u00a0\r\n\r\nIf I do the subset with the decimal I still get the same weird rows:\r\n\r\n\u00a0\r\n```java\n\r\nsch = arrow::schema(checklist_id = float32(),\r\n                    species_code = string(),\r\n                    exotic_category = float32(),\r\n                    obs_count = float32(),\r\n                    only_presence_reported = float32(),\r\n                    only_slash_reported = float32(),\r\n                    valid = float32(),\r\n                    reviewed = float32(),\r\n                    has_media = float32()\r\n                    )\r\n\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\", \r\n                           col_types = sch)\r\n\r\ncsv_stream |> \r\n   filter(checklist_id == 18543372.0) |> \r\n   arrange(species_code) |> \r\n   collect()\r\n\r\n# A tibble: 50 \u00d7 9\r\n   checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n          <dbl> <chr>                  <dbl>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n 1     18543372 altori                    NA         3                      0                   0     1        0         0\r\n 2     18543372 amekes                    NA         1                      0                   0     1        0         0\r\n 3     18543372 amered                    NA        40                      0                   0     1        1         0\r\n 4     18543372 amerob                    NA        30                      0                   0     1        0         0\r\n 5     18543372 amerob                    NA         9                      0                   0     1        0         0\r\n 6     18543372 balori                    NA         9                      0                   0     1        0         0\r\n 7     18543372 blkter                    NA         9                      0                   0     1        0         0\r\n 8     18543372 blkvul                    NA        20                      0                   0     1        0         0\r\n 9     18543372 buggna                    NA         1                      0                   0     1        0         0\r\n10     18543372 buwwar                    NA         1                      0                   0     1        0         0\r\n# \u2026 with 40 more rows\r\n# \u2139 Use `print(n = ...)` to see more rows\n```\r\n\u00a0\r\n\r\nEven if I filter by an interval, the result is the same:\r\n```java\n\r\ncsv_stream |> \r\n  filter(checklist_id > 18543371 & checklist_id < 18543373) |> \r\n  arrange(species_code) |> \r\n  collect()\r\n\r\n# A tibble: 50 \u00d7 9\r\n   checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n          <dbl> <chr>                  <dbl>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n 1     18543372 altori                    NA         3                      0                   0     1        0         0\r\n 2     18543372 amekes                    NA         1                      0                   0     1        0         0\r\n 3     18543372 amered                    NA        40                      0                   0     1        1         0\r\n 4     18543372 amerob                    NA        30                      0                   0     1        0         0\r\n 5     18543372 amerob                    NA         9                      0                   0     1        0         0\r\n 6     18543372 balori                    NA         9                      0                   0     1        0         0\r\n 7     18543372 blkter                    NA         9                      0                   0     1        0         0\r\n 8     18543372 blkvul                    NA        20                      0                   0     1        0         0\r\n 9     18543372 buggna                    NA         1                      0                   0     1        0         0\r\n10     18543372 buwwar                    NA         1                      0                   0     1        0         0\r\n# \u2026 with 40 more rows\r\n# \u2139 Use `print(n = ...)` to see more rows \n```\r\n\u00a0\r\n\r\nAlso, thinking about the possible differences between the schema used to import the csv in Arrow's Python vs R, it seems that both are the \"same\":\r\n```java\n\r\nimport pyarrow as pa\r\nimport pyarrow.dataset as ds\r\nimport pyarrow.compute as pc\r\nimport pandas as pd\u00a0\r\n\r\ntest_rows_csv = pd.read_csv(\"/ebird_erd2021/full/obs.csv\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nrows = 1000)\r\n\r\nsch = pa.Schema.from_pandas(test_rows_csv)\r\n\r\nsch\r\n\r\nchecklist_id: double\r\nspecies_code: string\r\nexotic_category: double\r\nobs_count: double\r\nonly_presence_reported: double\r\nonly_slash_reported: double\r\nvalid: double\r\nreviewed: double\r\nhas_media: double\r\n-- schema metadata --\r\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 1391\n```"
        },
        {
            "created_at": "2022-10-14T14:17:11.841Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17432?focusedCommentId=17617756) by Fran\u00e7ois Michonneau (fmic):*\nCould you use awk or python to see if there is a `checklist_id` associated with having 9 ``{}obs_count{`}` for ``{}amerob{`}`? and if there is one, you could create a small version of the CSV file with just these `checklist_ids` to see if you can reproduce this duplication."
        },
        {
            "created_at": "2022-10-14T18:19:42.902Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17432?focusedCommentId=17617907) by Guillermo Duran (gds506):*\nthanks again for your input `[~fmic]` \u00a0\r\n\r\nI selected all the rows with obs_count == 9 AND species_code == \"amerob\". The database/csv is quite big, so there are lots of these (a 7MB csv).\r\n\r\nInterestingly, when importing the csv with _open_dataset()_ I wasn't able to reproduce the issue. __ \r\n\r\nGenerating the \"test\" csv with awk:\r\n```java\n\r\n$ head -n 1 obs.csv > test_amerob_9.csv && awk -F \",\" '{ if (($2 ~ /amerob/) && ($4 == 9)) { print } }' obs.csv >> test_amerob_9.csv \r\n\r\n$ head test_amerob_9.csv\r\nchecklist_id,species_code,exotic_category,obs_count,only_presence_reported,only_slash_reported,valid,reviewed,has_media\r\n892273.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n926762.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n927961.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n932031.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n932082.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n932713.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n933502.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n934156.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n935005.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\n```\r\nLoading as Arrow and querying in R:\r\n```java\n\r\ncsv_file <- \"test_amerob_9.csv\"\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0schema = sch, skip_rows = 1)\r\n\r\ncsv_stream |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 collect()\r\n\r\n A tibble: 1 \u00d7 9\r\n  checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n         <dbl> <chr>                  <dbl>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n1     18543372 amerob                    NA         9                      0                   0     1        0         0\n```\r\n\u00a0\r\n\r\nI wonder if it has to be due to the large size of the csv and something internal of the \"csv importer/parser\" of the R Arrow library?"
        },
        {
            "created_at": "2022-10-17T02:32:56.035Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17432?focusedCommentId=17618380) by Guillermo Duran (gds506):*\nhey I tried with _schema = NULL_ to infer the schema from the csv and it worked!\r\n\r\n\u00a0\r\n```java\n\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0schema = NULL)\r\n\r\ncsv_stream |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 collect()\r\n\r\n# A tibble: 17 \u00d7 9\r\n   checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n          <dbl> <chr>                  <???>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n 1     18543372 amered                     .        40                      0                   0     1        1         0\r\n 2     18543372 amerob                     .        30                      0                   0     1        0         0\r\n 3     18543372 balori                     .         9                      0                   0     1        0         0\r\n 4     18543372 buggna                     .         1                      0                   0     1        0         0\r\n 5     18543372 buwwar                     .         1                      0                   0     1        0         0\r\n 6     18543372 cangoo                     .         6                      0                   0     1        0         0\r\n 7     18543372 eastow                     .         1                      0                   0     1        0         0\r\n 8     18543372 gowwar                     .         1                      0                   0     1        0         0\r\n 9     18543372 grycat                     .         1                      0                   0     1        0         0\r\n10     18543372 houwre                     .         1                      0                   0     1        0         0\r\n11     18543372 norwat                     .         2                      0                   0     1        0         0\r\n12     18543372 ovenbi1                    .         1                      0                   0     1        0         0\r\n13     18543372 reshaw                     .         1                      0                   0     1        0         0\r\n14     18543372 rewbla                     .        60                      0                   0     1        0         0\r\n15     18543372 robgro                     .         2                      0                   0     1        0         0\r\n16     18543372 sedwre1                    .         2                      0                   0     1        0         0\r\n17     18543372 turvul                     .         1                      0                   0     1        0         0 \n```\r\n\u00a0\r\n\r\n\u00a0"
        }
    ]
}