{
    "issue": {
        "title": "[C++][Python] Improve ChunkedArray's complexity for the access of elements",
        "body": "***Note**: This issue was originally created as [ARROW-11989](https://issues.apache.org/jira/browse/ARROW-11989). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nChunked arrays are stored as a C++ vector of Arrays.\r\n\r\nThere is currently no indexing structure on top of the vector to allow for anything better than O(chunk) to access an arbitrary element.\r\n\r\nFor example, with a Table consisting of 1 column \u201ctext\u201d defined by:\r\n- 1024 chunks\n- each chunk is 1024 rows\n- each row is a text of 1024 characters\n  \n  Then the time it takes to access one example are:\n  \n  ```java\n  \n  Time to access example at i=0%\t: 6.7\u03bcs\n  Time to access example at i=10%\t: 7.2\u03bcs\n  Time to access example at i=20%\t: 9.1\u03bcs\n  Time to access example at i=30%\t: 11.4\u03bcs\n  Time to access example at i=40%\t: 13.8\u03bcs\n  Time to access example at i=50%\t: 16.2\u03bcs\n  Time to access example at i=60%\t: 18.7\u03bcs\n  Time to access example at i=70%\t: 21.1\u03bcs\n  Time to access example at i=80%\t: 26.8\u03bcs\n  Time to access example at i=90%\t: 25.2\u03bcs\n  ```\n  \n  \n  The time measured are the average times to do `table[\u201ctext\u201d][j]` depending on the index we want to fetch (from the first example at 0% to the example at 90% of the length of the table).\n  \n  You can take a look at the code that produces this benchmark [here](https://pastebin.com/pSkYHQn9).\n  \n  Some discussions in [this thread on the mailing list](https://lists.apache.org/thread.html/r82d4cb40d72914977bf4c3c5b4c168ea03f6060d24279a44258a6394%40%3Cuser.arrow.apache.org%3E) suggested different approaches to improve the complexity:\n- use a contiguous array of chunk lengths, since having a contiguous array of lengths makes the iteration over the chunks lengths faster;\n- use a binary search, as in the Julia implementation [here](https://github.com/JuliaData/SentinelArrays.jl/blob/fe14a82b815438ee2e04b59bf7f337feb1ffd022/src/chainedvector.jl#L14);\n- use interpolation search.\n  \n  Apparently there is also a lookup structure in the compute layer [here](https://github.com/apache/arrow/blob/master/cpp/src/arrow/compute/kernels/vector_sort.cc#L94).\n  \n  cc `[~emkornfield]`, `[~wesm]`\n  \n  Thanks again for the amazing work !\n  \n",
        "created_at": "2021-03-16T18:27:51.000Z",
        "updated_at": "2022-05-01T18:08:51.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2022-04-14T10:43:36.000Z"
    },
    "comments": [
        {
            "created_at": "2021-03-16T18:34:46.880Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11989?focusedCommentId=17302786) by Antoine Pitrou (apitrou):*\nAFAIU, interpolation search is a variation on binary search to try and improve the common case?\r\n\r\nSince chunk offset comparisons are cheap (we're comparing integers) and interpolation is more expensive (it involves a division), I'm not sure it's a good idea here. Someone may want to benchmark for sure."
        },
        {
            "created_at": "2021-03-17T11:52:23.243Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11989?focusedCommentId=17303320) by Daniel Nugent (nugend):*\nSaw this on the list and just wanted to point out that individual index accessing or arbitrary vector at a time accessing might be less common than accessing with a sorted vector of indices at a time. Sorted contiguous vector at a time indexing may be most common of all (for example, an attempt to iterate across a table in batches of records not aligned to chunk size)."
        },
        {
            "created_at": "2021-03-19T04:28:54.399Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11989?focusedCommentId=17304638) by Micah Kornfield (emkornfield):*\n> AFAIU, interpolation search is a variation on binary search to try and improve the common case?\n> \n> Since chunk offset comparisons are cheap (we're comparing integers) and interpolation is more expensive (it involves a division), I'm not sure it's a good idea here. Someone may want to benchmark for sure.\r\nAgreed, benchmarks would be useful.\u00a0 It certainly depends on number of batches that need to be searched.\u00a0 Found <http://pages.cs.wisc.edu/~chronis/files/efficiently_searching_sorted_arrays.pdf>\u00a0this paper on some improvements to interpolation search as well."
        },
        {
            "created_at": "2021-12-27T07:11:45.564Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11989?focusedCommentId=17465561) by Eduardo Ponce (edponce):*\nIs the structure of the example ChunkedArray common (ie., having many chunks with the same length)? If that is the case, this type of access pattern would benefit from a \"FixedSizeChunkedArray\" (doesn't exists) where all chunks are of the same length and thus chunk access would be O(1). This can be implemented without defining a new class but by simply having a flag the ChunkedArray uses to track if chunks are of the same length.\r\n\r\nNow, wrt to using a binary search instead of a linear search for finding the chunk of interest, I expect the binary search to improve access time for high-value indices but worsen access time for low-value indices due to the overhead of performing binary search. Measurements are needed to verify this claim. The overall access time will depend on the application and access patterns and although a binary search would make the overall chunk finding more consistent it will also have its drawback for certain cases.\r\n\r\n_Food for thought:_ An alternative solution is to specify the direction of the linear search based on how the value compares to the length of the ChunkedArray. Basically, only apply the first partition of a binary search, then proceed with either a forward or backward linear search.\r\n- **forward** - begins at first chunk and is useful for low-value indices\n- **backward** - begins search at last chunk and is useful for high-value indices"
        },
        {
            "created_at": "2021-12-27T21:15:03.418Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11989?focusedCommentId=17465869) by Eduardo Ponce (edponce):*\n[Chunks are linearly searched in `GetScalar()` and `Slice()` methods](https://github.com/apache/arrow/blob/master/cpp/src/arrow/chunked_array.cc#L157-L173), so if a faster approach is implemented then it should be applied to both cases.\r\n\r\nI implemented a binary search in C++ for `GetScalar()` and noticed that [pyarrow performs its own linear search in ChunkedArray](https://github.com/apache/arrow/blob/master/python/pyarrow/table.pxi#L162-L188), and [does not has a binding for `GetScalar()`](https://github.com/apache/arrow/blob/master/python/pyarrow/includes/libarrow.pxd#L727-L744).\r\nIs there a particular reason why `GetScalar()` is not exposed in pyarrow?"
        },
        {
            "created_at": "2021-12-27T22:07:39.531Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11989?focusedCommentId=17465884) by Eduardo Ponce (edponce):*\nHere are my local results for the PyArrow benchmark provided by `[~lhoestq]` using `GetScalar()` directly with a linear and binary search.\r\n\r\nNote: The behavior exposed in this benchmark is particular in that it makes many consecutive accesses to the same data structure and in incremental order.\r\n\r\n1. No changes to Arrow\r\n```c++\n\r\nTime to access example at i=0%\t: 15.5\u03bcs\r\nTime to access example at i=10%\t: 11.3\u03bcs\r\nTime to access example at i=20%\t: 14.8\u03bcs\r\nTime to access example at i=30%\t: 18.5\u03bcs\r\nTime to access example at i=40%\t: 22.2\u03bcs\r\nTime to access example at i=50%\t: 26.0\u03bcs\r\nTime to access example at i=60%\t: 29.7\u03bcs\r\nTime to access example at i=70%\t: 33.5\u03bcs\r\nTime to access example at i=80%\t: 37.2\u03bcs\r\nTime to access example at i=90%\t: 41.2\u03bcs\r\n```\r\n\r\n2. Exposing C++ `GetScalar` with linear search in PyArrow and using it directly instead of linear search in Python.\r\n```c++\n\r\nTime to access example at i=0%\t: 10.4\u03bcs\r\nTime to access example at i=10%\t: 8.1\u03bcs\r\nTime to access example at i=20%\t: 8.6\u03bcs\r\nTime to access example at i=30%\t: 9.5\u03bcs\r\nTime to access example at i=40%\t: 10.7\u03bcs\r\nTime to access example at i=50%\t: 11.3\u03bcs\r\nTime to access example at i=60%\t: 12.8\u03bcs\r\nTime to access example at i=70%\t: 13.2\u03bcs\r\nTime to access example at i=80%\t: 14.8\u03bcs\r\nTime to access example at i=90%\t: 14.9\u03bcs\r\n```\r\n\r\n3. Exposing C++ `GetScalar` with binary search in PyArrow and using it directly instead of linear search in Python.\r\n```c++\n\r\nTime to access example at i=0%\t: 10.8\u03bcs\r\nTime to access example at i=10%\t: 7.5\u03bcs\r\nTime to access example at i=20%\t: 6.9\u03bcs\r\nTime to access example at i=30%\t: 6.8\u03bcs\r\nTime to access example at i=40%\t: 6.6\u03bcs\r\nTime to access example at i=50%\t: 6.6\u03bcs\r\nTime to access example at i=60%\t: 6.9\u03bcs\r\nTime to access example at i=70%\t: 6.8\u03bcs\r\nTime to access example at i=80%\t: 6.6\u03bcs\r\nTime to access example at i=90%\t: 6.6\u03bcs\r\n```\r\n\r\n4. Exposing C++ `GetScalar` with forward/backward linear search in PyArrow and using it directly instead of linear search in Python.\r\n```c++\n\r\nTime to access example at i=0%\t: 10.7\u03bcs\r\nTime to access example at i=10%\t: 7.8\u03bcs\r\nTime to access example at i=20%\t: 8.7\u03bcs\r\nTime to access example at i=30%\t: 9.5\u03bcs\r\nTime to access example at i=40%\t: 10.5\u03bcs\r\nTime to access example at i=50%\t: 17.1\u03bcs\r\nTime to access example at i=60%\t: 15.3\u03bcs\r\nTime to access example at i=70%\t: 13.0\u03bcs\r\nTime to access example at i=80%\t: 11.0\u03bcs\r\nTime to access example at i=90%\t: 8.6\u03bcs\r\n```"
        },
        {
            "created_at": "2022-04-01T16:22:37.745Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11989?focusedCommentId=17515990) by Eduardo Ponce (edponce):*\nWhile implementing in `GetScalar()` a lazy initialization of the internal offsets array used for the binary search, found out that such approach requires a mutex to check/initialize the offsets array because the immutability property of `ChunkedArray` entails thread-safe access.\r\n\r\nSo the current solution always initializes the offsets array during construction. This means that the overhead for creating the offsets is always observed even if `GetScalar()` does not gets called or called very few times. This is the current performance:\r\n```Java\n\r\nTime to access example at i=0%  : 20.7\u03bcs\r\nTime to access example at i=10% : 6.9\u03bcs\r\nTime to access example at i=20% : 6.7\u03bcs\r\nTime to access example at i=30% : 6.9\u03bcs\r\nTime to access example at i=40% : 6.8\u03bcs\r\nTime to access example at i=50% : 6.9\u03bcs\r\nTime to access example at i=60% : 6.9\u03bcs\r\nTime to access example at i=70% : 6.8\u03bcs\r\nTime to access example at i=80% : 6.8\u03bcs\r\nTime to access example at i=90% : 6.8\u03bcs\r\n```\r\n\r\nThe initial overhead can be reduced because at the moment the chunks are scanned twice during construction:\r\n1. Construct offsets array for binary search\r\n2. Calculate total ChunkedArray length and null count. Actually, the length can be computed in O(1) with the offsets.\r\n\r\nWe could combine this by adding a `length()` and `null_count()` to `ChunkResolver` class. The drawback here is that length and null count are not necessary for the ChunkResolver operations and can increase data structure size if variable members are used in ChunkResolver and ChunkedArray. Experiments do not show a significant difference between the two approaches choosing the former as it is simpler."
        },
        {
            "created_at": "2022-04-14T10:43:36.761Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11989?focusedCommentId=17522232) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 12055\n<https://github.com/apache/arrow/pull/12055>"
        }
    ]
}