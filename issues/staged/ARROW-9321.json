{
    "issue": {
        "title": "[C++][Dataset] Allow to \"collect\" statistics for ParquetFragment row groups if not constructed from _metadata",
        "body": "***Note**: This issue was originally created as [ARROW-9321](https://issues.apache.org/jira/browse/ARROW-9321). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nRight now, the statistics of the `RowGroupInfo` of ParquetFileFragments are only available when the dataset was constructed from a `_metadata` file:\r\n\r\n```python\n\r\nimport pandas as pd\r\ndf = pd.DataFrame({\"part\": ['A', 'A', 'B', 'B'], \"col\": range(4)})                                                                                                                                        \r\n# use dask to write partitioned dataset *with* _metadata file\r\nimport dask.dataframe as dd                                                                                                                                                                               \r\nddf = dd.from_pandas(df, npartitions=2) \r\nddf.to_parquet(\"test_dataset\", partition_on=[\"part\"], engine=\"pyarrow\")                                                                                                                     \r\n\r\nimport pyarrow.dataset as ds\r\ndataset_no_metadata = ds.dataset(\"test_dataset/\", format=\"parquet\", partitioning=\"hive\")\r\ndataset_from_metadata = ds.parquet_dataset(\"test_dataset/_metadata\", partitioning=\"hive\")                                                                                                                 \r\n```\r\n\r\n```Java\n\r\n\r\nIn [28]: list(dataset_no_metadata.get_fragments())[0].row_groups                                                                                                                                                   \r\n\r\nIn [30]: list(dataset_from_metadata.get_fragments())[0].row_groups                                                                                                                                                 \r\nOut[30]: [<pyarrow._dataset.RowGroupInfo at 0x7fd7882c0030>]\r\n\r\nIn [32]: list(dataset_from_metadata.get_fragments())[0].row_groups[0].statistics                                                                                                                                   \r\nOut[32]: {'col': {'min': 2, 'max': 3}, 'index': {'min': 2, 'max': 3}}\r\n```\r\n\r\nFor some applications (eg dask), one could want access to those statistics, even if the original dataset / fragments were not created from a `_metadata` file. This should not happen automatically since it's costly, but a method to trigger collecting all metadata would be useful.\r\n\r\ncc `[~rjzamora]`",
        "created_at": "2020-07-03T14:47:25.000Z",
        "updated_at": "2020-07-12T22:53:37.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-07-12T22:53:26.000Z"
    },
    "comments": [
        {
            "created_at": "2020-07-12T22:53:26.742Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9321?focusedCommentId=17156406) by Wes McKinney (wesm):*\nIssue resolved by pull request 7692\n<https://github.com/apache/arrow/pull/7692>"
        }
    ]
}