{
    "issue": {
        "title": "[R] Fix compression inference from filename",
        "body": "***Note**: This issue was originally created as [ARROW-16612](https://issues.apache.org/jira/browse/ARROW-16612). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nRight now arrow will silently write a file with a .gz extension to CompressedOutputStream rather than passing the compression option to the parquet writer itself. The internal detect_compression() function detects the extension and that is what passes it off incorrectly. However it only fails at the read_parquet stage which could lead to confusion. \r\n\r\n\r\n```java\n\r\nlibrary(arrow, warn.conflicts = FALSE) \r\ntf <- tempfile(fileext = \".parquet.gz\") \r\nwrite_parquet(data.frame(x = 1:5), tf, compression = \"gzip\", compression_level = 5) read_parquet(tf) \r\n#> Error: file must be a \"RandomAccessFile\"\n```",
        "created_at": "2022-05-18T22:12:24.000Z",
        "updated_at": "2022-08-03T12:13:36.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-07-27T11:02:09.000Z"
    },
    "comments": [
        {
            "created_at": "2022-07-26T13:30:40.871Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16612?focusedCommentId=17571428) by Ra\u00fal Cumplido (raulcd):*\nThis is identified as one of the tickets required to create the first 9.0.0 RC, should this block the release?"
        },
        {
            "created_at": "2022-07-27T11:02:09.801Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16612?focusedCommentId=17571843) by Neal Richardson (npr):*\nIssue resolved by pull request 13625\n<https://github.com/apache/arrow/pull/13625>"
        }
    ]
}