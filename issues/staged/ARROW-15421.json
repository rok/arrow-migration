{
    "issue": {
        "title": "Need a pip install option for out-of-the-box HDFS support",
        "body": "***Note**: This issue was originally created as [ARROW-15421](https://issues.apache.org/jira/browse/ARROW-15421). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHi folks! And thank you for your great work.\r\n\r\nI want to use PyArrow to develop a simple client application that needs to connect to HDFS clusters and exchange data with it\r\n\r\nBut if I want to use HDFS in PyArrow, I have to manually download full Hadoop distro, find there `libhdfs.so` \u2013 and manually provide hadoop's CLASSPATH as an environment variable.\r\n\r\nI need something like **`{}_pip3 install pyarrow_{`}{_}`[hdfs]`{_}**\u00a0that will give my pyarrow with pre-built libhdfs and minimal set of Hadoop JARs needed for its run \u2013 where pyarrow.hdfs.\\* classes could be called without additional boilerplate code.\r\n\r\nCan you please add it in future releases of PyArrow?",
        "created_at": "2022-01-24T02:36:35.000Z",
        "updated_at": "2022-01-24T02:36:52.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": []
}