{
    "issue": {
        "title": "[Python] from_pandas conversion casts values to string inconsistently",
        "body": "***Note**: This issue was originally created as [ARROW-5682](https://issues.apache.org/jira/browse/ARROW-5682). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen calling `pa.Array.from_pandas` primitive data as input, and casting to string with  \"type=pa.string()\", the resulting pyarrow Array can have inconsistent values. For most input, the result is an empty string, however for some types (int32, int64) the values are '\\x01' etc.\r\n\r\n```\n\r\nIn [8]: s = pd.Series([1, 2, 3], dtype=np.uint8)\r\n\r\nIn [9]: pa.Array.from_pandas(s, type=pa.string())                                                                            \r\nOut[9]: \r\n<pyarrow.lib.StringArray object at 0x7f90b6091a48>\r\n[\r\n  \"\",\r\n  \"\",\r\n  \"\"\r\n]\r\n\r\nIn [10]: s = pd.Series([1, 2, 3], dtype=np.uint32)                                                                           \r\n\r\nIn [11]: pa.Array.from_pandas(s, type=pa.string())                                                                           \r\nOut[11]: \r\n<pyarrow.lib.StringArray object at 0x7f9097efca48>\r\n[\r\n  \"\u0001\",\r\n  \"\u0002\",\r\n  \"\u0003\"\r\n]\r\n```\r\n\r\nThis came from the Spark discussion https://github.com/apache/spark/pull/24930/files#r296187903. Type casting this way in Spark is not supported, but it would be good to get the behavior consistent. Would it be better to raise an UnsupportedOperation error?\r\n",
        "created_at": "2019-06-21T17:46:46.000Z",
        "updated_at": "2019-09-12T11:44:37.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-09-12T11:23:29.000Z"
    },
    "comments": [
        {
            "created_at": "2019-08-02T10:48:54.406Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5682?focusedCommentId=16898787) by Joris Van den Bossche (jorisvandenbossche):*\nThis seems to be specific to the code paths dealing with numpy arrays, as from built-in python objects, you get a logical error:\r\n\r\n```Java\n\r\nIn [9]: pa.array([1, 2, 3], pa.string())\r\n...\r\nArrowTypeError: Expected a string or bytes object, got a 'int' object\r\n\r\nIn [10]: pa.array(np.array([1, 2, 3]), pa.string()) \r\nOut[10]: \r\n<pyarrow.lib.StringArray object at 0x7f0909c902b0>\r\n[\r\n  \"\u0001\",   # <-- this is actually not an empty string but '\\x01'\r\n  \"\u0002\",\r\n  \"\u0003\"\r\n]\r\n```\r\n\r\nI agree that at least an error should be raised instead of those incorrect values.\r\n\r\nIn numpy you can cast ints to their string representation by doing an equivalent call:\r\n\r\n```Java\n\r\nIn [13]: np.array(np.array([1, 2, 3], dtype=int), dtype=str)\r\nOut[13]: array(['1', '2', '3'], dtype='<U21')\r\n```\r\n\r\nNot sure if we should do something similar though (and certainly not a priority I would say)."
        },
        {
            "created_at": "2019-08-22T22:53:49.953Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5682?focusedCommentId=16913775) by Wes McKinney (wesm):*\nThis is a bit weird. I added to 0.15.0 in case we want to fix this"
        },
        {
            "created_at": "2019-09-12T11:23:29.086Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5682?focusedCommentId=16928458) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 5333\n<https://github.com/apache/arrow/pull/5333>"
        }
    ]
}