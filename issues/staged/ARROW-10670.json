{
    "issue": {
        "title": "[Python] Make self_destruct and RecordBatchReader work better together",
        "body": "***Note**: This issue was originally created as [ARROW-10670](https://issues.apache.org/jira/browse/ARROW-10670). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen reading record batches via IPC, Arrow generally constructs each batch as a single allocation, with each column in the batch composed of slices of that allocation. This doesn't play well with `to_pandas(self_destruct=True)` as even though Arrow will release references to each column, those references were just to slices of a larger allocation, so no memory actually gets freed until the end of the conversion - defeating the point.\r\n\r\nReallocating the batches via pa.concat_arrays avoids this but requires a copy. Additionally, it's unclear that pa.concat_arrays is suitable for this purpose. It would be convenient if the record batch readers could (at least in some cases) provide suitably allocated batches (this may be hard, e.g. in Flight, the batches are ultimately based on memory allocated by gRPC). If that's not possible, then at least, we should either guarantee that concat_arrays truly returns a copy, or provide an explicit way to copy arrays.\r\n\r\nThis came up when trying to integrate self_destruct into PySpark (see SPARK-32953/https://github.com/apache/spark/pull/29818)",
        "created_at": "2020-11-20T22:31:06.000Z",
        "updated_at": "2022-07-12T14:04:54.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-07-12T14:04:54.564Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10670?focusedCommentId=17565836) by @toddfarmer:*\nThis issue was last updated over 90 days ago, which may be an indication it is no longer being actively worked. To better reflect the current state, the issue is being unassigned. Please feel free to re-take assignment of the issue if it is being actively worked, or if you plan to start that work soon."
        }
    ]
}