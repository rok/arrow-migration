{
    "issue": {
        "title": "[Rust] [Parquet] Too many open files (os error 24)",
        "body": "***Note**: This issue was originally created as [ARROW-6154](https://issues.apache.org/jira/browse/ARROW-6154). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nUsed [rust]**parquet-read binary to read a deeply nested parquet file and see the below stack trace. Unfortunately won't be able to upload file.**\r\n```java\n\r\nstack backtrace:\r\n\r\n\u00a0\u00a0 0: std::panicking::default_hook::{{closure}}\r\n\r\n\u00a0\u00a0 1: std::panicking::default_hook\r\n\r\n\u00a0\u00a0 2: std::panicking::rust_panic_with_hook\r\n\r\n\u00a0\u00a0 3: std::panicking::continue_panic_fmt\r\n\r\n\u00a0\u00a0 4: rust_begin_unwind\r\n\r\n\u00a0\u00a0 5: core::panicking::panic_fmt\r\n\r\n\u00a0\u00a0 6: core::result::unwrap_failed\r\n\r\n\u00a0\u00a0 7: parquet::util::io::FileSource<R>::new\r\n\r\n\u00a0\u00a0 8: <parquet::file::reader::SerializedRowGroupReader<R> as parquet::file::reader::RowGroupReader>::get_column_page_reader\r\n\r\n\u00a0\u00a0 9: <parquet::file::reader::SerializedRowGroupReader<R> as parquet::file::reader::RowGroupReader>::get_column_reader\r\n\r\n\u00a0 10: parquet::record::reader::TreeBuilder::reader_tree\r\n\r\n\u00a0 11: parquet::record::reader::TreeBuilder::reader_tree\r\n\r\n\u00a0 12: parquet::record::reader::TreeBuilder::reader_tree\r\n\r\n\u00a0 13: parquet::record::reader::TreeBuilder::reader_tree\r\n\r\n\u00a0 14: parquet::record::reader::TreeBuilder::reader_tree\r\n\r\n\u00a0 15: parquet::record::reader::TreeBuilder::build\r\n\r\n\u00a0 16: <parquet::record::reader::RowIter as core::iter::traits::iterator::Iterator>::next\r\n\r\n\u00a0 17: parquet_read::main\r\n\r\n\u00a0 18: std::rt::lang_start::{{closure}}\r\n\r\n\u00a0 19: std::panicking::try::do_call\r\n\r\n\u00a0 20: __rust_maybe_catch_panic\r\n\r\n\u00a0 21: std::rt::lang_start_internal\r\n\r\n\u00a0 22: main\n```",
        "created_at": "2019-08-06T23:52:37.000Z",
        "updated_at": "2021-04-26T11:23:57.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Rust",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-04-26T11:23:57.000Z"
    },
    "comments": [
        {
            "created_at": "2019-08-07T06:02:08.709Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6154?focusedCommentId=16901748) by Chao Sun (csun):*\nThanks for reporting. Do you have rough idea how deep the nested data type is? is there any error message? would be great if we can reproduce this."
        },
        {
            "created_at": "2019-08-07T11:35:10.840Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6154?focusedCommentId=16902001) by Yesh (madras):*\nThanks for ack.\u00a0Below is the error message.\u00a0 Additional data point is that it is able to dump schema via parquet-schema .\u00a0\r\n```java\n\r\nthread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: General(\"underlying IO error: Too many open files (os error 24)\")', src/libcore/result.rs:1084:5\n```"
        },
        {
            "created_at": "2021-02-12T22:52:01.045Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6154?focusedCommentId=17284027) by Ahmed Riza (dr.riza@gmail.com):*\nI've come across the same error. In my case it appears to be due to the `try_clone` calls in <https://github.com/apache/arrow/blob/master/rust/parquet/src/util/io.rs#L82.>\u00a0 I have a Parquet file with 3000 columns (see attached example), and the `try_clone` calls here eventually fail as it ends up creating too many open file descriptors<font color=\"#000000\">.</font>\r\n\r\nHere's a stack trace from `gdb` which leads to the call in `io.rs`.\u00a0\u00a0 This can be reproduced by using the attached Parquet file.\r\n\r\nOne could increase the `ulimit -n` on Linux to get around this, but not really a solution, since the code path ends up just creating potentially a very large number of open file descriptors (one for each column in the Parquet file).\r\n\r\nThis is the initial stack trace when the footer is first read.\u00a0 `FileSource<std::fs::File>::new` (in io.rs) gets called for every column subsequently as well when reading the columns (see <font color=\"#cc844f\">fn </font><font color=\"#8ec1ff\">reader_tree </font>in `parquet/record/reader.rs`)\r\n\r\n\u00a0\r\n```java\n\r\n#0 \u00a0parquet::util::io::FileSource<std::fs::File>::new<std::fs::File> (fd=0x7ffff7c3fafc, start=807191, length=65536) at /home/a/.cargo/registry/src/github.com-1ecc6299db9ec823/parquet-3.0.0/src/util/io.rs:82\r\n\r\n#1 \u00a00x00005555558294ce in parquet::file::serialized_reader::{{impl}}::get_read (self=0x7ffff7c3fafc, start=807191, length=65536)\r\n\r\n \u00a0\u00a0\u00a0at /home/a/.cargo/registry/src/github.com-1ecc6299db9ec823/parquet-3.0.0/src/file/serialized_reader.rs:59\r\n\r\n#2 \u00a00x000055555590a3fc in parquet::file::footer::parse_metadata<std::fs::File> (chunk_reader=0x7ffff7c3fafc) at /home/a/.cargo/registry/src/github.com-1ecc6299db9ec823/parquet-3.0.0/src/file/footer.rs:57\r\n\r\n#3 \u00a00x0000555555845db1 in parquet::file::serialized_reader::SerializedFileReader<std::fs::File>::new<std::fs::File> (chunk_reader=...)\r\n\r\n \u00a0\u00a0\u00a0at /home/a/.cargo/registry/src/github.com-1ecc6299db9ec823/parquet-3.0.0/src/file/serialized_reader.rs:134\r\n\r\n#4 \u00a00x0000555555845bb6 in parquet::file::serialized_reader::{{impl}}::try_from (file=...) at /home/a/.cargo/registry/src/github.com-1ecc6299db9ec823/parquet-3.0.0/src/file/serialized_reader.rs:81\r\n\r\n#5 \u00a00x0000555555845c4a in parquet::file::serialized_reader::{{impl}}::try_from (path=0x7ffff0000d20) at /home/a/.cargo/registry/src/github.com-1ecc6299db9ec823/parquet-3.0.0/src/file/serialized_reader.rs:90\r\n\r\n#6 \u00a00x0000555555845d34 in parquet::file::serialized_reader::{{impl}}::try_from (path=\"resources/parquet/part-00001-33e6c49b-d6cb-4175-bc41-7198fd777d3a-c000.snappy.parquet\")\r\n\r\n \u00a0\u00a0\u00a0at /home/a/.cargo/registry/src/github.com-1ecc6299db9ec823/parquet-3.0.0/src/file/serialized_reader.rs:98\r\n\r\n#7 \u00a00x000055555577c7f5 in data_rust::parquet::parquet_demo::test::test_read_multiple_files () at /work/rust/data-rust/src/parquet/parquet_demo.rs:103\r\n\r\n\r\n \n```"
        },
        {
            "created_at": "2021-04-26T11:23:56.036Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6154?focusedCommentId=17332031) by Andrew Lamb (alamb):*\nMigrated to github: https://github.com/apache/arrow-rs/issues/47"
        }
    ]
}