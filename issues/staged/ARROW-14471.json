{
    "issue": {
        "title": "[R] Implement lubridate's individual date/time parsers",
        "body": "***Note**: This issue was originally created as [ARROW-14471](https://issues.apache.org/jira/browse/ARROW-14471). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nParse dates with year, month, and day components:\r\nymd() ydm() mdy() myd() dmy() dym() yq() ym() my()\r\n\t\r\nParse date-times with year, month, and day, hour, minute, and second components:\r\nymd_hms() ymd_hm() ymd_h() dmy_hms() dmy_hm() dmy_h() mdy_hms() mdy_hm() mdy_h() ydm_hms() ydm_hm() ydm_h()\r\n\r\nParse periods with hour, minute, and second components:\r\nms() hm() hms()\r\n\t\r\n\r\n",
        "created_at": "2021-10-26T12:44:16.000Z",
        "updated_at": "2022-08-29T14:15:18.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: task"
        ],
        "closed": true,
        "closed_at": "2022-08-29T14:14:00.000Z"
    },
    "comments": [
        {
            "created_at": "2021-11-08T19:47:13.181Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14471?focusedCommentId=17440722) by Dewey Dunnington (paleolimbot):*\nI did a bit of looking into this...lubridate uses a [custom C parser for its order-based datetime parsers](https://github.com/tidyverse/lubridate/blob/main/src/tparse.c#L46-L391). That said, its functionality can be approximated by `{}coalesce(strptime(dt_string, \"format1\"), strptime(dt_string, \"format2\"), ...){`}. Is it worth translating the functions with an approximation that handles most of the use cases?\r\n\r\nSome testing that might be useful when putting together a PR:\r\n```r\n\r\nlibrary(arrow, warn.conflicts = FALSE)\r\nlibrary(dplyr, warn.conflicts = FALSE)\r\n\r\ntest_dates <- tibble::tibble(\r\n  string_ymd = c(\"2021-09-10\", \"2021/09/10\", \"20210910\", \"2021 Sep 10\", \"2021 September 10\", NA),\r\n  string_dmy = c(\"10-09-2021\", \"10/09/2021\", \"10092021\", \"10 Sep 2021\", \"10 September 2021\", NA),\r\n  string_mdy = c(\"09-10-2021\", \"09/10/2021\", \"09102021\", \"Sep 10 2021\", \"September 10 2021\", NA),\r\n  date = c(rep(as.Date(\"2021-09-10\"), 5), NA),\r\n  date_midnight = c(rep(as.POSIXct(\"2021-09-10 00:00:00\", tz = \"UTC\"), 5), NA)\r\n)\r\n\r\n# these get dropped by as.POSIXct if the system tz is UTC?\r\nattr(test_dates$date_midnight, \"tzone\") <- \"UTC\"\r\n\r\ntest_datetimes <- tibble::tibble(\r\n  string_ymd_hms = stringr::str_c(test_dates$string_ymd, \"01:23:45\"),\r\n  string_dmy_hms = stringr::str_c(test_dates$string_dmy, \"01:23:45\"),\r\n  string_mdy_hms = stringr::str_c(test_dates$string_mdy, \"01:23:45\"),\r\n  string_ymd_hm = stringr::str_c(test_dates$string_ymd, \"01:23\"),\r\n  string_dmy_hm = stringr::str_c(test_dates$string_dmy, \"01:23\"),\r\n  string_mdy_hm = stringr::str_c(test_dates$string_mdy, \"01:23\"),\r\n  string_ymd_h = stringr::str_c(test_dates$string_ymd, \"01\"),\r\n  string_dmy_h = stringr::str_c(test_dates$string_dmy, \"01\"),\r\n  string_mdy_h = stringr::str_c(test_dates$string_mdy, \"01\"),\r\n  date_second = c(rep(as.POSIXct(\"2021-09-10 01:23:45\", tz = \"UTC\"), 5), NA),\r\n  date_minute = c(rep(as.POSIXct(\"2021-09-10 01:23\", tz = \"UTC\"), 5), NA),\r\n  date_hour = c(rep(as.POSIXct(\"2021-09-10\", tz = \"UTC\") + 60 * 60, 5), NA)\r\n)\r\n\r\n# these get dropped by as.POSIXct if the system tz is UTC?\r\nattr(test_datetimes$date_second, \"tzone\") <- \"UTC\"\r\nattr(test_datetimes$date_minute, \"tzone\") <- \"UTC\"\r\nattr(test_datetimes$date_hour, \"tzone\") <- \"UTC\"\r\n\r\n# tests with lubridate, R eval\r\nlibrary(testthat, warn.conflicts = FALSE)\r\nlibrary(lubridate, warn.conflicts = FALSE)\r\n\r\nexpect_identical(ymd(test_dates$string_ymd), test_dates$date)\r\nexpect_identical(dmy(test_dates$string_dmy), test_dates$date)\r\nexpect_identical(mdy(test_dates$string_mdy), test_dates$date)\r\n\r\nexpect_identical(ymd(test_dates$string_ymd, tz = \"UTC\"), test_dates$date_midnight)\r\nexpect_identical(dmy(test_dates$string_dmy, tz = \"UTC\"), test_dates$date_midnight)\r\nexpect_identical(mdy(test_dates$string_mdy, tz = \"UTC\"), test_dates$date_midnight)\r\n\r\nexpect_identical(\r\n  ymd_hms(test_datetimes$string_ymd_hms, tz = \"UTC\"),\r\n  test_datetimes$date_second\r\n)\r\nexpect_identical(\r\n  dmy_hms(test_datetimes$string_dmy_hms, tz = \"UTC\"),\r\n  test_datetimes$date_second\r\n)\r\nexpect_identical(\r\n  mdy_hms(test_datetimes$string_mdy_hms, tz = \"UTC\"),\r\n  test_datetimes$date_second\r\n)\r\n\r\nexpect_identical(\r\n  ymd_hm(test_datetimes$string_ymd_hm, tz = \"UTC\"),\r\n  test_datetimes$date_minute\r\n)\r\nexpect_identical(\r\n  dmy_hm(test_datetimes$string_dmy_hm, tz = \"UTC\"),\r\n  test_datetimes$date_minute\r\n)\r\nexpect_identical(\r\n  mdy_hm(test_datetimes$string_mdy_hm, tz = \"UTC\"),\r\n  test_datetimes$date_minute\r\n)\r\n\r\nexpect_identical(\r\n  ymd_h(test_datetimes$string_ymd_h, tz = \"UTC\"),\r\n  test_datetimes$date_hour\r\n)\r\nexpect_identical(\r\n  dmy_h(test_datetimes$string_dmy_h, tz = \"UTC\"),\r\n  test_datetimes$date_hour\r\n)\r\nexpect_identical(\r\n  mdy_h(test_datetimes$string_mdy_h, tz = \"UTC\"),\r\n  test_datetimes$date_hour\r\n)\r\n```"
        },
        {
            "created_at": "2021-11-18T15:26:29.798Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14471?focusedCommentId=17445986) by Nicola Crane (thisisnic):*\n`[~paleolimbot]` When you say 'approximated', how close or far is it?"
        },
        {
            "created_at": "2021-11-18T16:00:55.479Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14471?focusedCommentId=17446011) by Dewey Dunnington (paleolimbot):*\nlubridate does it by ignoring all non-alpha/numeric characters so it'll happily parse something like \"01:::::23::::45\" just the same as \"012345\" or anywhere inbetween. I forget the exact incantations for strptime, but we could provide a list of formats we're willing to consider for each of them or preprocess with a regex to reduce the number of formats we need to consider (i.e., `gsub(\"[^A-Za-z0-9.]\", \" \")`). If that sounds close enough for you I'm happy to make a PR!"
        },
        {
            "created_at": "2021-11-18T16:06:50.879Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14471?focusedCommentId=17446018) by Nicola Crane (thisisnic):*\nSounds like it'd be easy enough (famous last words!) to just strip out extra things with regex - so I'd say go ahead!  "
        },
        {
            "created_at": "2022-02-07T11:33:06.637Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14471?focusedCommentId=17488048) by Drago\u0219 Moldovan-Gr\u00fcnfeld (dragosmg):*\n`[~paleolimbot]` I don't think we can rely on `coalesce()` to iterate through the various formats supported for `{}ymd(){`}. It would need to rely on the assumption that the passed `format`\u00a0matches the data or otherwise fail. Sadly, arrow works with a wrong format resulting in weird timestamps:\r\n```r\n\r\nsuppressPackageStartupMessages(library(dplyr))\r\nsuppressPackageStartupMessages(library(arrow))\r\nsuppressPackageStartupMessages(library(lubridate))\r\n\r\ndf <- tibble(x = c(\"09-01-01\", \"09-01-02\", \"09-01-03\"))\r\ndf\r\n#> # A tibble: 3 \u00d7 1\r\n#>   x       \r\n#>   <chr>   \r\n#> 1 09-01-01\r\n#> 2 09-01-02\r\n#> 3 09-01-03\r\n\r\n# lubridate::ymd()\r\ndf %>% \r\n  mutate(y = ymd(x))\r\n#> # A tibble: 3 \u00d7 2\r\n#>   x        y         \r\n#>   <chr>    <date>    \r\n#> 1 09-01-01 2009-01-01\r\n#> 2 09-01-02 2009-01-02\r\n#> 3 09-01-03 2009-01-03\r\n\r\n# y = short year correct\r\ndf %>% \r\n  record_batch() %>% \r\n  mutate(y = strptime(x, format = \"%y-%m-%d\", unit = \"us\")) %>% \r\n  collect()\r\n#> # A tibble: 3 \u00d7 2\r\n#>   x        y                  \r\n#>   <chr>    <dttm>             \r\n#> 1 09-01-01 2009-01-01 00:00:00\r\n#> 2 09-01-02 2009-01-02 00:00:00\r\n#> 3 09-01-03 2009-01-03 00:00:00\r\n\r\n# Y = long year this should fail in order for us to rely on coalesce\r\ndf %>% \r\n  record_batch() %>% \r\n  mutate(y = strptime(x, format = \"%Y-%m-%d\", unit = \"us\")) %>% \r\n  collect()\r\n#> # A tibble: 3 \u00d7 2\r\n#>   x        y                  \r\n#>   <chr>    <dttm>             \r\n#> 1 09-01-01 0008-12-31 23:58:45\r\n#> 2 09-01-02 0009-01-01 23:58:45\r\n#> 3 09-01-03 0009-01-02 23:58:45\r\n```\r\nTherefore, my early (and somewhat naive) conclusion would be that we cannot implement `arrow::ymd()` binding as `{}coalesce(strptime(x, format1), strptime(x, format2), ...){`}. What do you think?"
        },
        {
            "created_at": "2022-02-07T11:35:41.910Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14471?focusedCommentId=17488050) by Drago\u0219 Moldovan-Gr\u00fcnfeld (dragosmg):*\nWe could to some processing to figure out how many characters we have (in the string to be parsed) in between the separators (or how many characters we have in total, in the cases where we have no separator) and only try with the suitable formats. i.e. in the example above not try to parse with `{}%Y{`}, only `{}%y{`}."
        },
        {
            "created_at": "2022-02-07T12:21:06.407Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14471?focusedCommentId=17488059) by Drago\u0219 Moldovan-Gr\u00fcnfeld (dragosmg):*\nAnother alternative would be for\u00a0`strptime` to error when the selected format does not match the data (for example, attempting to parse `\"09-12-31\"` with `{}\"%Y-%m-%d\"{`}should error due to a mismatch in the length of the year). Then we could rely on this behaviour with `{}coalesce{`}.\u00a0"
        },
        {
            "created_at": "2022-02-07T15:01:41.245Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14471?focusedCommentId=17488164) by Drago\u0219 Moldovan-Gr\u00fcnfeld (dragosmg):*\n`lubridate` uses\u00a0`guess_formats()` to identify the\u00a0likely candidates. We could try something similar, where we have a list of supported formats (something similar to [this](https://github.com/dragosmg/arrow/blob/cfba9e1dfbedd5dfdf652c805e93692808dd092e/r/R/dplyr-funcs-datetime.R#L152-L196)), which we then narrow down to the most likely ones. Only then use something like `{}coalesce(){`}."
        }
    ]
}