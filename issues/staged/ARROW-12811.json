{
    "issue": {
        "title": "[C++] [Dataset] Dataset repartition / filter / update",
        "body": "***Note**: This issue was originally created as [ARROW-12811](https://issues.apache.org/jira/browse/ARROW-12811). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThis feature would be to add support for an \"update\" workflow which scanned a set of batches and wrote them (potentially filtered/modified) back out to the same place.\r\n\r\n\r\nThe existing dataset read / dataset write features wouldn't work because they would append the data.\r\n\r\nThere is some discussion in ARROW-12358 and ARROW-12509 of an \"overwrite mode\" but an \"overwrite partition\" workflow wouldn't work unless you can scan in entire partitions at once (and in general this should probably be avoided).\r\n\r\nA naive \"write to a different directory and rename\" approach could work but it would be inefficient since it would require a copy of the entire dataset to modify a small part of it.\r\n\r\n\u00a0\r\n\r\nThe feature could be implemented using temporary directories in place that get renamed on top of the existing directory at the end.\u00a0 Files that are unchanged would be moved into the temporary directory instead of copied.\r\n\r\nPresumable no ACID guarantees would be made (and they would be quite hard to guarantee) since Arrow datasets do not make ACID guarantees of any kind currently.",
        "created_at": "2021-05-17T17:48:56.000Z",
        "updated_at": "2021-05-17T17:49:36.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": []
}