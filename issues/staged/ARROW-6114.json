{
    "issue": {
        "title": "[Python] Datatypes not preserved for partition fields in roundtrip to partitioned parquet dataset",
        "body": "***Note**: This issue was originally created as [ARROW-6114](https://issues.apache.org/jira/browse/ARROW-6114). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n### Datatypes are not preserved when a pandas data frame is **partitioned** and saved as parquet file using pyarrow but that's not the case when the data frame is not partitioned.\r\n\r\n**Case 1: Saving a partitioned dataset - Data Types are NOT preserved**\r\n```java\n\r\n# Saving a Pandas Dataframe to Local as a partioned parquet file using pyarrow\r\nimport pandas as pd\r\ndf = pd.DataFrame( {'age': [77,32,234],'name':['agan','bbobby','test'] }\r\n)\r\npath = 'test'\r\npartition_cols=['age']\r\nprint('Datatypes before saving the dataset')\r\nprint(df.dtypes)\r\ntable = pa.Table.from_pandas(df)\r\npq.write_to_dataset(table, path, partition_cols=partition_cols, preserve_index=False)\r\n\r\n# Loading a dataset partioned parquet dataset from local\r\ndf = pq.ParquetDataset(path, filesystem=None).read_pandas().to_pandas()\r\nprint('\\nDatatypes after loading the dataset')\r\nprint(df.dtypes)\r\n```\r\n**Output:**\r\n```java\n\r\nDatatypes before saving the dataset\r\nage int64\r\nname object\r\ndtype: object\r\n\r\nDatatypes after loading the dataset\r\nname object\r\nage category\r\ndtype: object\r\n```\r\n##### <font color=\"#d04437\">From the above output, we could see that the data type for age is int64 in the original pandas data frame but it got changed to category when we saved to local and loaded back.</font>\r\n\r\n**Case 2: Non-partitioned dataset - Data types are preserved**\r\n```java\n\r\nimport pandas as pd\r\nprint('Saving a Pandas Dataframe to Local as a parquet file without partitioning using pyarrow')\r\ndf = pd.DataFrame(\r\n\r\n{'age': [77,32,234],'name':['agan','bbobby','test'] }\r\n\r\n)\r\npath = 'test_without_partition'\r\nprint('Datatypes before saving the dataset')\r\nprint(df.dtypes)\r\ntable = pa.Table.from_pandas(df)\r\npq.write_to_dataset(table, path, preserve_index=False)\r\n# Loading a non-partioned parquet file from local\r\ndf = pq.ParquetDataset(path, filesystem=None).read_pandas().to_pandas()\r\nprint('\\nDatatypes after loading the dataset')\r\nprint(df.dtypes)\r\n\r\n```\r\n**Output:**\r\n```java\n\r\nSaving a Pandas Dataframe to Local as a parquet file without partitioning using pyarrow\r\nDatatypes before saving the dataset\r\nage int64\r\nname object\r\ndtype: object\r\n\r\nDatatypes after loading the dataset\r\nage int64\r\nname object\r\ndtype: object\r\n```\r\n**Versions**\r\n \\* Python 3.7.3\r\n \\* pyarrow 0.14.1",
        "created_at": "2019-08-02T04:32:59.000Z",
        "updated_at": "2020-07-08T08:27:59.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2019-08-02T09:36:59.542Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6114?focusedCommentId=16898737) by Joris Van den Bossche (jorisvandenbossche):*\n`[~bnriiitb]` thanks for opening the issue. \r\n\r\nSo when a partitioned dataset is written, the partition columns are not stored in the actual data, but are part of the directory schema (in your case you would have \"age=77\", \"age=32\", etc sub-folders). \r\n\r\nCurrently, we don't save any \"meta data\" about the columns used to partition, and since they are also not stored in the actual parquet files (where a schema of the data is stored), we don't have that information from there either.\r\n\r\nSo when reading a partitioned dataset, (py)arrow has not much information about the type of this partition column. Currently, the logic is to try to convert the values to ints and otherwise leave as strings, and then those values are converted to a Dictionary type (corresponding to categorical type in pandas). This logic is here: https://github.com/apache/arrow/blob/06fd2da5e8e71b660e6eea4b7702ca175e31f3f5/python/pyarrow/parquet.py#L585-L609\r\n\r\nThere is currently no option to change this. So right now, the workaround is to convert the categorical back to an integer column in pandas.  \r\nBut longer term, we should maybe think about storing the type of the partition keys as metadata, and an option to restore it as a dictionary column or not.\r\n\r\nRelated issues about the type of the partition column: ARROW-3388 (booleans as strings), ARROW-5666 (strings with underscores interpreted as int)"
        },
        {
            "created_at": "2019-08-20T23:26:06.118Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6114?focusedCommentId=16911813) by Wes McKinney (wesm):*\nFixing this is not that easy. If anyone looks at this I would recommend tackling after we've got Python up and running on a C++-based dataset implementation"
        },
        {
            "created_at": "2020-07-08T08:27:59.855Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6114?focusedCommentId=17153345) by Joris Van den Bossche (jorisvandenbossche):*\nOne possibility to look at (although it would only help on the python side, not for inferring the data type of the partition field in C++), is to ensure we store the data type information in the pandas metadata (right now we drop the partition fields from that), so this information can be used on conversion back to pandas (but of course this only helps for roundtrip from/to pandas, not for just pyarrow Table)."
        }
    ]
}