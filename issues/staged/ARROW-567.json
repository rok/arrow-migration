{
    "issue": {
        "title": "[C++] File and stream APIs for interacting with \"large\" schemas",
        "body": "***Note**: This issue was originally created as [ARROW-567](https://issues.apache.org/jira/browse/ARROW-567). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nFor data where the metadata itself is large (> 10000 fields), doing a full in-memory reconstruction of a record batch may be impractical if the user's goal is to do random access on a potentially small subset of a batch. \n\nI propose adding an API that enables \"cheap\" inspection of the record batch metadata and reconstruction of fields. \n\nBecause of the flattened buffer and field metadata, at the moment the complexity of random field access will scale with the number of fields \u2013 in the future we may devise strategies to mitigate this (e.g. storing a pre-computed buffer/field lookup table in the schema)",
        "created_at": "2017-02-18T15:12:50.000Z",
        "updated_at": "2021-06-21T22:40:38.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": []
}