{
    "issue": {
        "title": "[C++] Add support for multi-column sort on Table",
        "body": "***Note**: This issue was originally created as [ARROW-8199](https://issues.apache.org/jira/browse/ARROW-8199). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI'm just coming up to speed with Arrow and am noticing a dearth of examples ... maybe I can help here.\r\n\r\nI'd like to implement multi-column sorting for Tables and just want to ensure that I'm not duplicating existing work or proposing a bad design.\r\n\r\nMy thought was to create a Table-specific version of SortToIndices() where you can specify the columns and sort order.\r\n\r\nThen I'd create Array \"views\" that use the Indices to remap from the original Array values to the values in sorted order. (Original data is not sorted, but could be as a second step.) I noticed some of the array list variants keep offsets, but didn't see anything that supports remapping per a list of indices, but this may just be my oversight?\r\n\r\nThanks in advance, Scott",
        "created_at": "2020-03-24T19:58:24.000Z",
        "updated_at": "2021-03-18T03:46:26.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-11-24T17:32:04.000Z"
    },
    "comments": [
        {
            "created_at": "2020-03-24T20:05:54.200Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17066149) by Wes McKinney (wesm):*\nSorting Tables is a bit complicated on account of chunked arrays. There isn't a multi-column sort implemented but one will eventually need to be implemented. It might be worth soliciting ideas about sorting with chunked data in general on the mailing list (we will need to employ the sorting strategies used by analytic databases which operate on chunks of tables at a time \u2013 there are various open source DBMSs that we can use for inspiration). "
        },
        {
            "created_at": "2020-03-24T22:12:11.952Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17066226) by Scott Wilson (swilson314):*\nThanks Wes. I'm trying to replace portions of my python/pandas ML pipeline with arrow C++. As such, I don't lose anything by not initially being able to support chunked arrays. Does my approach seem reasonable assuming I\u00a0 start with non-chunked arrays? Any suggestions?"
        },
        {
            "created_at": "2020-03-24T23:43:23.414Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17066268) by Wes McKinney (wesm):*\nI don't have particular suggestions. This functionality will eventually find a home in the future \"C++ data frame API\" that has been discussed for addition to the project. \r\n\r\nhttps://docs.google.com/document/d/1XHe_j87n2VHGzEbnLe786GHbbcbrzbjgG8D0IXWAeHg/edit?usp=sharing"
        },
        {
            "created_at": "2020-03-25T01:09:51.059Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17066301) by Scott Wilson (swilson314):*\nAh, that's already helpful. I thought you meant for Table to become the DataFrame replacement, but now I see that's not true. This makes sense given the levels of abstraction I've seen so far in Arrow. Thanks!"
        },
        {
            "created_at": "2020-03-25T01:23:36.934Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17066305) by Wes McKinney (wesm):*\nRight, Table is just a data structure. We definitely are trying to keep the in-memory data structures simple and focused on providing access to the data, so computation will live in different APIs that act on the data structures"
        },
        {
            "created_at": "2020-04-23T17:34:00.078Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17090788) by Scott Wilson (swilson314):*\nHi Wes,\n\nI hope you and yours are staying healthy in this strange new world!\n\nI've taken a stab at creating a DataFrame like cover for arrow::Table. My\nfirst milestone was to see if I could come up with a df.eval() like\nrepresentation for single-line transforms \u2013 see the EVAL2 macro. Attached\nis my code, I'm not quite sure where, if anywhere, I should post it to get\nyour thoughts so I'm sending this email. (I posted an earlier version on\nJira Arrow-602.) Mainly I'd like to know if this looks like the direction\nyou're thinking for arrow::DataFrame?\n\nThanks, Scott\n\n\\*\\*\\*\\* Code, also included as attachment\n\n#include <cstdint>\n#include <memory>\n#include <numeric>\n#include <string>\n#include <iostream>\n#include <optional>\n#include <vector>\n#include <xutility>\n\n#include <arrow/api.h>\n#include <arrow/filesystem/localfs.h>\n#include <arrow/csv/api.h>\n#include <arrow/result.h>\n#include <arrow/builder.h>\n\n#include <boost/iterator/iterator_facade.hpp>\n#include <boost/range/iterator_range.hpp>\n#include <boost/preprocessor.hpp>\n\nusing namespace std;\nusing namespace arrow;\n\n// SBW 2020.04.15 For ArrayCoverRaw::iterator, we can simply use the the\npointer interface.\n// Wes suggests returning std::optional<T>, but sizeof(double) <\nsizeof(std::optional<double>) and\n// is not a drop-in replacement for T, i.e. optional<T> can't be used in\nexpression, need optional<T>.value().\n\n// STL container-like cover for arrow::Array.\n// Only works for Array types that support raw_values().\ntemplate<typename ArrType>\nclass ArrayCoverRaw\n{\npublic:\nusing T = typename ArrType::value_type;\nusing pointer = T\\*;\nusing const_pointer = const T\\*;\nusing reference = T&;\nusing const_reference = const T&;\n// Match size_type to Array offsets rather than using size_t and ptrdiff_t.\nusing size_type = int64_t;\nusing difference_type = int64_t;\nusing iterator = pointer;\nusing const_iterator = const_pointer;\nusing reverse_iterator = pointer;\nusing const_reverse_iterator = const_pointer;\n\nArrayCoverRaw(std::shared_ptr<ArrType>& array) : _array(array) {}\n\nsize_type size() const { return _array->length(); }\n\n// Should non-const versions fail if Array is immutable?\niterator begin() { return const_cast<pointer>(_array->raw_values()); }\niterator end() { return\nconst_cast<pointer>(_array->raw_values()+_array->length()); }\nreverse_iterator rbegin() { return\nconst_cast<pointer>(_array->raw_values()+_array->length()-1); }\nreverse_iterator rend() { return\nconst_cast<pointer>(_array->raw_values()-1); }\nconst_iterator cbegin() const { return _array->raw_values(); }\nconst_iterator cend() const { return _array->raw_values()+_array->length();\n}\nconst_reverse_iterator crbegin() const { return\n_array->raw_values()+_array->length()-1; }\nconst_reverse_iterator crend() const { return _array->raw_values()-1; }\n\n// We could return std::optional<T> to encapsulate IsNull() info, but this\nwould seem to break the expected semantics.\nreference operator[](const difference_type off) {\nassert(_array->data()~~>is_mutable()); return _array~~>raw_values()+off; }\nconst_reference operator[](const difference_type off) const { return\n_array->raw_values()+off; }\n// ISSUE: is there an interface for setting IsNull() if array is mutable.\nbool IsNull(difference_type off) const { return _array->IsNull(off); }\n\nprotected:\nstd::shared_ptr<ArrType> _array;\n};\n\n// TODO: Add ArrayCoverString and iterators, perhaps others.\n\n// Use template on RefType so we can create iterator and const_iterator by\nchanging Value.\n// Use class specializations to support Arrays that don't have raw_values().\ntemplate <typename CType, typename RefType>\nclass ChunkedArrayIterator\n: public boost::iterator_facade<ChunkedArrayIterator<CType, RefType>,\nRefType, boost::random_access_traversal_tag>\n{\npublic:\nusing difference_type = int64_t;\nusing T = CType;\nusing ArrayType = typename CTypeTraits<CType>::ArrayType;\nusing pointer = T\\*;\n\nexplicit ChunkedArrayIterator(std::shared_ptr<arrow::ChunkedArray> ch_arr =\n0, difference_type pos = 0)\n: _ch_arr(ch_arr)\n{\nset_position(pos);\n}\n\nbool IsNull() const\n{\nauto arr = _ch_arr->chunk(_chunk_index);\nreturn arr->IsNull(_current-_first);\n}\n\nprivate:\nfriend class boost::iterator_core_access;\n\n    bool equal(ChunkedArrayIterator<CType, RefType> const& other) const\n    {\n        return this->_position == other._position;\n    }\n\n    void increment()\n{\n_position++;\n// Need to move to next chunk?\nif ((_current == _last) && ((_chunk_index+1) < _ch_arr->num_chunks()))\n{\n_chunk_index++;\nauto arr = _ch_arr->chunk(_chunk_index);\nauto typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_first = const_cast<pointer>(typed_arr->raw_values());\n_last = _first + arr->length() - 1;\n_current = _first;\n}\nelse\n{\n_current++;\n}\n}\n\nvoid decrement()\n{\n_position--;\n// Need to move to previous chunk?\nif ((_current == _first) && (_chunk_index > 0))\n{\n_chunk_index--;\nauto arr = _ch_arr->chunk(_chunk_index);\nauto typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_first = const_cast<pointer>(typed_arr->raw_values());\n_last = _first + arr->length() - 1;\n_current = _last;\n}\nelse\n{\n_current--;\n}\n}\n\n    RefType& dereference() const { return \\*_current; }\n\nvoid advance(difference_type n)\n{\n_position += n;\nwhile (n > 0)\n{\ndifference_type max_delta = _last - _current;\nif ((max_delta >= n) || ((_chunk_index+1) == _ch_arr->num_chunks()))\n{\n_current += n;\nreturn;\n}\n// Move to next chunk.\nn -= max_delta;\n_chunk_index++;\nauto arr = _ch_arr->chunk(_chunk_index);\nauto typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_first = const_cast<pointer>(typed_arr->raw_values());\n_last = _first + arr->length() - 1;\n_current = _first;\n}\nwhile (n < 0)\n{\ndifference_type max_delta = _first - _current;\nif ((max_delta <= n) || (_chunk_index == 0))\n{\n_current += n;\nreturn;\n}\n// Move to previous chunk.\nn -= max_delta;\n_chunk_index--;\nassert(_chunk_index >= 0);\nauto arr = _ch_arr->chunk(_chunk_index);\nauto typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_first = const_cast<pointer>(typed_arr->raw_values());\n_last = _first + arr->length() - 1;\n_current = _last;\n}\n}\n\ndifference_type distance_to(ChunkedArrayIterator<CType, RefType> const&\nother)\n{\nreturn other._position - this->_position;\n}\n\n// Helper\nvoid set_position(difference_type pos)\n{\n_position = pos;\nconst int nchunks = _ch_arr->num_chunks();\nint64_t offset = 0;\nfor (_chunk_index = 0; _chunk_index < nchunks; _chunk_index++)\n{\nauto arr = _ch_arr->chunk(_chunk_index);\nint64_t arr_rows = arr->length();\nif (((offset+arr_rows) > pos) || ((_chunk_index+1)==nchunks))\n{\nauto typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_first = const_cast<T\\*>(typed_arr->raw_values());\n_last = _first + arr_rows - 1;\n_current = _first + (pos-offset);\nreturn;\n}\noffset += arr_rows;\n}\nassert(false);\n}\n\nstd::shared_ptr<arrow::ChunkedArray> _ch_arr;\n// Which Array we're looking at.\nint _chunk_index = 0;\n// Pointers into current Array. Use first/last rather than begin/end for\nsymmetry of moving forward/backward.\npointer _first = 0;\npointer _current = 0;\npointer _last = 0;\n// Cache position across all chunks for support of random access.\ndifference_type _position = 0;\n};\n\n// This implementation is a subclass for Arrays that use GetView(i),\nGetString(i), etc.\n// Concrete subclass only needs to implement dereference(i).\ntemplate <typename CType>\nclass ChunkedArrayIteratorIndexImpl\n{\npublic:\nusing difference_type = int64_t;\nusing ArrayType = typename CTypeTraits<CType>::ArrayType;\n\nexplicit ChunkedArrayIteratorIndexImpl(std::shared_ptr<arrow::ChunkedArray>\nch_arr = 0, difference_type pos = 0)\n: _ch_arr(ch_arr)\n{\nset_position(pos);\n}\n\nbool IsNull() const\n{\nauto arr = _ch_arr->chunk(_chunk_index);\nreturn arr->IsNull(_current);\n}\n\nprotected:\nfriend class boost::iterator_core_access;\n\n    bool equal(ChunkedArrayIteratorIndexImpl<CType> const& other) const\n    {\n        return this->_position == other._position;\n    }\n\n    void increment()\n{\n_position++;\n// Need to move to next chunk?\nif ((_current == _last) && ((_chunk_index+1) < _ch_arr->num_chunks()))\n{\n_chunk_index++;\nauto arr = _ch_arr->chunk(_chunk_index);\n_typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_last = arr->length() - 1;\n_current = 0;\n}\nelse\n{\n_current++;\n}\n}\n\nvoid decrement()\n{\n_position--;\n// Need to move to previous chunk?\nif ((_current == _first) && (_chunk_index > 0))\n{\n_chunk_index--;\nauto arr = _ch_arr->chunk(_chunk_index);\n_typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_last = arr->length() - 1;\n_current = _last;\n}\nelse\n{\n_current--;\n}\n}\n\n    // RefType& dereference() const { return \\*_current; }\n\nvoid advance(difference_type n)\n{\n_position += n;\nwhile (n > 0)\n{\ndifference_type max_delta = _last - _current;\nif ((max_delta >= n) || ((_chunk_index+1) == _ch_arr->num_chunks()))\n{\n_current += n;\nreturn;\n}\n// Move to next chunk.\nn -= max_delta;\n_chunk_index++;\nauto arr = _ch_arr->chunk(_chunk_index);\n_typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_last = arr->length() - 1;\n_current = 0;\n}\nwhile (n < 0)\n{\ndifference_type max_delta = 0 - _current;\nif ((max_delta <= n) || (_chunk_index == 0))\n{\n_current += n;\nreturn;\n}\n// Move to previous chunk.\nn -= max_delta;\n_chunk_index--;\nauto arr = _ch_arr->chunk(_chunk_index);\n_typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_last = arr->length() - 1;\n_current = _last;\n}\n}\n\ndifference_type distance_to(ChunkedArrayIteratorIndexImpl<CType> const&\nother)\n{\nreturn other._position - this->_position;\n}\n\n// Helper\nvoid set_position(difference_type pos)\n{\n_position = pos;\nconst int nchunks = _ch_arr->num_chunks();\nint64_t offset = 0;\nfor (_chunk_index = 0; _chunk_index < nchunks; _chunk_index++)\n{\nauto arr = _ch_arr->chunk(_chunk_index);\nint64_t arr_rows = arr->length();\nif (((offset+arr_rows) > pos) || ((_chunk_index+1)==nchunks))\n{\n_typed_arr = std::static_pointer_cast<ArrayType>(arr);\n_last = arr_rows - 1;\n_current = (pos-offset);\nreturn;\n}\noffset += arr_rows;\n}\nassert(false);\n}\n\nstd::shared_ptr<arrow::ChunkedArray> _ch_arr;\n// Which Array we're looking at.\nint _chunk_index = 0;\n// Current Array. Use first/last rather than begin/end for symmetry of\nmoving forward/backward.\nstd::shared_ptr<ArrayType> _typed_arr;\ndifference_type _current = 0;\ndifference_type _last = 0;\n// Cache position across all chunks for support of random access.\ndifference_type _position = 0;\n};\n\n// SBW 2020.04.23 for EVAL2() macro, even though code not called, need lhs\niterator for unused code branch to compile.\nusing ConstRefString = std::string;\ntemplate<>\nclass ChunkedArrayIterator<std::string, ConstRefString> :\npublic ChunkedArrayIteratorIndexImpl<std::string>,\npublic boost::iterator_facade<ChunkedArrayIterator<std::string,\nConstRefString>, ConstRefString, boost::random_access_traversal_tag>\n{\npublic:\nusing difference_type = int64_t;\nusing RefType = ConstRefString;\n\nexplicit ChunkedArrayIterator(std::shared_ptr<arrow::ChunkedArray> ch_arr =\n0, difference_type pos = 0)\n: ChunkedArrayIteratorIndexImpl(ch_arr, pos)\n{\n}\n\n// Cache value to avoid returning pointer to temp.\n    RefType& dereference() const { _cached =\n_typed_arr->GetString(_current); return _cached; }\n\nprivate:\nmutable std::string _cached;\n};\nusing ChunkedArrayIteratorString = ChunkedArrayIterator<std::string,\nConstRefString>;\n\ntemplate<>\nclass ChunkedArrayIterator<bool, const bool> :\npublic ChunkedArrayIteratorIndexImpl<bool>,\npublic boost::iterator_facade<ChunkedArrayIterator<bool, const bool>, const\nbool, boost::random_access_traversal_tag>\n{\npublic:\nusing difference_type = int64_t;\nusing RefType = const bool;\n\nexplicit ChunkedArrayIterator(std::shared_ptr<arrow::ChunkedArray> ch_arr =\n0, difference_type pos = 0)\n: ChunkedArrayIteratorIndexImpl(ch_arr, pos)\n{\n}\n\n// Cache value to avoid returning pointer to temp.\n    RefType& dereference() const { _cached = _typed_arr->GetView(_current);\nreturn _cached; }\n\nprivate:\nmutable bool _cached;\n};\nusing ChunkedArrayIteratorBoolean = ChunkedArrayIterator<bool, const bool>;\n\n// STL container-like cover for arrow::ChunkedArray.\n// Only works for ChunkedArrays composed of Array types that support\nraw_values().\ntemplate<typename CType>\nclass ChunkedArrayCover\n{\npublic:\n// Match size_type to Array offsets rather than using size_t and ptrdiff_t.\nusing size_type = int64_t;\nusing difference_type = int64_t;\nusing iterator = typename ChunkedArrayIterator<CType, CType>;\nusing const_iterator = typename ChunkedArrayIterator<CType, const CType>;\nusing reverse_iterator = iterator;\nusing const_reverse_iterator = const_iterator;\n\nChunkedArrayCover(std::shared_ptr<ChunkedArray>& array) : _array(array) {}\n\nsize_type size() const { return _array->length(); }\n\n// Should non-const versions fail if Array is immutable?\niterator begin() { return iterator(_array); }\niterator end() { return iterator(_array, size()); }\nreverse_iterator rbegin() { return iterator(_array, size()-1); }\nreverse_iterator rend() { return iterator(_array, -1); }\nconst_iterator cbegin() const { return const_iterator(_array); }\nconst_iterator cend() const { return const_iterator(_array, size()); }\nconst_reverse_iterator crbegin() const { return const_iterator(_array,\nsize()-1); }\nconst_reverse_iterator crend() const { return const_iterator(_array, -1); }\n\nprotected:\nstd::shared_ptr<ChunkedArray> _array;\n};\n\n#if 0 // SBW 2020.04.23 No longer needed no that we're using ContRefString\n= std::string.\ntemplate<>\nclass ChunkedArrayCover<std::string>\n{\npublic:\nusing CType = std::string;\nusing size_type = int64_t;\nusing difference_type = int64_t;\n// ISSUE: no specialization for ChunkedArrayIterator<std::string,\nstd::string>\n// Not sure how to handle setting of std::string values since StringArray\ndoesn't provide LHS access.\nusing iterator = typename ChunkedArrayIterator<CType, const CType>;\nusing const_iterator = typename ChunkedArrayIterator<CType, const CType>;\nusing reverse_iterator = iterator;\nusing const_reverse_iterator = const_iterator;\n\nChunkedArrayCover(std::shared_ptr<ChunkedArray>& array) : _array(array) {}\n\nsize_type size() const { return _array->length(); }\n\n// Should non-const versions fail if Array is immutable?\niterator begin() { return iterator(_array); }\niterator end() { return iterator(_array, size()); }\nreverse_iterator rbegin() { return iterator(_array, size()-1); }\nreverse_iterator rend() { return iterator(_array, -1); }\nconst_iterator cbegin() const { return const_iterator(_array); }\nconst_iterator cend() const { return const_iterator(_array, size()); }\nconst_reverse_iterator crbegin() const { return const_iterator(_array,\nsize()-1); }\nconst_reverse_iterator crend() const { return const_iterator(_array, -1); }\n\nprotected:\nstd::shared_ptr<ChunkedArray> _array;\n};\n#endif\n\nstruct TestFrame\n{\nTestFrame(std::shared_ptr<arrow::Table> table = nullptr) : _table(table)\n{\n}\n\nauto find_column(const char\\* name) { return _table->GetColumnByName(name); }\n\ntemplate<typename CType> typename ChunkedArrayCover<CType>::iterator\nbegin(const char\\* name)\n{\nauto col = _table->GetColumnByName(name);\nassert(col != nullptr);\nChunkedArrayCover<CType> cover(col);\nreturn cover.begin();\n}\ntemplate<typename CType> typename ChunkedArrayCover<CType>::iterator\nend(const char\\* name)\n{\nauto col = _table->GetColumnByName(name);\nassert(col != nullptr);\nChunkedArrayCover<CType> cover(col);\nreturn cover.end();\n}\n// Append to end if Index==-1.\ntemplate<typename CType> bool add_column(const char\\* name, int Index = -1)\n{\nvector<CType> values(_table->num_rows());\nreturn add_column(name, values, Index);\n}\ntemplate<typename CType> bool add_column(const char\\* name, const\nvector<CType>& values, int Index = -1)\n{\nusing Builder = typename CTypeTraits<CType>::BuilderType;\nassert(values.size() == _table->num_rows());\nBuilder builder;\nbuilder.Resize(values.size());\nbuilder.AppendValues(values);\nshared_ptr<arrow::Array> array;\narrow::Status st = builder.Finish(&array);\nauto ch_arr = std::make_shared<ChunkedArray>(array);\nauto field = arrow::field(name, builder.type());\n// Watch for existing name and delete if necessary.\nint icol = _table->schema()->GetFieldIndex(name);\nif (icol >= 0)\n{\nstd::shared_ptr<arrow::Table> out;\n_table->RemoveColumn(icol, &out);\n_table = out;\n}\nstd::shared_ptr<arrow::Table> out;\nif (Index < 0)\nIndex = _table->num_columns();\nst = _table->AddColumn(Index, field, ch_arr, &out);\nif (st.ok())\n{\n_table = out;\nreturn true;\n}\nreturn false;\n}\n\nstd::shared_ptr<arrow::Table> _table;\n};\n\n// Generalizing std::transform() to take any number of input iterators.\n//\nhttps://medium.com/@vgasparyan1995/generalizing-std-transform-8d2c41e1f958\n// https://github.com/vgasparyan1995/transform\n#include \"F:\\Dev\\transform-master\\transform.h\"\n\n// Use BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__)\n// Use BOOST_PP_SEQ_FOR_EACH_I twice, once to build list of input\niterators, once to build arg list for lambda.\n// Use BOOST_PP_TUPLE_ELEM to pull values out of tuple.\n\n#define DF_INPUT_ITER(r, data, i, elem) \\\ndata.begin<BOOST_PP_TUPLE_ELEM(2, 0,\nelem)>(BOOST_PP_STRINGIZE(BOOST_PP_TUPLE_ELEM(2, 1, elem))) \\\n, \\\nBOOST_PP_IF(i, , data.end<BOOST_PP_TUPLE_ELEM(2, 0,\nelem)>(BOOST_PP_STRINGIZE(BOOST_PP_TUPLE_ELEM(2, 1, elem)))) \\\nBOOST_PP_COMMA_IF(BOOST_PP_NOT(i))\n\n#define LAMBDA_INPUT(r, data, i, elem) \\\nBOOST_PP_COMMA_IF(i) \\\nauto BOOST_PP_TUPLE_ELEM(2, 1, elem)\n\n// Variable args are input 2-tuples (type, name).\n// Initially used BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__), but I think this\nis clearer to add inputs as pp_sequence.\n// Function signature: transform(in1.begin(), in1.end(), in2.begin() ...\ninN.begin(), dest.begin(), lambda).\n#define EVAL2(df, dest_tuple, func_body, input_seq) \\\n{ \\\nusing dest_type = BOOST_PP_TUPLE_ELEM(2, 0, dest_tuple); \\\nconst char\\* dest_name = BOOST_PP_STRINGIZE(BOOST_PP_TUPLE_ELEM(2, 1,\ndest_tuple)); \\\nif (is_number_type<CTypeTraits<dest_type>::ArrowType>::value) \\\n{ \\\nif (df.find_column(dest_name) == nullptr) \\\ndf.add_column<dest_type>(dest_name); \\\nmy::transform( \\\nBOOST_PP_SEQ_FOR_EACH_I(DF_INPUT_ITER, df, input_seq) \\\ndf.begin<dest_type>(dest_name) , \\\n[] (BOOST_PP_SEQ_FOR_EACH_I(LAMBDA_INPUT, df, input_seq)) func_body ); \\\n} \\\nelse \\\n{ \\\nusing Builder = typename CTypeTraits<dest_type>::BuilderType; \\\nvector<dest_type> dest(df._table->num_rows()); \\\nmy::transform( \\\nBOOST_PP_SEQ_FOR_EACH_I(DF_INPUT_ITER, df, input_seq) \\\ndest.begin() , \\\n[] (BOOST_PP_SEQ_FOR_EACH_I(LAMBDA_INPUT, df, input_seq)) func_body ); \\\ndf.add_column<dest_type>(dest_name, dest); \\\n} \\\n}\n\n\nint main(int argc, char \\*argv[])\n{\nauto fs = make_shared<fs::LocalFileSystem>();\nauto r_input = fs->OpenInputStream(\"c:/temp/_DatasetP14Seizures.csv\");\n\nauto pool = default_memory_pool();\nauto read_options = arrow::csv::ReadOptions::Defaults();\nauto parse_options = arrow::csv::ParseOptions::Defaults();\nauto convert_options = arrow::csv::ConvertOptions::Defaults();\n\nauto r_table_reader = csv::TableReader::Make(pool, r_input.ValueOrDie(),\nread_options, parse_options, convert_options);\nauto r_read = r_table_reader.ValueOrDie()->Read();\nauto p_table = r_read.ValueOrDie();\n\nPrettyPrintOptions options{0};\narrow::PrettyPrint(\\*p_table, options, &std::cout);\n\n// Test covers and iterators.\nconst Table& tlb = \\*p_table;\nconst int64_t rows = tlb.num_rows();\nconst int cols = tlb.num_columns();\nfor (int c = 0; c < cols; c++)\n{\nauto f = tlb.field(c);\nconst string& name = f->name();\nint type_id = f->type()->id();\nauto ch_arr = tlb.column(c);\nauto values_buffer = ch_arr->chunk(0)~~>data()~~>buffers[1];\ncout << \"is_mutable: \" << values_buffer->is_mutable() << endl;\nswitch (type_id)\n{\ncase Type::DOUBLE:\n{\n#if 0\nusing iterator = ChunkedArrayIteratorRaw<arrow::DoubleArray, double>;\niterator it(ch_arr, 2);\ncout << it.IsNull() << endl;\nboost::iterator_range<iterator> range(it-2, it+8);\nfor (double val : range)\ncout << val << endl;\n#else\nusing cover = ChunkedArrayCover<double>;\nusing iterator = typename cover::iterator;\nusing range = typename boost::iterator_range<iterator>;\ncover cvr(ch_arr);\nauto begin = cvr.begin();\nauto end = cvr.end();\nauto rbegin = cvr.rbegin();\nauto rend = cvr.rend();\nauto it = begin;\nit += 2;\ncout << \"value_isnull: \" << it.IsNull() << endl;\nrange rng(it-2, it+8);\nfor (double val : rng)\ncout << val << endl;\n#endif\n}\nbreak;\ncase Type::STRING:\n{\nusing iterator = ChunkedArrayIteratorString;\niterator it(ch_arr, 2);\ncout << \"value_isnull: \" << it.IsNull() << endl;\nboost::iterator_range<iterator> range(it-2, it+8);\nfor (const std::string val : range)\ncout << val << endl;\n}\nbreak;\ncase Type::BOOL:\n{\nusing iterator = ChunkedArrayIteratorBoolean;\niterator it(ch_arr, 2);\ncout << \"value_isnull: \" << it.IsNull() << endl;\nboost::iterator_range<iterator> range(it-2, it+8);\nfor (bool val : range)\ncout << val << endl;\n}\nbreak;\n\ndefault:\nbreak;\n}\n}\n\n// 1 cout << is_number_type<CTypeTraits<double>::ArrowType>::value << endl;\n// 1 cout << is_number_type<CTypeTraits<int>::ArrowType>::value << endl;\n// 0 cout << is_number_type<CTypeTraits<bool>::ArrowType>::value << endl;\n// 0 cout << is_number_type<CTypeTraits<std::string>::ArrowType>::value <<\nendl;\n\n// Testing code, to check templates.\nif (false)\n{\nTestFrame df;\nauto beg = df.begin<double>(\"foo\");\nEVAL2(df, (double, dest), { return foo\\*foo; }, ((double, foo)));\nEVAL2(df, (double, dest), { return foo\\*foo; }, ((double,\nfoo))((std::string, name)));\n}\n\nif (true)\n{\nTestFrame df(p_table);\nauto beg = df.begin<double>(\"Duration\");\nEVAL2(df, (double, LogDur), { return log10(Duration); }, ((double,\nDuration)));\nEVAL2(df, (std::string, Length), { return (LogDur>3) ? \"long\" : \"short\"; },\n((double, LogDur)));\narrow::PrettyPrint(\\*df._table, options, &std::cout);\n}\n\nreturn 1;\n}\n\n\n\n\n\u2013 \nScott B. Wilson\nChairman and Chief Scientist\nPersyst Development Corporation\n420 Stevens Avenue, Suite 210\nSolana Beach, CA 92075\n"
        },
        {
            "created_at": "2020-04-23T17:46:19.003Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17090795) by Wes McKinney (wesm):*\n> Mainly I'd like to know if this looks like the direction you're thinking for arrow::DataFrame?\r\n\r\nNo, to be honest from a glance it's a different direction from what I've been thinking. My thoughts there actually are for the data frame internally to be a mix of yet-to-be-scanned Datasets (e.g. from CSV or Parquet files), manifest (materialized in-memory) chunked arrays, and unevaluated expressions. Analytics requests translate requests into physical query plans to be executed by the to-be-developed query engine. I haven't been able to give this my full attention since writing the design docs last year but I intend to spend a large fraction of my time on it the rest of the year.\r\n\r\nThe reasoning for wanting to push data frame operations into a query engine is to get around the memory use issues and performance problems associated with \"eager evaluation\" data frame libraries like pandas (for example, a join in pandas materializes the entire joined data frame in memory). There are similar issues around sorting (particular with the knowledge of what you want to do with the sorted data \u2013 e.g. sort followed by a slice can be executed as a Top-K operation for substantially less memory use)\r\n\r\nThat said, I know a number of people have expressed interest in having STL interface layers in Arrow to the data structures. This would be a valuable thing to contribute to the project. It's not mutually exclusive with the stuff I wrote above but wanted to give some idea "
        },
        {
            "created_at": "2020-04-23T18:06:00.099Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17090811) by Scott Wilson (swilson314):*\nAh. That will be very cool. Thanks for your feedback. I\u2019ll continue with\nthis approach, we\u2019re moving our ML pipeline from python to c++, until yours\nmaterializes.\n\nOn Thu, Apr 23, 2020 at 10:47 AM Wes McKinney (Jira) <jira@apache.org>\n\n\u2013 \nSent from Gmail Mobile\n"
        },
        {
            "created_at": "2020-09-08T20:41:00.136Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17192466) by Scott Wilson (swilson314):*\nHey Wes,\n\nI hope you and yours are doing well in this strange time.\n\nI'm just writing to thank you for all the work you did on Arrow and the\nvarious discussions you've posted about the design decisions that drove\nthis development, post pandas. I've largely completed my C++ DataFrame and\nreplaced python/pandas code that we use for our ML pipeline. Using the\nArrow framework, I've been able to create a DataFrame object that wraps one\nor more arrow tables. The implementation supports no-copy subsets, joins\nand concatenations, and stl-like iterators. Also supported are transforms\nusing in-place lambda functions. The net is that a ~1 TB data processing\nstep that used to take 13 h now requires 15 m.\n\nThe only kluge I put into place has to do with support for null values. I\nallow in-place editing of values, but no changes to array sizes or types.\nThis is possible because the typed arrays offer access to the underlying\nraw values. To offer the same for null values I had to create derived\nclasses for Array and ChunkedArray offer access to the cached null_counts.\n\nI've attached the DataFrame header in case it's of interest.\n\nThanks again, Scott\n\n\n\n\n\u2013 \nScott B. Wilson\nChairman and Chief Scientist\nPersyst Development Corporation\n420 Stevens Avenue, Suite 210\nSolana Beach, CA 92075\n"
        },
        {
            "created_at": "2020-09-09T13:33:23.401Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17192873) by Wes McKinney (wesm):*\nThat's great news. Thanks for attaching the code \u2013 if you apply an open source license to it (like Apache 2.0) then others may be able to reuse parts of it. "
        },
        {
            "created_at": "2020-09-09T16:48:00.145Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17193028) by Scott Wilson (swilson314):*\nIs there a way it could become part of the Apache Arrow project?\n\n\n\n\n\u2013 \nScott B. Wilson\nChairman and Chief Scientist\nPersyst Development Corporation\n420 Stevens Avenue, Suite 210\nSolana Beach, CA 92075\n"
        },
        {
            "created_at": "2020-09-09T16:59:53.893Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17193036) by Wes McKinney (wesm):*\nSure, it would need to be contributed at least as pull request \u2013 depending on discussions on the mailing list about the origins of the software, since it was externally-developed we might need to obtain a software grant from your company. Then there is the question of \"productionizing\" it \u2013 conforming it to the code style of the project and writing unit tests. \r\n\r\nFor what it's worth, people have a lot of different expectations when they hear \"data frame\", and realistically we may end up with different kinds of data frame interfaces. From what I can see in the code, this is different than what I've proposed in https://docs.google.com/document/d/1XHe_j87n2VHGzEbnLe786GHbbcbrzbjgG8D0IXWAeHg/edit#heading=h.g70gstc7jq4h but have not been able to do any development on personally. I'm not personally able to invest time in this project in the near term unfortunately. "
        },
        {
            "created_at": "2020-09-10T16:47:00.141Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17193718) by Scott Wilson (swilson314):*\nOk, thanks! Seems like a fair amount of work without a really compelling\nreason....\n\n\n\n\n\u2013 \nScott B. Wilson\nChairman and Chief Scientist\nPersyst Development Corporation\n420 Stevens Avenue, Suite 210\nSolana Beach, CA 92075\n"
        },
        {
            "created_at": "2020-11-24T17:32:04.332Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8199?focusedCommentId=17238276) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 8612\n<https://github.com/apache/arrow/pull/8612>"
        }
    ]
}