{
    "issue": {
        "title": "[Python] add option for taking all columns from all files in pa.dataset",
        "body": "***Note**: This issue was originally created as [ARROW-9455](https://issues.apache.org/jira/browse/ARROW-9455). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIn PyArrow's dataset class, if I give it multiple parquet files in a list and these parquet files have potentially different columns, it will always take the schema from the first parquet file in the list, thus ignoring columns that the first file doesn't have. Getting all columns within the files into the same dataset implies passing a manual schema or constructing one by iterating over the files and checking for their columns.\r\n\r\n\u00a0\r\n\r\nWould be nicer if PyArrow's dataset class could have an option to automatically take all columns within the files from which it is constructed.\r\n```java\n\r\nimport numpy as np, pandas as pd\r\ndf1 = pd.DataFrame({\r\n    \"col1\" : np.arange(10),\r\n    \"col2\" : np.random.choice([\"a\", \"b\"], size=10)\r\n})\r\ndf2 = pd.DataFrame({\r\n    \"col1\" : np.arange(10, 20),\r\n    \"col3\" : np.random.random(size=10)\r\n})\r\ndf1.to_parquet(\"df1.parquet\")\r\ndf2.to_parquet(\"df2.parquet\")\n```\r\n```java\n\r\nimport pyarrow.dataset as pds\r\nff = [\"df1.parquet\", \"df2.parquet\"]\n```\r\n```java\n\r\n### Code below will generate a DF with col1 and col2, but no col3\n```\r\n```java\n\r\npds.dataset(ff, format=\"parquet\").to_table().to_pandas()\r\n```\r\n\u00a0\r\n\r\n\u00a0",
        "created_at": "2020-07-14T07:09:59.000Z",
        "updated_at": "2020-07-14T08:21:03.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-07-14T08:21:03.000Z"
    },
    "comments": [
        {
            "created_at": "2020-07-14T08:20:45.067Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9455?focusedCommentId=17157213) by Joris Van den Bossche (jorisvandenbossche):*\n`[~david-cortes]` thanks for the report!\r\n\r\nYes, currently the schema is inferred from the 'first' file, and you can only override this by providing the full schema manually. \r\n\r\nThere are however options to specify the number of files/fragments to infer from, or to infer from all files. This functionality already exists in C++, but is not yet exposed in Python. See ARROW-8221 for that. \r\n\r\nClosing as a duplicate of ARROW-8221, but feedback on that issue on a good API for this is very welcome!"
        }
    ]
}