{
    "issue": {
        "title": "[C++] Ability to skip CSV footer when reading in dataset",
        "body": "***Note**: This issue was originally created as [ARROW-15254](https://issues.apache.org/jira/browse/ARROW-15254). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIn ARROW-15252 a user reports wanting to be able to skip the final row of a CSV (the footer) when reading in a dataset of CSVs - is this possible to implement?",
        "created_at": "2022-01-05T13:41:47.000Z",
        "updated_at": "2022-01-05T15:26:29.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-01-05T13:43:37.379Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15254?focusedCommentId=17469320) by Antoine Pitrou (apitrou):*\nApparently Pandas has that option (see `skipfooter` in https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)."
        },
        {
            "created_at": "2022-01-05T13:56:19.754Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15254?focusedCommentId=17469324) by Antoine Pitrou (apitrou):*\nI think this is going to be difficult to implement. CSV files are read in a streaming fashion, with possibly parallel processing of file blocks. So, say the user asks to skip 10 rows at the footer, but the last block being read only has 5 rows, how do we handle that situation?\r\n\r\ncc `[~westonpace]` for ideas."
        },
        {
            "created_at": "2022-01-05T15:26:29.571Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15254?focusedCommentId=17469382) by Weston Pace (westonpace):*\nYes, that would be a difficult situation to handle, especially since we have no control over the size of the last block.\r\n\r\nOne thing we might be able to do is check the file size up front so we always know how many bytes are remaining.  Then we could change our chunking logic so that instead of a small trailing final block we have an overly large final block which is always `>= block_size && < 2*block_size`.  Then we could simply throw an error if we encounter a file where the footer is larger than the block size.  There is no way to check this at reader creation time since footer size is \"# of lines\" and block size is \"# of bytes\" but I imagine the situation would be quite rare.\r\n\r\nIt would add some complexity but it shouldn't have much impact on performance.  Although it would add a touch of latency because we'd need to query for the file size.  CSV blocks are typically small enough that having a slightly too large footer block shouldn't be a problem."
        }
    ]
}