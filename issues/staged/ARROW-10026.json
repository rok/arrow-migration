{
    "issue": {
        "title": "[C++] Improve kernel performance on small batches",
        "body": "***Note**: This issue was originally created as [ARROW-10026](https://issues.apache.org/jira/browse/ARROW-10026). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIt seems that invoking some kernels on smallish batches has quite an overhead:\r\n```Java\n\r\nArrayArrayKernel<Add, Int32Type>/32768/100                      2860 ns         2859 ns       245195 bytes_per_second=10.6727G/s items_per_second=2.86494G/s null_percent=1 size=32.768k\r\nArrayArrayKernel<Add, Int32Type>/32768/0                        2752 ns         2751 ns       249316 bytes_per_second=11.093G/s items_per_second=2.97775G/s null_percent=0 size=32.768k\r\nArrayArrayKernel<Add, Int32Type>/524288/100                    18633 ns        18630 ns        36548 bytes_per_second=26.2097G/s items_per_second=7.03561G/s null_percent=1 size=524.288k\r\nArrayArrayKernel<Add, Int32Type>/524288/0                      18260 ns        18257 ns        38245 bytes_per_second=26.7451G/s items_per_second=7.17933G/s null_percent=0 size=524.288k\r\n```\r\n\r\nWe should investigate and try to lighten the overhead.",
        "created_at": "2020-09-16T18:37:17.000Z",
        "updated_at": "2022-06-06T15:59:34.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: task"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-09-16T18:38:02.902Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10026?focusedCommentId=17197182) by Antoine Pitrou (apitrou):*\ncc [~frank.du]"
        },
        {
            "created_at": "2020-09-16T19:35:04.703Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10026?focusedCommentId=17197202) by Wes McKinney (wesm):*\nI haven't spent much time looking at microperformance in the kernel execution machinery. There is a separate JIRA about adding benchmarks for a no-op / no-allocation kernel so that we can measure the execution overhead more precisely. "
        },
        {
            "created_at": "2020-09-17T01:59:08.106Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10026?focusedCommentId=17197321) by Frank Du (frank.du):*\nHotspot for L1 size:\r\n```java\n\r\n  48.92%  libarrow.so.200.0.0                        [.] arrow::compute::internal::applicator::ScalarBinary<arrow::Int64Type, arrow::Int64Type, arrow::Int64Type, arrow::compute::internal\r\n   2.81%  arrow-compute-scalar-arithmetic-benchmark  [.] mpark::detail::visitation::base::make_fmatrix_impl<mpark::detail::dtor&&, mpark::detail::base<(mpark::detail::Trait)1, decltype(n\r\n   2.66%  libc-2.31.so                               [.] malloc\r\n   2.54%  libpthread-2.31.so                         [.] __pthread_mutex_trylock\r\n   2.28%  libarrow.so.200.0.0                        [.] arrow::ArrayData::Slice\r\n   1.55%  libarrow.so.200.0.0                        [.] mpark::detail::visitation::base::make_fdiagonal_impl<mpark::detail::assignment<mpark::detail::traits<decltype(nullptr), std::shar\r\n   1.48%  libarrow.so.200.0.0                        [.] arrow::compute::KernelSignature::MatchesInputs\r\n   1.39%  libpthread-2.31.so                         [.] __pthread_mutex_unlock\r\n   1.33%  libarrow.so.200.0.0                        [.] arrow::compute::detail::ScalarExecutor::Execute\r\n   1.23%  libarrow_testing.so.200.0.0                [.] std::vector<std::shared_ptr<arrow::Buffer>, std::allocator<std::shared_ptr<arrow::Buffer> > >::~vector\r\n```\r\nHotspot for L2 size:\r\n```java\n\r\n  78.21%  libarrow.so.200.0.0                        [.] arrow::compute::internal::applicator::ScalarBinary<arrow::Int64Type, arrow::Int64Type, arrow::Int64Type, arrow::compute::internal\r\n   0.93%  libarrow.so.200.0.0                        [.] arrow::internal::(anonymous namespace)::BitmapOp<std::bit_and>\r\n   0.87%  [kernel]                                   [k] mwait_idle_with_hints.constprop.0\r\n   0.82%  libpthread-2.31.so                         [.] __pthread_mutex_trylock\r\n   0.80%  arrow-compute-scalar-arithmetic-benchmark  [.] mpark::detail::visitation::base::make_fmatrix_impl<mpark::detail::dtor&&, mpark::detail::base<(mpark::detail::Trait)1, decltype(n\r\n   0.73%  libc-2.31.so                               [.] malloc\r\n   0.69%  [kernel]                                   [k] io_serial_out\r\n   0.64%  [kernel]                                   [k] io_serial_in\r\n   0.56%  libarrow.so.200.0.0                        [.] arrow::compute::KernelSignature::MatchesInputs\r\n   0.54%  libarrow.so.200.0.0                        [.] arrow::compute::detail::ScalarExecutor::Execute\r\n   0.43%  libarrow.so.200.0.0                        [.] arrow::ArrayData::Slice\r\n```\r\nMany additional overhead on benchmark itself for small batch.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2020-09-17T15:03:05.800Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10026?focusedCommentId=17197739) by Wes McKinney (wesm):*\nIMHO we should consider a slimmed down data structure for the implementation of `ExecBatch` that does not use `arrow::util::variant`, considering that we only ever will have either `ArrayData` or `Scalar` as value types. The overhead of slicing `ArrayData` objects is also non-trivial"
        },
        {
            "created_at": "2020-09-18T08:00:47.530Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10026?focusedCommentId=17198197) by Frank Du (frank.du):*\nSeems most batch for\u00a0ArrayData now is exactly a copy of current, worth to add a check before Slice?\u00a0\r\n\r\nPer perf, no\u00a0Slice anymore for scalar-arithmetic-benchmark, and the data improved slightly(3%)\r\n```java\n\r\ndiff --git a/cpp/src/arrow/compute/exec.cc b/cpp/src/arrow/compute/exec.cc\r\nindex 435d7dd74..7c33a7198 100644\r\n--- a/cpp/src/arrow/compute/exec.cc\r\n+++ b/cpp/src/arrow/compute/exec.cc\r\n@@ -171,7 +171,12 @@ bool ExecBatchIterator::Next(ExecBatch* batch) {\r\n     if (args_[i].is_scalar()) {\r\n       batch->values[i] = args_[i].scalar();\r\n     } else if (args_[i].is_array()) {\r\n-      batch->values[i] = args_[i].array()->Slice(position_, iteration_size);\r\n+      if (position_ || iteration_size != length_) {\r\n+        batch->values[i] = args_[i].array()->Slice(position_, iteration_size);\r\n+      } else {\r\n+        batch->values[i] = args_[i].array();\r\n+      }\r\n     } else {\r\n       const ChunkedArray& carr = *args_[i].chunked_array();\r\n       const auto& chunk = carr.chunk(chunk_indexes_[i]);\r\n\r\n```"
        },
        {
            "created_at": "2020-09-18T23:14:26.516Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10026?focusedCommentId=17198579) by Wes McKinney (wesm):*\nThat seems like a good start. I'd like to look at writing a patch to use a simpler data structure that doesn't involve a variant nor heap-allocating `ArrayData` objects. See for example the `PrimitiveArg` data structure that is being used in the selection kernels\r\n\r\nhttps://github.com/apache/arrow/blob/d0f3b5f3c74f67c7ca941c98bd60148e9a9e94f0/cpp/src/arrow/compute/kernels/util_internal.h#L30\r\n\r\nIt seems like some evolved version of that which satisfies the needs of kernels would make sense. "
        },
        {
            "created_at": "2020-10-22T16:43:45.406Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10026?focusedCommentId=17219157) by Antoine Pitrou (apitrou):*\nSo, on `ArrayArrayKernel<Add, Int64Type>/32768/100`, we've got roughly:\r\n- 50% CPU time spent on the kernel execution itself\n- 8% on `FunctionExecutorImpl::BindArgs`\n- 13% on `ScalarExecutor::SetupPreallocation` (including 12% for `FunctionExecutorImpl::PrepareOutput`)\n- 3.5% on `PropagateNulls`\n- 2.75% on `ExecBatchIterator::Next`\n- 8% on `~Datum` (including 5% in the jemalloc deallocator)\n- a ton of other smaller things\n"
        }
    ]
}