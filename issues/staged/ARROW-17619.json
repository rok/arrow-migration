{
    "issue": {
        "title": "[C++][Parquet] Add DELTA_BYTE_ARRAY encoder to Parquet writer",
        "body": "***Note**: This issue was originally created as [ARROW-17619](https://issues.apache.org/jira/browse/ARROW-17619). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nPARQUET-492 added DELTA_BYTE_ARRAY decoder, but we don't have an encoder.",
        "created_at": "2022-09-05T16:17:45.000Z",
        "updated_at": "2022-10-07T04:27:15.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Parquet",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-09-07T15:32:48.944Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17619?focusedCommentId=17601361) by Ian Cook (icook):*\n`[~rokm]` \u00a0how do you think we would we would expose an option for whether to apply the DELTA_BYTE_ARRAY encoder when writing column(s) to Parquet? Do you think it would be in the same way we expose the option for dictionary encoding, e.g. [here](https://arrow.apache.org/docs/python/parquet.html#compression-encoding-and-file-compatibility) in PyArrow?"
        },
        {
            "created_at": "2022-09-08T20:18:44.524Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17619?focusedCommentId=17602000) by Rok Mihevc (rokm):*\n`[~icook]` yes I believe so.\r\nWhile we already have the decoder we would need to implement the encoder for this to work though."
        },
        {
            "created_at": "2022-09-12T11:21:21.631Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17619?focusedCommentId=17603050) by Joris Van den Bossche (jorisvandenbossche):*\nThere is actually already a `column_encoding` option in pyarrow's write_table (just `encoding` on the C++ side), where you can specify the exact encoding to use per column. So the APIs to expose this as an option are already there (which encoding is used by default, that's something else)"
        }
    ]
}