{
    "issue": {
        "title": "[Python] Regression memory issue when calling pandas.read_parquet",
        "body": "***Note**: This issue was originally created as [ARROW-6059](https://issues.apache.org/jira/browse/ARROW-6059). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI have a ~3MB parquet file with the next schema:\r\n```java\n\r\nbag_stamp: timestamp[ns]\r\ntransforms_[]_.header.seq: list<item: int64>\r\n  child 0, item: int64\r\ntransforms_[]_.header.stamp: list<item: timestamp[ns]>\r\n  child 0, item: timestamp[ns]\r\ntransforms_[]_.header.frame_id: list<item: string>\r\n  child 0, item: string\r\ntransforms_[]_.child_frame_id: list<item: string>\r\n  child 0, item: string\r\ntransforms_[]_.transform.translation.x: list<item: double>\r\n  child 0, item: double\r\ntransforms_[]_.transform.translation.y: list<item: double>\r\n  child 0, item: double\r\ntransforms_[]_.transform.translation.z: list<item: double>\r\n  child 0, item: double\r\ntransforms_[]_.transform.rotation.x: list<item: double>\r\n  child 0, item: double\r\ntransforms_[]_.transform.rotation.y: list<item: double>\r\n  child 0, item: double\r\ntransforms_[]_.transform.rotation.z: list<item: double>\r\n  child 0, item: double\r\ntransforms_[]_.transform.rotation.w: list<item: double>\r\n  child 0, item: double\r\n```\r\n\u00a0If I read it with **pandas.read_parquet()** using pyarrow 0.13.0 all seems fine and it takes no time to load. If I try the same with 0.14.0 or 0.14.1 it takes a lot of time and uses\u00a0~10GB\u00a0of RAM. Many times if I don't have enough available memory it will just be killed OOM. Now, if I use the next code snippet instead it works perfectly with all the versions:\r\n```Java\n\r\nparquet_file = pq.ParquetFile(input_file)\r\ntables = []\r\nfor row_group in range(parquet_file.num_row_groups):\r\n    tables.append(parquet_file.read_row_group(row_group, columns=columns, use_pandas_metadata=True))\r\ndf = pa.concat_tables(tables).to_pandas()\r\n```",
        "created_at": "2019-07-29T10:21:45.000Z",
        "updated_at": "2019-08-07T18:35:53.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-08-07T18:35:53.000Z"
    },
    "comments": [
        {
            "created_at": "2019-07-29T14:39:25.631Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16895309) by Wes McKinney (wesm):*\nCan you provide a sample file that reproduces the issue?"
        },
        {
            "created_at": "2019-07-29T16:05:49.033Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16895397) by Francisco Sanchez (FJ_Sanchez):*\nFor some reason I cannot upload a file here, it always fails. I have uploaded a dummy file here that reproduces the issue: <http://s000.tinyupload.com/index.php?file_id=55835483534116457607>\r\n\r\n\u00a0"
        },
        {
            "created_at": "2019-07-30T13:37:00.942Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16896138) by Olivier Giboin (ggGibs):*\nI confirm a very similar issue:\r\n \\* Context: Reading\u00a0arrow table with pyarrow.parquet.read_table. When using 0.13 no memory error, ~6gb arrow RAM size when loaded, fast read.\r\n \\* Context: Script ran in a VM with ~12gb free RAM, Windows, python3.7.x (conda)\r\n \\* When reading the same parquet file with pyarrow 0.14.1 --> memory error (malloc failed, no more free ram availabe)\r\n \\* Parquet file was generated by pyarrow.parquet.ParquetWriter\r\n\r\n\u00a0\r\n\r\nI can provide full parquet file on secure channel if needed"
        },
        {
            "created_at": "2019-07-30T13:54:11.774Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16896158) by Francisco Sanchez (FJ_Sanchez):*\nI can confirm that in my case I also use pyarrow.parquet.ParquetWriter to build the parquet file, just in case it is relevant to the issue."
        },
        {
            "created_at": "2019-07-30T15:10:59.495Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16896213) by Olivier Giboin (ggGibs):*\n-Btw this issue seems to be linked with https://issues.apache.org/jira/browse/ARROW-6060-\r\n\r\nAfter further testing, I confirmed error occurs regardless use_threads = False/True \u2013> not directly related to ARROW-6060"
        },
        {
            "created_at": "2019-07-30T15:14:52.059Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16896218) by Wes McKinney (wesm):*\nI will try to investigate when I can, but as this software is developed largely by volunteers it's hard to predict how long a fix will take"
        },
        {
            "created_at": "2019-07-30T15:23:11.692Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16896224) by Francisco Sanchez (FJ_Sanchez):*\n`[~ggGibs]` I am not sure it is related to the one you mentioned, initially I also thought that and I tried to pass this argument set to False from the pandas call. It took more time but end up using the same amount of memory. I would think it is more related to ARROW-5965 but I don't have any evidence."
        },
        {
            "created_at": "2019-07-30T15:59:01.381Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16896260) by Olivier Giboin (ggGibs):*\nJust did a test with use_threads = False -~~> same error.\r\n\r\n-~~> correct, different symptoms\u00a0than\u00a0ARROW-6060, but same root cause?\r\n\r\n\u00a0\r\n\r\nInterestingly, the way memory gets allocated during read_table looks different between 0.13 and 0.14.1\r\n\r\nv0.13 - smooth memory allocation (took ~40s to load file). Load successful\r\n\r\n![Memory_profile_0.13_rs.png](https://issues.apache.org/jira/secure/attachment/12976233/Memory_profile_0.13_rs.png)\r\n\r\nv0.14.1 - weird spiky memory allocation (shown here with use_threads = False - gets spikier when switching to True)\r\n\r\nLoad failed: I get a malloc error at the end of the command\r\n\r\n![Memory_profile_0.14.1_use_thread_false_rs.png](https://issues.apache.org/jira/secure/attachment/12976234/Memory_profile_0.14.1_use_thread_false_rs.png)"
        },
        {
            "created_at": "2019-08-03T19:58:32.030Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16899521) by Wes McKinney (wesm):*\nI think this is the same underlying cause as ARROW-6060. I traced the issue to the patch for ARROW-3762. We can confirm on this issue once that is resolved"
        },
        {
            "created_at": "2019-08-07T18:35:53.628Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6059?focusedCommentId=16902394) by Wes McKinney (wesm):*\nThis should be resolved with the fix for ARROW-6060. If you can verify from master that would be helpful. If you run into more issues please reopen an issue"
        }
    ]
}