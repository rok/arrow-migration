{
    "issue": {
        "title": "[Python] Segfault when reading parquet files if torch is imported before pyarrow",
        "body": "***Note**: This issue was originally created as [ARROW-3346](https://issues.apache.org/jira/browse/ARROW-3346). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\npyarrow (version 0.10.0) appears to crash sporadically with a segmentation fault when reading parquet files if it is used in a program where torch is imported first.\r\n\r\nA self-contained example is available here: <https://gitlab.com/ostrokach/pyarrow_pytorch_segfault>.\r\n\r\nBasically, running\r\n\r\n`python -X faulthandler -c \"import torch; import pyarrow.parquet as pq; _ = pq.ParquetFile('example.parquet').read_row_group(0)\"`\r\n\r\nsooner or later results in a segfault:\r\n\r\n`Fatal Python error: Segmentation fault`\r\n\r\n`Current thread 0x00007f52959bb740 (most recent call first):`\r\n\r\n`File \"/home/kimlab1/strokach/anaconda/lib/python3.6/site-packages/pyarrow/parquet.py\", line 125 in read_row_group`\r\n `File \"<string>\", line 1 in <module>`\r\n `./test_fail.sh: line 5: 42612 Segmentation fault (core dumped) python -X faulthandler -c \"import torch; import pyarrow.parquet as pq; _ = pq.ParquetFile('example.parquet').read_row_group(0)\"`\r\n\r\nThe number of iterations before a segfault varies, but it usually happens within the first several calls.\r\n\r\nRunning\r\n\r\n`python -X faulthandler -c \"import pyarrow.parquet as pq import torch; _ = pq.ParquetFile('example.parquet').read_row_group(0)\"`\r\n\r\nworks without a problem.",
        "created_at": "2018-09-27T21:04:44.000Z",
        "updated_at": "2022-08-27T14:42:08.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-01-31T16:15:11.000Z"
    },
    "comments": [
        {
            "created_at": "2018-10-19T10:15:13.350Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3346?focusedCommentId=16656581) by Mathieu DESPRIEE (mathieude):*\nsimilar to ARROW-2657 ?"
        },
        {
            "created_at": "2019-01-23T12:51:08.443Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3346?focusedCommentId=16749922) by Jarno Seppanen (jseppanen):*\nI'm seeing this\u00a0with pyarrow 0.12.0 and pytorch 1.0.0.\r\n\r\nCode:\r\n\r\n`import torch`\r\n`import pyarrow.parquet as pq`\r\n`d = pq.read_table('data/train/part-00072-5085765f-c2cb-4669-bf43-815ac1c5e863-c000.snappy.parquet').to_pandas()`\r\n\r\nI got four crashes in five runs:\r\n\r\n`jarno@sp1295:~$ python crash.py `\r\n`Segmentation fault (core dumped)`\r\n`jarno@sp1295:~$ python crash.py `\r\n`Segmentation fault (core dumped)`\r\n`jarno@sp1295:~$ python crash.py `\r\n`Segmentation fault (core dumped)`\r\n`jarno@sp1295:~$ python crash.py `\r\n`jarno@sp1295:~$ python crash.py `\r\n`Segmentation fault (core dumped)`\r\n\r\nBacktrace:\r\n\r\n`(gdb) bt`\r\n`#0 0x00007fffeb589df2 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/torch/lib/libtorch_python.so`\r\n`#1 0x00007fffeb589df5 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/torch/lib/libtorch_python.so`\r\n`#2 0x00007fffa952c39f in parquet::internal::TypedRecordReader<parquet::DataType<(parquet::Type::type)1> >::ReadNewPage() ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libparquet.so.12`\r\n`#3 0x00007fffa9517261 in parquet::internal::RecordReader::ReadRecords(long) ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libparquet.so.12`\r\n`#4 0x00007fffa94feb36 in parquet::arrow::PrimitiveImpl::NextBatch(long, std::shared_ptr<arrow::ChunkedArray>*) ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libparquet.so.12`\r\n`#5 0x00007fffa94f974e in parquet::arrow::ColumnReader::NextBatch(long, std::shared_ptr<arrow::ChunkedArray>*) ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libparquet.so.12`\r\n`#6 0x00007fffa94fbb69 in parquet::arrow::FileReader::Impl::ReadSchemaField(int, std::vector<int, std::allocator<int> > const&, std::shared_ptr<arrow::ChunkedArray>*) () from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libparquet.so.12`\r\n`#7 0x00007fffa94fc01e in parquet::arrow::FileReader::Impl::ReadTable(std::vector<int, std::allocator<int> > const&, std::shared_ptr<arrow::Table>*)::\\{lambda(int)#1}::operator()(int) const () from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libparquet.so.12`\r\n`#8 0x00007fffa94fc182 in std::_Function_handler<arrow::Status (), std::reference_wrapper<std::_Bind_simple<std::reference_wrapper<std::_Bind<parquet::arrow::FileReader::Impl::ReadTable(std::vector<int, std::allocator<int> > const&, std::shared_ptr<arrow::Table>*)::\\{lambda(int)#1} (int)> > ()> > >::_M_invoke(std::_Any_data const&) () from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libparquet.so.12`\r\n`#9 0x00007fffa9895926 in std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<arrow::Status>, std::__future_base::_Result_base::_Deleter>, arrow::Status> >::_M_invoke(std::_Any_data const&) () from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libarrow_python.so.12`\r\n`#10 0x00007fffa9894bbe in std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&) ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libarrow_python.so.12`\r\n`#11 0x00007ffff7bc8a99 in __pthread_once_slow (once_control=0x555556efcaa4, init_routine=0x7fffb4510a1c <std::__once_proxy()>)`\r\n` at pthread_once.c:116`\r\n`#12 0x00007fffa950041c in std::__future_base::_Task_state<std::_Bind<parquet::arrow::FileReader::Impl::ReadTable(std::vector<int, std::allocator<int> > const&, std::shared_ptr<arrow::Table>*)::\\{lambda(int)#1} (int)>, std::allocator<int>, arrow::Status ()>::_M_run() ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libparquet.so.12`\r\n`#13 0x00007fffa9d197b9 in arrow::internal::ThreadPool::WorkerLoop(std::shared_ptr<arrow::internal::ThreadPool::State>, std::_List_iterator<std::thread>) () from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libarrow.so.12`\r\n`#14 0x00007fffa9d1998b in std::thread::_Impl<std::_Bind_simple<arrow::internal::ThreadPool::LaunchWorkersUnlocked(int)::\\{lambda()#1} ()> >::_M_run() () from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libarrow.so.12`\r\n`#15 0x00007fffa9fc1fb0 in execute_native_thread_routine ()`\r\n` from /home/jarno/miniconda3/envs/mlbootcamp/lib/python3.6/site-packages/pyarrow/./libarrow.so.12`\r\n`#16 0x00007ffff7bc16ba in start_thread (arg=0x7fffa061c700) at pthread_create.c:333`\r\n`#17 0x00007ffff78f741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109`"
        },
        {
            "created_at": "2019-01-23T15:55:22.484Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3346?focusedCommentId=16750160) by Wes McKinney (wesm):*\nDid you install pyarrow with pip or conda?"
        },
        {
            "created_at": "2019-01-23T16:52:03.258Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3346?focusedCommentId=16750209) by Jarno Seppanen (jseppanen):*\nwith pip, conda-forge didn't have 0.12 yet"
        },
        {
            "created_at": "2019-01-27T21:21:58.610Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3346?focusedCommentId=16753594) by Uwe Korn (uwe):*\n`[~jseppanen]` and `pytorch`, also with `pip` or did that come though `conda`?\u00a0\r\n\r\nThis looks like the classical libstc++ ABI issue we have seen several times. These problem will probably persist until also the manylinux packages have moved to the new C++ ABI."
        },
        {
            "created_at": "2019-01-31T11:20:23.311Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3346?focusedCommentId=16757142) by Jarno Seppanen (jseppanen):*\nHi, yeah previously I had pyarrow from pip and pytorch from conda which crashed, but now I tested installing both from conda and my three-line script (see above) doesn't crash!\r\n\r\n{{\r\n\r\njarno@sp1295:~$\u00a0conda create -n xyz -c conda-forge -c pytorch python=3.6 pyarrow=0.12 pytorch=1.0\r\njarno@sp1295:~$ source activate xyz\r\n(xyz) jarno@sp1295:~$ python crash.py \r\n(xyz) jarno@sp1295:~$ python crash.py \r\n(xyz) jarno@sp1295:~$ python crash.py\r\n\r\n}}\r\n\r\n\u00a0"
        },
        {
            "created_at": "2019-01-31T16:15:00.046Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3346?focusedCommentId=16757423) by Uwe Korn (uwe):*\n`[~jseppanen]` Thank you for testing. This is sadly an unfixable issue at the moment and the preferred thing is to ensure that all packages with binary code comes from conda(-forge)."
        },
        {
            "created_at": "2022-08-27T14:42:08.512Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3346?focusedCommentId=17586063) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}