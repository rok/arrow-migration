{
    "issue": {
        "title": "[C++] HADOOP_HOME doesn't work to find libhdfs.so",
        "body": "***Note**: This issue was originally created as [ARROW-7841](https://issues.apache.org/jira/browse/ARROW-7841). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI have my env variable setup correctly according to the pyarrow README\r\n```java\n\r\n$ ls $HADOOP_HOME/lib/native\r\nlibhadoop.a  libhadooppipes.a  libhadoop.so  libhadoop.so.1.0.0  libhadooputils.a  libhdfs.a  libhdfs.so  libhdfs.so.0.0.0 \n```\r\nUse the following script to reproduce\r\n```java\n\r\nimport pyarrow\r\npyarrow.hdfs.connect('hdfs://localhost')\n```\r\nWith pyarrow version 0.15.1 it is fine.\r\n\r\nHowever, version 0.16.0 will give error\r\n```java\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 2, in <module>\r\n  File \"/home/jackwindows/anaconda2/lib/python2.7/site-packages/pyarrow/hdfs.py\", line 215, in connect\r\n    extra_conf=extra_conf)\r\n  File \"/home/jackwindows/anaconda2/lib/python2.7/site-packages/pyarrow/hdfs.py\", line 40, in __init__\r\n    self._connect(host, port, user, kerb_ticket, driver, extra_conf)\r\n  File \"pyarrow/io-hdfs.pxi\", line 89, in pyarrow.lib.HadoopFileSystem._connect\r\n  File \"pyarrow/error.pxi\", line 99, in pyarrow.lib.check_status\r\nIOError: Unable to load libhdfs: /opt/hadoop/latest/libhdfs.so: cannot open shared object file: No such file or directory \n```",
        "created_at": "2020-02-12T18:13:49.000Z",
        "updated_at": "2020-03-18T23:13:35.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-02-14T15:52:47.000Z"
    },
    "comments": [
        {
            "created_at": "2020-02-13T15:14:40.318Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7841?focusedCommentId=17036293) by Krisztian Szucs (kszucs):*\n`[~JackWindows]` What are the values for HADOOP_HOME and ARROW_LIBHDFS_DIR environment variables? Arrow tries to load libhdfs.so from `$HADOOP_HOME/libhdfs.so` and `$ARROW_LIBHDFS_DIR/libhdfs.so`. You could try to set ARROW_LIBHDFS_DIR=$HADOOP_HOME/lib/native"
        },
        {
            "created_at": "2020-02-13T17:50:09.318Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7841?focusedCommentId=17036379) by Jack Fan (JackWindows):*\n`[~kszucs]`\r\n> What are the values for HADOOP_HOME and ARROW_LIBHDFS_DIR environment variables?\r\n```java\n\r\n $ echo $HADOOP_HOME\r\n/opt/hadoop/latest\r\n$ echo $ARROW_LIBHDFS_DIR\r\n```\r\n\u00a0\r\n> Arrow tries to load libhdfs.so from\u00a0`$HADOOP_HOME/libhdfs.so`\u00a0and\u00a0`$ARROW_LIBHDFS_DIR/libhdfs.so`\r\nWhy there is a change of behaviour in version 0.16.0?\r\n\r\nAccording to\u00a0<https://arrow.apache.org/docs/python/filesystems.html>, \"`ARROW_LIBHDFS_DIR`\u00a0(optional): explicit location of\u00a0`libhdfs.so`\u00a0if it is installed somewhere other than\u00a0`$HADOOP_HOME/lib/native`.\"\r\n\r\nIMHO it doesn't seem to make sense to try loading from\u00a0$HADOOP_HOME/libhdfs.so."
        },
        {
            "created_at": "2020-02-13T19:24:42.911Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7841?focusedCommentId=17036450) by Krisztian Szucs (kszucs):*\nThis regression was probably introduced with https://github.com/apache/arrow/commit/e12d2851fe60a3628d900f432950dc321db65ff9#diff-29a7b8eebea6dfdb3246dd2b853ba8dcR145\r\n\r\nCould you please try to set either ARROW_LIBHDFS_DIR=$HADOOP_HOME/lib/native to see whether that resolves the issue or not?"
        },
        {
            "created_at": "2020-02-13T19:56:23.198Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7841?focusedCommentId=17036471) by Jack Fan (JackWindows):*\n`[~kszucs]` \u00a0I can confirm that setting `ARROW_LIBHDFS_DIR=$HADOOP_HOME/lib/native`\u00a0solves the issue, but ideally I would like to avoid that.\r\n\r\nIMO I should have a working `pyarrow`\u00a0with a standard HADOOP setup. `ARROW_LIBHDFS_DIR`\u00a0should only be used if I explicitly want to load the `libhdfs.so` from a different location."
        },
        {
            "created_at": "2020-02-14T03:49:44.326Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7841?focusedCommentId=17036673) by Kouhei Sutou (kou):*\nOh, sorry.\r\nI missed the regression.\r\n\r\nI'll fix it."
        },
        {
            "created_at": "2020-02-14T06:55:11.905Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7841?focusedCommentId=17036730) by Krisztian Szucs (kszucs):*\n`[~JackWindows]` Agree, thanks for verifying it!"
        },
        {
            "created_at": "2020-02-14T15:52:47.126Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7841?focusedCommentId=17037076) by Wes McKinney (wesm):*\nIssue resolved by pull request 6424\n<https://github.com/apache/arrow/pull/6424>"
        }
    ]
}