{
    "issue": {
        "title": "[Python] Ability to create partitions when writing to Parquet",
        "body": "***Note**: This issue was originally created as [ARROW-1400](https://issues.apache.org/jira/browse/ARROW-1400). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI'm fairly new to pyarrow so I apologize if this is already a feature, but I couldn't find a solution in the documentation nor an existing issue.  Basically I'm trying to export pandas dataframes to .parquet files with partitions. I can see that pyarrow.parquet has a way of reading .parquet files with partitions, but there's no indication that it can write with partitions. E.g., it would be nice if there was a parameter in pyarrow.Table.write_table() that took a list of columns to partition the table similar to the pyspark implementation: spark.write.parquet's \"partitionBy\" parameter.\n\nReferenced links:\nhttps://arrow.apache.org/docs/python/parquet.html\nhttps://arrow.apache.org/docs/python/parquet.html?highlight=pyarrow%20parquet%20partition",
        "created_at": "2017-08-23T01:02:34.000Z",
        "updated_at": "2017-09-04T02:37:33.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2017-09-04T02:37:33.000Z"
    },
    "comments": [
        {
            "created_at": "2017-08-23T01:48:38.662Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1400?focusedCommentId=16137747) by Wes McKinney (wesm):*\nThis would be a very useful feature. The simplest way to do this in the short term will be to generate the partition scheme from a pandas.DataFrame using pandas operations to split the object into pieces. We should add a function in pyarrow.parquet which enables data to be \"inserted\" into a directory containing a standard Hive-like partition schema. So you could do something like (just spitballing here)\n\n```Java\npq.write_table_to_dataset(dataset_path, partition_keys=keys, **options)\n```\n\nHere dataset_path is a directory, and this will write a new Parquet file in the appropriate location in the subdirectory structure if partition_keys is not None.\n\nA patch would be welcome. I will mark this issue for 0.7.0"
        },
        {
            "created_at": "2017-08-24T06:32:48.282Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1400?focusedCommentId=16139620) by Safyre Anderson (saffrydaffry):*\nSubmitted a pull request (991) for a hot fix: <https://github.com/apache/arrow/pull/991>."
        },
        {
            "created_at": "2017-09-04T02:37:33.910Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1400?focusedCommentId=16152052) by Wes McKinney (wesm):*\nIssue resolved by pull request 991\n<https://github.com/apache/arrow/pull/991>"
        }
    ]
}