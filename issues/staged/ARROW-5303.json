{
    "issue": {
        "title": "[Rust] Add SIMD vectorization of numeric casts",
        "body": "***Note**: This issue was originally created as [ARROW-5303](https://issues.apache.org/jira/browse/ARROW-5303). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nTo improve the performance of cast kernels, we need SIMD support in numeric casts.\r\n\r\nAn initial exploration shows that we can't trivially add SIMD casts between our Arrow T::Simd types, because `packed_simd` only supports a cast between T::Simd types that have the same number of lanes.\r\n\r\nThis means that\u00a0adding casts from f64 to i64 (same lane length) satisfies the bound trait `where TO::Simd : packed_simd::FromCast<FROM::Simd>`, but f64 to i32 (different lane length) doesn't.\r\n\r\nWe would benefit from investigating work-arounds to this limitation. Please see\u00a0[github::nevi_me::arrow/\\{branch:simd-cast}/../kernels/cast.rs\\|[https://github.com/nevi-me/arrow/blob/simd-cast/rust/arrow/src/compute/kernels/cast.rs#L601]] for an example implementation that's limited by the differences in lane length.",
        "created_at": "2019-05-12T06:50:10.000Z",
        "updated_at": "2019-12-29T22:11:22.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Rust",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2019-12-29T22:11:22.000Z"
    },
    "comments": [
        {
            "created_at": "2019-12-09T14:47:13.213Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5303?focusedCommentId=16991657) by Andy Thomason (andy-thomason):*\nIt should be noted that LLVM autovectorisation does a pretty good job of generating SIMD code from cast loops:\r\n\r\n<https://godbolt.org/z/-EUSws>\r\n\r\nThe following loop consumes 32 bytes of u8 and emits 128 bytes of u32 per iteration on znver2 and much more on skylake-avx512 (although this is a stunt). It would be hard to see packed_simd doing any better and in fact may do worse.\r\n\u00a0\r\npub fn cast(dest: &mut [u32], src : &[u8]) {\r\n\u00a0 \u00a0 dest.iter_mut().zip(src.iter()).for_each(|(d, s)| \\*d = \\*s as u32);\r\n}\r\n\u00a0\r\nIn practice, you will be memory bandwidth limited quite quickly, especially as rust (and llvm) do not properly support non-temporal store vectorisation.\r\n\u00a0"
        },
        {
            "created_at": "2019-12-09T17:05:09.787Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5303?focusedCommentId=16991777) by Neville Dipale (nevi_me):*\nHi `[~andy-thomason]`, would null checks in arrays affect the performance? I tried\u00a0<https://godbolt.org/z/JKDXyb>, I don't know asm, so I can't tell from the instructions if there's some optimisation taking place.\r\n\r\nPerhaps instead of always checking if data is null, then appending a null byte, we could run the cast on all values (as null values would still return something), then just apply the null mask? This might only work on casts that don't flow, like going from \\{u|i}X to \\{u|i}Y where X < Y.\r\n\r\nI haven't seen\u00a0other users of Arrow's Rust impl outside of DataFusion, so I don't know if the cast kernel's performance is fine on large enough datasets, or whether this ticket is worth pursuing in the short-term."
        },
        {
            "created_at": "2019-12-10T14:04:22.918Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5303?focusedCommentId=16992584) by Andy Thomason (andy-thomason):*\n\"if\" statements (or match) in loops do not always have a happy ending.\r\n\r\nI would just do the cast, regardless of the validity and copy the null bitmap from the source to the destination. In theory, you should disregard the value of a null data item.\r\n\r\nVec<Option<int_type>> is never going to be efficient as it takes at leas 2n bytes per element because of alignment and has terrible access patterns."
        },
        {
            "created_at": "2019-12-10T14:27:22.624Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5303?focusedCommentId=16992598) by Andy Thomason (andy-thomason):*\nIt can be quite daunting. I'm happy to help with understanding the asm. I spent seven years teaching it to game programmers! I'm also quite old and grew up in a time when you wrote the instructions out by hand in hex.\r\n\r\nMatt's website is a godsend (to use a horrible pun).\r\n```java\n\r\n.LBB0_5:\r\n        vpmovzxbd       ymm0, qword ptr [rdx + rcx]\r\n        vpmovzxbd       ymm1, qword ptr [rdx + rcx + 8]\r\n        vpmovzxbd       ymm2, qword ptr [rdx + rcx + 16]\r\n        vpmovzxbd       ymm3, qword ptr [rdx + rcx + 24]\r\n        vmovdqu ymmword ptr [rdi + 4*rcx], ymm0\r\n        vmovdqu ymmword ptr [rdi + 4*rcx + 32], ymm1\r\n        vmovdqu ymmword ptr [rdi + 4*rcx + 64], ymm2\r\n        vmovdqu ymmword ptr [rdi + 4*rcx + 96], ymm3\r\n        add     rcx, 32\r\n        cmp     rax, rcx\r\n        jne     .LBB0_5\r\n```\r\nThe\u00a0 first instruction \"vpmovzxbd\" loads and converts 8 bytes of u8 to 32 bytes of u32.\r\n\r\nThe second instruction \"vmovdqu\" does an unaligned store of the value to 32 bytes of memory. Note that the index goes up by 8 and 32 in each case.\r\n\r\nThe last two instructions are just the loop management.\r\n\r\nThe instructions themselves have almost zero cost, but writing the data out through the cache could be very expensive.\r\n\r\nThe thing to look for here is lots of ymm or zmm regsiters and counters going up in large increments. You don't need to know every instruction, but this kind of pattern (four loads, four stores, loop) is about as good as it gets.\r\n\r\nThe loads occur in groups of four because there is a large latency on every instruction. We can start lots of them per cycle but it will take many cycles to get the data to RAM. Think of it as a production line with people fetching data from a warehouse and putting it on a conveyor belt and then taking it off and carrying it to another warehouse.\r\n\r\nThe conveyor belts can be quite long, but we can put lots of data on the belt at the same time.\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2019-12-29T22:11:22.605Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5303?focusedCommentId=17005054) by Neville Dipale (nevi_me):*\nWhen we have cast options, we can apply better optimisations rather than SIMD. `packed_simd` also currently makes it difficult to cast between different length numeric data"
        }
    ]
}