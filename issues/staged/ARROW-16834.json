{
    "issue": {
        "title": "Handle impossible conversions in csv.ConvertOptions",
        "body": "***Note**: This issue was originally created as [ARROW-16834](https://issues.apache.org/jira/browse/ARROW-16834). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nhttps://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html#pyarrow.csv.ParseOptions allows for skipping invalid rows by means of the `invalid_row_handler`.\r\n\r\nIn https://arrow.apache.org/docs/python/generated/pyarrow.csv.ConvertOptions.html#pyarrow.csv.ConvertOptions, one can supply a schema to get correct types in the resulting table.\r\nI have a data source that almost always follows a specific schema, but its data isn't validated beforehand. In practice, it's possible for a field which is int16 99.9% of the time to have an out-of-range value in a few rows.\r\n\r\nI'd like to handle those cases similarly to the `invalid_row_handler`, perhaps allowing to set failing conversions to NULL, or supplying a handler to apply a more specific operation.",
        "created_at": "2022-06-15T13:27:10.000Z",
        "updated_at": "2022-06-15T13:27:10.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": []
}