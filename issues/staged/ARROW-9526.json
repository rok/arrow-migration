{
    "issue": {
        "title": "[Python] Memorymapped arrow file conversion to parquet loads everything into RAM",
        "body": "***Note**: This issue was originally created as [ARROW-9526](https://issues.apache.org/jira/browse/ARROW-9526). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen converting a memory mapped arrow file into parquet file, it loads the whole table into RAM. This effectively negates the point of memory mapping.\r\n\r\nIf this is not a bug,\u00a0 perhaps there is a proper way of converting the memorymapped arrow file to parquet without using excessive memory?\r\n\r\n\u00a0\r\n\r\nExample code:\r\n```java\n\r\n    source = pa.memory_map(path_to_arrow_file, 'r')\r\n    table = pa.ipc.RecordBatchFileReader(source).read_all()\r\n# The followlng line will load the whole thing into RAM\r\n    pq.write_table(table, path_to_parquet)\n```",
        "created_at": "2020-07-20T06:25:41.000Z",
        "updated_at": "2020-07-20T08:23:47.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-07-20T08:23:41.137Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9526?focusedCommentId=17161016) by Antoine Pitrou (apitrou):*\nWhen memory mapping a file, it's the OS which makes decisions about whether to keep things in memory. Chances are that, if the file is kept entirely in memory, it simply means there's no other application requesting that memory.\r\n\r\nDo you have reasons to believe something different is happening?"
        }
    ]
}