{
    "issue": {
        "title": "[C++] Validation of ExtensionType with null storage type failing (Can't read empty-but-for-nulls data from Parquet if it has an ExtensionType)",
        "body": "***Note**: This issue was originally created as [ARROW-14522](https://issues.apache.org/jira/browse/ARROW-14522). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHere's a corner case: suppose that I have data with type null, but it can have missing values so the whole array consists of nothing but nulls. In real life, this might only happen inside a nested data structure, at some level where an untyped data source (e.g. nested Python lists) had no entries so a type could not be determined. We expect to be able to write and read this data to and from Parquet, and we can\u2014as long as it doesn't have an ExtensionType.\r\n\r\nHere's an example that works, _without_ ExtensionType:\r\n```python\n\r\n>>> import json\r\n>>> import numpy as np\r\n>>> import pyarrow as pa\r\n>>> import pyarrow.parquet\r\n>>> \r\n>>> validbits = np.packbits(np.ones(14, dtype=np.uint8), bitorder=\"little\")\r\n>>> empty_but_for_nulls = pa.Array.from_buffers(\r\n...     pa.null(), 14, [pa.py_buffer(validbits)], null_count=14\r\n... )\r\n>>> empty_but_for_nulls\r\n<pyarrow.lib.NullArray object at 0x7fb1560bbd00>\r\n14 nulls\r\n>>> \r\n>>> pa.parquet.write_table(pa.table({\"\": empty_but_for_nulls}), \"tmp.parquet\")\r\n>>> pa.parquet.read_table(\"tmp.parquet\")\r\npyarrow.Table\r\n: null\r\n----\r\n: [14 nulls]\r\n```\r\nAnd here's a continuation of that example, which doesn't work because the type `pa.null()` is replaced by `AnnotatedType(pa.null(), \\{\"cool\": \"beans\"})`:\r\n```python\n\r\n>>> class AnnotatedType(pa.ExtensionType):\r\n...     def __init__(self, storage_type, annotation):\r\n...         self.annotation = annotation\r\n...         super().__init__(storage_type, \"my:app\")\r\n...     def __arrow_ext_serialize__(self):\r\n...         return json.dumps(self.annotation).encode()\r\n...     @classmethod\r\n...     def __arrow_ext_deserialize__(cls, storage_type, serialized):\r\n...         annotation = json.loads(serialized.decode())\r\n...         return cls(storage_type, annotation)\r\n... \r\n>>> pa.register_extension_type(AnnotatedType(pa.null(), None))\r\n>>> \r\n>>> empty_but_for_nulls = pa.Array.from_buffers(\r\n...     AnnotatedType(pa.null(), {\"cool\": \"beans\"}),\r\n...     14,\r\n...     [pa.py_buffer(validbits)],\r\n...     null_count=14,\r\n... )\r\n>>> empty_but_for_nulls\r\n<pyarrow.lib.ExtensionArray object at 0x7fb14b5e1ca0>\r\n14 nulls\r\n>>> \r\n>>> pa.parquet.write_table(pa.table({\"\": empty_but_for_nulls}), \"tmp2.parquet\")\r\n>>> pa.parquet.read_table(\"tmp2.parquet\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/jpivarski/miniconda3/lib/python3.9/site-packages/pyarrow/parquet.py\", line 1941, in read_table\r\n    return dataset.read(columns=columns, use_threads=use_threads,\r\n  File \"/home/jpivarski/miniconda3/lib/python3.9/site-packages/pyarrow/parquet.py\", line 1776, in read\r\n    table = self._dataset.to_table(\r\n  File \"pyarrow/_dataset.pyx\", line 491, in pyarrow._dataset.Dataset.to_table\r\n  File \"pyarrow/_dataset.pyx\", line 3235, in pyarrow._dataset.Scanner.to_table\r\n  File \"pyarrow/error.pxi\", line 143, in pyarrow.lib.pyarrow_internal_check_status\r\n  File \"pyarrow/error.pxi\", line 99, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowInvalid: Array of type extension<my:app<AnnotatedType>> has 14 nulls but no null bitmap\r\n```\r\nIf \"nullable type null\" were outside the set of types that should be writable to Parquet, then it would not work for the non-ExtensionType or it would fail on writing, not reading, so I'm quite sure this is a bug.",
        "created_at": "2021-10-29T21:28:25.000Z",
        "updated_at": "2021-12-17T22:01:14.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-12-15T13:52:36.000Z"
    },
    "comments": [
        {
            "created_at": "2021-11-09T10:45:54.113Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14522?focusedCommentId=17441091) by Joris Van den Bossche (jorisvandenbossche):*\n`[~jpivarski]` Thanks for the report!\r\n\r\nWhile trying to replicate this with simplified code (you can create a null array more easily, and an ExtensionArray from its storage array), it seems just creating this array already fails that way:\r\n\r\n```python\n\r\n>>> null_array = pa.array([None] * 14)\r\n>>> ext_type = AnnotatedType(pa.null(), {\"cool\": \"beans\"})\r\n>>> arr = pa.ExtensionArray.from_storage(ext_type, null_array)\r\nTraceback (most recent call last)\r\n~/scipy/repos/arrow/python/pyarrow/array.pxi in pyarrow.lib.ExtensionArray.from_storage()\r\n~/scipy/repos/arrow/python/pyarrow/array.pxi in pyarrow.lib.Array.validate()\r\n~/scipy/repos/arrow/python/pyarrow/error.pxi in pyarrow.lib.check_status()\r\nArrowInvalid: Array of type extension<my:app<AnnotatedType>> has 14 nulls but no null bitmap\r\n```\r\n\r\nAlso doing a full validation of the null extension array you created with `from_buffers` seems to fail (although without `full=True` it does not fail, which is a bit strange):\r\n\r\n```python\n\r\n>>> empty_but_for_nulls.validate(full=True)\r\nTraceback (most recent call last)\r\n~/scipy/repos/arrow/python/pyarrow/array.pxi in pyarrow.lib.Array.validate()\r\n~/scipy/repos/arrow/python/pyarrow/error.pxi in pyarrow.lib.check_status()\r\nArrowInvalid: null_count value (14) doesn't match actual number of nulls in array (0)\r\n```\r\n\r\n"
        },
        {
            "created_at": "2021-11-09T12:53:09.254Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14522?focusedCommentId=17441144) by Joris Van den Bossche (jorisvandenbossche):*\nThere is a second issue here that the way you are creating the null array is using a buffer, while a it is expected that a NullArray has no buffers allocated at all (only stores the length). That trips up the ValidationFull (the second code example in the comment above)\r\n\r\n"
        },
        {
            "created_at": "2021-12-15T13:52:36.013Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14522?focusedCommentId=17459953) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 11650\n<https://github.com/apache/arrow/pull/11650>"
        }
    ]
}