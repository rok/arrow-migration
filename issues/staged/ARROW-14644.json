{
    "issue": {
        "title": "[C++] open_dataset doesn't ignore BOM in csv file",
        "body": "***Note**: This issue was originally created as [ARROW-14644](https://issues.apache.org/jira/browse/ARROW-14644). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nDragosMG: I believe this is a bug that should be fixed in the C++ code as there isn't an option we could leverage on the R side.\r\n\r\nI have draft PR with a failing test, but it's identical to Andy's _reproducible example_ below.\r\n\r\nOriginal description below:\r\n======================\r\nWhen a CSV file starts with byte order mark, `arrow::open_dataset()` reads the file but populates the first column with `NA` values. It appears a similar issue was raised and fixed here: https://issues.apache.org/jira/browse/ARROW-5413. `read_csv_arrow()` deals with the BOM correctly.\r\n\r\nReproducible Example:\r\n```java\n\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\n\r\nwriteLines('\\xef\\xbb\\xbfa,b\\n1,2\\n', con = \"testfile.csv\")\r\n\r\nread_csv_arrow(\"testfile.csv\") # works\r\n#> # A tibble: 1 \u00d7 2\r\n#> a b\r\n#> <int> <int>\r\n#> 1 1 2\r\n\r\nopen_dataset(\"testfile.csv\", format = \"csv\") |> \r\n\u00a0 collect()\r\n#> # A tibble: 1 \u00d7 2\r\n#> a b\r\n#> <int> <int>\r\n#> 1 NA 2 \n```",
        "created_at": "2021-11-09T17:41:15.000Z",
        "updated_at": "2021-12-10T12:41:28.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-12-08T20:48:15.000Z"
    },
    "comments": [
        {
            "created_at": "2021-12-07T00:25:35.377Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14644?focusedCommentId=17454307) by Weston Pace (westonpace):*\n`[~willjones127]` Sorry for the assignment dance.  I hadn't realized you had assigned this as I had earmarked it this morning.  I did a bit of investigation.  I agree it is a C++ issue.  The following python reproduction runs into the same problem:\r\n\r\n```\n\r\nimport pyarrow.csv as csv\r\nimport pyarrow.dataset as ds\r\n\r\nwith open('/tmp/my_dataset/blah.csv', mode='wb') as f:\r\n    f.write(b'\\xef\\xbb\\xbfa,b\\n1,2\\n3,4\\n')\r\n\r\nprint(csv.read_csv('/tmp/my_dataset/blah.csv').to_pydict())\r\ndataset = ds.dataset('/tmp/my_dataset', format='csv')\r\nprint(dataset.to_table().to_pydict())\r\nprint(dataset.to_table())\r\n```\r\n\r\nI had thought that maybe it was a streaming / file reader issue but I tested both the streaming and file readers and they seem to be properly skipping the BOM.  Here are those tests if you want them: https://github.com/apache/arrow/compare/master...westonpace:experiment/ARROW-14644-investigation?expand=1\r\n\r\nHowever, that didn't seem to be the problem either.  So then I thought that maybe it was the fact that the datasets API will specify the schema when reading the data (instead of inferring it) but some initial testing there wasn't very fruitful either.\r\n\r\nSo I'll let you take this, I'm still not quite sure the root cause.  My guess would be that it is still some option getting passed when the reader is called from the datasets API but I don't know which one it would be."
        },
        {
            "created_at": "2021-12-08T20:48:15.578Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14644?focusedCommentId=17455985) by Jonathan Keane (jonkeane):*\nIssue resolved by pull request 11892\n<https://github.com/apache/arrow/pull/11892>"
        }
    ]
}