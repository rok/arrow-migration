{
    "issue": {
        "title": "[Python] Unable to write StructArrays with multiple children to parquet",
        "body": "***Note**: This issue was originally created as [ARROW-2587](https://issues.apache.org/jira/browse/ARROW-2587). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAlthough I am able to read StructArray from parquet, I am still unable to write it back from pa.Table to parquet.\r\n\r\nI get an \"ArrowInvalid: Nested column branch had multiple children\"\r\n\r\nHere is a quick example:\r\n\r\n```\n\r\n\r\nIn [2]: import pyarrow.parquet as pq\r\n\r\nIn [3]: table = pq.read_table('test.parquet')\r\n\r\nIn [4]: table\r\n Out[4]: \r\n pyarrow.Table\r\n weight: double\r\n animal_type: string\r\n animal_interpretation: struct<is_large_animal: bool, is_mammal: bool>\r\n \u00a0 child 0, is_large_animal: bool\r\n \u00a0 child 1, is_mammal: bool\r\n metadata\r\n --------\r\n \\{'org.apache.spark.sql.parquet.row.metadata': '{\"type\":\"struct\",\"fields\":[{\"name\":\"weight\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},\\{\"name\":\"animal_type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"animal_interpretation\",\"type\":{\"type\":\"struct\",\"fields\":[\\\\{\"name\":\"is_large_animal\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},\\\\\\{\"name\":\"is_mammal\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":false,\"metadata\":{}}]}'}\r\n\r\nIn [5]: table.schema\r\n Out[5]: \r\n weight: double\r\n animal_type: string\r\n animal_interpretation: struct<is_large_animal: bool, is_mammal: bool>\r\n \u00a0 child 0, is_large_animal: bool\r\n \u00a0 child 1, is_mammal: bool\r\n metadata\r\n --------\r\n \\{'org.apache.spark.sql.parquet.row.metadata': '{\"type\":\"struct\",\"fields\":[{\"name\":\"weight\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},\\{\"name\":\"animal_type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"animal_interpretation\",\"type\":{\"type\":\"struct\",\"fields\":[\\\\{\"name\":\"is_large_animal\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},\\\\\\{\"name\":\"is_mammal\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":false,\"metadata\":{}}]}'}\r\n\r\nIn [6]: pq.write_table(table,\"test_write.parquet\")\r\n ---------------------------------------------------------------------------\r\n ArrowInvalid\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Traceback (most recent call last)\r\n <ipython-input-6-bd9d7deee437> in <module>()\r\n ----> 1 pq.write_table(table,\"test_write.parquet\")\r\n\r\n/usr/local/lib/python2.7/dist-packages/pyarrow/parquet.pyc in write_table(table, where, row_group_size, version, use_dictionary, compression, use_deprecated_int96_timestamps, coerce_timestamps, flavor, **kwargs)\r\n \u00a0\u00a0\u00a0 982\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 use_deprecated_int96_timestamps=use_int96,\r\n \u00a0\u00a0\u00a0 983\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 **kwargs) as writer:\r\n --> 984\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 writer.write_table(table, row_group_size=row_group_size)\r\n \u00a0\u00a0\u00a0 985\u00a0\u00a0\u00a0\u00a0 except Exception:\r\n \u00a0\u00a0\u00a0 986\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 if is_path(where):\r\n\r\n/usr/local/lib/python2.7/dist-packages/pyarrow/parquet.pyc in write_table(self, table, row_group_size)\r\n \u00a0\u00a0\u00a0 325\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 table = _sanitize_table(table, self.schema, self.flavor)\r\n \u00a0\u00a0\u00a0 326\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 assert self.is_open\r\n --> 327\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 self.writer.write_table(table, row_group_size=row_group_size)\r\n \u00a0\u00a0\u00a0 328 \r\n \u00a0\u00a0\u00a0 329\u00a0\u00a0\u00a0\u00a0 def close(self):\r\n\r\n/usr/local/lib/python2.7/dist-packages/pyarrow/_parquet.so in pyarrow._parquet.ParquetWriter.write_table()\r\n\r\n/usr/local/lib/python2.7/dist-packages/pyarrow/lib.so in pyarrow.lib.check_status()\r\n\r\nArrowInvalid: Nested column branch had multiple children\r\n\r\n```\r\n\r\n\u00a0\r\n\r\nI would really appreciate a fix on this.\r\n\r\nBest,\r\n\r\nJacques",
        "created_at": "2018-05-16T10:23:55.000Z",
        "updated_at": "2020-03-29T22:08:48.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-03-29T22:08:48.000Z"
    },
    "comments": [
        {
            "created_at": "2018-05-20T23:54:00.431Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2587?focusedCommentId=16482087) by Wes McKinney (wesm):*\nThis work is ongoing in https://github.com/apache/parquet-cpp/pull/462, it would be helpful if you could help kick the tires"
        },
        {
            "created_at": "2019-05-31T00:44:22.142Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2587?focusedCommentId=16852504) by Wes McKinney (wesm):*\nNested Parquet is not yet on my immediate critical path, but it will be eventually (hopefully in 2019)"
        },
        {
            "created_at": "2019-07-02T13:05:01.985Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2587?focusedCommentId=16876946) by Micah Kornfield (emkornfield@gmail.com):*\nI'm going to take a look at doing this on top of https://github.com/apache/arrow/pull/4066"
        },
        {
            "created_at": "2019-07-03T00:01:24.564Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2587?focusedCommentId=16877371) by Wes McKinney (wesm):*\nThat would be nice. Be careful as the last attempt (ARROW-1644) at this caused performance regressions on the flat read path"
        },
        {
            "created_at": "2019-09-30T03:55:15.427Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2587?focusedCommentId=16940638) by harikrishnan (harish1792):*\n\u00a0Any update on this one? Is there any alternative/hack I can follow to make it work till this gets fixed?\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2019-10-02T01:21:06.632Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2587?focusedCommentId=16942420) by Micah Kornfield (emkornfield@gmail.com):*\nI hope to have sometime to continue work on it this week, but not sure how far I'll get.\u00a0 As a workaround you could flatten the struct so that all columns are top-levels array and then reassemble them."
        },
        {
            "created_at": "2019-10-02T02:36:03.900Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2587?focusedCommentId=16942439) by Wes McKinney (wesm):*\nIt's a large project and, as far as I can tell, entirely unfunded. We want to make sure we take the time to implement and test this properly"
        },
        {
            "created_at": "2020-03-29T22:08:48.551Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2587?focusedCommentId=17070552) by Wes McKinney (wesm):*\nIssue resolved by pull request 6751\n<https://github.com/apache/arrow/pull/6751>"
        }
    ]
}