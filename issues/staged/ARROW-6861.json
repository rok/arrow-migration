{
    "issue": {
        "title": "[Python] arrow-0.15.0 reading arrow-0.14.1-output Parquet dictionary column: Failure reading column: IOError: Arrow error: Invalid: Resize cannot downsize",
        "body": "***Note**: This issue was originally created as [ARROW-6861](https://issues.apache.org/jira/browse/ARROW-6861). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI'll need to jump through hoops to upload the (seemingly-valid) Parquet file that triggers this bug. In the meantime, here's the error I get, reading the Parquet file with read_dictionary=true. I'll start with the stack trace:\r\n\r\n`Failure reading column: IOError: Arrow error: Invalid: Resize cannot downsize`\r\n\r\n`#0 0x0000000000b9fffd in __cxa_throw ()`\r\n `#1 0x00000000004ce7b5 in parquet::PlainByteArrayDecoder::DecodeArrow (this=0x555556612e50, num_values=67339, null_count=0, valid_bits=0x7f39a764b780 '\\377' <repeats 200 times>..., valid_bits_offset=748544,`\r\n \\` builder=0x555556616330) at /src/apache-arrow-0.15.0/cpp/src/parquet/encoding.cc:886`\r\n `#2 0x000000000046d703 in parquet::internal::ByteArrayDictionaryRecordReader::ReadValuesSpaced (this=0x555556616260, values_to_read=67339, null_count=0)`\r\n \\` at /src/apache-arrow-0.15.0/cpp/src/parquet/column_reader.cc:1314`\r\n `#3 0x00000000004a13f8 in parquet::internal::TypedRecordReader<parquet::PhysicalType<(parquet::Type::type)6> >::ReadRecordData (this=0x555556616260, num_records=67339)`\r\n \\` at /src/apache-arrow-0.15.0/cpp/src/parquet/column_reader.cc:1096`\r\n `#4 0x0000000000493876 in parquet::internal::TypedRecordReader<parquet::PhysicalType<(parquet::Type::type)6> >::ReadRecords (this=0x555556616260, num_records=815883)`\r\n \\` at /src/apache-arrow-0.15.0/cpp/src/parquet/column_reader.cc:875`\r\n `#5 0x0000000000413955 in parquet::arrow::LeafReader::NextBatch (this=0x555556615640, records_to_read=815883, out=0x7ffd4b5afab0) at /src/apache-arrow-0.15.0/cpp/src/parquet/arrow/reader.cc:413`\r\n `#6 0x0000000000412081 in parquet::arrow::FileReaderImpl::ReadColumn (this=0x5555566067a0, i=7, row_groups=..., out=0x7ffd4b5afab0) at /src/apache-arrow-0.15.0/cpp/src/parquet/arrow/reader.cc:218`\r\n `#7 0x00000000004121b0 in parquet::arrow::FileReaderImpl::ReadColumn (this=0x5555566067a0, i=7, out=0x7ffd4b5afab0) at /src/apache-arrow-0.15.0/cpp/src/parquet/arrow/reader.cc:223`\r\n `#8 0x0000000000405fbd in readParquet(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) ()`\r\n\r\nAnd now a report of my gdb adventures:\r\n\r\nIn Arrow 0.15.0, when reading a particular dictionary column (`read_dictionaries=true`) with\u00a0815883 rows that was written by Arrow 0.14.1, `arrow::Dictionary32Builder<arrow::BinaryType>::AppendIndices(...)` is called twice (once with 493568 values, once with 254976 values); and then `PlainByteArrayDecoder::DecodeArrow()` is called. (I'm a novice; I don't know why this column comes in three batches.) On first `AppendIndices()` call, the buffer capacity is equal to the number of values. On second call, that's no longer the case: the buffer grows using `BufferBuilder::GrowByFactor`, so its capacity is\u00a0987136.\r\n\r\nBut there's a bug: the 987136-capacity buffer is in `Dictionary32Builder::indices_builder_`; so\u00a0987136 is stored in `Dictionary32Builder::indices_builder_.capacity_`. `Dictionary32Builder::capacity_` does not change when `AppendIndices()`\u00a0is called. (Dictionary32Builder behaves like a proxy for its `indices_builder_`; but its `capacity()` method is not virtual, so things are messy.)\r\n\r\nSo `builder.capacity_` is 0. Then comes the final batch of\u00a067339 values, via `DecodeArrow()`. It calls `builder->Reserve(num_values)`. But `builder->Reserve(num_values)` tries to increase the capacity from 0 (its wrong, cached value) to `length_ + num_values` (815883). Since\u00a0`indicies_builder->capacity_` is\u00a0987136, that's a downsize \u2013 which throws an exception.\r\n\r\nThe only workaround I can find: use `read_dictionaries=false`.\r\n\r\nThis affects Python, too.\r\n\r\nI've attached a patch that fixes the issue for my file. I don't know how to formulate a reduction, though, so I haven't contributed unit tests. I'm also not certain how FinishInternal is meant to work, so this definitely needs expert review. (FinishInternal was _definitely_ buggy before my patch; after my patch it _might_ be buggy but I don't know.)",
        "created_at": "2019-10-11T17:20:12.000Z",
        "updated_at": "2019-10-17T18:02:45.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-10-17T18:02:45.000Z"
    },
    "comments": [
        {
            "created_at": "2019-10-11T19:20:15.690Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6861?focusedCommentId=16949738) by Adam Hooper (adamhooper):*\nI've attached a Parquet file, written by Arrow 0.14.1, which causes this problem. Column 8 (among others) causes this problem. Most columns work fine."
        },
        {
            "created_at": "2019-10-11T21:03:43.071Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6861?focusedCommentId=16949801) by Wes McKinney (wesm):*\nThanks. This should be enough information to help write a unit test to reproduce the issue. `[~bkietz]` are you interested in taking a look?"
        },
        {
            "created_at": "2019-10-11T21:44:57.070Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6861?focusedCommentId=16949809) by Wes McKinney (wesm):*\nSeems like a good candidate for 0.15.1. Marked as such"
        },
        {
            "created_at": "2019-10-14T01:16:07.675Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6861?focusedCommentId=16950648) by Wes McKinney (wesm):*\nI started looking at this"
        },
        {
            "created_at": "2019-10-17T18:02:45.099Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6861?focusedCommentId=16953978) by Wes McKinney (wesm):*\nIssue resolved by pull request 5643\n<https://github.com/apache/arrow/pull/5643>"
        }
    ]
}