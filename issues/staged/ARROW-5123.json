{
    "issue": {
        "title": "[Rust] derive RecordWriter from struct definitions",
        "body": "***Note**: This issue was originally created as [ARROW-5123](https://issues.apache.org/jira/browse/ARROW-5123). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nMigrated from previous github issue (which saw a lot of comments but at a rough transition time in the project): https://github.com/sunchao/parquet-rs/pull/197\r\n\r\n\u00a0\r\n\r\nGoal\r\n\r\n===\r\n\r\nWriting many columns to a file is a chore. If you can put your values in to a struct which mirrors the schema of your file, this `derive(ParquetRecordWriter)` will write out all the fields, in the order in which they are defined, to a row_group.\r\n\r\nHow to Use\r\n===\r\n\r\n```\r\nextern crate parquet;\r\n#[macro_use] extern crate parquet_derive;\r\n\r\n#[derive(ParquetRecordWriter)]\r\nstruct ACompleteRecord<'a> {\r\n\u00a0 pub a_bool: bool,\r\n\u00a0 pub a_str: &'a str,\r\n}\r\n```\r\n\r\nRecordWriter trait\r\n===\r\n\r\nThis is the new trait which `parquet_derive` will implement for your structs.\r\n\r\n```\r\nuse super::RowGroupWriter;\r\n\r\npub trait RecordWriter<T> {\r\n\u00a0 fn write_to_row_group(&self, row_group_writer: &mut Box<RowGroupWriter>);\r\n}\r\n```\r\n\r\nHow does it work?\r\n===\r\n\r\nThe `parquet_derive` crate adds code generating functionality to the rust compiler. The code generation takes rust syntax and emits additional syntax. This macro expansion works on rust 1.15+ stable. This is a dynamic plugin, loaded by the machinery in cargo. Users don't have to do any special `build.rs` steps or anything like that, it's automatic by including `parquet_derive` in their project. The `parquet_derive/src/Cargo.toml` has a section saying as much:\r\n\r\n```\r\n[lib]\r\nproc-macro = true\r\n```\r\n\r\nThe rust struct tagged with `#[derive(ParquetRecordWriter)]` is provided to the `parquet_record_writer` function in `parquet_derive/src/lib.rs`. The `syn` crate parses the struct from a string-representation to a AST (a recursive enum value). The AST contains all the values I care about when generating a `RecordWriter` impl:\r\n\r\n\u00a0- the name of the struct\r\n\u00a0- the lifetime variables of the struct\r\n\u00a0- the fields of the struct\r\n\r\nThe fields of the struct are translated from AST to a flat `FieldInfo` struct. It has the bits I care about for writing a column: `field_name`, `field_lifetime`, `field_type`, `is_option`, `column_writer_variant`.\r\n\r\nThe code then does the equivalent of templating to build the `RecordWriter` implementation. The templating functionality is provided by the `quote` crate. At a high-level the template for `RecordWriter` looks like:\r\n\r\n```\r\nimpl RecordWriter for $struct_name {\r\n\u00a0 fn write_row_group(..) {\r\n\u00a0\u00a0\u00a0 $({\r\n\u00a0\u00a0\u00a0\u00a0\u00a0 $column_writer_snippet\r\n\u00a0\u00a0\u00a0 })\r\n\u00a0 } \r\n}\r\n```\r\n\r\nthis template is then added under the struct definition, ending up something like:\r\n\r\n```\r\nstruct MyStruct {\r\n}\r\nimpl RecordWriter for MyStruct {\r\n\u00a0 fn write_row_group(..) {\r\n\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 write_col_1();\r\n\u00a0\u00a0\u00a0 };\r\n\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 write_col_2();\r\n\u00a0\u00a0 }\r\n\u00a0 }\r\n}\r\n```\r\n\r\nand finally _THIS_ is the code passed to rustc. It's just code now, fully expanded and standalone. If a user ever changes their `struct MyValue` definition the `ParquetRecordWriter` will be regenerated. There's no intermediate values to version control or worry about.\r\n\r\nViewing the Derived Code\r\n===\r\n\r\nTo see the generated code before it's compiled, one very useful bit is to install `cargo expand` [more info on gh](https://github.com/dtolnay/cargo-expand), then you can do:\r\n\r\n```\r\n$WORK_DIR/parquet-rs/parquet_derive_test\r\ncargo expand --lib > ../temp.rs\r\n```\r\n\r\nthen you can dump the contents:\r\n\r\n```\r\nstruct DumbRecord {\r\n\u00a0\u00a0\u00a0 pub a_bool: bool,\r\n\u00a0\u00a0\u00a0 pub a2_bool: bool,\r\n}\r\nimpl RecordWriter<DumbRecord> for &[DumbRecord] {\r\n\u00a0\u00a0\u00a0 fn write_to_row_group(\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 &self,\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 row_group_writer: &mut Box<parquet::file::writer::RowGroupWriter>,\r\n\u00a0\u00a0\u00a0 ) {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let mut row_group_writer = row_group_writer;\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let vals: Vec<bool> = self.iter().map(|x| x.a_bool).collect();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let mut column_writer = row_group_writer.next_column().unwrap().unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 if let parquet::column::writer::ColumnWriter::BoolColumnWriter(ref mut typed) =\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 column_writer\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 typed.write_batch(&vals[..], None, None).unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 row_group_writer.close_column(column_writer).unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 };\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let vals: Vec<bool> = self.iter().map(|x| x.a2_bool).collect();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let mut column_writer = row_group_writer.next_column().unwrap().unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 if let parquet::column::writer::ColumnWriter::BoolColumnWriter(ref mut typed) =\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 column_writer\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 typed.write_batch(&vals[..], None, None).unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 row_group_writer.close_column(column_writer).unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\r\n\u00a0\u00a0\u00a0 }\r\n}\r\n```\r\n\r\nnow I need to write out all the combinations of types we support and make sure it writes out data.\r\n\r\nProcedural Macros\r\n===\r\n\r\nThe `parquet_derive` crate can ONLY export the derivation functionality. No traits, nothing else. The derive crate can not host test cases. It's kind of like a \"dummy\" crate which is only used by the compiler, never the code.\r\n\r\nThe parent crate cannot use the derivation functionality, which is important because it means test code cannot be in the parent crate. This forces us to have a third crate, `parquet_derive_test`.\r\n\r\nI'm open to being wrong on any one of these finer points. I had to bang on this for a while to get it to compile!\r\n\r\nPotentials For Better Design\r\n===\r\n\r\n\u00a0- [x] Recursion could be limited by generating the code as \"snippets\" instead of one big `quote!` AST generator. Or so I think. It might be nicer to push generating each columns writing code to another loop.\r\n\u00a0- [X] ~<sub>It would be nicer if I didn't have to be so picky about data going in to the `write_batch` function. Is it possible we could make a version of the function which accept `Into<DataType>` or similar? This would greatly simplify this derivation code as it would not need to enumerate all the supported types. Something like `write_generic_batch(&[impl Into<DataType>])` would be neat.</sub>~ (not tackling in this generation of the plugin)\r\n\u00a0- [X] ~<sub>Another idea to improving writing columns, could we have a write function for `Iterator`s? I already have a `Vec<DumbRecord>`, if I could just write a mapping for accessing the one value, we could skip the whole intermediate vec for `write_batch`. Should have some significant memory advantages.</sub>~ (not tackling in this generation of the plugin, it's a bigger parquet-rs enhancement)\r\n\u00a0- [X] ~<sub>It might be worthwhile to derive a parquet schema directly from a struct definition. That should stamp out opportunities for type errors.</sub>~ (moved to #203)\r\n\r\nStatus\r\n===\r\n\r\nI have successfully integrated this work with my own data exporter (takes postgres/couchdb and outputs a single parquet file).\r\n\r\nI think this code is worth including in the project, with the caveat that it only generates simplistic `RecordWriter`s. As people start to use we can add code generation for more complex, nested structs.",
        "created_at": "2019-04-05T01:38:24.000Z",
        "updated_at": "2020-09-14T11:53:39.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Rust",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-09-14T11:49:53.000Z"
    },
    "comments": [
        {
            "created_at": "2020-09-14T11:49:53.516Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5123?focusedCommentId=17195405) by Neville Dipale (nevi_me):*\nIssue resolved by pull request 4140\n<https://github.com/apache/arrow/pull/4140>"
        },
        {
            "created_at": "2020-09-14T11:50:35.459Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5123?focusedCommentId=17195410) by Neville Dipale (nevi_me):*\nI'm unable to assign to Xavier"
        }
    ]
}