{
    "issue": {
        "title": "[Parquet][C++][Python] \"List index overflow\" when read parquet file",
        "body": "***Note**: This issue was originally created as [ARROW-17983](https://issues.apache.org/jira/browse/ARROW-17983). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nFrom issue https://github.com/apache/arrow/issues/14229.\r\n\r\nThe bug looks like this:\r\n- create a pandas dataframe with **one column** and `n` rows, `n < max(int32)`\n- each elemenet is a list with `m` integers, `m * n > max(int32)`\n- save to a parquet file\n- reading from the parquet file fails with \"OSError: List index overflow\"\n  \n  See comment below on details to reproudce this bug:\n  https://github.com/apache/arrow/issues/14229#issuecomment-1272223773\n  \n  Tested with a small dataset, the error might come from below code.\n  https://github.com/apache/arrow/blob/master/cpp/src/parquet/level_conversion.cc#L63-L64\n  `OffsetType` is `int32`, but the loop is executed (and `*offset` is incremented) `m * n` times which is beyond `max(int32)`.",
        "created_at": "2022-10-11T05:21:06.000Z",
        "updated_at": "2022-10-18T05:33:52.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Parquet",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-10-17T10:11:08.666Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17983?focusedCommentId=17618804) by Yibo Cai (yibocai):*\ncc [~emkornfield@gmail.com] for comments."
        },
        {
            "created_at": "2022-10-18T05:33:52.160Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17983?focusedCommentId=17619234) by Micah Kornfield (emkornfield):*\nIIRC, I think offset type here is inferred from the schema (i.e. List vs LargeList) that we are trying to read back into, once offsets reaches int32 max we can't return, since the reading path doesn't support chunking at the moment.\r\n\r\nTwo options to fix this seems to either be:\r\n1.  Infer LargeList should be used based on RowGroup/File statistics.\r\n2. Allow overriding the schema (this might already be an option) to take LargeList override.\r\n3. Modify code to allow for chunking arrays (I seem to recall this would be a fare amount of work based on current assumption but its been a while since I dug into the code).\r\n\r\nI seem to recall someone tried prototyping 2, recently but I'm having trouble finding the thread/JIRA at the moment."
        }
    ]
}