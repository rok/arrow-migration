{
    "issue": {
        "title": "[Python] Dataset Timezone Handling",
        "body": "***Note**: This issue was originally created as [ARROW-11388](https://issues.apache.org/jira/browse/ARROW-11388). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI'm trying to write a pandas dataframe with a datetimeindex with timezone information to a pyarrow dataset but the timezone information doesn't seem to be written (apart from in the pandas metadata)\r\n\r\n\u00a0\r\n\r\nFor example\r\n\r\n\u00a0\r\n```java\n\r\nimport os\r\nimport pandas as pd\r\nimport numpy as np\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport pyarrow.dataset as ds\r\n\r\nfrom pathlib import Path\r\n\r\n# I've tried with both v2.0 and v3.0 today\r\nprint(pa.__version__)\r\n\r\n# create dummy dataframe with datetime index containing tz info\r\ndf = pd.DataFrame(\r\n    dict(\r\n        timestamp=pd.date_range(\"2021-01-01\", freq=\"1T\", periods=100, tz=\"US/Eastern\"),\r\n        x=np.arange(100),\r\n     )\r\n).set_index(\"timestamp\")\r\n\r\ntest_dir = Path(\"test_dir\")\r\ntable = pa.Table.from_pandas(df)\r\nschema = table.schema\r\n\r\nprint(schema)\r\nprint(schema.pandas_metadata)\r\n\r\n# warning - creates dir in cwd\r\npq.write_to_dataset(table, test_dir)\r\n\r\n# timestamp column is us and UTC\r\nprint(pq.ParquetFile(test_dir / os.listdir(test_dir)[0]).read())\r\n\r\n# create dataset using schema from earlier\r\ndataset = ds.dataset(test_dir, format=\"parquet\", schema=schema)\r\n\r\n# doesn't work\r\ndataset.to_table()\r\n```\r\n\u00a0\r\n\r\n\u00a0\r\n\r\nIs this a bug or am I missing something?\r\n\r\nThanks\r\n\r\nAndy\r\n\r\n\u00a0",
        "created_at": "2021-01-26T10:43:57.000Z",
        "updated_at": "2022-07-04T17:41:28.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-01-27T08:15:48.990Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11388?focusedCommentId=17272656) by Joris Van den Bossche (jorisvandenbossche):*\n`[~andydoug]` thanks for the report, there are a few different issues you are bumping into here:\r\n\r\n1. The fact that `Dataset.to_table()` raises an error when you specify the `schema` manually and it doesn't match exactly with the file's schema is a known limitation right now (_\"fields had matching names but differing types. From: timestamp: timestamp[us, tz=UTC] To: timestamp: timestamp[ns, tz=US/Eastern]\"_). Right now types need to match exactly, but we need to relax this constraint. We hope to fix this for the next version, and this is generally covered by ARROW-11003\r\n\r\n2. Normally, when writing a pyarrow Table with a timezone to parquet and reading it back in, we should be able to preserve the timezone. Parquet itself doesn't support it (we can only store that it is \"timezone-aware\" (in UTC), that's the reason it still comes back as UTC), but we store the timezone in additional metadata stored in the parquet file. For non-nanosecond resolutions this actually works, but so not if the data originally is in nanosecond resolution. This is covered by ARROW-9634 (and the reason you originally have nanosecond data, is because your data comes from pandas)\r\n\r\nNote that if you don't specify the schema, the timezone will still be restored after conversion to pandas (because we also store the timezone in the pandas metadata):\r\n\r\n```Java\n\r\nIn [61]: dataset = ds.dataset(test_dir, format=\"parquet\")\r\n\r\nIn [62]: dataset.to_table().to_pandas().index.dtype\r\nOut[62]: datetime64[ns, US/Eastern]\r\n```"
        },
        {
            "created_at": "2021-01-27T09:36:02.547Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11388?focusedCommentId=17272711) by Andy Douglas (andydoug):*\nThanks for your response `[~jorisvandenbossche]`, that makes sense and fits with what I'm seeing.\r\n\r\nBasically I have a small python library that wraps pyarrow datasets to provide a convenient method for accessing multiple datasets and exposing via pandas. One of the things I want to be able to do is define schemas for all datasets upfront in something like a YAML file. The schema can then be applied/checked consistently on write/read avoiding issues like numerical columns being typed based on contents and therefore sometimes ending up as integers and other times floats. I initially tried to do this using pyarrow schemas however (as you mention above) the schema alone is not enough to restore a pandas dataframe which contains both index and timezone info.\r\n\r\nDo you have any suggestions for how I would handle the above? Would you suggest doing the schema checking within the library and not passing the schema parameter on pyarrow dataset read/write calls?\r\n\r\nSeparately, I also see an issue on write for indexed pandas dataframes where the index column is duplicated in the pandas metadata without the timezone information being added. I'll raise a separate issue for this.\u00a0"
        },
        {
            "created_at": "2021-01-27T09:54:29.956Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11388?focusedCommentId=17272727) by Joris Van den Bossche (jorisvandenbossche):*\n> Do you have any suggestions for how I would handle the above? Would you suggest doing the schema checking within the library and not passing the schema parameter on pyarrow dataset read/write calls?\r\n\r\nSpecifically for reading, I would indeed not pass the schema to the dataset read call (as that will error if not matching exactly, as your report above shows). We certainly want to make this work in the next release, but for now I would advise to read it in first as is, and then (if the schema of the dataset doesn't match with the known schema), you could still cast the resulting table to that schema (so `ds.dataset(...).to_table().cast(schema)` instead of `ds.dataset(..., schema=schema).to_table()`). In the end, when we add support, it will basically also be a cast under the hood.\r\n\r\nFor writing, you can ensure the correct schema on conversion from pandas -> pyarrow, that should work already fine, I think?\r\n\r\n> Separately, I also see an issue on write for indexed pandas dataframes where the index column is duplicated in the pandas metadata without the timezone information being added. I'll raise a separate issue for this. \r\n\r\nYes, please do (I recall an issue about duplicated columns for the index, so this aspect might already be solved in pyarrow 3.0)\r\n\r\n\r\n"
        },
        {
            "created_at": "2021-01-30T09:26:10.154Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11388?focusedCommentId=17275545) by Andy Douglas (andydoug):*\n\u00a0\r\n```java\n\r\nds.dataset(...).to_table().cast(schema)\n```\r\n\u00a0\r\n\r\nI think this should work but now I'm hitting the following error:\r\n\r\n\r\n`ValueError: Target schema's field names are not matching the table's field names: ['high', 'low', 'open', 'close', 'volume', 'timestamp', 'exchange', 'symbol'], ['high', 'low', 'open', 'close', 'volume', 'exchange', 'symbol', 'timestamp']`\r\n\r\n\u00a0\r\n\r\nShouldn't cast ignore column ordering? If not, then I seem to get different column orderings when writing an index column and then reading it back. If I write with the index column in index 0 it's read back in index -1, then schema cast fails."
        },
        {
            "created_at": "2021-02-08T12:08:41.217Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11388?focusedCommentId=17280991) by Joris Van den Bossche (jorisvandenbossche):*\n`[~andydoug]` good point about casting Tables and order of the fields in the schema. I am not sure how flexible we want to make this method, but opened ARROW-11553 to track this (input on that issue certainly welcome!). "
        }
    ]
}