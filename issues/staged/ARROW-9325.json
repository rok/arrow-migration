{
    "issue": {
        "title": "[C++][Dataset][Python] ParquetDataset typecast on read",
        "body": "***Note**: This issue was originally created as [ARROW-9325](https://issues.apache.org/jira/browse/ARROW-9325). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen reading large Parquet tables, it would be useful to have the option to cast columns to a different type. Consider a large table with double precision types (float64 and int64), the user might prefer to read these in as single precision if double precision is not required.\u00a0\r\n\r\n**Current behavior:** One must first read the table and then cast\r\n\r\n**Desired behavior:** provide an additional kwarg that allows the user to specify a target schema. This would be propagated through to ParquetFileFragment, and each fragment can be cast as soon as it is read.\r\n\r\n**Impact:** In cases where the user wants to cast all columns to single precision and the dataset has many partitions, this feature would reduce max memory required by roughly 50%.\r\n\r\n--------------\r\n\r\nI've already implemented a POC using the old Dataset API, and can reimplement using the v2 dataset API, and then submit a patch.\r\n\r\nA couple questions:\r\n\r\n1. Does this feature fit in with the Arrow roadmap?\r\n\r\n2. Alternatively, is there a way to accomplish this already in v0.17 that I am missing?",
        "created_at": "2020-07-04T19:38:19.000Z",
        "updated_at": "2020-08-13T09:09:18.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-07-31T21:31:47.187Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9325?focusedCommentId=17169172) by Wes McKinney (wesm):*\nProviding a schema to coerce/cast to sounds reasonable to me, and within scope for the C++ datasets framework"
        }
    ]
}