{
    "issue": {
        "title": "[Python] \"pyarrow.parquet.write_to_dataset\", option \"file_visitor\" nothing happen",
        "body": "***Note**: This issue was originally created as [ARROW-17068](https://issues.apache.org/jira/browse/ARROW-17068). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen try to use the callback \"file_visitor\", nothing happens.\r\n\r\n\u00a0\r\n\r\nExample:\r\n```java\n\r\nimport pyarrow as pa\r\nfrom pyarrow import parquet as pa_parquet\r\n\r\ntable = pa.table([\r\n\u00a0 \u00a0 \u00a0 \u00a0 pa.array([1, 2, 3, 4, 5]),\r\n\u00a0 \u00a0 \u00a0 \u00a0 pa.array([\"a\", \"b\", \"c\", \"d\", \"e\"]),\r\n\u00a0 \u00a0 \u00a0 \u00a0 pa.array([1.0, 2.0, 3.0, 4.0, 5.0])\r\n\u00a0 \u00a0 ], names=[\"col1\", \"col2\", \"col3\"])\r\n\r\nwritten_files = []\r\npa_parquet.write_to_dataset(table, partition_cols=[\"col2\"], root_path=\"tests\", file_visitor=lambda x: written_files.append(x.path)))\r\n\r\nassert len(written_files) > 0  # This raises, length is 0\n```",
        "created_at": "2022-07-13T19:34:56.000Z",
        "updated_at": "2022-08-27T14:41:48.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-07-14T20:19:58.000Z"
    },
    "comments": [
        {
            "created_at": "2022-07-13T22:40:03.316Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17068?focusedCommentId=17566543) by Will Jones (willjones127):*\nMy guess is that if you pass `use_legacy_dataset=False` it should work. This option will become the default in 9.0.0 and we are removing legacy datasets implementation eventually so we might not fix this.\r\n\r\nIf you can, it would be preferable to use the dataset writer in `pyarrow.dataset`:\r\n\r\n```python\n\r\nimport pyarrow.dataset as ds\r\n\r\nds.write_dataset(table, base_dir=\"tests\", partitioning=[\"col2\"], file_visitor=lambda x: written_files.append(x.path)))\r\n```"
        },
        {
            "created_at": "2022-07-14T04:50:04.775Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17068?focusedCommentId=17566637) by Alejandro Marco Ramos (alex_marco):*\nHi Will, thanks for response.\r\n\r\nPassing `use_legacy_dataset=False` don't fix this situation, the list remains empty.\r\n\r\nI will follow your recommendation to use the new dataset API.\r\n\r\nThanks.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-08-27T14:41:48.047Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17068?focusedCommentId=17585851) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}