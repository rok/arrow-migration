{
    "issue": {
        "title": "[Python] Encoding? issue with error reporting for parquet.read_table",
        "body": "***Note**: This issue was originally created as [ARROW-1306](https://issues.apache.org/jira/browse/ARROW-1306). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThis is only error-reporting, somehow the filename in the exception for a not found file is getting garbled, example below\n\n```Java\nimport pyarrow.parquet as pq\npq.read_table('non_existent_file.parquet')\n\nArrowIOError                              Traceback (most recent call last)\n\npq.read_table('non_existent_file.parquet')\n\n---------------------------------------------------------------------------\nArrowIOError                              Traceback (most recent call last)\n----> 1 pq.read_table('non_existent_file.parquet')\n\n~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\pyarrow\\parquet.py in read_table(source, columns, nthreads, metadata, use_pandas_metadata)\n    709                                    metadata=metadata)\n    710 \n--> 711     pf = ParquetFile(source, metadata=metadata)\n    712     return pf.read(columns=columns, nthreads=nthreads,\n    713                    use_pandas_metadata=use_pandas_metadata)\n\n~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\pyarrow\\parquet.py in __init__(self, source, metadata, common_metadata)\n     52     def __init__(self, source, metadata=None, common_metadata=None):\n     53         self.reader = ParquetReader()\n---> 54         self.reader.open(source, metadata=metadata)\n     55         self.common_metadata = common_metadata\n     56 \n\n_parquet.pyx in pyarrow._parquet.ParquetReader.open()\n\nio.pxi in pyarrow.lib.get_reader()\n\nio.pxi in pyarrow.lib.memory_map()\n\nio.pxi in pyarrow.lib.MemoryMappedFile._open()\n\nerror.pxi in pyarrow.lib.check_status()\n\nArrowIOError: IOError: Failed to open file: \u6f6e\u5f6e\u7865\u7369\u6574\u746e\u665f\u6c69\u2e65\u6170\u7172\u6575\n```\n\n\nverions - Python 3.6 Windows x64\n```Java\n    arrow-cpp:   0.5.0-np112py36_vc14_1 conda-forge [vc14]\n    parquet-cpp: 1.2.0.pre-vc14_3       conda-forge [vc14]\n    pyarrow:     0.5.0-np112py36_vc14_0 conda-forge [vc14]\n```\n",
        "created_at": "2017-08-01T15:36:31.000Z",
        "updated_at": "2017-08-08T15:56:40.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2017-08-08T15:56:40.000Z"
    },
    "comments": [
        {
            "created_at": "2017-08-01T19:10:46.366Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1306?focusedCommentId=16109551) by Wes McKinney (wesm):*\nThis is happening because Windows unicode file names have to be encoded to UTF16-LE (see https://github.com/apache/arrow/blob/master/python/pyarrow/compat.py#L133). This definitely should be fixed \u2013 marked for 0.6.0. I'm not sure of the right fix without taking a deeper look, since the Arrow file APIs take `std::string` they aren't aware of the encoded file name when they generate the error message. One way to handle it might be to add some kind of auxiliary data structure that has both the platform-encoded path and a UTF8 path. On Linux/macOS they'll be the same, but we can use the UTF8 version for making error messages"
        },
        {
            "created_at": "2017-08-08T05:16:17.230Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1306?focusedCommentId=16117870) by Wes McKinney (wesm):*\nPR: https://github.com/apache/arrow/pull/951"
        },
        {
            "created_at": "2017-08-08T15:56:40.486Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1306?focusedCommentId=16118512) by Wes McKinney (wesm):*\nIssue resolved by pull request 951\n<https://github.com/apache/arrow/pull/951>"
        }
    ]
}