{
    "issue": {
        "title": "[Python] Allow per column encoding in parquet writer ",
        "body": "***Note**: This issue was originally created as [ARROW-13781](https://issues.apache.org/jira/browse/ARROW-13781). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAdd a new parameter to `write_table` to allow parquet encodings to be defined on a per column basis. This should supercede use_dictionary and use_byte_stream_split.",
        "created_at": "2021-08-27T02:58:35.000Z",
        "updated_at": "2021-12-23T15:51:16.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Parquet",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-12-23T13:26:53.000Z"
    },
    "comments": [
        {
            "created_at": "2021-11-04T16:56:19.314Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17438836) by Brian Kiefer (Bkief):*\n`[~alenkaf]` \u00a0- I have a first pass at the code changes available. It compiled but crashed at runtime, then other priorities pulled me away. I'll throw it up on Github tonight and link to it here"
        },
        {
            "created_at": "2021-11-04T17:18:18.866Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17438843) by Alenka Frim (alenka):*\n`[~Bkief]` \u00a0that would be great, thanks!"
        },
        {
            "created_at": "2021-11-06T16:31:28.446Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17439709) by Brian Kiefer (Bkief):*\n`[~alenkaf]` - The branch can be found here: <https://github.com/bkief/arrow/tree/ARROW-13781>"
        },
        {
            "created_at": "2021-11-07T15:43:28.336Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17440029) by Alenka Frim (alenka):*\n`[~Bkief]` thanks a bunch!"
        },
        {
            "created_at": "2021-11-16T11:25:00.558Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17444484) by Alenka Frim (alenka):*\nI am having some trouble with understanding the 'use_dictionary' vs 'col_encoding' of dictionary type \"RLE_DICTIONARY\" and \"PLAIN_DICTIONARY\". An C++ exception is triggered when using mentioned encodings. Thought it would help turning 'use_dictionary' to False but it doesn't.\r\n\r\nRunning this code on my working branch:\r\n```java\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\n\r\narr_float = pa.array(list(map(float, range(100))))\r\narr_int = pa.array(list(map(int, range(100))))\r\nmixed_table = pa.Table.from_arrays([arr_float, arr_int], names=['a', 'b'])\r\n\r\npq.write_table(mixed_table, '/users/alenkafrim/example_col_encoding_1.parquet', use_dictionary=False, col_encoding={'a': \"RLE_DICTIONARY\"})\n```\r\nterminates Python and gives this error:\u00a0\r\n```java\n\r\nparquet::ParquetException: Can't use dictionary encoding as fallback encoding\n```\r\nDoes anybody have any idea what I could try?\r\n\r\nThe code with the failing test can be found on my branch:\r\nhttps://github.com/AlenkaF/arrow/tree/ARROW-13781"
        },
        {
            "created_at": "2021-11-16T12:32:28.323Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17444510) by Joris Van den Bossche (jorisvandenbossche):*\nIt's generally not good that C++ exceptions can get to Python code, but the reason it is raising an exception here is that the `col_encoding` configuration for Parquet is to specify which encoding to use _when not using dictionary encoding_. So that's the reason it is raising an exception if you pass a dictionary encoding option to `col_encoding`.\r\n\r\nShort term, I think the easiest solution for your PR is to explicitly check for this as well in the Python bindings, so avoiding that \"RLE_DICTIONARY\" gets passed to the C++ code setting this option, and this way avoiding to trigger the C++ exception (and instead raise a python exception)."
        },
        {
            "created_at": "2021-11-16T14:26:13.942Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17444568) by Brian Kiefer (Bkief):*\nCorrect me if I am wrong, but wasn't delta_binary_packed encoding to arrow v6.0.0? https://issues.apache.org/jira/browse/PARQUET-490 If so, PyArrow should support that also"
        },
        {
            "created_at": "2021-11-17T07:42:16.180Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17444983) by Alenka Frim (alenka):*\nI am not sure ... https://arrow.apache.org/docs/cpp/parquet.html#encodings"
        },
        {
            "created_at": "2021-11-17T08:02:25.541Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17444995) by Alenka Frim (alenka):*\n`[~apitrou]` do you know, are the docs outdated for the Parquet encodings?\r\n\r\nhttps://issues.apache.org/jira/browse/PARQUET-490\r\n<https://arrow.apache.org/docs/cpp/parquet.html#encodings>"
        },
        {
            "created_at": "2021-11-17T09:01:46.923Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17445021) by Antoine Pitrou (apitrou):*\nYes, we forgot to update them for DELTA_BINARY_PACKED and did it later in PARQUET-492. Unfortunately, 6.0.0 came in-between."
        },
        {
            "created_at": "2021-11-17T09:02:10.661Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17445022) by Antoine Pitrou (apitrou):*\n(this is also why we would need docs of git master, not only the latest release...)"
        },
        {
            "created_at": "2021-11-17T09:55:23.999Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17445049) by Alenka Frim (alenka):*\nGot it, thanks for all the help!\r\n\r\nWill add delta_binary_packed so PyArrow supports it also.\r\n\r\nI did have to remove PLAIN_DICTIONARY and RLE_DICTIONARY as those options are already used by default in the C++ Parquet library.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2021-12-23T13:26:53.082Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-13781?focusedCommentId=17464565) by Joris Van den Bossche (jorisvandenbossche):*\nIssue resolved by pull request 11724\n<https://github.com/apache/arrow/pull/11724>"
        }
    ]
}