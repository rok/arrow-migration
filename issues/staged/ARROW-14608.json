{
    "issue": {
        "title": "[Python] Provide access to hash_aggregate functions through a group_by method",
        "body": "***Note**: This issue was originally created as [ARROW-14608](https://issues.apache.org/jira/browse/ARROW-14608). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n",
        "created_at": "2021-11-05T11:17:28.000Z",
        "updated_at": "2022-10-23T18:28:32.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: task"
        ],
        "closed": true,
        "closed_at": "2021-11-25T16:43:40.000Z"
    },
    "comments": [
        {
            "created_at": "2021-11-25T16:43:40.423Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14608?focusedCommentId=17449260) by Joris Van den Bossche (jorisvandenbossche):*\nIssue resolved by pull request 11624\n<https://github.com/apache/arrow/pull/11624>"
        },
        {
            "created_at": "2021-11-29T23:49:21.261Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14608?focusedCommentId=17450770) by Lance Dacey (ldacey):*\nIf we can do group_by using the pyarrow table, then I should be able to drop_duplicates as well if it is combined with a filter right? Sorting and dropping duplicates is one of the big reasons I still need to convert some pyarrow tables into a pandas DataFrame temporarily.\r\n```java\n\r\ndf.sort_values(['id', 'updated_at'], ascending=True).drop_duplicates(subset=['id'], keep='last')\n```"
        },
        {
            "created_at": "2022-10-23T18:15:29.369Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14608?focusedCommentId=17622856) by Jacek Pliszka (jacek.pliszka):*\nThis ticket is closed so I created new one: ARROW-18137"
        }
    ]
}