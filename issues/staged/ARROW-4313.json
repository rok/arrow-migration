{
    "issue": {
        "title": "Define general benchmark database schema",
        "body": "***Note**: This issue was originally created as [ARROW-4313](https://issues.apache.org/jira/browse/ARROW-4313). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nSome possible attributes that the benchmark database should track, to permit heterogeneity of hardware and programming languages\r\n\r\n- Timestamp of benchmark run\n- Git commit hash of codebase\n- Machine unique name (sort of the \"user id\")\n- CPU identification for machine, and clock frequency (in case of overclocking)\n- CPU cache sizes (L1/L2/L3)\n- Whether or not CPU throttling is enabled (if it can be easily determined)\n- RAM size\n- GPU identification (if any)\n- Benchmark unique name\n- Programming language(s) associated with benchmark (e.g. a benchmark\n  may involve both C++ and Python)\n- Benchmark time, plus mean and standard deviation if available, else NULL\n  \n  see discussion on mailing list https://lists.apache.org/thread.html/278e573445c83bbd8ee66474b9356c5291a16f6b6eca11dbbe4b473a@%3Cdev.arrow.apache.org%3E",
        "created_at": "2019-01-21T17:14:15.000Z",
        "updated_at": "2019-02-28T13:38:28.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Benchmarking",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2019-02-27T14:18:19.000Z"
    },
    "comments": [
        {
            "created_at": "2019-01-21T17:32:14.181Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16748117) by Antoine Pitrou (apitrou):*\nNote that some benchmarks may not give you a time (for example [memory benchmarks](https://asv.readthedocs.io/en/stable/writing_benchmarks.html#memory) with ASV). For some other benchmarks, the preferred unit of reporting may be something else (for example MB/s for a memory copy benchmark)."
        },
        {
            "created_at": "2019-01-21T17:34:34.700Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16748119) by Wes McKinney (wesm):*\nVery good point. So we should generalize to:\r\n\r\n- Benchmark result\n- Benchmark unit\n  \n  Or something else?\n  \n  We should make an effort to standardize the permitted values of \"Unit\". "
        },
        {
            "created_at": "2019-01-21T17:38:20.882Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16748125) by Antoine Pitrou (apitrou):*\nYes, result + unit sounds good. Plus a boolean flag that indicates \"higher is better\" or something (to be able to distinguish regressions from improvements). In this manner, the unit could be pretty much arbitrary (as long as a given benchmark always reports the same unit, instead of e.g. switching between \"MB\" and \"GB\")."
        },
        {
            "created_at": "2019-01-21T23:01:35.897Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16748260) by Tanya Schlusser (tanya):*\nPinging `[~aregm]` \u00a0who started the email discussion, and\u00a0volunteering to help in what ways I can \ud83d\udc4b. I said I'd mock\u00a0a backend and will edit this comment with a hyperlink\u00a0when a mock is up."
        },
        {
            "created_at": "2019-01-22T06:02:20.097Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16748409) by Areg Melik-Adamyan (aregm):*\n\u00a0I think it will be easy if we keep it a little bit simple in the beginning, not to redo a lot in the future.\r\n\r\nSo replies to original comments:\r\n \\* Timestamp of benchmark run - **We should be careful, as this is helpful, but you cannot rely on this timestamp as, there is no guarantee that systems are synced in time. So for purely informational purposes, it is fine.**\u00a0\r\n \\* Git commit hash of codebase\u00a0\r\n \\* Machine unique name (sort of the \"user id\") - **Machine ID and machine information should go to a\u00a0different database, as they can change, come and go, you do not want to keep that info tied to benchmarks**\r\n \\* CPU identification for machine, and clock frequency (in case of overclocking)\r\n \\* CPU cache sizes (L1/L2/L3)\r\n \\* Whether or not CPU throttling is enabled (if it can be easily determined) - **for benchmarking you should always set it to max, not fixing the governor will add additional unpredictable flakiness to the benchmarks. Also you need to lock machine\u00a0when the benchmarks are running to prevent\u00a0noise.**\u00a0\r\n \\* RAM size\r\n \\* GPU identification (if any)\r\n \\* Benchmark unique name -\u00a0**For the start I would say yes, but it can quickly get out of control, as you have e.g. TestFeatureA, then it gets flavors, like input size, and you start naming it TestFeatureA5GB, then**\u00a0**TestFeatureA5GB-CPU,**\u00a0**TestFeatureA5GB-GPU-Nvidia,**\u00a0**TestFeatureA5GB-GPU-Radeon, and it gets out of control. The best know method to control is hierarchical name or unique id with benchmark\u00a0table, which is kind of overkill for now.**\\*\\*\r\n \\* Programming language(s) associated with benchmark (e.g. a benchmark\r\nmay involve both C++ and Python)\u00a0 -\u00a0**Why would you need this? Maybe put into hierarchical name?**\r\n \\* Benchmark time, plus mean and standard deviation if available, else NULL \u00a0\\*\\*\u00a0"
        },
        {
            "created_at": "2019-01-24T07:27:37.834Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16750812) by Areg Melik-Adamyan (aregm):*\n`[~tanya]` I have created the task 4354 - can you please take a look?\r\n\r\nMeanwhile I have created the first version of teh spec to work on - <https://cwiki.apache.org/confluence/display/ARROW/Performance+Dashboard>\u00a0"
        },
        {
            "created_at": "2019-01-27T06:08:02.500Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16753301) by Tanya Schlusser (tanya):*\nI've attached a diagram [benchmark-data-model.png](https://issues.apache.org/jira/secure/attachment/12956481/benchmark-data-model.png) and a corresponding `.erdplus` file [benchmark-data-model.erdplus](https://issues.apache.org/jira/secure/attachment/12956482/benchmark-data-model.erdplus) (JSON--viewable and editable by getting a free account on [erdplus.com](https://erdplus.com/#/)) with a draft data model for everyone's consideration.  I tried to incorporate elements of both the codespeed and the ASV projects.\r\n\r\nHappy to modify per feedback\u2014or leave this to a more experienced person if I'm becoming the slow link.\r\nOf course there will be a view with all of the relevant information joined."
        },
        {
            "created_at": "2019-01-29T12:49:23.821Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16754973) by Antoine Pitrou (apitrou):*\nSome thoughts:\r\n\r\n- in `cpu_dim`, perhaps add a `cpu_thread_count` (the CPU's number of hardware threads, which can be a multiple of the number of distinct cores)\n- either in `machine_dim` or `os_dim`, store the bitness? (usually 64-bit I suppose, though perhaps some people will want to benchmark on 32-bit). Or, more generally perhaps, the architecture name (such as \"x86-64\" or \"ARMv8\" or \"AArch64\").\n- not sure why tables are suffixed with `_dim`?\n"
        },
        {
            "created_at": "2019-01-29T18:58:10.105Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755291) by Areg Melik-Adamyan (aregm):*\n- in `cpu_dim`, perhaps add a `cpu_thread_count` (the CPU's number of hardware threads, which can be a multiple of the number of distinct cores)\n   \\*\\* there is a 'core_count', for IA it is better to\u00a0have\u00a0HT flag, for others threads=cores\n   \\* either in `machine_dim` or `os_dim`, store the bitness? (usually 64-bit I suppose, though perhaps some people will want to benchmark on 32-bit). Or, more generally perhaps, the architecture name (such as \"x86-64\" or \"ARMv8\" or \"AArch64\").\n   \\*\\* short uname\u00a0-i should be\u00a0enough.\u00a0\n   \\* not sure why tables are suffixed with `_dim`?\n   \\*\\* I guess those are conditional names and not necessarily the resulting.\u00a0"
        },
        {
            "created_at": "2019-01-29T20:13:05.068Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755350) by Antoine Pitrou (apitrou):*\n> there is a 'core_count', for IA it is better to have HT flag, for others threads=cores\r\n\r\nNot really, for example IBM POWER CPUs can have 2, 4 or 8 threads per core.\r\n"
        },
        {
            "created_at": "2019-01-29T20:23:16.401Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755360) by Areg Melik-Adamyan (aregm):*\nOk, if we want to add them, then it should be named 'smt_thread_count' or 'threads_per_core'. And\u00a0there is a case for multiple CPUs also. Do you anticipate using Arrow on mainframes? I would say that most likely FPGA usage will preceed\u00a0Power usage.\u00a0"
        },
        {
            "created_at": "2019-01-29T21:11:33.435Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755383) by Antoine Pitrou (apitrou):*\nMultiple CPUs would go under the core_count IMO.\r\n\r\nAs for mainframes, no, but AFAIK there are regular Linux-based (or AIX-based) POWER servers."
        },
        {
            "created_at": "2019-01-29T22:22:17.785Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755433) by Wes McKinney (wesm):*\nI recall an e-mail thread some time back about IBM POWER support \u2013 some of us (myself, `[~kou]`) were given access to Power Z -based CI infrastructure for testing but we have yet to try it. I doubt that the project works on big endian right now (Arrow is current little-endian, even running on big-endian hardware)"
        },
        {
            "created_at": "2019-01-30T00:23:01.216Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755504) by Tanya Schlusser (tanya):*\nThank you very much for everyone's detailed feedback. I absolutely need guidance with the Machine / CPU / GPU specs. I have updated the [benchmark-data-model.png](benchmark-data-model.png) and the [benchmark-data-model.erdplus](benchmark-data-model.erdplus), and added all of the recommended columns.\r\n\r\n\u00a0\r\n\r\n**Summary of changes:**\r\n \\* All the dimension tables have been renamed to exclude the\u00a0`_dim`. (It was to distinguish dimension vs. fact tables.)\r\n\r\n \\* `cpu`\r\n \\*\\* Added a `cpu_thread_count`.\u00a0\r\n \\*\\* Changed `cpu.speed_Hz` to two columns: `frequency_max_Hz` and `frequency_min_Hz` and also added a column `machine.overclock_frequency_Hz` to the `machine` table to allow for overclocking like Wes mentioned in the beginning.\r\n\r\n \\* `os`\r\n \\*\\* Added both `os.architecture_name` and `os.architecture_bits`, the latter forced to be in \\{32, 64}, and pulled from the architecture name (maybe it will become just a computed column in the joined view...). I think it's a good idea.\r\n\r\n \\* `project`\r\n \\*\\* Added a `project.project_name` (oversight before)\r\n\r\n \\* `benchmark_language`\r\n \\*\\* Split out `language` to `language_name` and `language_version` because maybe people will want to compare between them (e.g. Python 2.7, 3.5+)\r\n\r\n \\* `environment`\r\n \\*\\* Removed foreign key for `machine_id` \u2014\u00a0that should be in the benchmark report separately. Many machines will have the same environment.\r\n\r\n \\* `benchmark`\r\n \\*\\* Added foreign key for `benchmark_language_id`\u2014a benchmark with the same name may exist for different languages.\r\n \\*\\* Added foreign key for `project_id`\u2014moved it from table `benchmark_result`\r\n\r\n \\* `benchmark_result`\r\n \\*\\* Added foreign key for `machine_id` (was removed from `environment`)\r\n \\*\\* Deleted foreign key for `project_id`, placing it in `benchmark` (as stated above)\r\n\r\n**Questions**\r\n \\* `cpu` and `gpu` dimension\r\n \\*\\* Is it a mistake to make `cpu.cpu_model_name` unique? I mean, are the LX cache levels, core counts, or any other attribute ever different for the same CPU model string?\r\n \\*\\* The same for GPU.\r\n \\*\\* I have commented the columns to say that\u00a0 `cpu_thread_count` corresponds to `sysctl -n hw.logicalcpu` and `cpu_core_count` corresponds to `sysctl -n hw.physicalcpu`; corrections gratefully accepted.\r\n \\*\\* Would it be less confusing to make the column names the exact same strings as correspond to their value from `sysctl`, e.g. change `cpu.cpu_model_name` to `cpu.cpu_brand_string` to correspond to the output of `sysctl -n machdep.cpu.brand_string`?\r\n \\*\\* On that note is CPU RAM the same thing as `sysctl -n machdep.cpu.cache.size`?\r\n \\* `environment`\r\n \\*\\* I'm worried I'm doing something inelegant with the dependency list. It will hold everything \u2013 Conda / virtualenv; versions of Numpy; all permutations of the various dependencies in what in ASV is the dependency matrix."
        },
        {
            "created_at": "2019-01-30T00:24:27.427Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755506) by Areg Melik-Adamyan (aregm):*\n`[~tanya]` why we need 'overclock_freq_HZ'? What is the practical usage model for this field?"
        },
        {
            "created_at": "2019-01-30T00:28:21.400Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755509) by Tanya Schlusser (tanya):*\n`[~aregm]` I do not know. I am depending on the other people commenting here to make sure the hardware\u00a0tables\u00a0make sense because honestly I don't ever pay attention to\u00a0hardware\u00a0because my use cases never stress my system.\u00a0At one point Wes suggested it. I am glad there is a debate."
        },
        {
            "created_at": "2019-01-30T00:33:04.180Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755513) by Areg Melik-Adamyan (aregm):*\nGot it. I think that mostly those numbers are never used because you run benchmarks on a fixed freq always to get consistent results in time. So they can be easily determined from the model name or cpuid, just for informational purposes, but will never be used in a serial benchmarking. In a serial benchmarking everything should be fixed, nailed and unchanged, except the variable you are measuring, and it is the arrow code measured through the benchmark code.\u00a0"
        },
        {
            "created_at": "2019-01-30T01:59:15.857Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755570) by Tanya Schlusser (tanya):*\nI think part of this was to allow anybody to contribute benchmarks from their own machine. And while dedicated benchmarking machines like the ones you will set up will have all parameters set for\u00a0optimal benchmarking, benchmarks run on other machines may give different results. Collecting details about the machine that might explain those differences (in case someone cares to explore the dataset) is part of the goal of the data model.\r\n\r\nOne concern, of course, is that people get wildly different results than a benchmark says, and may say \"Oh boo\u2013the representative person from the company made fake results that I can't replicate on my machine\" ... and with details about a system, performance differences can maybe be traced back to differences in setup, because they were recorded.\r\n\r\nNot all fields need to be filled out all the time. My priorities are:\r\n1. Identifying which\u00a0fields flat-out wrong\n1. Differentiating between necessary columns and extraneous ones that can be left null\n   \n   \n   To me, it is not a big deal to have an extra column dangling around that almost nobody uses. No harm. (Unless it's mislabeled or otherwise wrong; that's what I'm interested in getting out of the discussion here.)"
        },
        {
            "created_at": "2019-01-30T07:54:15.815Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755807) by Antoine Pitrou (apitrou):*\nFor the record, IBM POWER CPUs support little-endian mode on Linux:\r\nhttps://www.ibm.com/developerworks/library/l-power-little-endian-faq-trs/index.html\r\n\r\nSo big-endian support in Arrow would probably not be a roadblock."
        },
        {
            "created_at": "2019-01-30T07:55:18.915Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16755808) by Antoine Pitrou (apitrou):*\n\"Is it a mistake to make `cpu.cpu_model_name` unique? I mean, are the LX cache levels, core counts, or any other attribute ever different for the same CPU model string?\"\r\n\r\nThe overclocked frequency may vary (which we could also call \"actual frequency\"), the rest should be the same."
        },
        {
            "created_at": "2019-02-07T22:45:18.005Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16763145) by Tanya Schlusser (tanya):*\nThank you Antoine! I missed this last comment. \"actual frequency\" is a good name, and I used it.\r\n \\* I did not understand the conversations about little-and-big-endian, and did not add fields related to that to the database.\r\n \\* I was surprised during testing about the behavior of nulls in the database, so some things don't yet work the way I'd like (the example script fails in one place.)\r\n\r\nThank you everyone for so much feedback. I have uploaded new files for the current data model and am happy to change things according to feedback. If you don't like something, it can be fixed :)\u00a0"
        },
        {
            "created_at": "2019-02-19T19:03:11.189Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16772241) by Areg Melik-Adamyan (aregm):*\n`[~wesmckinn]` and `[~pitrou]` - need your input.\r\n\r\n> My understanding of [this conversation] (https://lists.apache.org/thread.html/dcc08ab10507a5139178d7f816c0f5177ff0657546a4ade3ed71ffd5@%3Cdev.arrow.apache.org%3E) was that a data model not tied to any ORM tool was the desired path to take.\r\n> \r\nI think we need to take a step back, and sync and agree with the @wesm and @pitrou on the goals for this little project: \r\n- for me the goal is to continuously track the performance for the core C++ library and help everybody who is doing performance work to catch regressions and contribute improvements. \n- do that in a validated form, so we can rely on the numbers.\n- there is no goal to provide infrastructure for contributing 3rd party numbers, as they cannot be validated in a quick manner.\n- there is no goal to bench other languages, as they rely on C++ library calls and you will benchmark the wrapper conversion speed\n- there is no goal, for now, to anticipate and satisfy all the future possible needs.\n  \n  The ability of the Arrow test library (practically GTest) to provide performance numbers on a run platform is more than enough. I would not like to limit users to have a different kind of databases, performance monitors or dashboards of their need. I am duplicating this in the issue 4313 to move the discussion from code review."
        },
        {
            "created_at": "2019-02-19T20:43:03.191Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16772315) by Wes McKinney (wesm):*\nI'm involved many projects so I haven't been able to follow the discussion to see where there is disagreement or conflict. \r\n\r\nFrom my perspective I want the following in the short term\r\n\r\n- A general purpose database schema, preferably for PostgreSQL, which can be used to easily provision a new benchmark database\n- A script for running the C++ benchmarks and inserting the results into _any instance_ of that database. This script should capture hardware information as well as any additional information that is known about the environment (OS, thirdparty library versions \u2013 e.g. so we can see if upgrading a dependency, like gRPC for example, causes a performance problem). The script should not be coupled to a particular instance of the database. It should work in an air-gapped environment\n  \n  I think until we should work as quickly as possible to have a working version of both of these to validate that we are on the right track. If we try to come up with the \"perfect database schema\" and punt the benchmark collector script until later we could be waiting a long time. \n  \n  Ideally the database schema can accommodate results from multiple benchmark execution frameworks other than Google benchmark for C++. So we could write an adapter script to export data from ASV (for Python) into this database.\n  \n  `[~aregm]` this does not seem to be out of line with the requirements you listed unless I am misunderstanding. I would rather not be too involved with the details right now unless the project stalls out for some reason and needs me to help push it through to completion. "
        },
        {
            "created_at": "2019-02-20T12:13:56.056Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16772959) by Antoine Pitrou (apitrou):*\nIndeed, agreed with Wes.\r\n\r\nJust to answer one comment:\r\n\r\n> there is no goal to bench other languages, as they rely on C++ library calls and you will benchmark the wrapper conversion speed\r\n\r\nIt's a bit more involved than that. For example the speed of creating an Arrow array (or an Arrow dataframe) from Python objects is important, and this requires specific optimizations inside Arrow. Technically we _could_ benchmark it using the C++ infrastructure, it's just massively easier to write the benchmarks in Python using ASV, so that's what we're doing now.\r\n\r\nThat said, yes, recording C++ benchmark results is a good first-priority goal. The thing to keep in mind is that we don't want the adopted DB schema to limit ourselves in this regard.\r\n\r\n(also, some implementations are not based on the C++ library, they are independent reimplementations of the Arrow data model, e.g. Java, C# or Rust)\r\n"
        },
        {
            "created_at": "2019-02-27T14:18:19.655Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4313?focusedCommentId=16779359) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 3586\n<https://github.com/apache/arrow/pull/3586>"
        }
    ]
}