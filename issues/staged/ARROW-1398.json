{
    "issue": {
        "title": "[Python] No support reading columns of type decimal(19,4)",
        "body": "***Note**: This issue was originally created as [ARROW-1398](https://issues.apache.org/jira/browse/ARROW-1398). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI have a localy saved parquet database created in spark from querrying an SQL database. When I run:\n\n```python\nimport pyarrow.parquet as pq\n\npath = \"path/to/parquet/dataset\"\ndataset = pq.ParquetDataset(path)\ndataset.read()\n```\n\nan error indicating that there is no support for reading columns of type decimal(19,4). It's quite a common type used in SQL databases and I saw in the source code that there is an implementation for decimals. I'm stuck trying to figuring out a solution. Is there a walk around (conversion of decimals to integers during reading)?",
        "created_at": "2017-08-22T14:48:26.000Z",
        "updated_at": "2017-12-05T03:40:34.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2017-12-05T03:40:34.000Z"
    },
    "comments": [
        {
            "created_at": "2017-08-22T14:58:46.053Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1398?focusedCommentId=16136902) by Wes McKinney (wesm):*\nhi `[~LudwikB]` indeed support for reading these in parquet-cpp has not been implemented yet. `[~cpcloud]` has been working on this (there's a patch up to make the decimal in-memory representation consistent with Java: https://github.com/apache/arrow/pull/981); I suspect we can get this fully working within the next month or so. Any help would be appreciated"
        },
        {
            "created_at": "2017-08-22T14:59:28.627Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1398?focusedCommentId=16136904) by Wes McKinney (wesm):*\nMarking for 0.7.0 in hopes that we can get it done in time. I don't think it should be difficult on the Parquet side as we simply have to copy over the decoded bytes"
        },
        {
            "created_at": "2017-09-10T00:11:25.335Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1398?focusedCommentId=16160126) by Wes McKinney (wesm):*\nThis turns out to be a bit of a rabbit hole. I opened PARQUET-1095 which is where most of the work will be. We'll need to write some unit tests on the Arrow side for this JIRA"
        },
        {
            "created_at": "2017-12-05T03:40:34.148Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1398?focusedCommentId=16277971) by Wes McKinney (wesm):*\nResolved by PR https://github.com/apache/arrow/commit/b241eb699b6151d9b1c8809528be4c80cce26c7e"
        }
    ]
}