{
    "issue": {
        "title": "[R] Update function examples to show how to open CSV dataset with partitioning and a schema",
        "body": "***Note**: This issue was originally created as [ARROW-17700](https://issues.apache.org/jira/browse/ARROW-17700). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI feel like this might be a duplicate of a previous ticket, but can't find it.\r\n\r\n\r\n```r\n\r\nlibrary(dplyr)\r\nlibrary(arrow)\r\n\r\n# all good!\r\ntf <- tempfile()\r\ndir.create(tf)\r\nwrite_dataset(mtcars, tf, format = \"csv\")\r\nopen_dataset(tf, format = \"csv\") %>% collect()\r\n#> # A tibble: 32 \u00d7 11\r\n#>      mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\r\n#>    <dbl> <int> <dbl> <int> <dbl> <dbl> <dbl> <int> <int> <int> <int>\r\n#>  1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\r\n#>  2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\r\n#>  3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\r\n#>  4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\r\n#>  5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\r\n#>  6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\r\n#>  7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\r\n#>  8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\r\n#>  9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\r\n#> 10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\r\n#> # \u2026 with 22 more rows\r\n\r\n# all good\r\ntf <- tempfile()\r\ndir.create(tf)\r\nwrite_dataset(group_by(mtcars, cyl), tf, format = \"csv\")\r\nopen_dataset(tf, format = \"csv\") %>% collect()\r\n#> # A tibble: 32 \u00d7 11\r\n#>      mpg  disp    hp  drat    wt  qsec    vs    am  gear  carb   cyl\r\n#>    <dbl> <dbl> <int> <dbl> <dbl> <dbl> <int> <int> <int> <int> <int>\r\n#>  1  22.8 108      93  3.85  2.32  18.6     1     1     4     1     4\r\n#>  2  24.4 147.     62  3.69  3.19  20       1     0     4     2     4\r\n#>  3  22.8 141.     95  3.92  3.15  22.9     1     0     4     2     4\r\n#>  4  32.4  78.7    66  4.08  2.2   19.5     1     1     4     1     4\r\n#>  5  30.4  75.7    52  4.93  1.62  18.5     1     1     4     2     4\r\n#>  6  33.9  71.1    65  4.22  1.84  19.9     1     1     4     1     4\r\n#>  7  21.5 120.     97  3.7   2.46  20.0     1     0     3     1     4\r\n#>  8  27.3  79      66  4.08  1.94  18.9     1     1     4     1     4\r\n#>  9  26   120.     91  4.43  2.14  16.7     0     1     5     2     4\r\n#> 10  30.4  95.1   113  3.77  1.51  16.9     1     1     5     2     4\r\n#> # \u2026 with 22 more rows\r\nlist.files(tf)\r\n#> [1] \"cyl=4\" \"cyl=6\" \"cyl=8\"\r\n\r\n# hive-style=FALSE leads to no `cyl` column, which, sure, makes sense\r\ntf <- tempfile()\r\ndir.create(tf)\r\nwrite_dataset(group_by(mtcars, cyl), tf, format = \"csv\", hive_style = FALSE)\r\nopen_dataset(tf, format = \"csv\") %>% collect()\r\n#> # A tibble: 32 \u00d7 10\r\n#>      mpg  disp    hp  drat    wt  qsec    vs    am  gear  carb\r\n#>    <dbl> <dbl> <int> <dbl> <dbl> <dbl> <int> <int> <int> <int>\r\n#>  1  22.8 108      93  3.85  2.32  18.6     1     1     4     1\r\n#>  2  24.4 147.     62  3.69  3.19  20       1     0     4     2\r\n#>  3  22.8 141.     95  3.92  3.15  22.9     1     0     4     2\r\n#>  4  32.4  78.7    66  4.08  2.2   19.5     1     1     4     1\r\n#>  5  30.4  75.7    52  4.93  1.62  18.5     1     1     4     2\r\n#>  6  33.9  71.1    65  4.22  1.84  19.9     1     1     4     1\r\n#>  7  21.5 120.     97  3.7   2.46  20.0     1     0     3     1\r\n#>  8  27.3  79      66  4.08  1.94  18.9     1     1     4     1\r\n#>  9  26   120.     91  4.43  2.14  16.7     0     1     5     2\r\n#> 10  30.4  95.1   113  3.77  1.51  16.9     1     1     5     2\r\n#> # \u2026 with 22 more rows\r\nlist.files(tf)\r\n#> [1] \"4\" \"6\" \"8\"\r\n\r\n\r\n# *but* if we try to add it in via a schema, it doesn't work\r\n\r\ndesired_schema <- schema(mpg = float64(), disp = float64(), hp = int64(), drat = float64(), \r\n    wt = float64(), qsec = float64(), vs = int64(), am = int64(), \r\n    gear = int64(), carb = int64(), cyl = int64())\r\n\r\ntf <- tempfile()\r\ndir.create(tf)\r\nwrite_dataset(group_by(mtcars, cyl), tf, format = \"csv\", hive_style = FALSE)\r\nopen_dataset(tf, format = \"csv\", schema = desired_schema) %>% collect()\r\n#> Error in `dplyr::collect()`:\r\n#> ! Invalid: Could not open CSV input source '/tmp/RtmpnInOwc/file13f0d38c5b994/4/part-0.csv': Invalid: CSV parse error: Row #1: Expected 11 columns, got 10: \"mpg\",\"disp\",\"hp\",\"drat\",\"wt\",\"qsec\",\"vs\",\"am\",\"gear\",\"carb\"\r\n#> /home/nic2/arrow/cpp/src/arrow/csv/parser.cc:477  (ParseLine<SpecializedOptions, false>(values_writer, parsed_writer, data, data_end, is_final, &line_end, bulk_filter))\r\n#> /home/nic2/arrow/cpp/src/arrow/csv/parser.cc:566  ParseChunk<SpecializedOptions>( &values_writer, &parsed_writer, data, data_end, is_final, rows_in_chunk, &data, &finished_parsing, bulk_filter)\r\n#> /home/nic2/arrow/cpp/src/arrow/csv/reader.cc:426  parser->ParseFinal(views, &parsed_size)\r\n#> /home/nic2/arrow/cpp/src/arrow/compute/exec/exec_plan.cc:573  iterator_.Next()\r\n#> /home/nic2/arrow/cpp/src/arrow/record_batch.cc:337  ReadNext(&batch)\r\n#> /home/nic2/arrow/cpp/src/arrow/record_batch.cc:351  ToRecordBatches()\r\nlist.files(tf)\r\n#> [1] \"4\" \"6\" \"8\"\r\n\r\n```\r\n\r\nIf I include a schema which does not include the partitioning column, it works, but I lost the partitioning column\r\n\r\n\r\n```r\n\r\n# this works minus the col\r\ndesired_schema <- schema(mpg = float64(), disp = float64(), hp = int64(), drat = float64(), \r\n    wt = float64(), qsec = float64(), vs = int64(), am = int64(), \r\n    gear = int64(), carb = int64())\r\n\r\ntf <- tempfile()\r\ndir.create(tf)\r\nwrite_dataset(group_by(mtcars, cyl), tf, format = \"csv\", hive_style = FALSE)\r\nopen_dataset(tf, format = \"csv\", schema = desired_schema, skip = 1) %>% collect()\r\n```\r\n",
        "created_at": "2022-09-13T09:47:03.000Z",
        "updated_at": "2022-11-17T19:46:49.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: R",
            "Type: task"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-09-13T11:10:26.501Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17700?focusedCommentId=17603519) by Nicola Crane (thisisnic):*\nThis is a duplicate of ARROW-14743, which was previously resolved."
        },
        {
            "created_at": "2022-09-13T12:06:12.357Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17700?focusedCommentId=17603539) by Nicola Crane (thisisnic):*\nDo y'all mind not looking into this too much right now, as I'm wanting to level up my C++ and trying to work it out on my own!"
        },
        {
            "created_at": "2022-09-13T12:51:45.013Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17700?focusedCommentId=17603558) by Neal Richardson (npr):*\nAlso sounds like ARROW-15879"
        },
        {
            "created_at": "2022-09-13T19:13:14.277Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17700?focusedCommentId=17603728) by Nicola Crane (thisisnic):*\nRight, totally stuck here.  It looks like there is a variable `batch_.num_cols_` in arrow/cpp/src/arrow/csv/parser.cc which is set to the number of fields in the schema which is why it's complaining about being too high (as the data being read in is partitioned, so has 1 less field than expected), but I'm struggling to think of how I'd work out if this is something in the C++ or something in the stuff we pass to the C++ from R that should set this. \r\n"
        },
        {
            "created_at": "2022-09-13T19:14:41.799Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17700?focusedCommentId=17603730) by Nicola Crane (thisisnic):*\nCC `[~westonpace]`"
        },
        {
            "created_at": "2022-09-14T15:23:05.604Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17700?focusedCommentId=17604806) by Nicola Crane (thisisnic):*\nI've been looking in the `parser.cc` file mentioned in the error message, and I think what it is is that it's using the number of fields in the schema to set some variable, `batch_.num_cols_`, instead of however that variable is set when we don't manually pass a schema in.  As the schema contains the partitioning column, and that variable is used to work out how much data to read, the `Expected 11 columns, got 10` error is triggered."
        },
        {
            "created_at": "2022-09-20T13:36:34.663Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17700?focusedCommentId=17607201) by Nicola Crane (thisisnic):*\nFWIW in case anyyone else comes up against this issue, after some help from `[~westonpace]`, we worked out to read in the partitioning column successfully, you have to pass in the column as a schema via the `partitioning` argument:\r\n\r\n```r\n\r\n\r\ntf <- tempfile()\r\ndir.create(tf)\r\nwrite_dataset(mtcars, tf, partitioning = \"cyl\", hive_style = FALSE)\r\nopen_dataset(tf, partitioning = schema(cyl = int64())) %>% collect()\r\n#>     mpg  disp  hp drat    wt  qsec vs am gear carb cyl\r\n#> 1  22.8 108.0  93 3.85 2.320 18.61  1  1    4    1   4\r\n#> 2  24.4 146.7  62 3.69 3.190 20.00  1  0    4    2   4\r\n#> 3  22.8 140.8  95 3.92 3.150 22.90  1  0    4    2   4\r\n...\r\n```\r\n"
        },
        {
            "created_at": "2022-09-29T16:40:10.736Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17700?focusedCommentId=17611130) by Nicola Crane (thisisnic):*\nWe should add an example to the docs for `open_dataset()` which shows the correct way to do this when passing a schema to both the `schema` and `partitioning` arguments."
        }
    ]
}