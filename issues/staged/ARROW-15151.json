{
    "issue": {
        "title": " write_dataset() never increments {i} in partitions part-{i}",
        "body": "***Note**: This issue was originally created as [ARROW-15151](https://issues.apache.org/jira/browse/ARROW-15151). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIntroducing partitioning in write_dataset() creates sub-folders just fine, but the lowest-level subfolder only ever contains a part-0.parquet.\u00a0 I don't see how to get write_dataset() to ever generate output with multiple part-filenames in a single directory, like part-0.parquet, part-1.parquet, etc.\u00a0 e.g. the documentation for open_dataset() implies we should get three `Z` level parts:\r\n\r\n\r\n```java\n\r\n# You can also partition by the values in multiple columns\r\n# (here: \"cyl\" and \"gear\").\r\n# This creates a structure of the form cyl=X/gear=Y/part-Z.parquet.\r\ntwo_levels_tree <- tempfile()\r\nwrite_dataset(mtcars, two_levels_tree, partitioning = c(\"cyl\", \"gear\"))\r\nlist.files(two_levels_tree, recursive = TRUE)\r\n\r\n# In the two previous examples we would have:\r\n# X = {4,6,8}, the number of cylinders.\r\n# Y = {3,4,5}, the number of forward gears.\r\n# Z = {0,1,2}, the number of saved parts, starting from 0. \n```\r\nBut I only get the expected structure with part-0.parquet files.\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\nContext: I frequently need to partition large files that lack any natural grouping variable; I merely want a bunch of small parts of equal size.\u00a0 It would be great if there was an automatic way of doing this; currently I can hack this by creating a partition column with integers 1...n where n is my desired number of partitions, and partition on that.\u00a0 I'd then like to write these to a flat structure with part-0.parquet, part-1.parquet etc, not a nested folder structure, if possible.\u00a0\r\n\r\n(Or better yet, it would be amazing if write_dataset() just let us set a maximum partition file size and could automate the sharding into parts while preserving the existing behavior for actually semantically meaningful groups.\u00a0 Maybe that is already the intent but I cannot see how to activate it!)",
        "created_at": "2021-12-19T18:35:11.000Z",
        "updated_at": "2022-07-02T14:14:18.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-07-02T14:14:18.000Z"
    },
    "comments": [
        {
            "created_at": "2021-12-20T13:18:42.667Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15151?focusedCommentId=17462604) by David Li (lidavidm):*\nCC `[~westonpace]` in case he has something to add, but I think this is two things:\r\n \\* 6.0.x changed it so that the counter is reset for each partition; you will see the counter increment if a partition has multiple files, though. So the documentation there needs updating.\r\n \\* The new dataset writer in 6.0.x has options to limit the max file size (which should get you multiple files), but the option is not yet exposed to R. ARROW-13703 and its child tasks should fix that.\r\n\r\nSo what you want should be possible, it just needs some plumbing to get everything exposed (and sorry for the misleading docs)."
        },
        {
            "created_at": "2021-12-20T17:20:01.638Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15151?focusedCommentId=17462733) by Carl Boettiger (cboettig):*\n> The new dataset writer in 6.0.x has options to limit the max file size (which should get you multiple files)\r\n\r\n\u00a0\r\n\r\nYay!\u00a0 that's fantastic! I'll just keep an eye on https://issues.apache.org/jira/browse/ARROW-13703 then :)"
        }
    ]
}