{
    "issue": {
        "title": "[Format] Support lossy compression",
        "body": "***Note**: This issue was originally created as [ARROW-6282](https://issues.apache.org/jira/browse/ARROW-6282). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nArrow dataframes with large columns of integers or floats can be compressed using gzip or brotli. However, in some cases it will be okay to compress the data lossy to achieve even higher compression ratios. The main use case for this is visualization where small inaccuracies matter less. ",
        "created_at": "2019-08-17T10:32:35.000Z",
        "updated_at": "2020-09-07T16:35:09.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Format",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-09-07T16:35:09.000Z"
    },
    "comments": [
        {
            "created_at": "2019-08-17T17:49:10.061Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6282?focusedCommentId=16909778) by Martin Radev (martinradev):*\nHello Dominik,\r\n\r\nare you going to work on this new feature?\r\n\r\nI actually already began working on this feature though not directly for Arrow. In particular, my work focuses on investigating, designing, proposing and implementing an extension to Apache Parquet for support of lossy and lossless floating-point compression.\r\nI had an initial report which can be read here: <https://drive.google.com/file/d/1wfLQyO2G5nofYFkS7pVbUW0-oJkQqBvv/view?usp=sharing>\r\n\r\nI investigated two lossy compressors: ZFP and SZ. I concluded that, despite SZ's better compression ratio, it cannot be introduced to Parquet since the implementation is not mature enough - the API is poorly designed, it is not thread safe and I observed two segfaults locally. Developers have been also slow to correspond. For example, this issue I opened has not led to any discussion <https://github.com/disheng222/SZ/issues/29>\r\n\r\nZFP seems to be a safer choice for using it\u00a0in Parquet. There's still some consideration on the way the user should specify how data should be discarded. In particular, it should be designed in such a way that\u00a0other lossy compressors can be added in the future.\u00a0These are the error modes I've observed in my investigation: absolute error, relative error, number of mantissa bits to discard.\r\n\r\nCan you please share at what stage are you currently in working on the feature? I think we can collaborate."
        },
        {
            "created_at": "2019-08-17T23:35:55.568Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6282?focusedCommentId=16909851) by Brian Hulette (bhulette):*\nGreat idea! I think right now we only support compressing entire record record batches, to make this work would need buffer-level compression so that we could just compress the floating-point buffers. [~emkornfield@gmail.com] did write up a proposal that included buffer-level compression, among other things: [strawman PR](https://github.com/apache/arrow/pull/4815), [ML discussion](https://lists.apache.org/thread.html/a99124e57c14c3c9ef9d98f3c80cfe1dd25496bf3ff7046778add937@%3Cdev.arrow.apache.org%3E)"
        },
        {
            "created_at": "2019-08-18T02:26:46.573Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6282?focusedCommentId=16909870) by Micah Kornfield (emkornfield@gmail.com):*\n`[~domoritz]` it is definitely worth discussing your implementation plans/design on ML before getting too far, especially if this will require changes to the IPC specification."
        },
        {
            "created_at": "2019-08-18T12:23:40.245Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6282?focusedCommentId=16909946) by Dominik Moritz (domoritz):*\nThank you for the support and comments. I won't be implementing this but I wanted to propose this as a feature since it would be incredibly useful for visualization. "
        },
        {
            "created_at": "2019-10-31T20:34:57.988Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6282?focusedCommentId=16964376) by Martin Radev (martinradev):*\nHello Dominik,\r\n\r\nI recently worked on a PoC implementation of introducing the lossy ZFP floating-point compressor into Arrow.\r\nNote that this is mainly for compressing Parquet files but the path can serve other needs.\r\n\r\nAn unpolished Arrow patch is here:\u00a0https://github.com/martinradev/arrow/commit/4bfc052aaaf7ad9b6db521316a20c9fbf86120d8\r\n\r\nResults can be viewed here:\u00a0https://github.com/martinradev/arrow-fp-compression-bench/blob/master/LOSSY.md\r\n\r\n\u00a0"
        },
        {
            "created_at": "2020-09-07T16:35:09.533Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6282?focusedCommentId=17191783) by Antoine Pitrou (apitrou):*\nI will close this, as this should certainly be discussed on the Arrow development mailing-list first."
        }
    ]
}