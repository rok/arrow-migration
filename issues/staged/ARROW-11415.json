{
    "issue": {
        "title": "[R] experimental map_batches cannot find columns",
        "body": "***Note**: This issue was originally created as [ARROW-11415](https://issues.apache.org/jira/browse/ARROW-11415). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWith dataset:\r\n\r\n\u00a0\r\n```java\n\r\nSchema\r\nX3: timestamp[us]\r\nuser_id: dictionary<values=string, indices=int32>\r\nclassification_name: dictionary<values=string, indices=int32>\r\nX2: string\r\nX1: dictionary<values=string, indices=int32>\r\nX4: string\r\nX5: dictionary<values=string, indices=int32>\r\nX6: dictionary<values=string, indices=int32>\r\n```\r\nThe following succeeds:\r\n```java\n\r\nchunk <- ds %>%\r\n    select(user_id) %>%\r\n    collect() %>%\r\n    count(user_id) %>%\r\n    as_tibble() %>%\r\n    count(user_id, wt=n)\r\n```\r\nWhile the following fails:\r\n```java\n\r\nchunk <- ds %>%\r\n    select(user_id) %>%\r\n    arrow::map_batches(~count(., user_id)) %>%\r\n    as_tibble() %>%\r\n    count(user_id, wt=x)\r\n```\r\nWith error:\r\n```java\n\r\nError: Can't subset columns that don't exist.\r\n\u2716 Column `.drop` doesn't exist.\r\nTraceback:\r\n\r\n1. ds %>% select(user_id) %>% arrow::map_batches(~count(., \r\n .     user_id)) %>% as_tibble() %>% count(user_id, wt = x)\r\n2. count(., user_id, wt = x)\r\n3. group_by(x, ..., .add = TRUE, .drop = .drop)\r\n4. as_tibble(.)\r\n5. arrow::map_batches(., ~count(., user_id))\r\n6. lapply(scanner$Scan(), function(scan_task) {\r\n .     lapply(scan_task$Execute(), function(batch) {\r\n .         FUN(batch, ...)\r\n .     })\r\n . })\r\n7. map(.x, .f, ...)\r\n8. .f(.x[[i]], ...)\r\n9. lapply(scan_task$Execute(), function(batch) {\r\n .     FUN(batch, ...)\r\n . })\r\n10. map(.x, .f, ...)\r\n11. .f(.x[[i]], ...)\r\n12. FUN(batch, ...)\r\n13. count(., user_id)\r\n14. tally(out, wt = !!enquo(wt), sort = sort, name = name)\r\n15. (function() {\r\n  .     old.options <- options(dplyr.summarise.inform = FALSE)\r\n  .     on.exit(options(old.options))\r\n  .     summarise(x, `:=`(!!name, !!n))\r\n  . })()\r\n16. summarise(x, `:=`(!!name, !!n))\r\n17. summarise.arrow_dplyr_query(x, `:=`(!!name, !!n))\r\n18. dplyr::select(.data, vars_to_keep)\r\n19. select.arrow_dplyr_query(.data, vars_to_keep)\r\n20. column_select(arrow_dplyr_query(.data), !!!enquos(...))\r\n21. .FUN(names(.data), !!!enquos(...))\r\n22. eval_select_impl(NULL, .vars, expr(c(!!!dots)), include = .include, \r\n  .     exclude = .exclude, strict = .strict, name_spec = unique_name_spec, \r\n  .     uniquely_named = TRUE)\r\n23. with_subscript_errors(vars_select_eval(vars, expr, strict, data = x, \r\n  .     name_spec = name_spec, uniquely_named = uniquely_named, allow_rename = allow_rename, \r\n  .     type = type), type = type)\r\n24. tryCatch(instrument_base_errors(expr), vctrs_error_subscript = function(cnd) {\r\n  .     cnd$subscript_action <- subscript_action(type)\r\n  .     cnd$subscript_elt <- \"column\"\r\n  .     cnd_signal(cnd)\r\n  . })\r\n25. tryCatchList(expr, classes, parentenv, handlers)\r\n26. tryCatchOne(expr, names, parentenv, handlers[[1L]])\r\n27. value[[3L]](cond)\r\n28. cnd_signal(cnd)\r\n29. rlang:::signal_abort(x)\r\n```\r\nThe dataset is 8 parquet files with no hive partitioning.\r\n\r\n\u00a0\r\n\r\nsessionInfo():\r\n```java\n\r\nR version 4.0.3 (2020-10-10)\r\nPlatform: x86_64-pc-linux-gnu (64-bit)\r\nRunning under: Ubuntu 18.04.3 LTSMatrix products: default\r\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3\r\nLAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.solocale:\r\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \r\n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \r\n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \r\n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \r\n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \r\n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       attached base packages:\r\n[1] stats     graphics  grDevices utils     datasets  methods   base     other attached packages:\r\n [1] forcats_0.5.0     stringr_1.4.0     dplyr_1.0.2       purrr_0.3.4      \r\n [5] readr_1.4.0       tidyr_1.1.2       tibble_3.0.4      ggplot2_3.3.2    \r\n [9] tidyverse_1.3.0   dtplyr_1.0.1      data.table_1.13.2loaded via a namespace (and not attached):\r\n [1] Rcpp_1.0.5            lubridate_1.7.9.2     aws.ec2metadata_0.2.0\r\n [4] ps_1.5.0              arrow_2.0.0           assertthat_0.2.1     \r\n [7] digest_0.6.27         utf8_1.1.4            aws.signature_0.6.0  \r\n[10] mime_0.9              IRdisplay_0.7.0       R6_2.5.0             \r\n[13] cellranger_1.1.0      repr_1.1.0            backports_1.2.0      \r\n[16] reprex_0.3.0          evaluate_0.14         httr_1.4.2           \r\n[19] pillar_1.4.7          rlang_0.4.9           curl_4.3             \r\n[22] uuid_0.1-4            readxl_1.3.1          rstudioapi_0.13      \r\n[25] bit_4.0.4             munsell_0.5.0         broom_0.7.2          \r\n[28] compiler_4.0.3        modelr_0.1.8          pkgconfig_2.0.3      \r\n[31] base64enc_0.1-3       htmltools_0.5.0       tidyselect_1.1.0     \r\n[34] fansi_0.4.1           crayon_1.3.4          dbplyr_2.0.0         \r\n[37] withr_2.3.0           grid_4.0.3            jsonlite_1.7.1       \r\n[40] gtable_0.3.0          lifecycle_0.2.0       DBI_1.1.0            \r\n[43] magrittr_2.0.1        scales_1.1.1          cli_2.2.0            \r\n[46] stringi_1.5.3         fs_1.5.0              xml2_1.3.2           \r\n[49] ellipsis_0.3.1        generics_0.1.0        vctrs_0.3.5          \r\n[52] IRkernel_1.1.1        tools_4.0.3           bit64_4.0.5          \r\n[55] glue_1.4.2            hms_0.5.3             aws.s3_0.3.22        \r\n[58] colorspace_2.0-0      rvest_0.3.6           pbdZMQ_0.3-3.1\r\n```\r\n\u00a0",
        "created_at": "2021-01-28T15:29:25.000Z",
        "updated_at": "2022-04-25T14:52:00.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-04-22T11:52:47.000Z"
    },
    "comments": [
        {
            "created_at": "2021-01-29T22:56:49.294Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11415?focusedCommentId=17275417) by Neal Richardson (npr):*\nThanks. The `FUN` function isn't doing any NSE to map references to the columns in each record batch, so that's what's missing. "
        },
        {
            "created_at": "2021-01-30T00:05:05.392Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11415?focusedCommentId=17275433) by Neal Richardson (npr):*\nActually, that might be wrong, will have to look into it."
        },
        {
            "created_at": "2021-12-17T20:18:06.307Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11415?focusedCommentId=17461652) by Dewey Dunnington (paleolimbot):*\nMay be a different issue now, but at present issue here is that `~count(., user_id)` will return an arrow_dplyr_query, not a data.frame (as is required by the underlying `purrr::map_dfr()`:\r\n\r\n```R\n\r\nlibrary(arrow, warn.conflicts = FALSE)\r\nlibrary(dplyr, warn.conflicts = FALSE)\r\n\r\nds <- InMemoryDataset$create(record_batch(col = letters))\r\nmap_batches(ds, ~count(., col), .data.frame = TRUE)\r\n#> Error: Argument 1 must be a data frame or a named atomic vector.\r\nmap_batches(ds, ~count(., col), .data.frame = FALSE)\r\n#> [[1]]\r\n#> InMemoryDataset (query)\r\n#> col: string\r\n#> n: int32\r\n#> \r\n#> See $.data for the source Arrow object\r\n```\r\n\r\nThe workaround is to use `~collect(count(., user_id))`:\r\n\r\n```R\n\r\nlibrary(arrow, warn.conflicts = FALSE)\r\nlibrary(dplyr, warn.conflicts = FALSE)\r\n\r\nds <- InMemoryDataset$create(record_batch(col = letters))\r\nmap_batches(ds, ~collect(count(., col)))\r\n#> # A tibble: 26 \u00d7 2\r\n#>    col       n\r\n#>    <chr> <int>\r\n#>  1 a         1\r\n#>  2 b         1\r\n#>  3 c         1\r\n#>  4 d         1\r\n#>  5 e         1\r\n#>  6 f         1\r\n#>  7 g         1\r\n#>  8 h         1\r\n#>  9 i         1\r\n#> 10 j         1\r\n#> # \u2026 with 16 more rows\r\n```\r\n\r\nI imagine we should force a `collect()` if `.data.frame = TRUE` (or do a better job erroring)?\r\n"
        },
        {
            "created_at": "2021-12-21T12:53:03.004Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11415?focusedCommentId=17463229) by Dewey Dunnington (paleolimbot):*\nThis will likely be fixed by ARROW-14029."
        },
        {
            "created_at": "2022-04-21T18:19:07.783Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11415?focusedCommentId=17525936) by Krisztian Szucs (kszucs):*\nPostponing to 9.0, feel free to put it back if the patch is going to land for 8.0"
        },
        {
            "created_at": "2022-04-22T11:52:47.793Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11415?focusedCommentId=17526349) by Neal Richardson (npr):*\nIssue resolved by pull request 12948\n<https://github.com/apache/arrow/pull/12948>"
        }
    ]
}