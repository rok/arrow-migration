{
    "issue": {
        "title": "[Python] Resource temporarily unavailable when using the new Dataset API with Pandas",
        "body": "***Note**: This issue was originally created as [ARROW-11857](https://issues.apache.org/jira/browse/ARROW-11857). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen using the new Dataset API under v3.0.0 it instantly crashes with\r\n```java\n\r\n terminate called after throwing an instance of 'std::system_error'\r\n what(): Resource temporarily unavailable\n```\r\nThis does not happen in an earlier version. The error message leads me to believe that the issue is not on the Python side but might be in the C++ libraries.\r\n\r\nAs background, I am using the new Dataset API by calling the following\r\n```java\n\r\ns3_fs = fs.S3FileSystem(<minio credentials>)\r\ndataset = pq.ParquetDataset(\r\n        f\"{bucket}/{base_path}\",\r\n        filesystem=s3_fs,\r\n        partitioning=\"hive\",\r\n        use_legacy_dataset=False,\r\n        filters=filters\r\n)\r\ndataframe = dataset.read_pandas(columns=columns).to_pandas()\n```\r\nThe dataset itself contains 10,000s of files around 100 MB in size and is created using incremental bulk processing from pandas and pyarrow v1.0.1. With the filters I am limiting the amount of files that are fetch to around 20.\r\n\r\nI am suspecting an issue with a limit in the total amount of threads that are spawning but I have been unable to resolve it by calling\r\n```java\n\r\npyarrow.set_cpu_count(1) \n```",
        "created_at": "2021-03-04T11:01:32.000Z",
        "updated_at": "2021-04-07T11:06:53.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-04-07T11:06:53.000Z"
    },
    "comments": [
        {
            "created_at": "2021-04-06T15:21:02.165Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17315654) by Joris Van den Bossche (jorisvandenbossche):*\n`[~AntonFriberg]` sorry for the slow reply, but thanks for the report!\r\n\r\n`[~westonpace]` should this already be fixed in master with all the threadpool-related work? "
        },
        {
            "created_at": "2021-04-06T17:38:55.514Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17315746) by Antoine Pitrou (apitrou):*\n`[~AntonFriberg]` Would you be able to run your code under gdb and get a backtrace at the crash point?"
        },
        {
            "created_at": "2021-04-07T08:49:27.314Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17316128) by Anton Friberg (AntonFriberg):*\n`[~apitrou]` I have never done it before but I am willing to try. Please let me know if I did anything wrong.\r\n\r\nEnvironment\r\n```java\n\r\n$ which python\r\n/home/antonfr/.virtualenvs/pyarrow-stacktrace/bin/python\r\n$ python --version\r\nPython 3.7.3\r\n$ pip freeze               \r\nappdirs==1.4.4\r\ndateutils==0.6.12\r\nnumpy==1.20.2\r\npackaging==20.9\r\npkg-resources==0.4.0\r\npyarrow==3.0.0\r\npyparsing==2.4.7\r\npython-dateutil==2.8.1\r\npytz==2021.1\r\nsix==1.15.0\n```\r\nTo run gdb I installed _python3-gdb_ and _python3-dev_ in addition to gdb but did not manage to run python3-gdb and install pyarrow in that virtualenv.\r\n\r\nThen I ran the following (my script is called _anja_range_download.py_)\r\n```java\n\r\n$ gdb /home/antonfr/.virtualenvs/pyarrow-stacktrace/bin/python\r\nGNU gdb (Debian 8.2.1-2+b3) 8.2.1\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"x86_64-linux-gnu\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.For help, type \"help\".\r\n--Type <RET> for more, q to quit, c to continue without paging--\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from /home/antonfr/.virtualenvs/pyarrow-stacktrace/bin/python...Reading symbols from /usr/lib/debug/.build-id/99/21c75e6930d3e9d9fa8c942aca9dc4500bb65f.debug...done.\r\ndone.\r\n(gdb) set logging on\r\nCopying output to gdb.txt.\r\n(gdb) run anja_range_download.py\r\nStarting program: /home/antonfr/.virtualenvs/pyarrow-stacktrace/bin/python anja_range_download.py\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n[New Thread 0x7ffff47ff700 (LWP 27230)]\r\n\r\n... Multiple thousands of threads started and exited ...\r\n\r\n[New Thread 0x7fec62358700 (LWP 5825)]\r\nterminate called after throwing an instance of 'std::system_error'\r\n  what():  Resource temporarily unavailable\r\n\r\n... Hangs for a while ...\r\n\r\nThread 920 \"python\" received signal SIGABRT, Aborted.\r\n[Switching to Thread 0x7ffd34cf9700 (LWP 28235)]\r\n__GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50\r\n50      ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.\r\n\r\n... Tested py-bt unsuccessfully ...\r\n\r\n(gdb) py-bt\r\nUndefined command: \"py-bt\".  Try \"help\".\r\n\r\n... Running normal bt ...\r\n(gdb) bt\r\n#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50\r\n#1  0x00007ffff79c8535 in __GI_abort () at abort.c:79\r\n#2  0x00007ffff51ff983 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#3  0x00007ffff52058c6 in ?? () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#4  0x00007ffff5205901 in std::terminate() () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#5  0x00007ffff5205b34 in __cxa_throw () from /lib/x86_64-linux-gnu/libstdc++.so.6\r\n#6  0x00007ffff5742f4c in std::__throw_system_error(int) () from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#7  0x00007ffff64f65f9 in std::thread::_M_start_thread(std::unique_ptr<std::thread::_State, std::default_delete<std::thread::_State> >, void (*)()) ()\r\n   from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#8  0x00007ffff60b23df in Aws::Utils::Threading::DefaultExecutor::SubmitToThread(std::function<void ()>&&) ()\r\n   from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#9  0x00007ffff60427c5 in Aws::S3::S3Client::ListObjectsV2Async(Aws::S3::Model::ListObjectsV2Request const&, std::function<void (Aws::S3::S3Client const*, Aws::S3::Model::ListObjectsV2Request const&, Aws::Utils::Outcome<Aws::S3::Model::ListObjectsV2Result, Aws::S3::S3Error> const&, std::shared_ptr<Aws::Client::AsyncCallerContext const> const&)> const&, std::shared_ptr<Aws::Client::AsyncCallerContext const> const&) const () from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#10 0x00007ffff5d9e19b in arrow::fs::(anonymous namespace)::TreeWalker::WalkChild(std::string, int) ()\r\n   from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#11 0x00007ffff5d9efc0 in arrow::fs::(anonymous namespace)::TreeWalker::ListObjectsV2Handler::HandleResult(Aws::S3::Model::ListObjectsV2Result const&) ()\r\n   from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#12 0x00007ffff5d9f18b in std::_Function_handler<void (Aws::S3::S3Client const*, Aws::S3::Model::ListObjectsV2Request const&, Aws::Utils::Outcome<Aws::S3::Model::ListObjectsV2Result, Aws::S3::S3Error> const&, std::shared_ptr<Aws::Client::AsyncCallerContext const> const&), arrow::fs::(anonymous namespace)::TreeWalker::ListObjectsV2Handler>::_M_invoke(std::_Any_data const&, Aws::S3::S3Client const*&&, Aws::S3::Model::ListObjectsV2Request const&, Aws::Utils::Outcome<Aws::S3::Model::ListObjectsV2Result, Aws::S3::S3Error> const&, std::shared_ptr<Aws::Client::AsyncCallerContext const> const&) () from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#13 0x00007ffff5fa9972 in Aws::S3::S3Client::ListObjectsV2AsyncHelper(Aws::S3::Model::ListObjectsV2Request const&, std::function<void (Aws::S3::S3Client const*, Aws::S3::Model::ListObjectsV2Request const&, Aws::Utils::Outcome<Aws::S3::Model::ListObjectsV2Result, Aws::S3::S3Error> const&, std::shared_ptr<Aws::Client::AsyncCallerContext const> const&)> const&, std::shared_ptr<Aws::Client::AsyncCallerContext const> const&) const () from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#14 0x00007ffff60e2f07 in std::thread::_State_impl<std::thread::_Invoker<std::tuple<Aws::Utils::Threading::DefaultExecutor::SubmitToThread(std::function<void ()>&&)::{lambda()#1}> > >::_M_run() () from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#15 0x00007ffff64f6580 in execute_native_thread_routine () from /home/antonfr/.virtualenvs/pyarrow-stacktrace/lib/python3.7/site-packages/pyarrow/libarrow.so.300\r\n#16 0x00007ffff7f58fa3 in start_thread (arg=<optimized out>) at pthread_create.c:486\r\n#17 0x00007ffff7a9f4cf in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n```\r\nIs this the necessary information or do you need anything else?"
        },
        {
            "created_at": "2021-04-07T08:52:32.254Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17316134) by Anton Friberg (AntonFriberg):*\nNote that the AWS S3 solution is actually a Minio instance\u00a0<https://min.io/> . The minio version is \"`RELEASE.2020-02-07T04:56:50Z\" .`"
        },
        {
            "created_at": "2021-04-07T09:07:30.290Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17316147) by Antoine Pitrou (apitrou):*\nCan you also run the following command in gdb: `info threads`\r\n"
        },
        {
            "created_at": "2021-04-07T09:31:21.505Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17316169) by Anton Friberg (AntonFriberg):*\n[gdb.txt.gz](gdb.txt.gz)\r\n\r\nHere is the entire gdb.txt log with the _info threads_ command on the bottom."
        },
        {
            "created_at": "2021-04-07T09:51:52.538Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17316181) by Antoine Pitrou (apitrou):*\nThank you very much. I think I understand what's happening: you're walking a very wide directory (lots of subdirectories) and the AWS SDK launches a new thread for each subdirectory.\r\n\r\nIn any case, the implementation for this functionality has been reworked recently and it should be fixed. Can you try one of the nightly builds and report the results? See https://arrow.apache.org/docs/python/install.html#installing-nightly-packages"
        },
        {
            "created_at": "2021-04-07T10:40:39.597Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17316207) by Anton Friberg (AntonFriberg):*\nYes, we have the data partitioned on hourly files and are going up to about 2.5 years of data currently which would mean that we have about 20 000 directories in total. I will try the nightly build and get back to you."
        },
        {
            "created_at": "2021-04-07T10:46:25.410Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17316212) by Anton Friberg (AntonFriberg):*\nIt works without any noticeable issue (very fast as well) on latest nightly `pyarrow==3.1.0.dev538` . Thanks for all of your hard work! Should I resolve this issue myself or will you do it?"
        },
        {
            "created_at": "2021-04-07T11:06:19.784Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11857?focusedCommentId=17316220) by Joris Van den Bossche (jorisvandenbossche):*\n`[~AntonFriberg]` Thanks a lot for testing with the nightlies! Resolving the issue then."
        }
    ]
}