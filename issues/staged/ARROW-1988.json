{
    "issue": {
        "title": "[Python] Extend flavor=spark in Parquet writing to handle INT types",
        "body": "***Note**: This issue was originally created as [ARROW-1988](https://issues.apache.org/jira/browse/ARROW-1988). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nSee the relevant code sections at https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/parquet/ParquetSchemaConverter.scala#L139\r\n\r\nWe should cater for them in the `pyarrow` code and also reach out to Spark developers so that they are supported there in the longterm.",
        "created_at": "2018-01-11T08:13:37.000Z",
        "updated_at": "2021-08-04T08:55:23.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-08-04T08:55:23.000Z"
    },
    "comments": [
        {
            "created_at": "2021-08-04T08:55:23.913Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1988?focusedCommentId=17392882) by Antoine Pitrou (apitrou):*\nThe issue is vague and the code reference is obsolete, but I'm assuming Spark finally implemented the missing type support. Feel free to reopen if not, and then please make the description more precise ;-)"
        }
    ]
}