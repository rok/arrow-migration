{
    "issue": {
        "title": "[Python][C++] Cannot read parquet from encrypted hdfs",
        "body": "***Note**: This issue was originally created as [ARROW-4874](https://issues.apache.org/jira/browse/ARROW-4874). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nUsing pyarrow 0.12 I was able to read parquet at first and then the admins added KMS servers and encrypted all of the files on the cluster. Now I get an error and the file system object can only read objects from the local file system of the edge node.\r\n\r\nReproducible example:\r\n```java\n\r\nimport pyarrow as pa\r\nfs = pa.hdfs.connect()\r\nwith fs.open('/user/jlord/test_lots_of_parquet/', 'rb') as fil:\r\n\u00a0 \u00a0 _ = fil.read()\n```\r\nerror:\r\n```java\n\r\n19/03/14 10:29:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable hdfsOpenFile(/user/jlord/test_lots_of_parquet/): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream\u00a0error: FileNotFoundException: File /user/jlord/test_lots_of_parquet does not existjava.io.FileNotFoundException: File /user/jlord/test_lots_of_parquet does not exist at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:598) at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:811) at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:588) at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:432) at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142) at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:344) Traceback (most recent call last): File \"local_hdfs.py\", line 15, in <module> with fs.open(file, 'rb') as fil: File \"pyarrow/io-hdfs.pxi\", line 431, in pyarrow.lib.HadoopFileSystem.open File \"pyarrow/error.pxi\", line 83, in pyarrow.lib.check_status pyarrow.lib.ArrowIOError: HDFS file does not exist: /user/jlord/test_lots_of_parquet/\n```\r\nIf I specify a specific parquet file in that folder I get the following error:\r\n```java\n\r\n19/03/14 10:07:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable hdfsOpenFile(/user/jlord/test_lots_of_parquet/part-00000-0f130b19-8c8c-428c-9854-fc76bdee1cfa.snappy.parquet): FileSystem#open((Lorg/apache/hadoop/fs/Path;I)Lorg/apache/hadoop/fs/FSDataInputStream error: FileNotFoundException: File /user/jlord/test_lots_of_parquet/part-00000-0f130b19-8c8c-428c-9854-fc76bdee1cfa.snappy.parquet does not existjava.io.FileNotFoundException: File /user/jlord/test_lots_of_parquet/part-00000-0f130b19-8c8c-428c-9854-fc76bdee1cfa.snappy.parquet does not exist at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:598) at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:811) at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:588) at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:432) at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142) at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:344) Traceback (most recent call last): File \"local_hdfs.py\", line 15, in <module> with fs.open(file, 'rb') as fil: File \"pyarrow/io-hdfs.pxi\", line 431, in pyarrow.lib.HadoopFileSystem.open File \"pyarrow/error.pxi\", line 83, in pyarrow.lib.check_status pyarrow.lib.ArrowIOError: HDFS file does not exist: /user/jlord/test_lots_of_parquet/part-00000-0f130b19-8c8c-428c-9854-fc76bdee1cfa.snappy.parquet\n```\r\n\u00a0\r\n\r\nNot sure if this is relevant: spark can read continue to read the parquet files, but it takes a cloudera specific version that can read the following KMS keys from the core-site.xml and hdfs-site.xml:\r\n```java\n\r\n<property>\r\n  <name>dfs.encryption.key.provider.uri</name>\r\n  <value>kms://https@server1.com;server2.com:16000/kms</value>\r\n</property>\n```\r\n\u00a0\r\n\r\nUsing the open source version of spark requires changing these xml values to:\r\n```java\n\r\n<property>\r\n  <name>dfs.encryption.key.provider.uri</name>\r\n  <value>kms://https@server1.com:16000/kms</value>\r\n  <value>kms://https@server2.com:16000/kms</value>\r\n</property>\n```\r\nMight need to\u00a0point arrow to separate configuration xmls.",
        "created_at": "2019-03-14T16:12:22.000Z",
        "updated_at": "2022-08-27T14:42:07.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-06-27T06:41:34.000Z"
    },
    "comments": [
        {
            "created_at": "2019-04-19T18:17:04.650Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4874?focusedCommentId=16822109) by Jesse Lord (quartox):*\nFixing the classpath environment variable resolved this issue."
        },
        {
            "created_at": "2022-08-27T14:42:07.096Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-4874?focusedCommentId=17586049) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}