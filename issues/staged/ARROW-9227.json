{
    "issue": {
        "title": "[Python][Dataset] Write a custom field to _metadata caching file size",
        "body": "***Note**: This issue was originally created as [ARROW-9227](https://issues.apache.org/jira/browse/ARROW-9227). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nhttps://github.com/apache/arrow/pull/7547#discussion_r445663612\r\n\r\nThis will save unecessary HEAD requests when using S3",
        "created_at": "2020-06-25T16:08:32.000Z",
        "updated_at": "2021-04-08T13:33:53.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-07-02T11:26:24.657Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9227?focusedCommentId=17150198) by Joris Van den Bossche (jorisvandenbossche):*\nThe parquet FileMetadata don't directly include the file size, I think (https://parquet.apache.org/documentation/latest/#metadata, only the serialized size of the metadata itself, and each RowGroup has a total_byte_suze). So this would be custom metadata? And needs to be stored for each file of a partitioned dataset?"
        },
        {
            "created_at": "2021-04-06T18:10:40.850Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9227?focusedCommentId=17315759) by Antoine Pitrou (apitrou):*\nIt's not obvious which kind of metadata field would store the info, and it would probably be non-standard.\r\nSuggest closing."
        }
    ]
}