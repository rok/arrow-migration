{
    "issue": {
        "title": "[R] file readers should mmap",
        "body": "***Note**: This issue was originally created as [ARROW-5502](https://issues.apache.org/jira/browse/ARROW-5502). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nArrow is supposed to let you work with datasets bigger than memory. Memory mapping is a big part of that. It should be the default way that files are read in the `read_\\*` functions. To disable memory mapping, we could use a global `option()`, or a function argument, but that might clutter the interface. Or we could not give a choice and only fall back to not memory mapping if the platform/file system doesn't support it.",
        "created_at": "2019-06-03T22:52:33.000Z",
        "updated_at": "2022-08-27T14:41:42.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2019-10-10T22:34:27.000Z"
    },
    "comments": [
        {
            "created_at": "2019-06-11T14:12:15.141Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5502?focusedCommentId=16861084) by Romain Francois (romainfrancois):*\nYou can memory map right now, although at this point data is being copied to R vectors rather than borrowed from the memory mapped file, we'll need to use ALTREP to go further.\u00a0\r\n\r\n\u00a0\r\n\r\nThe file argument of most reading functions may be an instance of arrow::io::MemoryMappedFile, which you get by using the mmap_open() function in R:\u00a0\r\n```Java\n\r\nlibrary(arrow, warn.conflicts = FALSE)\r\nlibrary(tibble)\r\ntf <- tempfile()\r\nwrite.csv(iris, tf, row.names = FALSE, quote = FALSE)\r\nf <- mmap_open(tf)\r\nf\r\n#> arrow::io::MemoryMappedFile\r\ntab <- read_csv_arrow(f)\r\nas_tibble(tab)\r\n#> # A tibble: 150 x 5\r\n#> Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r\n#> <dbl> <dbl> <dbl> <dbl> <chr> \r\n#> 1 5.1 3.5 1.4 0.2 setosa \r\n#> 2 4.9 3 1.4 0.2 setosa \r\n#> 3 4.7 3.2 1.3 0.2 setosa \r\n#> 4 4.6 3.1 1.5 0.2 setosa \r\n#> 5 5 3.6 1.4 0.2 setosa \r\n#> 6 5.4 3.9 1.7 0.4 setosa \r\n#> 7 4.6 3.4 1.4 0.3 setosa \r\n#> 8 5 3.4 1.5 0.2 setosa \r\n#> 9 4.4 2.9 1.4 0.2 setosa \r\n#> 10 4.9 3.1 1.5 0.1 setosa \r\n#> # \u2026 with 140 more rows\r\n```\r\nCreated on 2019-06-11 by the [reprex package](https://reprex.tidyverse.org/) (v0.3.0.9000)"
        },
        {
            "created_at": "2019-06-11T14:28:31.207Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5502?focusedCommentId=16861100) by Neal Richardson (npr):*\nMemory mapping would make the loading in memory to copy to R lazy, and will be necessary for things like `read_parquet(f, col_select)` to not read all columns into Arrow before copying to R.\r\n\r\nYes, I believed it was possible now, but that's not a friendly enough interface\u00a0for package users, IMO.\u00a0"
        },
        {
            "created_at": "2019-06-11T15:02:11.713Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5502?focusedCommentId=16861119) by Wes McKinney (wesm):*\nThe Parquet C++ library by default only reads the serialized column data from disk that needs to be deserialized. Using memory-mapping indeed avoids memory allocation.\r\n\r\nNote that for high latency file sources (like Amazon S3) \u2013 where memory mapping is not possible \u2013 many data warehousing systems have found it more efficient to read an entire Parquet row group into memory at a time and discard the unused columns. We will likely be forced as a matter of performance optimization to add some reader options to parquet-cpp around this issue"
        },
        {
            "created_at": "2019-10-10T22:34:27.084Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5502?focusedCommentId=16948980) by Neal Richardson (npr):*\nClosing this. All file readers now do memory map, and if you want to turn that off, you can invoke the appropriate R6 classes directly."
        },
        {
            "created_at": "2019-10-11T14:13:20.819Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5502?focusedCommentId=16949488) by Wes McKinney (wesm):*\nNote that we stopped memory mapping by default in `pyarrow.parquet`."
        },
        {
            "created_at": "2022-08-27T14:41:42.254Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5502?focusedCommentId=17585794) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}