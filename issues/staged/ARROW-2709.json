{
    "issue": {
        "title": "[Python] write_to_dataset poor performance when splitting",
        "body": "***Note**: This issue was originally created as [ARROW-2709](https://issues.apache.org/jira/browse/ARROW-2709). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHello,\r\n\r\nPosting this from github (master `[~wesmckinn]` asked for it :)\u00a0)\r\n\r\n<https://github.com/apache/arrow/issues/2138>\r\n\r\n\u00a0\r\n```java\n\r\nimport pandas as pd \r\nimport numpy as np \r\nimport pyarrow.parquet as pq \r\nimport pyarrow as pa \r\n\r\nidx = pd.date_range('2017-01-01 12:00:00.000', '2017-03-01 12:00:00.000', freq = 'T') \r\ndataframe = pd.DataFrame({'numeric_col' : np.random.rand(len(idx)), \r\n                          'string_col' : pd.util.testing.rands_array(8,len(idx))}, \r\n                         index = idx)\n```\r\n\u00a0\r\n```java\n\r\ndf[\"dt\"] = df.index \r\ndf[\"dt\"] = df[\"dt\"].dt.date \r\ntable = pa.Table.from_pandas(df) \r\npq.write_to_dataset(table, root_path='dataset_name', partition_cols=['dt'], flavor='spark')\n```\r\n\u00a0\r\n\r\n`this works but is inefficient memory-wise. The arrow table is a copy of the large pandas daframe and quickly saturates the RAM.`\r\n\r\n\u00a0\r\n\r\n`Thanks!`",
        "created_at": "2018-06-13T21:15:09.000Z",
        "updated_at": "2019-04-29T15:27:15.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2019-04-29T11:51:05.000Z"
    },
    "comments": [
        {
            "created_at": "2018-12-26T09:20:26.546Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2709?focusedCommentId=16728948) by Lee June Woo (na11an):*\nHello,\r\n\r\nMay I ask you simple question about the improvement? I think that It seem to be more efficient\u00a0to split the pandas dataframe\u00a0base on \"dt\" column before converting dataframe\u00a0to arrow table.\r\n\r\nWould you have any plan to implement\u00a0group-by operation of arrow table or improve write_to_dataset function?"
        },
        {
            "created_at": "2018-12-26T14:34:14.480Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2709?focusedCommentId=16729054) by Wes McKinney (wesm):*\nWe do plan to implement group-by operations on Arrow tables eventually. If you would like to propose some improvements in the meantime, please go right ahead"
        },
        {
            "created_at": "2019-04-29T11:50:09.443Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2709?focusedCommentId=16829173) by Joris Van den Bossche (jorisvandenbossche):*\nThis seems a duplicate of ARROW-2628, so closing this issue (both are about the (memory) performance issues due to the usage of pandas' groupby functionality). I will update the other issue with some of the discussion in the closed PR."
        },
        {
            "created_at": "2019-04-29T15:27:15.031Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2709?focusedCommentId=16829346) by Wes McKinney (wesm):*\nThanks. I hope to see the group-splitting implemented natively against Arrow tables at some point"
        }
    ]
}