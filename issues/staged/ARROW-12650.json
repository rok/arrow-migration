{
    "issue": {
        "title": "[Doc][Python] Improve documentation regarding dealing with memory mapped files",
        "body": "***Note**: This issue was originally created as [ARROW-12650](https://issues.apache.org/jira/browse/ARROW-12650). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhile one of the Arrow promises is that it makes easy to read/write data bigger than memory, it's not immediately obvious from the pyarrow documentation how to deal with memory mapped files.\r\n\r\nThe doc hints that you can open files as memory mapped ( <https://arrow.apache.org/docs/python/memory.html?highlight=memory_map#on-disk-and-memory-mapped-files>\u00a0) but then it doesn't explain how to read/write Arrow Arrays or Tables from there.\r\n\r\nWhile most high level functions to read/write formats (pqt, feather, ...) have an easy to guess `memory_map=True` option, the doc doesn't seem to have any example of how that is meant to work for Arrow format itself. For example how you can do that using\u00a0`RecordBatchFile*`.\u00a0\r\n\r\nAn addition to the memory mapping section that makes a more meaningful example that reads/writes actual arrow data (instead of plain bytes) would probably be helpful",
        "created_at": "2021-05-04T15:08:42.000Z",
        "updated_at": "2021-07-26T15:48:27.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Documentation",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-07-26T15:44:45.000Z"
    },
    "comments": [
        {
            "created_at": "2021-07-26T15:44:45.259Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12650?focusedCommentId=17387434) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 10266\n<https://github.com/apache/arrow/pull/10266>"
        }
    ]
}