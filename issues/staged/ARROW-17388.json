{
    "issue": {
        "title": "[Python] Prevent corrupting files with Multiple matches for FieldRef.Name",
        "body": "***Note**: This issue was originally created as [ARROW-17388](https://issues.apache.org/jira/browse/ARROW-17388). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n{**}Version{**}: pyarrow 9.0.0\r\n\r\n\u00a0\r\n\r\n**Description**\r\n\r\nUsers can add a column with the the same name as an existing column to a table via `pyarrow.Table.add_column()`.\r\n\r\n\u00a0\r\n\r\nAdditionally, that table can be written to a parquet file with `pyarrow.parquet.write_table()`.\r\n\r\n\u00a0\r\n\r\nHowever, the written file cannot be read with `pyarrow.parquet.read_table()` due to having multiple columns with the same name.\r\n\r\n\u00a0\r\n\r\nFlagging this as a bug because I believe anything that is successfully written by `write_table()` should be readable by `read_table()`.\r\n\r\n\u00a0\r\n\r\n**Minimum reproducible example**\r\n\r\n```\r\n\r\n>>> import pyarrow.parquet as pq\r\n>>> import pyarrow as pa\r\n>>> t = pa.Table.from_pydict(\\{'a': [1,2,3]})\r\n>>> pq.write_table(t.add_column(0, 'a', pa.array([1.1,2.2,3.3])), 'test.parquet')\r\n>>> pq.read_table('test.parquet')\r\npyarrow.lib.ArrowInvalid: Multiple matches for FieldRef.Name(a) in a: double\r\na: int64\r\n__fragment_index: int32\r\n__batch_index: int32\r\n__last_in_fragment: bool\r\n__filename: string\r\n\r\n```",
        "created_at": "2022-08-11T15:39:40.000Z",
        "updated_at": "2022-08-23T08:33:21.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-08-23T08:33:21.000Z"
    },
    "comments": [
        {
            "created_at": "2022-08-23T08:32:40.234Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-17388?focusedCommentId=17583437) by Miles Granger (milesgranger):*\nAs mentioned in the related PR, namely [in this comment](https://github.com/apache/arrow/pull/13938#issuecomment-1223688965). Parquet supports it, but the new dataset reader does not.\r\nFurther, in your example using `pq.read_table(..., use_legacy_dataset=True)` will work.\r\n\r\nWe can close this as a duplicate of the current underlying bug in ARROW-8210"
        }
    ]
}