{
    "issue": {
        "title": "[Python] Dataset API seg fault when filtering string column for None",
        "body": "***Note**: This issue was originally created as [ARROW-12066](https://issues.apache.org/jira/browse/ARROW-12066). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nTrying to load a parquet file using the dataset api leads to a segmentation fault when filtering string columns for None values.\r\n\r\nMinimal reproducing example:\u00a0\r\n```python\n\r\nimport pyarrow as pa\r\nimport pyarrow.dataset\r\nimport pyarrow.parquet\r\nimport pandas as pd\r\n\r\npath = \"./test.parquet\"\r\ndf = pd.DataFrame({\"A\": (\"a\", \"b\", None)})\r\npa.parquet.write_table(pa.table(df), path)\r\n\r\nds = pa.dataset.dataset(path, format=\"parquet\")\r\nfilter = pa.dataset.field(\"A\") == pa.dataset.scalar(None)\r\ntable = ds.to_table(filter=filter)\r\n```\r\nBacktrace:\r\n```bash\n\r\n(lldb) target create \"/usr/local/mambaforge/envs/xxx/bin/python\"\r\nCurrent executable set to '/usr/local/mambaforge/envs/xxx/bin/python' (x86_64).\r\n(lldb) settings set -- target.run-args  \"./tmp.py\"\r\n(lldb) r\r\nProcess 35235 launched: '/usr/local/mambaforge/envs/xxx/bin/python' (x86_64)\r\nProcess 35235 stopped\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x9)\r\n    frame #0: 0x000000010314be48 libarrow.300.0.0.dylib`arrow::Status arrow::VisitScalarInline<arrow::ScalarHashImpl>(arrow::Scalar const&, arrow::ScalarHashImpl*) + 104\r\nlibarrow.300.0.0.dylib`arrow::VisitScalarInline<arrow::ScalarHashImpl>:\r\n->  0x10314be48 <+104>: cmpb   $0x0, 0x9(%rax)\r\n    0x10314be4c <+108>: je     0x10314c0bc               ; <+732>\r\n    0x10314be52 <+114>: movq   0x10(%rax), %rdi\r\n    0x10314be56 <+118>: movq   0x20(%rax), %rsi\r\nTarget 0: (python) stopped.\r\n(lldb) bt\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x9)\r\n  * frame #0: 0x000000010314be48 libarrow.300.0.0.dylib`arrow::Status arrow::VisitScalarInline<arrow::ScalarHashImpl>(arrow::Scalar const&, arrow::ScalarHashImpl*) + 104\r\n    frame #1: 0x000000010314bd4f libarrow.300.0.0.dylib`arrow::ScalarHashImpl::AccumulateHashFrom(arrow::Scalar const&) + 111\r\n    frame #2: 0x0000000103134bca libarrow.300.0.0.dylib`arrow::Scalar::Hash::hash(arrow::Scalar const&) + 42\r\n    frame #3: 0x0000000132fa0ea8 libarrow_dataset.300.0.0.dylib`arrow::dataset::Expression::hash() const + 264\r\n    frame #4: 0x0000000132fc913c libarrow_dataset.300.0.0.dylib`std::__1::__hash_const_iterator<std::__1::__hash_node<arrow::dataset::Expression, void*>*> std::__1::__hash_table<arrow::dataset::Expression, arrow::dataset::Expression::Hash, std::__1::equal_to<arrow::dataset::Expression>, std::__1::allocator<arrow::dataset::Expression> >::find<arrow::dataset::Expression>(arrow::dataset::Expression const&) const + 28\r\n    frame #5: 0x0000000132faca9b libarrow_dataset.300.0.0.dylib`arrow::Result<arrow::dataset::Expression> arrow::dataset::Modify<arrow::dataset::Canonicalize(arrow::dataset::Expression, arrow::compute::ExecContext*)::$_1, arrow::dataset::Canonicalize(arrow::dataset::Expression, arrow::compute::ExecContext*)::$_9>(arrow::dataset::Expression, arrow::dataset::Canonicalize(arrow::dataset::Expression, arrow::compute::ExecContext*)::$_1 const&, arrow::dataset::Canonicalize(arrow::dataset::Expression, arrow::compute::ExecContext*)::$_9 const&) + 123\r\n    frame #6: 0x0000000132fac623 libarrow_dataset.300.0.0.dylib`arrow::dataset::Canonicalize(arrow::dataset::Expression, arrow::compute::ExecContext*) + 131\r\n    frame #7: 0x0000000132fac76d libarrow_dataset.300.0.0.dylib`arrow::dataset::Canonicalize(arrow::dataset::Expression, arrow::compute::ExecContext*) + 461\r\n    frame #8: 0x0000000132fb00cb libarrow_dataset.300.0.0.dylib`arrow::dataset::SimplifyWithGuarantee(arrow::dataset::Expression, arrow::dataset::Expression const&)::$_10::operator()() const + 75\r\n    frame #9: 0x0000000132faf6b5 libarrow_dataset.300.0.0.dylib`arrow::dataset::SimplifyWithGuarantee(arrow::dataset::Expression, arrow::dataset::Expression const&) + 517\r\n    frame #10: 0x0000000132f893f8 libarrow_dataset.300.0.0.dylib`arrow::dataset::Dataset::GetFragments(arrow::dataset::Expression) + 88\r\n    frame #11: 0x0000000132f8d25c libarrow_dataset.300.0.0.dylib`arrow::dataset::GetFragmentsFromDatasets(std::__1::vector<std::__1::shared_ptr<arrow::dataset::Dataset>, std::__1::allocator<std::__1::shared_ptr<arrow::dataset::Dataset> > > const&, arrow::dataset::Expression)::'lambda'(std::__1::shared_ptr<arrow::dataset::Dataset>)::operator()(std::__1::shared_ptr<arrow::dataset::Dataset>) const + 76\r\n    frame #12: 0x0000000132f8cd6c libarrow_dataset.300.0.0.dylib`arrow::MapIterator<arrow::dataset::GetFragmentsFromDatasets(std::__1::vector<std::__1::shared_ptr<arrow::dataset::Dataset>, std::__1::allocator<std::__1::shared_ptr<arrow::dataset::Dataset> > > const&, arrow::dataset::Expression)::'lambda'(std::__1::shared_ptr<arrow::dataset::Dataset>), std::__1::shared_ptr<arrow::dataset::Dataset>, arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> > >::Next() + 316\r\n    frame #13: 0x0000000132f8cb27 libarrow_dataset.300.0.0.dylib`arrow::Result<arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> > > arrow::Iterator<arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> > >::Next<arrow::MapIterator<arrow::dataset::GetFragmentsFromDatasets(std::__1::vector<std::__1::shared_ptr<arrow::dataset::Dataset>, std::__1::allocator<std::__1::shared_ptr<arrow::dataset::Dataset> > > const&, arrow::dataset::Expression)::'lambda'(std::__1::shared_ptr<arrow::dataset::Dataset>), std::__1::shared_ptr<arrow::dataset::Dataset>, arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> > > >(void*) + 39\r\n    frame #14: 0x0000000132f8dcdb libarrow_dataset.300.0.0.dylib`arrow::Iterator<arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> > >::Next() + 43\r\n    frame #15: 0x0000000132f8d692 libarrow_dataset.300.0.0.dylib`arrow::FlattenIterator<std::__1::shared_ptr<arrow::dataset::Fragment> >::Next() + 258\r\n    frame #16: 0x0000000132f8d477 libarrow_dataset.300.0.0.dylib`arrow::Result<std::__1::shared_ptr<arrow::dataset::Fragment> > arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> >::Next<arrow::FlattenIterator<std::__1::shared_ptr<arrow::dataset::Fragment> > >(void*) + 39\r\n    frame #17: 0x0000000132f8de0b libarrow_dataset.300.0.0.dylib`arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> >::Next() + 43\r\n    frame #18: 0x0000000132fffe80 libarrow_dataset.300.0.0.dylib`arrow::MapIterator<arrow::dataset::GetScanTaskIterator(arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> >, std::__1::shared_ptr<arrow::dataset::ScanOptions>, std::__1::shared_ptr<arrow::dataset::ScanContext>)::'lambda'(std::__1::shared_ptr<arrow::dataset::Fragment>), std::__1::shared_ptr<arrow::dataset::Fragment>, arrow::Iterator<std::__1::shared_ptr<arrow::dataset::ScanTask> > >::Next() + 48\r\n    frame #19: 0x0000000132fffd47 libarrow_dataset.300.0.0.dylib`arrow::Result<arrow::Iterator<std::__1::shared_ptr<arrow::dataset::ScanTask> > > arrow::Iterator<arrow::Iterator<std::__1::shared_ptr<arrow::dataset::ScanTask> > >::Next<arrow::MapIterator<arrow::dataset::GetScanTaskIterator(arrow::Iterator<std::__1::shared_ptr<arrow::dataset::Fragment> >, std::__1::shared_ptr<arrow::dataset::ScanOptions>, std::__1::shared_ptr<arrow::dataset::ScanContext>)::'lambda'(std::__1::shared_ptr<arrow::dataset::Fragment>), std::__1::shared_ptr<arrow::dataset::Fragment>, arrow::Iterator<std::__1::shared_ptr<arrow::dataset::ScanTask> > > >(void*) + 39\r\n    frame #20: 0x0000000133003dcb libarrow_dataset.300.0.0.dylib`arrow::Iterator<arrow::Iterator<std::__1::shared_ptr<arrow::dataset::ScanTask> > >::Next() + 43\r\n    frame #21: 0x0000000133003782 libarrow_dataset.300.0.0.dylib`arrow::FlattenIterator<std::__1::shared_ptr<arrow::dataset::ScanTask> >::Next() + 258\r\n    frame #22: 0x0000000133003567 libarrow_dataset.300.0.0.dylib`arrow::Result<std::__1::shared_ptr<arrow::dataset::ScanTask> > arrow::Iterator<std::__1::shared_ptr<arrow::dataset::ScanTask> >::Next<arrow::FlattenIterator<std::__1::shared_ptr<arrow::dataset::ScanTask> > >(void*) + 39\r\n    frame #23: 0x0000000132fd479b libarrow_dataset.300.0.0.dylib`arrow::Iterator<std::__1::shared_ptr<arrow::dataset::ScanTask> >::Next() + 43\r\n    frame #24: 0x0000000132fd44e8 libarrow_dataset.300.0.0.dylib`arrow::Iterator<std::__1::shared_ptr<arrow::dataset::ScanTask> >::RangeIterator::Next() + 88\r\n    frame #25: 0x0000000132ffe43d libarrow_dataset.300.0.0.dylib`arrow::dataset::Scanner::ToTable() + 589\r\n    frame #26: 0x0000000132f2963a _dataset.cpython-39-darwin.so`__pyx_pw_7pyarrow_8_dataset_7Scanner_13to_table(_object*, _object*) + 74\r\n    frame #27: 0x0000000132ef47d4 _dataset.cpython-39-darwin.so`__Pyx_PyObject_CallNoArg(_object*) + 132\r\n    frame #28: 0x0000000132ef0cc9 _dataset.cpython-39-darwin.so`__pyx_pw_7pyarrow_8_dataset_7Dataset_14to_table(_object*, _object*, _object*) + 569\r\n    frame #29: 0x00000001000d5a04 python`cfunction_call + 52\r\n    frame #30: 0x0000000100074998 python`_PyObject_MakeTpCall + 136\r\n    frame #31: 0x00000001001aa8f3 python`call_function + 323\r\n    frame #32: 0x00000001001a843f python`_PyEval_EvalFrameDefault + 45039\r\n    frame #33: 0x000000010019bc04 python`_PyEval_EvalCode + 548\r\n    frame #34: 0x000000010020ec51 python`pyrun_file + 321\r\n    frame #35: 0x000000010020e49c python`pyrun_simple_file + 412\r\n    frame #36: 0x000000010020e2ad python`PyRun_SimpleFileExFlags + 109\r\n    frame #37: 0x0000000100239ed9 python`pymain_run_file + 329\r\n    frame #38: 0x00000001002395c0 python`pymain_run_python + 992\r\n    frame #39: 0x0000000100239185 python`Py_RunMain + 37\r\n    frame #40: 0x000000010023a8f1 python`pymain_main + 49\r\n    frame #41: 0x0000000100001b48 python`main + 56\r\n    frame #42: 0x00007fff73ab2cc9 libdyld.dylib`start + 1\r\n```",
        "created_at": "2021-03-23T16:51:21.000Z",
        "updated_at": "2021-11-17T22:15:32.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-11-17T14:32:02.000Z"
    },
    "comments": [
        {
            "created_at": "2021-03-24T08:54:00.539Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12066?focusedCommentId=17307666) by Joris Van den Bossche (jorisvandenbossche):*\n`[~ThomasBlauthQC]` thanks for the report.\r\n\r\nOn latest master, this seems to work for me now without crashing (on linux). But we could maybe add a test to ensure this is the case for all platforms / this keeps working.\r\n\r\nOne note, though: a filter using _equality_ for null will not select any row (as null is not equal to anything else). If you want to filter the rows where the column A is null, you can use `filter = pa.dataset.field(\"A\").is_null()`.\r\n\r\n"
        },
        {
            "created_at": "2021-03-24T17:59:04.329Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12066?focusedCommentId=17308073) by Thomas Blauth (ThomasBlauthQC):*\n`[~jorisvandenbossche]` \u00a0thank you very much for your answer and the advice! However, if I try\u00a0 `filter = pa.dataset.field(\"A\").is_null()` with 3.0.0 I get\r\n```python\n\r\nAttributeError: 'pyarrow._dataset.Expression' object has no attribute 'is_null'\r\n```\r\nWas `.is_null()` maybe also added later on?"
        },
        {
            "created_at": "2021-03-26T08:04:26.268Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12066?focusedCommentId=17309243) by Joris Van den Bossche (jorisvandenbossche):*\nAh, yes, `is_null` was only added recently. The `is_valid` method already existed before, so you can probably achieve the same with `~ds.field(\"A\").is_valid()`"
        },
        {
            "created_at": "2021-11-16T14:16:47.742Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12066?focusedCommentId=17444564) by Ben Kietzman (bkietz):*\n`[~jorisvandenbossche]` is this issue still necessary?"
        },
        {
            "created_at": "2021-11-17T09:35:57.624Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12066?focusedCommentId=17445042) by Joris Van den Bossche (jorisvandenbossche):*\nWill make a PR to add the case as a test and then close this."
        },
        {
            "created_at": "2021-11-17T14:32:02.987Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12066?focusedCommentId=17445249) by Antoine Pitrou (apitrou):*\nIssue resolved by pull request 11722\n<https://github.com/apache/arrow/pull/11722>"
        }
    ]
}