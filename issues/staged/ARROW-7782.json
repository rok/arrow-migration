{
    "issue": {
        "title": "[Python] Losing index information when using write_to_dataset with partition_cols",
        "body": "***Note**: This issue was originally created as [ARROW-7782](https://issues.apache.org/jira/browse/ARROW-7782). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nOne cannot save the index when using `pyarrow.parquet.write_to_dataset()` with given partition_cols arguments. Here I have created a minimal example which shows the issue:\r\n```java\n\r\n\u00a0\r\nfrom pathlib import Path\r\nimport pandas as pd\r\nfrom pyarrow import Table\r\nfrom pyarrow.parquet import write_to_dataset, read_table\r\n\r\npath = Path('/home/user/trials')\r\nfile_name = 'local_database.parquet'\r\ndf = pd.DataFrame({\"A\": [1, 2, 3], \"B\": ['a', 'a', 'b']}, \r\n                  index=pd.Index(['a', 'b', 'c'], \r\n                  name='idx'))\r\n\r\ntable = Table.from_pandas(df)\r\nwrite_to_dataset(table, \r\n                 str(path / file_name), \r\n                 partition_cols=['B']\r\n                )\r\ndf_read\u00a0=\u00a0read_table(str(path\u00a0/\u00a0file_name))\r\ndf_read.to_pandas()\r\n```\r\n\u00a0\r\n\r\nThe issue is rather important for pandas and dask users.",
        "created_at": "2020-02-06T15:07:57.000Z",
        "updated_at": "2020-06-02T15:00:14.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-04-29T02:43:43.000Z"
    },
    "comments": [
        {
            "created_at": "2020-02-06T15:27:54.430Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7782?focusedCommentId=17031673) by Joris Van den Bossche (jorisvandenbossche):*\nThis might be solved in master (will be released as 0.16 this week):\r\n\r\n```Java\n\r\nIn [1]: from pathlib import Path \r\n   ...: import pandas as pd \r\n   ...: from pyarrow import Table \r\n   ...: from pyarrow.parquet import write_to_dataset \r\n   ...: path = Path('.') \r\n   ...: file_name = 'trial_pq.parquet' \r\n   ...: df = pd.DataFrame({\"A\": [1, 2, 3],  \r\n   ...:  \"B\": ['a', 'a', 'b'] \r\n   ...:  },  \r\n   ...:  index=pd.Index(['a', 'b', 'c'], name='idx')) \r\n   ...:  \r\n   ...: table = Table.from_pandas(df) \r\n   ...: write_to_dataset(table, str(path / file_name), partition_cols=['B'], \r\n   ...:  partition_filename_cb=None, filesystem=None) \r\n   ...:                                                                                                                                                                                                            \r\n\r\nIn [2]: table                                                                                                                                                                                                      \r\nOut[2]: \r\npyarrow.Table\r\nA: int64\r\nB: string\r\nidx: string\r\nmetadata\r\n--------\r\n{b'pandas': b'{\"index_columns\": [\"idx\"], \"column_indexes\": [{\"name\": null, \"fi'\r\n            b'eld_name\": null, \"pandas_type\": \"unicode\", \"numpy_type\": \"object'\r\n            b'\", \"metadata\": {\"encoding\": \"UTF-8\"}}], \"columns\": [{\"name\": \"A\"'\r\n            b', \"field_name\": \"A\", \"pandas_type\": \"int64\", \"numpy_type\": \"int6'\r\n            b'4\", \"metadata\": null}, {\"name\": \"B\", \"field_name\": \"B\", \"pandas_'\r\n            b'type\": \"unicode\", \"numpy_type\": \"object\", \"metadata\": null}, {\"n'\r\n            b'ame\": \"idx\", \"field_name\": \"idx\", \"pandas_type\": \"unicode\", \"num'\r\n            b'py_type\": \"object\", \"metadata\": null}], \"creator\": {\"library\": \"'\r\n            b'pyarrow\", \"version\": \"0.15.1.dev736+g46d0b7f47\"}, \"pandas_versio'\r\n            b'n\": \"1.1.0.dev0+369.ga62dbda20\"}'}\r\n\r\nIn [3]: pd.read_parquet(file_name)                                                                                                                                                                                 \r\nOut[3]: \r\n   A idx  B\r\n0  1   a  a\r\n1  2   b  a\r\n2  3   c  b\r\n```\r\n\r\nwhich seem to preserve the \"idx\" index as a column?"
        },
        {
            "created_at": "2020-02-06T15:31:32.997Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7782?focusedCommentId=17031678) by Ludwik Bielczynski (LudwikB):*\nMaybe I was not clear. The index is moved from the index to the columns. That's the buggy behaviour I am describing. Version 0.9 before ARROW-2891 preserved the index as an index between writting and reading the data.\r\n\r\nDoes it make sense?"
        },
        {
            "created_at": "2020-02-06T16:25:26.314Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7782?focusedCommentId=17031729) by Joris Van den Bossche (jorisvandenbossche):*\nAh, OK. So the index information is preserved for single files (with your dataframe above):\r\n\r\n```Java\n\r\nIn [4]: df                                                                                                                                                                                                         \r\nOut[4]: \r\n     A  B\r\nidx      \r\na    1  a\r\nb    2  a\r\nc    3  b\r\n\r\nIn [5]: df.to_parquet(\"test_index.parquet\")                                                                                                                                                                        \r\n\r\nIn [6]: pd.read_parquet(\"test_index.parquet\")                                                                                                                                                                      \r\nOut[6]: \r\n     A  B\r\nidx      \r\na    1  a\r\nb    2  a\r\nc    3  b\r\n```\r\n\r\nbut for partitioned data this is more difficult. \r\nThe problem is the current implementation of `write_to_dataset`, which splits the pandas dataframe in parts using pandas' groupby, and then writes those parts to parquet. But in this current process, the index information is lost. It might need some more investigation if it is easy/possible to still preserve that information here.\r\n\r\n \r\n"
        },
        {
            "created_at": "2020-02-06T16:44:07.271Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7782?focusedCommentId=17031743) by Ludwik Bielczynski (LudwikB):*\nThanks Joris for checking this out. Yes for single files data the index is preserved, however, I am sure that you are aware that the usual use-case of parquet databases is not that simple. I think preserving this index in one case and resetting the index in the another can lead to one's confusion.\r\n\r\nPlease let me know when you have more information about the feasibility of this issue's correction."
        },
        {
            "created_at": "2020-04-29T06:21:14.094Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7782?focusedCommentId=17095114) by Joris Van den Bossche (jorisvandenbossche):*\nIssue resolved by pull request 7054\r\nhttps://github.com/apache/arrow/pull/7054"
        },
        {
            "created_at": "2020-06-02T14:57:04.211Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7782?focusedCommentId=17123905) by Tom Augspurger (TomAugspurger):*\nJoris, was this fix included in 0.17.1? Or is it just for 1.0?"
        },
        {
            "created_at": "2020-06-02T15:00:14.879Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7782?focusedCommentId=17123906) by Joris Van den Bossche (jorisvandenbossche):*\nI don't think we backported this to 0.17.x, so only for master / 1.0.0"
        }
    ]
}