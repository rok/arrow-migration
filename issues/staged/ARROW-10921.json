{
    "issue": {
        "title": "`TypeError: 'coroutine' object is not iterable` when reading parquet partitions via s3fs >= 0.5 with pyarrow",
        "body": "***Note**: This issue was originally created as [ARROW-10921](https://issues.apache.org/jira/browse/ARROW-10921). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nTrying to read partitioned parquet files using updated s3fs `>= 0.5 (using via ``dask`), and got this error:\r\n\r\n\u00a0\r\n```python\n\r\n410 files = set()\r\n 411 \r\n--> 412 for key in list(self.fs._ls(path, refresh=refresh)):\r\n 413 path = key['Key']\r\n 414 if key['StorageClass'] == 'DIRECTORY':\r\n\r\nTypeError: 'coroutine' object is not iterable\r\n\r\n```\r\ncoming from <https://github.com/apache/arrow/blob/9baa123ea38ee9cc1d3a90cfc9347239cd28064c/python/pyarrow/filesystem.py#L415>\u00a0\r\n\r\n\u00a0\r\n\r\nSeems related to switching s3fs to asyncio in [https://github.com/dask/s3fs/pull/336.](https://github.com/dask/s3fs/pull/336)",
        "created_at": "2020-12-15T16:10:18.000Z",
        "updated_at": "2020-12-15T16:29:12.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-12-15T16:29:12.000Z"
    },
    "comments": [
        {
            "created_at": "2020-12-15T16:28:36.198Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10921?focusedCommentId=17249778) by Joris Van den Bossche (jorisvandenbossche):*\n`[~inecas]` thanks for the report! It's good to have an issue with this error, so others can find it. But so as you already noted yourself (on the PR), this is a duplicate of ARROW-10433 and fixed on master (to be released in pyarrow 3.0.0 in January). For now the best solution is indeed to pin s3fs to <0.5)."
        }
    ]
}