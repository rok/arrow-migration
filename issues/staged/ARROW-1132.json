{
    "issue": {
        "title": "[Python] Unable to write pandas DataFrame w/MultiIndex containing duplicate values to parquet",
        "body": "***Note**: This issue was originally created as [ARROW-1132](https://issues.apache.org/jira/browse/ARROW-1132). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nPanda DataFrames that have `MultiIndex`es seem to always be converted to a `Table` just fine. However, when writing the `Table` to disk using `pyarrow.parquet`, I am unable to write DataFrames whose `MultiIndex` contains a level with duplicate values (which is nearly always the case for me). Here is an example in python with working cases and a failure case at bottom:\n\n```python\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\nnum_rows = 3\nexample = pd.DataFrame({'strs': ['foo', 'foo', 'bar'],\n                        'nums_b': range(num_rows),\n                        'nums_a': range(num_rows)})\n\n\ndef pq_write(df):\n    table = pa.Table.from_pandas(df)\n    pq.write_table(table, '/tmp/df.parquet')\n\n# single index works\npq_write(example)\npq_write(example.set_index(['nums_b']))\n\n# single index with duplicate values work\npq_write(example.set_index(['strs']))\n\n# MultiIndex with all unique, relative to the level/column, values works\npq_write(example.set_index(['nums_b', 'nums_a']))\n\n# MultiIndex with one level with duplicate values in one index FAILS\npq_write(example.set_index(['strs', 'nums_a']))\n```\n\n```\nTraceback (most recent call last):\n  File \"test_arrow.py\", line 26, in <module>\n    pq_write(example.set_index(['strs', 'nums_a']))\n  File \"test_arrow.py\", line 13, in pq_write\n    pq.write_table(table, '/tmp/df.parquet')\n  File \"/Users/bmabey/anaconda/envs/test_pyarrow/lib/python3.5/site-packages/pyarrow/parquet.py\", line 702, in write_table\n    writer.write_table(table, row_group_size=row_group_size)\n  File \"pyarrow/_parquet.pyx\", line 609, in pyarrow._parquet.ParquetWriter.write_table (/Users/travis/miniconda3/conda-bld/pyarrow_1497322770287/work/arrow-46315431aeda3b6968b3ac4c1087f6d41052b99d/python/build/temp.macosx-10.9-x86_64-3.5/_parquet.cxx:11025)\n  File \"pyarrow/error.pxi\", line 60, in pyarrow.lib.check_status (/Users/travis/miniconda3/conda-bld/pyarrow_1497322770287/work/arrow-46315431aeda3b6968b3ac4c1087f6d41052b99d/python/build/temp.macosx-10.9-x86_64-3.5/lib.cxx:6899)\npyarrow.lib.ArrowIOError: IOError: Written rows: 2 != expected rows: 3in the current column chunk\n```\n\nNote that the written rows is equal to the number of unique values in the `strs` level. I have found this to always be the case when I've hit this error message.\n\nI'm happy to write a patch for this assuming this is a bug and you can point me in the right direction.",
        "created_at": "2017-06-20T20:36:21.000Z",
        "updated_at": "2017-07-09T16:40:06.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2017-06-23T19:29:49.000Z"
    },
    "comments": [
        {
            "created_at": "2017-06-20T22:09:46.740Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1132?focusedCommentId=16056557) by Wes McKinney (wesm):*\n`[~cpcloud]` could you take a look at this?"
        },
        {
            "created_at": "2017-06-22T14:35:44.722Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1132?focusedCommentId=16059469) by Phillip Cloud (cpcloud):*\nYep, on it."
        },
        {
            "created_at": "2017-06-23T19:29:49.561Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1132?focusedCommentId=16061407) by Wes McKinney (wesm):*\nIssue resolved by pull request 768\n<https://github.com/apache/arrow/pull/768>"
        }
    ]
}