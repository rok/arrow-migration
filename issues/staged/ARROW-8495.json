{
    "issue": {
        "title": "[C++][Parquet] Implement non-vectorized array reconstruction logic.",
        "body": "***Note**: This issue was originally created as [ARROW-8495](https://issues.apache.org/jira/browse/ARROW-8495). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIn contrast to the \"Vectorized\" reassembly this would scan:\r\n\r\n\u00a0\r\n\r\n`for each rep/def level entry:`\r\n\r\n`\u00a0 \u00a0 \u00a0for each field:`\r\n\r\n`\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0update null bitmask and offsets.`",
        "created_at": "2020-04-17T04:19:40.000Z",
        "updated_at": "2020-10-22T03:11:52.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: task"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-08-26T16:48:11.300Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8495?focusedCommentId=17185320) by Antoine Pitrou (apitrou):*\nAre you expecting to switch between both approaches (vectorized / non-vectorized) depending on heuristics?\r\n\r\nIt seems to me that in most/all cases, the vectorized approach should be faster, perhaps by operating on limited-size chunks, such that we make better use of the CPU cache:\r\n```java\n\r\nfor each cache-sized chunk (e.g. 1K levels):\r\n  for each field:\r\n    for each rep/dep level entry in chunk:\r\n      update null bitmask and offsets\r\n```\r\n\r\nAlso, I assume this is for a single Parquet leaf node, right?"
        },
        {
            "created_at": "2020-08-27T03:28:57.454Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8495?focusedCommentId=17185584) by Micah Kornfield (emkornfield@gmail.com):*\n> Are you expecting to switch between both approaches (vectorized / non-vectorized) depending on heuristics?\r\nI was thinking this originally.\u00a0\r\n\r\n\u00a0\r\n\r\nI think for most common cases vectorized will probably be better.\u00a0 However for deeper nested list levels end up replicating comparisons, so there is a tradeoff.\u00a0 I should have a proof of concept algorithm implementation for vectorized sometime next week and we can maybe see if we still want to implement this (this is why this is relatively low\u00a0 down the ranking on the JIRA)"
        }
    ]
}