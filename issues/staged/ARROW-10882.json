{
    "issue": {
        "title": "[Python][Dataset] Writing dataset from python iterator of record batches",
        "body": "***Note**: This issue was originally created as [ARROW-10882](https://issues.apache.org/jira/browse/ARROW-10882). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAt the moment, from python you can write a dataset with `ds.write_dataset` for example starting from a **list** of record batches. \r\n\r\nBut this currently needs to be an actual list (or gets converted to a list), so an iterator or generated gets fully consumed (potentially bringing the record batches in memory), before starting to write. \r\n\r\nWe should also be able to use the python iterator itself to back a `RecordBatchIterator`-like object, that can be consumed while writing the batches.\r\n\r\nWe already have a `arrow::py::PyRecordBatchReader` that might be useful here.",
        "created_at": "2020-12-11T10:58:26.000Z",
        "updated_at": "2021-04-06T15:31:45.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2021-04-06T12:01:01.000Z"
    },
    "comments": [
        {
            "created_at": "2021-04-06T12:01:01.183Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10882?focusedCommentId=17315477) by David Li (lidavidm):*\nIssue resolved by pull request 9802\n<https://github.com/apache/arrow/pull/9802>"
        }
    ]
}