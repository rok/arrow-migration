{
    "issue": {
        "title": "[JavaScript] TypeError: RecordBatchReader.from(...).toNodeStream is not a function",
        "body": "***Note**: This issue was originally created as [ARROW-16705](https://issues.apache.org/jira/browse/ARROW-16705). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nTrying to code a real-time stream from an async iterable of objects to an IPC Streaming format file I'm getting a TypeError.\r\n\r\nThe idea is to stream every message to the arrow file as soon as it arrives without waiting to build the complete table to stream it. To take advantage of the stream event handling, I'm using the functional approach of [node:stream](https://nodejs.org/docs/latest-v16.x/api/stream.html) module (Nodejs v16.13.0).\r\n\r\nThe async iterable contains messages that are JS objects containing different data types, for example:\r\n```javascript\n\r\n{\r\n    id: '6345',\r\n    product: 'foo',\r\n    price: 62.78,\r\n    created: '2022-05-01T16:01:00.105Z',\r\n}\n```\r\nCode to replicate the error:\r\n```javascript\n\r\nconst {\r\n    Struct, Field, Utf8, Float32, TimestampMillisecond,\r\n    RecordBatchReader, RecordBatchStreamWriter,\r\n    builderThroughAsyncIterable,\r\n} = require('apache-arrow')\r\nconst fs = require(\"fs\");\r\nconst path = require(\"path\");\r\nconst {pipeline} = require('node:stream');\r\n\r\nconst asyncIterable = {\r\n    [Symbol.asyncIterator]: async function* () {\r\n        while (true) {\r\n            const obj = {\r\n                id: Math.floor(Math.random() * 10).toString(),\r\n                product: 'foo',\r\n                price: Math.random() + Math.floor(Math.random() * 10),\r\n                created: new Date(),\r\n            }\r\n            yield obj;\r\n            // insert some asynchrony\r\n            await new Promise((r) => setTimeout(r, 1000));\r\n        }\r\n    }\r\n}\r\n\r\nasync function streamToArrow(messagesAsyncIterable) {\r\n    const message_type = new Struct([\r\n        new Field('id', new Utf8, false),\r\n \u00a0 \u00a0 \u00a0 \u00a0new Field('product', new Utf8, false),\r\n  \u00a0 \u00a0 \u00a0 new Field('price', new Float32, false),\r\n        new Field('created', new TimestampMillisecond, false),\r\n    ]);\r\n\r\n    const builderOptions = {\r\n        type: message_type,\r\n        nullValues: [null, 'n/a', undefined],\r\n        highWaterMark: 30,\r\n        queueingStrategy: 'count',\r\n    };\r\n\r\n    const transform = builderThroughAsyncIterable(builderOptions);  \r\n    let file_path = './ipc_stream.arrow';\r\n    const fsWriter = fs.createWriteStream(file_path);\r\n\r\n    pipeline(\r\n        RecordBatchReader\r\n            .from(transform(messagesAsyncIterable))\r\n            .toNodeStream(),  // Throws TypeError: RecordBatchReader.from(...).toNodeStream is not a function \u00a0 \u00a0 \u00a0 \u00a0 \r\n        RecordBatchStreamWriter.throughNode(),\r\n        fsWriter,\r\n        (err, value) => {\r\n            if (err) {\r\n                console.error(err);\r\n            } else {\r\n                console.log(value, 'value returned');\r\n            }\r\n        }\r\n    ).on('close', () => {\r\n        console.log('Closed pipeline')\r\n    });\r\n\r\n}\r\n\r\nstreamToArrow(asyncIterable)\n```\r\n\u00a0",
        "created_at": "2022-06-01T09:38:21.000Z",
        "updated_at": "2022-06-03T07:58:27.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: JavaScript",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-06-03T07:58:13.000Z"
    },
    "comments": [
        {
            "created_at": "2022-06-01T16:25:31.618Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16705?focusedCommentId=17545007) by Paul Taylor (paul.e.taylor):*\n`[~vic-bonilla]` \u00a0The RecordBatchReader is used to transform the IPC format off the wire into RecordBatches. You don't need to use the RecordBatchReader, because the Builder already produces RecordBatches (or the Vectors that can go inside a RecordBatch).\r\n\r\nInstead you can transform the StructVector produced by the Builder into a RecordBatch, and go straight to the IPC format with the writer like this:\r\n```java\n\r\nconst {Readable, pipeline} = require('node:stream');\r\nconst {RecordBatch, Schema} = require('apache-arrow')\r\n\r\nconst messagesToBatches = async function*(source) {\r\n  let schema = undefined; \r\n \u00a0const transform = builderThroughAsyncIterable(builderOptions);\r\n  for await (const vector of transform(source)) {\r\n    schema ??= new Schema(vector.type.children);\r\n    for (const chunk of vector.data) {\r\n      yield new RecordBatch(schema, chunk);\r\n    }\r\n  }\r\n}\r\n\r\npipeline(\r\n \u00a0Readable.from(messagesToBatches(messagesAsyncIterable)),\r\n \u00a0RecordBatchStreamWriter.throughNode(),\r\n  fsWriter\r\n) \n```\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-06-03T07:54:43.354Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16705?focusedCommentId=17545765) by Victor Bonilla (vic-bonilla):*\nHey [~paul.e.taylor] , I tried skipping RecordBatchReader as you suggest and it works fine, thanks for the help.\r\n\r\nA quick remark to avoid confusion about the pipeline declaration, it'll raise an error due to the missing callback (or promise). I personally solved with:\r\n```javascript\n\r\nconst stream = require('stream'); \r\n\r\nconst pipe = stream.promises.pipeline(\r\n  Readable.from(messagesToBatches(messagesAsyncIterable)),\r\n  RecordBatchStreamWriter.throughNode(),\r\n  fsWriter\r\n);\r\nawait pipe;\r\n```"
        }
    ]
}