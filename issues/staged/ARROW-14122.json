{
    "issue": {
        "title": "[C++] interval comparison kernels",
        "body": "***Note**: This issue was originally created as [ARROW-14122](https://issues.apache.org/jira/browse/ARROW-14122). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nSubtask for tracking interval comparison kernels",
        "created_at": "2021-09-24T15:20:18.000Z",
        "updated_at": "2021-12-16T17:10:10.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: task"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2021-09-24T18:18:54.576Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17419918) by Weston Pace (westonpace):*\nThis has come up in ML discussions and comparing intervals is a difficult topic because \"1 day\" is sometimes \"23 hours, 24 hours, and 25 hours\" and \"1 month\" is sometimes \"28/29/30/31 days\" and \"1 year\" is either \"360 days, 365 days, or 365.25 days\" and even the 365 day crowd will admit it is sometimes 364 days.\r\n\r\nThat being said, for simplicity, I would like to see a comparison scheme for intervals simply because every other simple type is comparable.  I'd like to propose the postgres ordering which can be summed up as:\r\n\r\n```\n\r\n1 day = 24 hours\r\n1 month = 30 days\r\n1 year = 12 months (and thus, transitively, 360 days)\r\n```\r\n"
        },
        {
            "created_at": "2021-09-24T19:38:35.053Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17419949) by Weston Pace (westonpace):*\nRelated ML thread which proposed (from a data fusion perspective) that intervals should not be comparable.  I think I'd also be ok with not comparing intervals under the justification of compatibility with DF.\r\n\r\nhttps://lists.apache.org/thread.html/rbe0921d898711f052c48f926450d903b352a6a0f6a163872ce43e1a9%40%3Cdev.arrow.apache.org%3E"
        },
        {
            "created_at": "2021-09-24T22:04:36.693Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17420003) by Phillip Cloud (cpcloud):*\nAre there any operations for which interval comparison is necessary and not fraught with under-defined behavior?\r\n\r\nTo be clear, it's only when you have intervals with mixed >= day components and < day components such as `DayMilliseconds`. I think the only sane interval type for comparison would be the month interval type, but special casing seems likely to cause confusion.\r\n\r\nI would imagine that the functions in https://github.com/apache/arrow/pull/10960 are sufficient to cover most or all cases where interval comparison would be needed except pretty printing, and they all have fully defined behavior."
        },
        {
            "created_at": "2021-09-26T05:47:35.161Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17420212) by Jorge Leit\u00e3o (jorgecarleitao):*\nIt seems that the question is whether arrow intervals have a [total order](https://en.wikipedia.org/wiki/Total_order) or [partial order](https://en.wikipedia.org/wiki/Partially_ordered_set#Non-strict_partial_order).\r\n\r\nIMO intervals should not have a total order, only partial order. IMO total order is only defined for \"duration\", that has a physical meaning and an non-overlapping arrow of time.\r\n\r\nTo get total order, I would suggest people to cast the interval to a duration (e.g. following postgres' definition of 30 days, 24h, 12 months) and ordering that. Adopting an assumption over duration of months and days results in loss of generality, while an extra cast does not and it is more explicit where the assumption is being made.\r\n\r\nPostgres has no concept of duration and thus it makes sense for them to have both concepts (physical and calendar time differences) mixed together in intervals.\r\n\r\n"
        },
        {
            "created_at": "2021-09-26T05:54:04.528Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17420213) by QP Hou (houqp):*\n`[~westonpace]` my dev list thread was proposing that we should make interval type partially ordered in arrow compute, which is what I am working on at the moment for the new rust implementation: https://github.com/jorgecarleitao/arrow2/pull/398. The reason I proposed that is because I am trying to make the compute behavior compatible with the type semantics defined in the Arrow spec. It would be odd if in the spec we specify that hours in day can vary between 23 to 25 hours due to daylight saving, but always use 24 hours in compute. However, I found partial order semantic is not easy for users to understand due to various edge-cases. For example, should we consider \"1 days 22 hours\" greater than \"2 days -22 hours\"? \"1 days 23 hours\" is not comparable to \"2 days\" because 2 days could have 50 hours or 46 hours, but should we consider \"1 days 50 hours\" greater than \"2 days\"?\r\n\r\nI also like the Joda time approach you mentioned in https://lists.apache.org/thread.html/rb7c2f111c4fb07ca7a0182f5608cf1380e6daabc05846e8503c1a7c3%40%3Cdev.arrow.apache.org%3E. Making interval type totally unordered and require users to use it together with timestamp for ordering makes everything really easy to understand.\r\n\r\nFor datafusion, we will go with postgres's approach because it aims to be postgres compatible. This is not a problem for datafusion SQL interface because we never said the SQL types maps one to one to Arrow types. In order words, Arrow interval type semantic is an implementation detail that's hidden from the users. The consequence of postgres's behavior is we won't be able to simply hash interval types by their physical bytes. We will need to normalize them first, i.e. \"1 days 24 days\" and \"2 days\" should result in the same hash key in hash aggregate and hash join compute kernels. Or maybe we could even make this compute semantic configurable in datafusion if different users need different behavior depending on their needs.\r\n\r\nRegardless which way we go, I think it would be good for all Arrow compute implementations to have the same consistent behavior.\r\n\r\nI am not familiar with the CPP code base, so please correct me if I am wrong. `[~cpcloud]` I believe the  https://github.com/apache/arrow/pull/10960 focuses on computing the interval from two timestamps, but not ordering between intervals?"
        },
        {
            "created_at": "2021-09-26T06:07:25.819Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17420214) by QP Hou (houqp):*\nI think `[~jorgecarleitao]`'s idea of letting users perform duration casting with their own logic is also a good one that's fully compatible with the Arrow spec."
        },
        {
            "created_at": "2021-09-26T20:57:59.317Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17420386) by Phillip Cloud (cpcloud):*\n`[~jorgecarleitao]` If I understand correctly the antisymmetry relation doesn't hold for compound interval values with components that mix `>= day` and `< day` resolution because `<=` and `>=` operations are not well defined for those types, so the evaluating the statement \"is a <= b and b <= a?\" cannot be done without knowledge of the reference point. For example:\r\n\r\n```sql\n\r\ninterval '1 day -1 millisecond' \r\ninterval '86399999 milliseconds'\r\n```\r\n\r\nThese two values cannot be distinctly ordered without additional information. For example, DST might cause a day's length to be something other than 24 hours, which would make these two values compare less than, equal to, and greater than, depending on what the start and end points of the interval are.\r\n\r\nI don't think Arrow intervals except for Month, have a well-defined partial or total ordering, nor can they be compared for equality.\r\n\r\nI don't think we should special case anything here either. Partial functionality like \"only month intervals can be compared\" or \"month intervals and intervals whose values don't mix >= day and < day resolution units can be compared\". I think this will generate a lot of confusion about what operations are valid on what values.\r\n\r\n`[~houqp]` I brought up that PR as a point of reference for my claim that I don't think there's any interval comparison implementation whose functionality cannot be achieved with comparing the output from a set of time-units-between functions. That includes hashing needed for grouped aggregations, as well as comparison for sorting.\r\n\r\nI am -1 on implementing any kind of comparison operations for Arrow interval types."
        },
        {
            "created_at": "2021-09-27T18:09:44.156Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17420946) by Weston Pace (westonpace):*\n> For datafusion, we will go with postgres's approach because it aims to be postgres compatible. This is not a problem for datafusion SQL interface because we never said the SQL types maps one to one to Arrow types. In order words, Arrow interval type semantic is an implementation detail that's hidden from the users. The consequence of postgres's behavior is we won't be able to simply hash interval types by their physical bytes. We will need to normalize them first, i.e. \"1 days 24 days\" and \"2 days\" should result in the same hash key in hash aggregate and hash join compute kernels. Or maybe we could even make this compute semantic configurable in datafusion if different users need different behavior depending on their needs.\r\n\r\n> Regardless which way we go, I think it would be good for all Arrow compute implementations to have the same consistent behavior.\r\n\r\nAn SQL postgres query will still need to map down to some kind of IR so even if we don't define it at the \"Arrow data type\" level I think it would need to be defined at some level.\r\n\r\nWhat if we were to phrase it this way:\r\n\r\n- The Interval type has no ordering (looks like partial ordering is up for debate but I don't actually know what that buys us)\n- There is an extension type \"Postgres Interval\" (I don't think it matters whether we call it an Arrow extension type, an Arrow Compute IR type, or a substrait type) which has a total ordering based on 24 hour days, 30 day months, and 360 day years\n- There is a cast from Arrow interval to Postgres Interval\n  \n  Query plan producers that want to maintain Postgres compatibility can insert the cast \n  \n  So then, if I understand correctly, the point on hashing comes down to whether or not the cast from Arrow Interval to Postgres Interval is a zero-copy metadata only cast or the bytes need to be mutated for consistent hashing.  I don't know enough about the design of either system's hashing impl to answer that."
        },
        {
            "created_at": "2021-09-28T06:47:53.610Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17421197) by Jorge Leit\u00e3o (jorgecarleitao):*\nYou are right, `[~cpcloud]`: I change my opinion: partial order is not defined to the intervals. Thank you very much for that!\r\n\r\n`[~houqp]`, I think that the `PartialOrd` in Rust is not the same as partial order I referenced above. `PartialOrd` may return None when two types are not comparable, whereas the partial order above must always return true or false. However, even that is not what we want for compatibility with postgres.\r\n\r\nSo, from my side this discussion brought ideas on how to address this in datafusion and C++ compute kernels that wish compatibility with postgres, as `[~westonpace]` summarized: interval -> \"postgres duration\" -> hash/cmp/etc."
        },
        {
            "created_at": "2021-09-28T13:56:39.071Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17421416) by Phillip Cloud (cpcloud):*\n`[~jorgecarleitao]` `[~westonpace]` `[~houqp]` I personally am +1 on `[~westonpace]`'s idea, since it allows Arrow compute to avoid having to bake in a specific behavior to the core Arrow type.\r\n\r\nDo we need a new JIRA/set of JIRAs to track the work of adding the extension type?"
        },
        {
            "created_at": "2021-09-29T01:03:19.147Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17421849) by QP Hou (houqp):*\nAwesome, looks like we have a consensus here :) +1 on making arrow interval type unordered and introduce a totally ordered postgres interval type for compatibility purpose.\r\n\r\n> QP Hou, I think that the `PartialOrd` in Rust is not the same as partial order I referenced above. `PartialOrd` may return None when two types are not comparable, whereas the partial order above must always return true or false. However, even that is not what we want for compatibility with postgres.\r\n\r\nI still think the ParitialOrd trait semantic matches the partial order definition in the wiki page you linked, specially the non-strict partial order definition. The only difference between non-strict partial order and total order is missing of the `strongly connected` rule. Lack of strong connectivity in plain English means an order cannot be defined for all pairs of elements from the set, which is exactly the semantic we have for the current arrow interval type. The antisymmetry rule starts with `if a<=b and b <=a`. The preceding `if` means it is only applicable for a, b where an order can be defined between them. The strong connectivity rule `a <= b or a >= b` is what requires order to be defined for any two pairs of elements from the set.\r\n\r\nHowever, I don't think this changes our conclusion :) As I mentioned in my first comment and `[~cpcloud]` mentioned in his second comment, a correctly defined partial order for the arrow interval type can be very confusing to our end users. Partial order is useful for floating point number because it is only NaN that cannot have order defined, so the set of unordered elements is very sparse. While for  arrow's interval type, the set of unordered elements is very dense. This makes the partial order relation not very useful in practice. Most of the time you will still need to convert it to timestamp or duration with a reference point. So we might as well not define an order for it.\r\n\r\n> Do we need a new JIRA/set of JIRAs to track the work of adding the extension type?\r\n\r\nI think this is best tracked as a separate ticket and link to this one."
        },
        {
            "created_at": "2021-09-29T01:12:35.113Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14122?focusedCommentId=17421853) by QP Hou (houqp):*\n> So then, if I understand correctly, the point on hashing comes down to whether or not the cast from Arrow Interval to Postgres Interval is a zero-copy metadata only cast or the bytes need to be mutated for consistent hashing.\r\n\r\nYes, regardless how it is casted to the postgres interval type, normalization needs to be applied to the postgres interval type before we can perform hashing and comparison operation on it.\r\n\r\nI fee like we can leave it to individual compute engine implementations to decide how they want to perform the cast. They could choose to do zero-copy metadata cast or use a reference point in time to take leap seconds/days/months into account depending on the contract they provide to the users."
        }
    ]
}