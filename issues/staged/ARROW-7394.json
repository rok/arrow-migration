{
    "issue": {
        "title": "[C++][DataFrame] Implement zero-copy optimizations when performing Filter",
        "body": "***Note**: This issue was originally created as [ARROW-7394](https://issues.apache.org/jira/browse/ARROW-7394). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nFor high-selectivity filters (most elements included), it may be wasteful and slow to copy large contiguous ranges of array chunks into the resulting ChunkedArray. Instead, we can scan the filter boolean array and slice off chunks of the source data rather than copying. \r\n\r\nWe will need to empirically determine how large the contiguous range needs to be in order to merit the slice-based approach versus simple/native materialization. For example, in a filter array like\r\n\r\n1 0 1 0 1 0 1 0 1\r\n\r\nit would not make sense to slice 5 times because slicing carries some overhead. But if we had\r\n\r\n1 ... 1 [100 1's] 0 1 ... 1 [100 1's] 0 1 ... 1 [100 1's] 0 1 ... 1 [100 1's] \r\n\r\nthen performing 4 slices may be faster than doing a copy materialization. ",
        "created_at": "2019-12-13T22:08:15.000Z",
        "updated_at": "2022-07-12T14:04:51.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-07-12T14:04:51.323Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7394?focusedCommentId=17565794) by @toddfarmer:*\nThis issue was last updated over 90 days ago, which may be an indication it is no longer being actively worked. To better reflect the current state, the issue is being unassigned. Please feel free to re-take assignment of the issue if it is being actively worked, or if you plan to start that work soon."
        }
    ]
}