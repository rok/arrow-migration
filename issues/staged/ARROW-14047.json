{
    "issue": {
        "title": "[C++] [Parquet] FileReader returns inconsistent results on repeat reads",
        "body": "***Note**: This issue was originally created as [ARROW-14047](https://issues.apache.org/jira/browse/ARROW-14047). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWe are seeing that for certain data sets when dealing with lists of structs, repeated reads yield different results - I have a file that exhibits this behavior and below is the code for reproducing it:\r\n```java\n\r\n  filesystem::path filePath = dirPath / \"writeReadRowGroup.parquet\";\r\n  arrow::MemoryPool *pool = arrow::default_memory_pool();  std::shared_ptr<arrow::io::ReadableFile> infile;\r\n  PARQUET_ASSIGN_OR_THROW(infile, arrow::io::ReadableFile::Open(filePath, pool));\r\n  std::unique_ptr<parquet::arrow::FileReader> arrow_reader;\r\n  auto status = parquet::arrow::OpenFile(infile, pool, &arrow_reader);\r\n  CHECK_OK(status);  std::shared_ptr<arrow::Schema> readSchema;\r\n  CHECK_OK(arrow_reader->GetSchema(&readSchema));\r\n  std::shared_ptr<arrow::Table> table;\r\n  std::vector<int> indicesToGet;\r\n  CHECK_OK(arrow_reader->ReadTable(&table));  auto recordListCol1 = arrow::Table::Make(arrow::schema({table->schema()->GetFieldByName(\"recordList\")}),\r\n                                           {table->GetColumnByName(\"recordList\")});  for (int i = 0; i < 20; ++i) {\r\n    cout << \"data reread operation number = \" + std::to_string(i) << endl;\r\n    std::shared_ptr<arrow::Table> table2;\r\n    CHECK_OK(arrow_reader->ReadTable(&table2));\r\n    auto recordListCol2 = arrow::Table::Make(arrow::schema({table2->schema()->GetFieldByName(\"recordList\")}),\r\n                                             {table2->GetColumnByName(\"recordList\")});\r\n    bool equals = recordListCol1->Equals(*recordListCol2);\r\n    if (!equals) {\r\n      cout << recordListCol1->ToString() << endl;\r\n      cout << endl << \"new table\" << endl;\r\n      cout << recordListCol2->ToString() << endl;\r\n      throw std::runtime_error(\"Subsequent re-read failure \");\r\n    }  }\r\n\r\n```\r\nApparently, as shown in the attached capture the state machine used to track nulls is broken on subsequent usage\r\n\r\n\u00a0",
        "created_at": "2021-09-20T22:17:40.000Z",
        "updated_at": "2022-02-09T18:32:37.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-02-09T10:49:22.000Z"
    },
    "comments": [
        {
            "created_at": "2022-01-13T22:34:53.031Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14047?focusedCommentId=17475812) by Will Jones (willjones127):*\nI have yet to be able to reproduce this issue, because I instead am getting segfaults. Unfortunately, these don't seem particularly related to your issue, so I might create separate tickets to look at what I'm encountering and will see if someone else can help me reproduce.\r\n\r\nI tried reproducing the issue in Python (hoping for a quicker repro) with the following snippet:\r\n\r\n```python\n\r\nimport pyarrow.parquet as pq\r\npath = \"writeReadRowGroup.parquet\"\r\nreader = pq.ParquetFile(path).reader\r\ntables = [reader.read_all() for _ in range(20)]\r\n\r\nall(tables[0].column(\"recordList\") == table.column(\"recordList\") for table in tables)\r\n```\r\n\r\nBut that segfaults with the following traceback:\r\n\r\n```Java\n\r\n_mi_heap_malloc_zero (@_mi_heap_malloc_zero:20)\r\narrow::BaseMemoryPoolImpl<arrow::(anonymous namespace)::MimallocAllocator>::Allocate(long long, unsigned char**) (@arrow::BaseMemoryPoolImpl<arrow::(anonymous namespace)::MimallocAllocator>::Allocate(long long, unsigned char**):22)\r\narrow::PoolBuffer::Reserve(long long) (@arrow::PoolBuffer::Reserve(long long):74)\r\narrow::PoolBuffer::Resize(long long, bool) (@arrow::PoolBuffer::Resize(long long, bool):31)\r\narrow::AllocateResizableBuffer(long long, arrow::MemoryPool*) (@arrow::AllocateResizableBuffer(long long, arrow::MemoryPool*):21)\r\nparquet::arrow::(anonymous namespace)::StructReader::BuildArray(long long, std::__1::shared_ptr<arrow::ChunkedArray>*) (@parquet::arrow::(anonymous namespace)::StructReader::BuildArray(long long, std::__1::shared_ptr<arrow::ChunkedArray>*):88)\r\nparquet::arrow::(anonymous namespace)::ListReader<int>::BuildArray(long long, std::__1::shared_ptr<arrow::ChunkedArray>*) (@parquet::arrow::(anonymous namespace)::ListReader<int>::BuildArray(long long, std::__1::shared_ptr<arrow::ChunkedArray>*):125)\r\nparquet::arrow::ColumnReaderImpl::NextBatch(long long, std::__1::shared_ptr<arrow::ChunkedArray>*) (@parquet::arrow::ColumnReaderImpl::NextBatch(long long, std::__1::shared_ptr<arrow::ChunkedArray>*):30)\r\nparquet::arrow::(anonymous namespace)::FileReaderImpl::ReadColumn(int, std::__1::vector<int, std::__1::allocator<int> > const&, parquet::arrow::ColumnReader*, std::__1::shared_ptr<arrow::ChunkedArray>*) (@parquet::arrow::(anonymous namespace)::FileReaderImpl::ReadColumn(int, std::__1::vector<int, std::__1::allocator<int> > const&, parquet::arrow::ColumnReader*, std::__1::shared_ptr<arrow::ChunkedArray>*):77)\r\nparquet::arrow::(anonymous namespace)::FileReaderImpl::DecodeRowGroups(std::__1::shared_ptr<parquet::arrow::(anonymous namespace)::FileReaderImpl>, std::__1::vector<int, std::__1::allocator<int> > const&, std::__1::vector<int, std::__1::allocator<int> > const&, arrow::internal::Executor*)::$_4::operator()(unsigned long, std::__1::shared_ptr<parquet::arrow::ColumnReaderImpl>) const (@parquet::arrow::(anonymous namespace)::FileReaderImpl::DecodeRowGroups(std::__1::shared_ptr<parquet::arrow::(anonymous namespace)::FileReaderImpl>, std::__1::vector<int, std::__1::allocator<int> > const&, std::__1::vector<int, std::__1::allocator<int> > const&, arrow::internal::Executor*)::$_4::operator()(unsigned long, std::__1::shared_ptr<parquet::arrow::ColumnReaderImpl>) const:19)\r\narrow::internal::FnOnce<void ()>::FnImpl<std::__1::__bind<arrow::detail::ContinueFuture, arrow::Future<std::__1::shared_ptr<arrow::ChunkedArray> >&, parquet::arrow::(anonymous namespace)::FileReaderImpl::DecodeRowGroups(std::__1::shared_ptr<parquet::arrow::(anonymous namespace)::FileReaderImpl>, std::__1::vector<int, std::__1::allocator<int> > const&, std::__1::vector<int, std::__1::allocator<int> > const&, arrow::internal::Executor*)::$_4&, unsigned long&, std::__1::shared_ptr<parquet::arrow::ColumnReaderImpl> > >::invoke() (@arrow::internal::FnOnce<void ()>::FnImpl<std::__1::__bind<arrow::detail::ContinueFuture, arrow::Future<std::__1::shared_ptr<arrow::ChunkedArray> >&, parquet::arrow::(anonymous namespace)::FileReaderImpl::DecodeRowGroups(std::__1::shared_ptr<parquet::arrow::(anonymous namespace)::FileReaderImpl>, std::__1::vector<int, std::__1::allocator<int> > const&, std::__1::vector<int, std::__1::allocator<int> > const&, arrow::internal::Executor*)::$_4&, unsigned long&, std::__1::shared_ptr<parquet::arrow::ColumnReaderImpl> > >::invoke():31)\r\nvoid* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, arrow::internal::ThreadPool::LaunchWorkersUnlocked(int)::$_3> >(void*) (@void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, arrow::internal::ThreadPool::LaunchWorkersUnlocked(int)::$_3> >(void*):182)\r\n_pthread_start (@_pthread_start:40)\r\n```\r\n\r\nIn C++, having a different problem:\r\n\r\n```cpp\n\r\n#include<memory>\r\n#include<iostream>\r\n#include<stdexcept>\r\n#include<filesystem>\r\n#include<arrow/api.h>\r\n#include<arrow/io/api.h>\r\n#include<parquet/arrow/reader.h>\r\n\r\nusing namespace std;\r\nusing namespace std::__fs;\r\n\r\narrow::Status inner_main() {\r\n    filesystem::path filePath = \"writeReadRowGroup.parquet\";\r\n    arrow::MemoryPool *pool = arrow::default_memory_pool();\r\n    std::shared_ptr<arrow::io::ReadableFile> infile;\r\n    PARQUET_ASSIGN_OR_THROW(infile, arrow::io::ReadableFile::Open(filePath, pool));\r\n    std::unique_ptr<parquet::arrow::FileReader> arrow_reader;\r\n    auto status = parquet::arrow::OpenFile(infile, pool, &arrow_reader); // segfaults here\r\n    ARROW_RETURN_NOT_OK(status);\r\n    std::shared_ptr<arrow::Schema> readSchema;\r\n    ARROW_RETURN_NOT_OK(arrow_reader->GetSchema(&readSchema));\r\n    std::shared_ptr<arrow::Table> table;\r\n    std::vector<int> indicesToGet;\r\n    ARROW_RETURN_NOT_OK(arrow_reader->ReadTable(&table));\r\n    auto recordListCol1 = arrow::Table::Make(arrow::schema({table->schema()->GetFieldByName(\"recordList\")}),\r\n                                             {table->GetColumnByName(\"recordList\")});\r\n    for (int i = 0; i < 20; ++i)\r\n    {\r\n        cout << \"data reread operation number = \" + std::to_string(i) << endl;\r\n        std::shared_ptr<arrow::Table> table2;\r\n        ARROW_RETURN_NOT_OK(arrow_reader->ReadTable(&table2));\r\n        auto recordListCol2 = arrow::Table::Make(arrow::schema({table2->schema()->GetFieldByName(\"recordList\")}),\r\n                                                 {table2->GetColumnByName(\"recordList\")});\r\n        bool equals = recordListCol1->Equals(*recordListCol2);\r\n        if (!equals)\r\n        {\r\n            cout << recordListCol1->ToString() << endl;\r\n            cout << endl\r\n                 << \"new table\" << endl;\r\n            cout << recordListCol2->ToString() << endl;\r\n            throw std::runtime_error(\"Subsequent re-read failure \");\r\n        }\r\n    }\r\n\r\n    return arrow::Status::OK();\r\n}\r\n\r\nint main()\r\n{\r\n    auto status = inner_main();\r\n    return status.ok() ? 0 : 1;\r\n}\r\n```\r\n\r\nCall stack from C++ \r\n\r\n```Java\n\r\n__pthread_kill (@__pthread_kill:5)\r\npthread_kill (@pthread_kill:75)\r\nabort (@abort:44)\r\nmalloc_vreport (@has_default_zone0:3)\r\nmalloc_report (@malloc_report:19)\r\nfree (@free:128)\r\napache::thrift::transport::TMemoryBuffer::~TMemoryBuffer() (@apache::thrift::transport::TMemoryBuffer::~TMemoryBuffer():14)\r\nvoid parquet::DeserializeThriftUnencryptedMsg<parquet::format::FileMetaData>(unsigned char const*, unsigned int*, parquet::format::FileMetaData*) (@void parquet::DeserializeThriftUnencryptedMsg<parquet::format::FileMetaData>(unsigned char const*, unsigned int*, parquet::format::FileMetaData*):104)\r\nparquet::FileMetaData::FileMetaDataImpl::FileMetaDataImpl(void const*, unsigned int*, std::__1::shared_ptr<parquet::InternalFileDecryptor>) (@parquet::FileMetaData::FileMetaDataImpl::FileMetaDataImpl(void const*, unsigned int*, std::__1::shared_ptr<parquet::InternalFileDecryptor>):100)\r\nparquet::FileMetaData::FileMetaData(void const*, unsigned int*, std::__1::shared_ptr<parquet::InternalFileDecryptor>) (@parquet::FileMetaData::FileMetaData(void const*, unsigned int*, std::__1::shared_ptr<parquet::InternalFileDecryptor>):27)\r\nparquet::FileMetaData::Make(void const*, unsigned int*, std::__1::shared_ptr<parquet::InternalFileDecryptor>) (@parquet::FileMetaData::Make(void const*, unsigned int*, std::__1::shared_ptr<parquet::InternalFileDecryptor>):27)\r\nparquet::SerializedFile::ParseUnencryptedFileMetadata(std::__1::shared_ptr<arrow::Buffer> const&, unsigned int) (@parquet::SerializedFile::ParseUnencryptedFileMetadata(std::__1::shared_ptr<arrow::Buffer> const&, unsigned int):31)\r\nparquet::SerializedFile::ParseMetaData() (@parquet::SerializedFile::ParseMetaData():217)\r\nparquet::ParquetFileReader::Contents::Open(std::__1::shared_ptr<arrow::io::RandomAccessFile>, parquet::ReaderProperties const&, std::__1::shared_ptr<parquet::FileMetaData>) (@parquet::ParquetFileReader::Contents::Open(std::__1::shared_ptr<arrow::io::RandomAccessFile>, parquet::ReaderProperties const&, std::__1::shared_ptr<parquet::FileMetaData>):56)\r\nparquet::ParquetFileReader::Open(std::__1::shared_ptr<arrow::io::RandomAccessFile>, parquet::ReaderProperties const&, std::__1::shared_ptr<parquet::FileMetaData>) (@parquet::ParquetFileReader::Open(std::__1::shared_ptr<arrow::io::RandomAccessFile>, parquet::ReaderProperties const&, std::__1::shared_ptr<parquet::FileMetaData>):18)\r\nparquet::arrow::FileReaderBuilder::Open(std::__1::shared_ptr<arrow::io::RandomAccessFile>, parquet::ReaderProperties const&, std::__1::shared_ptr<parquet::FileMetaData>) (@parquet::arrow::FileReaderBuilder::Open(std::__1::shared_ptr<arrow::io::RandomAccessFile>, parquet::ReaderProperties const&, std::__1::shared_ptr<parquet::FileMetaData>):22)\r\nparquet::arrow::OpenFile(std::__1::shared_ptr<arrow::io::RandomAccessFile>, arrow::MemoryPool*, std::__1::unique_ptr<parquet::arrow::FileReader, std::__1::default_delete<parquet::arrow::FileReader> >*) (@parquet::arrow::OpenFile(std::__1::shared_ptr<arrow::io::RandomAccessFile>, arrow::MemoryPool*, std::__1::unique_ptr<parquet::arrow::FileReader, std::__1::default_delete<parquet::arrow::FileReader> >*):32)\r\ninner_main() (/Users/willjones/Documents/arrow_cpp_example/example.cc:18)\r\nmain (/Users/willjones/Documents/arrow_cpp_example/example.cc:50)\r\nstart (@start:133)\r\n```\r\n"
        },
        {
            "created_at": "2022-01-14T18:53:41.054Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14047?focusedCommentId=17476352) by Will Jones (willjones127):*\nUpdate: I've managed to reproduce this issue in Arrow 6.0.1, so it's likely still a problem. I'm now working on creating a unit test that captures this issue."
        },
        {
            "created_at": "2022-01-18T23:31:06.523Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14047?focusedCommentId=17478271) by Will Jones (willjones127):*\n`[~rteodorescu]` Do you happen to have the code that generated that file? I can reproduce an issue from that particular file, but I haven't been able to figure out how to generate data that has the same issue. All examples I've generated from the same schema are being read consistently, so I think I must be missing something in the structure of the data that's triggering this behavior."
        },
        {
            "created_at": "2022-01-20T20:17:14.460Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14047?focusedCommentId=17479652) by Will Jones (willjones127):*\nA couple further notes:\r\n\r\n- \u00a0The issue doesn't seem to be just with the parquet file. I can save a new file with the latest Arrow that has the same read issue.\n- \u00a0The issue seems to be related to overall structure rather than any particular row. If I remove any single row (doesn't matter which one) the issue disappears.\n- The first read is always good, and the sequence of valid and invalid reads seems to be deterministic, though the pattern isn't obvious.\n- An invalid read can be detected with `ValidateFull()` on the `recordList`  array. Here is the error message it yields:\n  \n  ```Java\n  \n  Invalid: List child array invalid: Invalid: Struct child array #0 invalid: Invalid: null_count value (854) doesn't match actual number of nulls in array (861)\n  ```"
        },
        {
            "created_at": "2022-02-09T10:49:22.599Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14047?focusedCommentId=17489460) by Antoine Pitrou (apitrou):*\nPatch was incorporated with ARROW-15550."
        }
    ]
}