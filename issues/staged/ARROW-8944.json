{
    "issue": {
        "title": "[Python] Pandas - Parquet - Pandas roundtrip causes out of bounds timestamp",
        "body": "***Note**: This issue was originally created as [ARROW-8944](https://issues.apache.org/jira/browse/ARROW-8944). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe following pandas -> parquet -> pandas roudtrip raises an out of bounds timestamp error with pyarrow 0.17.0 and 0.17.1:\r\n```python\n\r\nimport pandas\r\n\r\ntarget = 'ts_roundtrip.parquet'\r\n\r\ndataframe = pandas.DataFrame({'id':[1,2,3],'timestamp':['', '', '']})\r\ndataframe['timestamp'] = pandas.to_datetime(dataframe['timestamp'],errors='raise')\r\n\r\ndataframe2 = pandas.DataFrame({'id':[4,5,6,7],'timestamp':['', '2020-03-02T03:03:17.791062Z','','']})\r\ndataframe2['timestamp'] = pandas.to_datetime(dataframe2['timestamp'],errors='raise')\r\ndataframe = dataframe.append(dataframe2)\r\n\r\nprint(dataframe.head(10))\r\n\r\ndataframe.to_parquet(target, coerce_timestamps=None, index=False, version='2.0')\r\n\r\ndataframe_new = pandas.read_parquet(target)\r\nprint(dataframe_new.head())\r\n```\r\nOutput:\r\n```\n\r\n   id                         timestamp\r\n0   1                               NaT\r\n1   2                               NaT\r\n2   3                               NaT\r\n0   4                               NaT\r\n1   5  2020-03-02 03:03:17.791062+00:00\r\n2   6                               NaT\r\n3   7                               NaT\r\nTraceback (most recent call last):\r\n  File \"c:\\some\\path\\pyarrow_ts_test.py\", line 16, in <module>\r\n    dataframe_new = pandas.read_parquet(target)\r\n  File \"c:\\some\\path\\venv\\lib\\site-packages\\pandas\\io\\parquet.py\", line 310, in read_parquet\r\n    return impl.read(path, columns=columns, **kwargs)\r\n  File \"c:\\some\\path\\venv\\lib\\site-packages\\pandas\\io\\parquet.py\", line 125, in read\r\n    path, columns=columns, **kwargs\r\n  File \"pyarrow\\array.pxi\", line 587, in pyarrow.lib._PandasConvertible.to_pandas\r\n  File \"pyarrow\\table.pxi\", line 1640, in pyarrow.lib.Table._to_pandas\r\n  File \"c:\\some\\path\\venv\\lib\\site-packages\\pyarrow\\pandas_compat.py\", line 766, in table_to_blockmanager\r\n    blocks = _table_to_blocks(options, table, categories, ext_columns_dtypes)\r\n  File \"c:\\some\\path\\venv\\lib\\site-packages\\pyarrow\\pandas_compat.py\", line 1102, in _table_to_blocks\r\n    list(extension_columns.keys()))\r\n  File \"pyarrow\\table.pxi\", line 1107, in pyarrow.lib.table_to_blocks\r\n  File \"pyarrow\\error.pxi\", line 85, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowInvalid: Casting from timestamp[us] to timestamp[ns] would result in out of bounds timestamp: -62135596800000000\r\n```\r\nBackground: \r\n We have a dataset with a timestamp column that is\u00a0sparsely populated and originates from many json files. So it is very likely that in some of those json files there is no timestamp (as string in ISO format) and instead just an empty string. Each JSON file was read into a pandas dataframe, the timestamp column casted to datetime and all dataframes appended. That was done with pyarrow<0.17.0 and those parquet files cannot be read any longer and result in the above mentioned error message as well.\r\n\r\nA closer look at our old parquets show that the NaTs are converted to \"1754-08-30 22:43:41.128654848\" when reading back to a pandas dataframe :(. You get the same result when you run the above code and pyarrow==0.16.0.\u00a0",
        "created_at": "2020-05-26T14:43:35.000Z",
        "updated_at": "2020-10-27T12:30:21.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-10-27T12:30:21.000Z"
    },
    "comments": [
        {
            "created_at": "2020-05-26T18:16:27.561Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8944?focusedCommentId=17116951) by Joris Van den Bossche (jorisvandenbossche):*\nThe problem here is that the NaT values are converted to pyarrow as \"0001-01-01\". Using a simplified example:\r\n\r\n```Java\n\r\nIn [22]: pa.array(pd.Series([pd.NaT, pd.Timestamp(\"2012-01-01\")], dtype=object)) \r\nOut[22]: \r\n<pyarrow.lib.TimestampArray object at 0x7f954b176fa8>\r\n[\r\n 0001-01-01 00:00:00.000000,\r\n 2012-01-01 00:00:00.000000\r\n]\r\n```\r\n\r\nThis in itself is a bug, which is covered by \u00a0ARROW-842 (and ARROW-8115). \r\nWhen converting back to pandas, it tries to convert this to nanosecond resolution, because this is the only resolution that pandas supports. However, \"0001-01-01\" doesn't fit into the nanosecond range, and therefore you get this error. There is work underway to make this conversion back to pandas more flexible, so you can opt for datetime objects (see eg ARROW-5359).\r\n\r\nThe above clarifies the behaviour you see. But in your case, the actual problem is that you are having object dtype data:\r\n\r\n```python\n\r\nIn [23]: dataframe.dtypes                                                                                                                                                                                          \r\nOut[23]: \r\nid            int64\r\ntimestamp    object\r\ndtype: object\r\n\r\nIn [24]: dataframe['timestamp'].values                                                                                                                                                                             \r\nOut[24]: \r\narray([NaT, NaT, NaT, NaT,\r\n       Timestamp('2020-03-02 03:03:17.791062+0000', tz='UTC'), NaT, NaT],\r\n      dtype=object)\r\n```\r\n\r\nAnd it is therefore you run into this NaT conversion bug. \r\nNow the reason you have object dtype data is because of appending a dataframe with tz-aware data to tz-naive data:\r\n\r\n```python\n\r\n# dataframe before appending dataframe2\r\nIn [27]: dataframe.dtypes                                                                                                                                                                                          \r\nOut[27]: \r\nid                    int64\r\ntimestamp    datetime64[ns]\r\ndtype: object\r\n\r\nIn [28]: dataframe2.dtypes                                                                                                                                                                                         \r\nOut[28]: \r\nid                         int64\r\ntimestamp    datetime64[ns, UTC]\r\ndtype: object\r\n\r\nIn [29]: dataframe.append(dataframe2).dtypes                                                                                                                                                                       \r\nOut[29]: \r\nid            int64\r\ntimestamp    object\r\ndtype: object\r\n```"
        },
        {
            "created_at": "2020-05-27T12:11:04.673Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8944?focusedCommentId=17117709) by Daniel Figus (goddi):*\n Thanks Joris, I'll watch ARROW-842 (and ARROW-8115). If my understanding is correct, I would need to do the following to correct the existing parquets and use pyarrow>=0.17.0:\r\n\r\n1. Read the parquets into an arrow table\n1. Convert arrow table to pandas with `safe=False` to avoid the out-of-bound error\n1. Replace the 1754-08-30 22:43:41.128654848 with NaT values\n1. Cast column to datetime64[ns, UTC] dtype (to avoid issue described in ARROW-842 & your comment in [ARROW-8115](https://issues.apache.org/jira/browse/ARROW-842?focusedCommentId=16833703&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16833703))\n1. Write back parquet"
        },
        {
            "created_at": "2020-05-28T18:31:32.280Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8944?focusedCommentId=17118972) by Joris Van den Bossche (jorisvandenbossche):*\nYes, for existing parquet files written with the \"0001-01-01\" dates in it, that seems like a decent solution. \r\nAnd so when writing new parquet files, best ensure you don't have \"object\" dtype columns (at least for columns with datetimes in it, for string columns that is normal), to avoid the whole issue."
        },
        {
            "created_at": "2020-09-10T10:04:12.768Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8944?focusedCommentId=17193511) by Daniel Figus (goddi):*\n`[~jorisvandenbossche]` I think this can be closed as it was resolved with ARROW-842. Just double checked it and my example from above works."
        },
        {
            "created_at": "2020-10-27T12:30:21.569Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8944?focusedCommentId=17221382) by Daniel Figus (goddi):*\nClosing as this is fixed by ARROW-842"
        }
    ]
}