{
    "issue": {
        "title": "[Python] Specifying compression type on a column basis when writing Parquet not working",
        "body": "***Note**: This issue was originally created as [ARROW-10482](https://issues.apache.org/jira/browse/ARROW-10482). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nFrom https://stackoverflow.com/questions/64666270/using-per-column-compression-codec-in-parquet-write-table\r\n\r\nAccording to the docs, you can specify the compression type on a column-by-column basis, but that doesn't seem to be working:\r\n\r\n```Java\n\r\nIn [5]: table = pa.table([[1, 2], [3, 4], [5, 6]], names=[\"foo\", \"bar\", \"baz\"])\r\n\r\nIn [6]: pq.write_table(table, 'test1.parquet', compression=dict(foo='zstd',bar='snappy',baz='brotli'))\r\n...\r\n~/scipy/repos/arrow/python/pyarrow/_parquet.cpython-37m-x86_64-linux-gnu.so in string.from_py.__pyx_convert_string_from_py_std__in_string()\r\n\r\nTypeError: expected bytes, str found\r\n```\r\n",
        "created_at": "2020-11-03T16:30:28.000Z",
        "updated_at": "2020-11-06T14:38:52.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2020-11-06T14:38:48.000Z"
    },
    "comments": [
        {
            "created_at": "2020-11-06T14:38:48.604Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10482?focusedCommentId=17227439) by Uwe Korn (uwe):*\nIssue resolved by pull request 8580\n<https://github.com/apache/arrow/pull/8580>"
        }
    ]
}