{
    "issue": {
        "title": "[C++] Add option to CSV reader to dictionary encode individual columns or all string / binary columns",
        "body": "***Note**: This issue was originally created as [ARROW-3408](https://issues.apache.org/jira/browse/ARROW-3408). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nFor many datasets, dictionary encoding everything can result in drastically lower memory usage and subsequently better performance in doing analytics\r\n\r\nOne difficulty of dictionary encoding in multithreaded conversions is that ideally you end up with one dictionary at the end. So you have two options:\r\n\r\n- Implement a concurrent hashing scheme \u2013 for low cardinality dictionaries, the overhead associated with mutex contention will not be meaningful, for high cardinality it can be more of a problem\n  \n- Hash each chunk separately, then normalize at the end\n  \n  My guess is that a crude concurrent hash table with a mutex to protect mutations and resizes is going to outperform the latter",
        "created_at": "2018-10-02T17:48:31.000Z",
        "updated_at": "2020-04-10T15:33:01.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2019-11-07T16:49:04.000Z"
    },
    "comments": [
        {
            "created_at": "2018-11-30T22:10:49.930Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3408?focusedCommentId=16705341) by Wes McKinney (wesm):*\n`[~pitrou]` if this makes the cut for 0.12 that's great, but no rush on it"
        },
        {
            "created_at": "2019-08-29T13:34:26.538Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3408?focusedCommentId=16918629) by Antoine Pitrou (apitrou):*\n`[~wesmckinn]` Are chunked dictionary arrays still supposed to have the same dictionary for all chunks?"
        },
        {
            "created_at": "2019-09-10T15:19:07.969Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3408?focusedCommentId=16926724) by Wes McKinney (wesm):*\nNope. That's what ARROW-3144 was about, so each chunk can have a different dictionary"
        },
        {
            "created_at": "2019-11-07T16:49:04.210Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-3408?focusedCommentId=16969408) by Wes McKinney (wesm):*\nIssue resolved by pull request 5785\n<https://github.com/apache/arrow/pull/5785>"
        }
    ]
}