{
    "issue": {
        "title": "[Java] JDBC Adapter for Apache Arrow",
        "body": "***Note**: This issue was originally created as [ARROW-1780](https://issues.apache.org/jira/browse/ARROW-1780). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAt a high level the JDBC Adapter will allow upstream apps to query RDBMS data over JDBC and get the JDBC objects converted to Arrow objects/structures. The upstream utility can then work with Arrow objects/structures with usual performance benefits. The utility will be very much similar to C++ implementation of \"Convert a vector of row-wise data into an Arrow table\" as described here - https://arrow.apache.org/docs/cpp/md_tutorials_row_wise_conversion.html\r\n\r\nThe utility will read data from RDBMS and covert the data into Arrow objects/structures. So from that perspective this will Read data from RDBMS, If the utility can push Arrow objects to RDBMS is something need to be discussed and will be out of scope for this utility for now. ",
        "created_at": "2017-11-08T17:50:19.000Z",
        "updated_at": "2018-07-27T15:32:17.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Java",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2018-06-21T03:58:40.000Z"
    },
    "comments": [
        {
            "created_at": "2018-02-19T19:49:21.036Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1780?focusedCommentId=16369457) by Atul Dambalkar (atul_dambalkar):*\nComments from Uwe Korn on Slack channel -\u00a0\r\n\r\nMy main plan was to make JDBC drivers accessible very fast from Python / Pandas programs. Currently, you either have the option for most DBs to either use ODBC/python-native drivers that are quite often awful or use JDBC ones but have a high cost of serialization between the JVM and the Python objects. By using Arrow, we should be able to use the good JDBC drivers from Python without the normal serialization overhead.\r\n\r\nWe\u2019re looking at SQL-engines that work on distributed filesystem in general at the moment (Apache Drill and Presto are two best candidates at the moment) and the common pattern is that they have good JDBC drivers but the other connectors are not so well maintained or really slow.\u00a0Currently, Presto is the one of biggest interest for me.\r\n\r\nFor me it seems that having a JDBC<->Arrow adapter already yields a significant performance impact in comparison to the current situation. And it will also give the speedup independent of the underlying DB.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2018-02-19T19:50:46.824Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1780?focusedCommentId=16369458) by Atul Dambalkar (atul_dambalkar):*\nI have put together some very basic interface for the JDBC Adapter - so far by forking Arrow (https://github.com/atuldambalkar/arrow/tree/master/java/adapter/jdbc). I had a brief discussion with Uwe earlier on this on Slack, so wanted to get some more views on this and also not to redo or overstep. At this time, I have one API in the adapter which can return Arrow Vector objects after executing SQL query on the given JDBC connection object - VectorSchemaRoot sqlToArrow(Connection connection, String query).\r\n\r\nOne more possible interface could be to fetch a certain number of records from all the tables from the SQL database and build Arrow objects for that. The API can of-course be implemented lazily and only when the data for a particular table is requested."
        },
        {
            "created_at": "2018-02-19T19:51:55.436Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1780?focusedCommentId=16369459) by Atul Dambalkar (atul_dambalkar):*\nComment from Jacques Nadeau on Slack channel -\r\n\r\nNice start @atul_dambalkar.\u00a0It would be good to add the ability to set the amount to return per call as opposed to trying to deplete the whole dataset in one call.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2018-02-20T00:26:30.306Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1780?focusedCommentId=16369612) by Atul Dambalkar (atul_dambalkar):*\nBased on above comments, I will update the API with necessary parameters. It will be more or less like pagination."
        },
        {
            "created_at": "2018-06-21T03:58:40.518Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1780?focusedCommentId=16518882) by Atul Dambalkar (atul_dambalkar):*\nAdded the necessary components - <https://github.com/apache/arrow/pull/1759/>\r\n\r\nCode is under -\u00a0https://github.com/apache/arrow/tree/master/java/adapter/jdbc"
        }
    ]
}