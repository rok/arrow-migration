{
    "issue": {
        "title": "[R] Problem counting number of records of a parquet dataset created using Spark",
        "body": "***Note**: This issue was originally created as [ARROW-15201](https://issues.apache.org/jira/browse/ARROW-15201). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen I open a dataset of parquet files created by Spark I cannot get a count of the number of records, the process hangs with 100% CPU usage.\r\n\r\nIf I use DuckDB (to_duckdb) to perform the count, \u00a0the operation completes as expected.\r\n\r\nThe example below reproduces the problem:\r\n```r\n\r\nlibrary(tidyverse) # v 1.3.1\r\nlibrary(arrow) # v 6.0.1\r\nlibrary(duckdb) # v 0.3.1-1\r\nlibrary(sparklyr) # v 1.7.3\r\n\r\n# Using Spark: 3.0.0, but the same occurs when using Spark 2.4\r\nsc <- spark_connect(master = \"local\")\r\n\r\n# Create a simple data frame and save it to parquet using Spark\r\ntest_df <- tibble(a = 1:10e6)\r\ntest_spark_tbl <- copy_to(sc, test_df)\r\nspark_write_parquet(test_spark_tbl, path=\"test\")\r\n\r\ntest_arrow_ds <- open_dataset(sources = \"test\")\r\n\r\n# This works as expected\r\nsystem.time(\r\n  test_arrow_ds %>% \r\n    to_duckdb() %>% \r\n    count() \r\n)\r\n#  user  system elapsed \r\n#  0.039   0.040   0.065 \r\n\r\n\r\n# The following will hang the process with 100% CPU usage \r\ntest_arrow_ds %>% \r\n  count() %>% \r\n  collect()\r\n```\r\n\u00a0\r\nThe session information:\r\n```\n\r\nR version 4.1.2 (2021-11-01)\r\nPlatform: x86_64-apple-darwin17.0 (64-bit)\r\nRunning under: macOS Monterey 12.1\r\n\r\nMatrix products: default\r\nLAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\r\n\r\nlocale:\r\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\r\n\r\nattached base packages:\r\n[1] stats     graphics  grDevices utils     datasets  methods   base     \r\n\r\nother attached packages:\r\n [1] sparklyr_1.7.3  duckdb_0.3.1-1  DBI_1.1.2       arrow_6.0.1    \r\n [5] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.7     purrr_0.3.4    \r\n [9] readr_2.1.1     tidyr_1.1.4     tibble_3.1.6    ggplot2_3.3.5  \r\n[13] tidyverse_1.3.1\r\n\r\nloaded via a namespace (and not attached):\r\n [1] Rcpp_1.0.7        lubridate_1.8.0   forge_0.2.0       rprojroot_2.0.2  \r\n [5] assertthat_0.2.1  digest_0.6.29     utf8_1.2.2        R6_2.5.1         \r\n [9] cellranger_1.1.0  backports_1.4.1   reprex_2.0.1      evaluate_0.14    \r\n[13] httr_1.4.2        pillar_1.6.4      rlang_0.4.12      readxl_1.3.1     \r\n[17] rstudioapi_0.13   blob_1.2.2        rmarkdown_2.11    htmlwidgets_1.5.4\r\n[21] r2d3_0.2.5        bit_4.0.4         munsell_0.5.0     broom_0.7.10     \r\n[25] compiler_4.1.2    modelr_0.1.8      xfun_0.29         pkgconfig_2.0.3  \r\n[29] base64enc_0.1-3   htmltools_0.5.2   tidyselect_1.1.1  fansi_0.5.0      \r\n[33] crayon_1.4.2      tzdb_0.2.0        dbplyr_2.1.1      withr_2.4.3      \r\n[37] grid_4.1.2        jsonlite_1.7.2    gtable_0.3.0      lifecycle_1.0.1  \r\n[41] magrittr_2.0.1    scales_1.1.1      cli_3.1.0         stringi_1.7.6    \r\n[45] fs_1.5.2          xml2_1.3.3        ellipsis_0.3.2    generics_0.1.1   \r\n[49] vctrs_0.3.8       tools_4.1.2       bit64_4.0.5       glue_1.6.0       \r\n[53] hms_1.1.1         fastmap_1.1.0     yaml_2.2.1        colorspace_2.0-2 \r\n[57] rvest_1.0.2       knitr_1.37        haven_2.4.3      \r\n```\r\nI can also reproduce this in on Linux machine.\u00a0",
        "created_at": "2021-12-24T10:38:06.000Z",
        "updated_at": "2022-03-01T12:35:54.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-03-01T12:35:54.000Z"
    },
    "comments": [
        {
            "created_at": "2022-01-17T15:32:09.435Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15201?focusedCommentId=17477283) by Nelson Areal (nareal):*\nThe problem also occurs when counting the number of lines of a dataset (of a single parquet file), even when the parquet file is created using Arrow (write_parquet function).\r\n```r\n\r\ntest_df <- tibble(a = 1:10e6)\r\n\r\nwrite_parquet(test_df, sink=\"test.parquet\")\r\n\r\ntest_arrow_ds <- open_dataset(sources = \"test.parquet\")\r\n\r\n# Works as expected\r\nsystem.time(\r\n  test_arrow_ds %>% \r\n    to_duckdb() %>% \r\n    count() \r\n)\r\n#  user  system elapsed \r\n#  0.048   0.058   0.153 \r\n\r\n# The following will hang the process at 100% CPU usage, and exhausts all available memory\r\ntest_arrow_ds %>% \r\n  count() %>% \r\n  collect()\r\n\r\n```\r\nIt seems that this bug occurs when counting the number of lines of a dataset (of parquet files)."
        },
        {
            "created_at": "2022-01-31T17:59:45.253Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15201?focusedCommentId=17484829) by Dewey Dunnington (paleolimbot):*\nThank you for reporting this!\r\n\r\nI was able to replicate your hang with the Arrow R package 6.0.1, but the issue seems to be fixed with the development version:\r\n\r\n```R\n\r\nlibrary(arrow, warn.conflicts = FALSE)\r\nlibrary(dplyr, warn.conflicts = FALSE)\r\n\r\ntest_df <- data.frame(a = 1:10e6)\r\nfile <- tempfile()\r\nwrite_parquet(test_df, file)\r\n\r\n# hangs using a FileSystemDataset\r\nopen_dataset(file) %>%\r\n  count() %>%\r\n  collect()\r\n#> # A tibble: 1 \u00d7 1\r\n#>          n\r\n#>      <int>\r\n#> 1 10000000\r\n```\r\n\r\nYou can install the latest version using `install.packages(\"arrow\", repos = \"https://arrow-r-nightly.s3.amazonaws.com\")` to see if this still hangs on your system!\r\n"
        },
        {
            "created_at": "2022-02-08T14:07:05.214Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15201?focusedCommentId=17488866) by Nelson Areal (nareal):*\nThank you! I can confirm the problem is solved in the nightly build.\r\n\r\n\u00a0"
        }
    ]
}