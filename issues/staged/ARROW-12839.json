{
    "issue": {
        "title": "[Python] ImportError: The pyarrow installation is not built with support for 'HadoopFileSystem'",
        "body": "***Note**: This issue was originally created as [ARROW-12839](https://issues.apache.org/jira/browse/ARROW-12839). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nTried to install pyarrow with\r\n```\n\r\npython3.7 -m pip install hdfs pyarrow=4.00\n```\r\nwhich gave me this\r\n```\n\r\nCMake Error at /usr/share/cmake-3.13/Modules/FindPackageHandleStandardArgs.cmake:137 (message):\r\n Could NOT find ArrowPython (missing: ARROW_PYTHON_INCLUDE_DIR\r\n ARROW_PYTHON_LIB_DIR) (found version \"4.0.0\")\n```\r\nso I installed the C++ libs as listed on <https://arrow.apache.org/install/>\r\n\r\nWith that I was able to run the above pip install w/o errors but now an\r\n```\n\r\nhdfs = fs.HadoopFileSystem('namenode', 8020)\n```\r\nthrows an\r\n```\n\r\nImportError: The pyarrow installation is not built with support for 'HadoopFileSystem'\n```\r\nI do have hadoop installed in that container, HADOOP_HOME and CLASSPATH is set and I have found some\r\n```java\n\r\n/usr/include/arrow/filesystem/hdfs.h\r\n/usr/include/arrow/io/hdfs.h\u00a0\r\n```\r\nin this container.\r\n\r\nWhat am I missing?",
        "created_at": "2021-05-20T14:31:40.000Z",
        "updated_at": "2022-03-09T07:25:06.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-03-09T07:25:06.000Z"
    },
    "comments": [
        {
            "created_at": "2022-03-08T18:02:43.343Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12839?focusedCommentId=17503092) by Joris Van den Bossche (jorisvandenbossche):*\n`[~amueller]` sorry for the very late response.\r\n\r\nIt seems you are installing from source? (pip is not installing using a binary wheel? Which platform are you using?)\r\n\r\nIf installing from source, you need to ensure to enable HDFS while building (both for C++, see https://arrow.apache.org/docs/developers/cpp/building.html#optional-components (`ARROW_HFDS`) as for Python: `export PYARROW_WITH_HDFS=1`)"
        },
        {
            "created_at": "2022-03-09T07:08:07.993Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12839?focusedCommentId=17503334) by Armin M\u00fcller (amueller):*\nI don't fully recall the details, but according to our ticket logs, the issue had to do with [blanks in HDFS path names](https://issues.apache.org/jira/browse/ARROW-12790) which were supposedly fixed in a newer version, so yes, I was trying to build form source. At that point for a prototype/mockup inside a tiangolo/uvicorn-gunicorn-fastapi:python3.7 Docker container.\r\n\r\nMeanwhile, we've switched to a Java/Spring based container and the issue hasn't come up again since we don't need PyArrow anymore.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-03-09T07:24:56.219Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12839?focusedCommentId=17503343) by Joris Van den Bossche (jorisvandenbossche):*\nOK, thanks for the update, closing this issue then."
        }
    ]
}