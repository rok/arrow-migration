{
    "issue": {
        "title": "[Python] Array to_numpy slow compared to Numpy.view",
        "body": "***Note**: This issue was originally created as [ARROW-11006](https://issues.apache.org/jira/browse/ARROW-11006). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe method `to_numpy` is quite slow compare Numpy slice and viewing performance. For instance:\r\n```java\n\r\nN = 1000000\r\nnp_arr = np.arange(N)\r\npa_arr = pa.array(np_arr)\r\n\r\n%timeit l = [np_arr.view() for _ in range(N)]\r\n251 ms \u00b1 27.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n\r\n%timeit l = [pa_arr.to_numpy(zero_copy_only=True) for _ in range(N)]\r\n1.2 s \u00b1 50.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n```\r\nThe previous benchmark is clearly an extreme case, but the idea is that for any operation not available in PyArrow, failing back on Numpy is a good option and the cost of extracting should be as minimal as possible (there are scenarios where you can't cache easily this view, so you end up calling `to_numpy` a fair amount of times).\r\n\r\nI would believe that a bit part of this overhead is due to PyArrow implementing a very generic Pandas conversion, and using this one even for very simple Numpy-like dense arrays.\r\n\r\nThere are a lot of use cases of PyArrow <=> Numpy interaction projects where I think most would be interested in not paying any Pandas compatibility additional cost. And in this particular case, it could be valuable to implement a direct Numpy conversion method for some Array subclasses (starting with the simple `NumericArray`).\r\n\r\n`",
        "created_at": "2020-12-22T15:58:37.000Z",
        "updated_at": "2022-07-12T14:04:48.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-12-22T19:43:32.667Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11006?focusedCommentId=17253716) by Wes McKinney (wesm):*\nHere we are looking at microperformance of 250 nanoseconds versus 1200 nanoseconds. I do not believe this code path has been optimized for nanosecond-level microperformance. If this is important to you, you are free to investigate and propose improvements (and add some benchmarks to our ASV suite so we can keep an eye on this). "
        },
        {
            "created_at": "2020-12-30T19:18:23.101Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11006?focusedCommentId=17256676) by Paul Balanca (balancap):*\nThanks, I wanted to make sure any work I start would not conflict with the existing direction of the Arrow library project.\r\n\r\nI fully agree, we are in the realm of fine micro-optimizations. As we have experienced in FiveAI by increasingly using PyArrow as a backbone library for our internal tooling, data scientists / ML scientists enjoy being able to quickly experiment with some non-optimized dirty data pipeline, and we are trying to get as close as possible to Numpy performance in these cases. Which explains why this kind of library optimization can be useful, even if in a properly vectorized code it would not matter."
        },
        {
            "created_at": "2021-01-04T12:01:11.616Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11006?focusedCommentId=17258162) by Joris Van den Bossche (jorisvandenbossche):*\nDid a quick profile of `[pa_arr.to_numpy(zero_copy_only=True) for _ in range(N)]`, and eg around 20% of the time is spent in creating a ChunkedArray from the single Array, because all actual conversion functions are written for chunked arrays (`ConvertArrayToPandas` calls `ConvertChunkedArrayToPandas`). So not sure that is easily avoidable. \r\n\r\nAnother part is spent in creating/destroying the `IntWriter` class which does the actual conversion.\r\n\r\n(to be clear, performance improvements are certainly welcome! I am not fully sure how much room for improvement there is, and the `to_numpy` will always be slower as the fast numpy-native view)"
        },
        {
            "created_at": "2021-01-06T19:38:51.083Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11006?focusedCommentId=17260021) by Paul Balanca (balancap):*\nThanks `[~jorisvandenbossche]` \u00a0for the profiling. I might still have a look at it, half curious to see how close to Numpy it can be pushed. If nothing interesting comes out, I'll just close the ticket :)"
        },
        {
            "created_at": "2022-07-12T14:04:48.426Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11006?focusedCommentId=17565759) by @toddfarmer:*\nThis issue was last updated over 90 days ago, which may be an indication it is no longer being actively worked. To better reflect the current state, the issue is being unassigned. Please feel free to re-take assignment of the issue if it is being actively worked, or if you plan to start that work soon."
        }
    ]
}