{
    "issue": {
        "title": "[Python] Add documentation about parquet.write_to_dataset and related methods",
        "body": "***Note**: This issue was originally created as [ARROW-1858](https://issues.apache.org/jira/browse/ARROW-1858). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n`pyarrow` does not only allow one to write to a single Parquet file but you can also write only the schema metadata for a full multi-file dataset. This dataset can also be automatically partitioned by one or more columns. At the moment, this functionality is not really visible in the documentation. You mainly find the API documentation for it but we should have a small tutorial-like section that explains the differences and use cases for each of these functions.\r\n\r\nSee also https://stackoverflow.com/questions/47482434/can-pyarrow-write-multiple-parquet-files-to-a-folder-like-fastparquets-file-sch",
        "created_at": "2017-11-25T22:43:02.000Z",
        "updated_at": "2021-02-16T12:42:13.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2018-04-21T20:22:05.000Z"
    },
    "comments": [
        {
            "created_at": "2018-03-05T22:51:22.719Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1858?focusedCommentId=16386898) by Wes McKinney (wesm):*\nThe lack of documentation about this came up in https://stackoverflow.com/questions/49085686/pyarrow-s3fs-partition-by-timetsamp"
        },
        {
            "created_at": "2018-04-21T20:22:05.954Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1858?focusedCommentId=16446970) by Uwe Korn (uwe):*\nIssue resolved by pull request 1925\n<https://github.com/apache/arrow/pull/1925>"
        },
        {
            "created_at": "2021-02-16T12:42:13.346Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1858?focusedCommentId=17285173) by ARF (ARF1):*\nEven with the new documentation I am unclear on whether I can append to partitioned datasets.\r\n\r\nI.e. is it possible to write a partitioned dataset when the entire dataset is too large to hold in memory prior to writing?"
        }
    ]
}