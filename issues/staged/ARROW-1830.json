{
    "issue": {
        "title": "[Python] Error when loading all the files in a dictionary",
        "body": "***Note**: This issue was originally created as [ARROW-1830](https://issues.apache.org/jira/browse/ARROW-1830). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI can read one parquet file, but when I tried to read all the parquet files in a folder, I got an error.\r\n\r\n```java\n\r\n>>> data = pq.ParquetDataset('./aaa/part-00000-d8268e3a-4e65-41a3-a43e-01e0bf68ee86')\r\n>>> data = pq.ParquetDataset('./aaa/')\r\nIgnoring path: ./aaa//part-00000-d8268e3a-4e65-41a3-a43e-01e0bf68ee86\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/site-packages/pyarrow/parquet.py\", line 638, in __init__\r\n    self.validate_schemas()\r\n  File \"/usr/local/lib/python2.7/site-packages/pyarrow/parquet.py\", line 647, in validate_schemas\r\n    self.schema = self.pieces[0].get_metadata(open_file).schema\r\nIndexError: list index out of range\r\n>>> \r\n```\r\n",
        "created_at": "2017-11-18T01:50:28.000Z",
        "updated_at": "2017-11-21T13:35:40.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2017-11-21T13:35:40.000Z"
    },
    "comments": [
        {
            "created_at": "2017-11-18T02:16:32.406Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1830?focusedCommentId=16257879) by Wes McKinney (wesm):*\nAppears we should relax the constraint that Parquet files end in `.parq` or `.parquet`. What system wrote the Parquet files?"
        },
        {
            "created_at": "2017-11-20T08:13:25.341Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1830?focusedCommentId=16258929) by DB Tsai (dbtsai):*\nThose are parquet files generated by Spark written into Hive with S3 storage. Will be great to relax this constraint. Thanks."
        },
        {
            "created_at": "2017-11-21T13:35:40.192Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1830?focusedCommentId=16260725) by Uwe Korn (uwe):*\nIssue resolved by pull request 1340\n<https://github.com/apache/arrow/pull/1340>"
        }
    ]
}