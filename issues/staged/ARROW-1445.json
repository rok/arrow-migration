{
    "issue": {
        "title": "[Python] Segfault when using libhdfs3 in pyarrow using latest API",
        "body": "***Note**: This issue was originally created as [ARROW-1445](https://issues.apache.org/jira/browse/ARROW-1445). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI'm encoutering a segfault when using libhdfs3 with pyarrow.\n\nMy script is:\n\n```Java\nimport pyarrow\n\ndef main():\n    hdfs = pyarrow.hdfs.connect(\"<host>\", <port>, \"<username>\", driver='libhdfs')\n    print hdfs.ls('<my path>')\n    hdfs3a = pyarrow.HdfsClient(\"<host>\", <port>, \"<username>\", driver='libhdfs3')\n    print hdfs3a.ls('<my path>')\n    hdfs3b = pyarrow.hdfs.connect(\"<host>\", <port>, \"<username>\", driver='libhdfs3')\n    print hdfs3b.ls('<my path>')\n\nmain()\n```\n\nThe first two hdfs connections yield the correct list. The third yields:\n\n```\n#\n# A fatal error has been detected by the Java Runtime Environment:\n#\n#  SIGSEGV (0xb) at pc=0x00007f69c0c8b57f, pid=88070, tid=140092200666880\n#\n# JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27)\n# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode linux-amd64 compressed oops)\n# Problematic frame:\n# C  [libc.so.6+0x13357f]  __strlen_sse42+0xf\n```\n\nIt dumps an error report file too.\n\nI created my conda environment with:\n\n```\nconda create -n parquet\nsource activate parquet\nconda install pyarrow libhdfs3 -c conda-forge\n```\n\nThe packages used are:\n\n```\narrow-cpp                 0.6.0               np113py27_1    conda-forge\nboost-cpp                 1.64.0                        1    conda-forge\nbzip2                     1.0.6                         1    conda-forge\nca-certificates           2017.7.27.1                   0    conda-forge\ncertifi                   2017.7.27.1              py27_0    conda-forge\ncurl                      7.54.1                        0    conda-forge\nicu                       58.1                          1    conda-forge\nkrb5                      1.14.2                        0    conda-forge\nlibgcrypt                 1.8.0                         0    conda-forge\nlibgpg-error              1.27                          0    conda-forge\nlibgsasl                  1.8.0                         1    conda-forge\nlibhdfs3                  2.3                           0    conda-forge\nlibiconv                  1.14                          4    conda-forge\nlibntlm                   1.4                           0    conda-forge\nlibssh2                   1.8.0                         1    conda-forge\nlibuuid                   1.0.3                         1    conda-forge\nlibxml2                   2.9.4                         4    conda-forge\nmkl                       2017.0.3                      0  \nncurses                   5.9                          10    conda-forge\nnumpy                     1.13.1                   py27_0  \nopenssl                   1.0.2l                        0    conda-forge\npandas                    0.20.3                   py27_1    conda-forge\nparquet-cpp               1.3.0.pre                     1    conda-forge\npip                       9.0.1                    py27_0    conda-forge\nprotobuf                  3.3.2                    py27_0    conda-forge\npyarrow                   0.6.0               np113py27_1    conda-forge\npython                    2.7.13                        1    conda-forge\npython-dateutil           2.6.1                    py27_0    conda-forge\npytz                      2017.2                   py27_0    conda-forge\nreadline                  6.2                           0    conda-forge\nsetuptools                36.2.2                   py27_0    conda-forge\nsix                       1.10.0                   py27_1    conda-forge\nsqlite                    3.13.0                        1    conda-forge\ntk                        8.5.19                        2    conda-forge\nwheel                     0.29.0                   py27_0    conda-forge\nxz                        5.2.3                         0    conda-forge\nzlib                      1.2.11                        0    conda-forge\n```\n\nI've set my ARROW_LIBHDFS_DIR to point at the location of the libhdfs3.so file.\nI've populated my CLASSPATH as per the documentation.\n\nPlease advise.\n",
        "created_at": "2017-09-01T10:07:25.000Z",
        "updated_at": "2019-11-14T12:54:53.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-11-14T12:54:53.000Z"
    },
    "comments": [
        {
            "created_at": "2017-09-01T12:58:36.041Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150462) by Uwe Korn (uwe):*\n`[~jporritt]` Can you try to downgrade to `libhdfs3==2.2.31`\u00a0and see if the segmentation fault still appears?"
        },
        {
            "created_at": "2017-09-01T13:05:53.021Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150476) by Wes McKinney (wesm):*\nAlso, does the problem occur if you only use libhdfs3 in the session? "
        },
        {
            "created_at": "2017-09-01T13:12:30.063Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150482) by James Porritt (jporritt):*\nDowngrading works. The problem also occurs when libhdfs3 is the only one in the session."
        },
        {
            "created_at": "2017-09-01T13:18:51.289Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150504) by Wes McKinney (wesm):*\ncc `[~mdurant]`"
        },
        {
            "created_at": "2017-09-01T13:30:01.717Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150523) by Martin Durant (mdurant):*\nSo sorry, I should have let you know I was working on this.\nhttps://github.com/ContinuumIO/libhdfs3-downstream/pull/1 describes the changes in libhdfs3, whihch is now based on HAWQ + other PRs from the Pivotal libhdfs3.\nThe easiest way to see changes in the interface is to look in https://github.com/dask/hdfs3/pull/130/files#diff-7078a7f455006c4cf95aecd328479d7f (in particular, the file records returned by ls now have an extra pointer to a struct representing encryption information).\n\nThis was released in libhdfs3 2.3 on Aug 28."
        },
        {
            "created_at": "2017-09-01T15:13:45.510Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150698) by Wes McKinney (wesm):*\nIs there an alternate solution that does not involve breaking the libhdfs ABI? "
        },
        {
            "created_at": "2017-09-01T15:17:28.135Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150702) by Martin Durant (mdurant):*\nNot any easy solution: the data passed back is necessarily different at the binary level int he new version. One could posit a function on the C side which unpacks these and rewraps them in the old struct, providing two public API functions for each."
        },
        {
            "created_at": "2017-09-01T15:22:52.836Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150715) by Wes McKinney (wesm):*\nRight, but you could preserve the libhdfs ABI in libhdfs3 while adding new APIs that deal in the extended file information. "
        },
        {
            "created_at": "2017-09-01T16:52:45.573Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16150824) by Martin Durant (mdurant):*\nCertainly not while at the same time remaining faithful to the interface as defined upstream at HAWQ - which is a necessity, should we ever succeed in pushing changes upstream."
        },
        {
            "created_at": "2018-11-10T21:36:52.597Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16682608) by Wes McKinney (wesm):*\n`[~kszucs]` did this get fixed? I thought you were working on it"
        },
        {
            "created_at": "2018-11-11T19:39:00.770Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16682991) by Krisztian Szucs (kszucs):*\n`[~wesmckinn]` Nope, We have a docker setup for testing hdfs integration with libhdfs3==2.2.31"
        },
        {
            "created_at": "2019-11-14T12:54:53.279Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1445?focusedCommentId=16974220) by Antoine Pitrou (apitrou):*\nClosing as outdated. Feel free to open a new issue if you still experience this."
        }
    ]
}