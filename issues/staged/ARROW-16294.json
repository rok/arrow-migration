{
    "issue": {
        "title": "[C++] Improve performance of parquet readahead",
        "body": "***Note**: This issue was originally created as [ARROW-16294](https://issues.apache.org/jira/browse/ARROW-16294). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe 7.0.0 readahead for parquet would read up to 256 row groups at once which meant that, if the consumer were too slow, we would almost certainly run out of memory.\r\n\r\nARROW-15410 improved readahead as a whole and, in the process, changed parquet so it's always  reading 1 row group in advance.\r\n\r\nThis is not always ideal in S3 scenarios.  We may want to read many row groups in advance if the row groups are small.  To fix this we should continue reading in parallel until there are at least batch_size \\* batch_readahead rows being fetched.",
        "created_at": "2022-04-22T22:58:25.000Z",
        "updated_at": "2022-05-04T00:18:35.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2022-04-27T21:03:47.000Z"
    },
    "comments": [
        {
            "created_at": "2022-04-22T23:00:09.961Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16294?focusedCommentId=17526714) by David Li (lidavidm):*\nThis is very similar to ARROW-14648 right? Or rather ARROW-14648 is the fully general solution?"
        },
        {
            "created_at": "2022-04-27T21:03:47.515Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16294?focusedCommentId=17529073) by David Li (lidavidm):*\nIssue resolved by pull request 12967\n<https://github.com/apache/arrow/pull/12967>"
        }
    ]
}