{
    "issue": {
        "title": "[R] How to filter array columns?",
        "body": "***Note**: This issue was originally created as [ARROW-16641](https://issues.apache.org/jira/browse/ARROW-16641). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIn the parquet data we have, there is a column with the array data type ({**}list<array_element <string>>{**}), which flags records that have different issues. For each record, multiple values could be stored in the column. For example, `{_}[A, B, C]{_}`.\r\n\r\nI'm trying to perform a data filtering step and exclude some flagged records.\r\n\r\nFiltering is trivial for the regular columns that contain just a single value. E.g.,\r\n```java\n\r\nflags_to_exclude <- c(\"A\", \"B\")\r\ndatt %>% filter(! col %in% flags_to_exclude)\r\n```\r\nGiven the array column, is it possible to exclude records with at least one of the flags from `flags_to_exclude` using the arrow R package?\r\n\r\nI really appreciate any advice you can provide!",
        "created_at": "2022-05-24T13:55:34.000Z",
        "updated_at": "2022-06-30T16:18:47.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2022-06-30T16:18:47.000Z"
    },
    "comments": [
        {
            "created_at": "2022-05-24T16:08:37.808Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16641?focusedCommentId=17541596) by Will Jones (willjones127):*\nI don't think there's a compute function that does what you want directly, but you should be able to achieve this by flattening the list, doing the filter, and aggregating on the indices to get a filter vector.\u00a0\r\n\r\nIs the following example helpful?\r\n```r\n\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\n\r\n# Filter `tab` for and `tab$x` in `valid`\r\nvalid <- Array$create(c(2))\r\n\r\ntab <- arrow_table(\r\n\u00a0 x = Array$create(list(c(1, 2), c(3, 2), c(1, 3))),\r\n\u00a0 y = Array$create(c(\"a\", \"b\", \"c\"))\r\n)\r\n\r\ntab_exploded <- arrow_table(\r\n\u00a0 i = call_function(\"list_parent_indices\", tab$x),\r\n\u00a0 x_flat = call_function(\"list_flatten\", tab$x)\r\n)\r\n\r\nto_keep <- tab_exploded %>%\r\n\u00a0 group_by(i) %>%\r\n\u00a0 summarise(keep = any(x_flat %in% valid)) %>%\r\n\u00a0 compute() %>%\r\n\u00a0 .$keep\r\n\r\nres <- tab[to_keep,]\r\nas_tibble(res)\r\n#> # A tibble: 2 \u00d7 2\r\n#> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0x y \u00a0 \u00a0\r\n#> \u00a0 <list<double>> <chr>\r\n#> 1 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0[2] a \u00a0 \u00a0\r\n#> 2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0[2] b\r\nres$x\r\n#> ChunkedArray\r\n#> [\r\n#> \u00a0 [\r\n#> \u00a0 \u00a0 [\r\n#> \u00a0 \u00a0 \u00a0 1,\r\n#> \u00a0 \u00a0 \u00a0 2\r\n#> \u00a0 \u00a0 ],\r\n#> \u00a0 \u00a0 [\r\n#> \u00a0 \u00a0 \u00a0 3,\r\n#> \u00a0 \u00a0 \u00a0 2\r\n#> \u00a0 \u00a0 ]\r\n#> \u00a0 ]\r\n#> ]\r\n```"
        },
        {
            "created_at": "2022-05-24T16:38:43.285Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16641?focusedCommentId=17541611) by Will Jones (willjones127):*\nOh correction: to flatten a chunked array, you should use\u00a0\r\n```R\n\r\n  x_flat = call_function(\"list_flatten\", tab$x)\r\n```"
        },
        {
            "created_at": "2022-05-25T09:33:14.239Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16641?focusedCommentId=17541934) by Vladimir (Mikryukov):*\nThank you very much for the comprehensive answer! It's very helpful!\r\n\r\nAs I understand, `list_parent_indices` discards records without any flags (`{}NULL{`} values). Is it possible to keep the nulls? I've tried to specify the options (`{}skip_nulls = \"false\" {`}or `{}skip_nulls = FALSE{`}), but it doesn't have any effect.\r\n\r\n\u00a0\r\n```java\n\r\ntab <- arrow_table(\r\n  x = Array$create(list(c(1, 2), 1, NULL)),\r\n  y = Array$create(c(\"a\", \"b\", \"c\"))\r\n)\r\ntab_exploded <- arrow_table(\r\n\u00a0 i = call_function(\"list_parent_indices\", tab$x, options = list(skip_nulls = \"false\")),\r\n\u00a0 x_flat = call_function(\"list_flatten\", tab$x)\r\n)\r\n```\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-05-25T17:26:11.568Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16641?focusedCommentId=17542142) by Will Jones (willjones127):*\nYes that option doesn't seem to do anything here. I think the semantics are a little tough to design for that. `list_parent_indices` returns a value per value in the subarray; if there are zero values, should there not be zero indices?\r\n\r\nIt does make this set filtering more awkward though; this probably deserves it's own function.\r\n\r\nA different approach might be constructing the indices to exclude:\r\n\r\n```R\n\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\n\r\n# Filter `tab` for any `tab$x` in that doesn't contain value in `exclude`\r\nexclude <- Array$create(c(1))\r\n\r\ntab <- arrow_table(\r\n  x = Array$create(list(c(1, 2), c(3, 2), c(), c(1, 3))),\r\n  y = Array$create(c(\"a\", \"b\", \"c\", \"d\"))\r\n)\r\n\r\ntab_exploded <- arrow_table(\r\n  i = call_function(\"list_parent_indices\", tab$x),\r\n  x_flat = call_function(\"list_flatten\", tab$x)\r\n  #x_flat = tab$x$chunk(0)$values()\r\n)\r\n\r\nto_drop <- tab_exploded %>%\r\n  group_by(i) %>%\r\n  summarise(to_drop = any((x_flat %in% exclude))) %>%\r\n  filter(to_drop) %>%\r\n  compute() %>%\r\n  .$i\r\n\r\nselection <- !(1:nrow(tab) %in% as.vector(to_drop + 1))\r\nres <- tab[selection,]\r\nas_tibble(res)\r\n#> # A tibble: 2 \u00d7 2\r\n#>                x y    \r\n#>   <list<double>> <chr>\r\n#> 1            [2] b    \r\n#> 2                c\r\nres$x\r\n#> ChunkedArray\r\n#> [\r\n#>   [\r\n#>     [\r\n#>       3,\r\n#>       2\r\n#>     ],\r\n#>     null\r\n#>   ]\r\n#> ]\r\n```\r\n\r\n"
        },
        {
            "created_at": "2022-05-27T09:23:55.450Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16641?focusedCommentId=17542849) by Vladimir (Mikryukov):*\nWill, thank you very much for your support!\r\nThe solution you proposed works very well.\r\n\r\n\r\nHowever, there is an issue applying it to a real dataset. It looks like the ``{}call_function(\"list_parent_indices\"){`}` does not work with a ``{}FileSystemDataset{`}` (parquet files opened with ``{}arrow::open_dataset(){`}`). So to prepare an \"exploded table\", we need to load the full dataset into memory. And the \"exploded table\" becomes huge if there are multiple flags per record. So I'm running out of RAM very quickly (>100 GB).\r\n\r\nI've also tried the other way to filter the records - using `DuckDB`+`arrow` with \u00a0SQL query of form \"`{}SELECT * FROM my_table WHERE 'FlagA' != ANY (my_table.issue) AND 'FlagB' != ANY (my_table.issue){`}\". But this approach is also very RAM-consuming.\r\n\r\nSo probably currently, there is no simple way to perform this filtering in one pass, and we need to split the data into chunks.\r\n\r\nIt would be pretty cool if one day `arrow` would have a built-in function to perform such a task on the fly!\r\n\r\nPS. The dataset we are working on is in open access - it's [GBIF occurrence records](https://github.com/gbif/occurrence/blob/master/aws-public-data.md). It has almost 2 billion records, and some of the records could have ~10 flags (column `issue`).\r\n\r\n\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-05-31T21:03:04.580Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16641?focusedCommentId=17544604) by Will Jones (willjones127):*\n> It would be pretty cool if one day `arrow` would have a built-in function to perform such a task on the fly!\r\nYes, I agree. I believe what you are looking for is the `arrays_overlap()` function in Spark or the `&&` operator in PostgreSQL, so I've created a new ticket to implement that: https://issues.apache.org/jira/browse/ARROW-16702\r\n> So to prepare an \"exploded table\", we need to load the full dataset into memory.\r\nI'd also add that for cases like this, `map_batches()` will one day be a good solution. Right now it collects its results fully into memory, but we should eventually let it stream out the results. For now, it does process the _inputs_ one-by-one, so it works well for reducing/aggregating."
        }
    ]
}