{
    "issue": {
        "title": "C++/Parquet: Support writing chunked arrays as part of a table ",
        "body": "***Note**: This issue was originally created as [ARROW-232](https://issues.apache.org/jira/browse/ARROW-232). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\n",
        "created_at": "2016-06-28T19:26:01.000Z",
        "updated_at": "2017-12-19T14:40:19.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2017-12-19T14:40:19.000Z"
    },
    "comments": [
        {
            "created_at": "2017-07-17T17:52:45.860Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-232?focusedCommentId=16090172) by Wes McKinney (wesm):*\nThis can be solved by creating a record batch iterator for tables"
        },
        {
            "created_at": "2017-08-03T19:08:00.893Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-232?focusedCommentId=16113313) by Wes McKinney (wesm):*\nMoving this to 0.7.0; there are a number of interrelated issues involving chunked tables"
        },
        {
            "created_at": "2017-09-09T09:57:09.522Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-232?focusedCommentId=16159863) by Uwe Korn (uwe):*\n> This can be solved by creating a record batch iterator for tables\n\nThis does not like a solution to me. As far as I yet understood chunking, the chunks sizes do not need to match between different columns inside a Table."
        },
        {
            "created_at": "2017-09-09T18:06:26.795Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-232?focusedCommentId=16160042) by Wes McKinney (wesm):*\nI will defer this to 0.8.0 since there's more work that needs to be done in parquet-cpp for this. The record batch iterator can be used to solve other outstanding problems  (like writing chunked tables to stream format). Patch forthcoming today"
        },
        {
            "created_at": "2017-10-23T22:12:30.426Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-232?focusedCommentId=16215946) by Wes McKinney (wesm):*\nI took a look at how to do this in parquet-cpp. This is going to require some work to make `FileWriter::Impl::WriteColumnChunk` less monolithic, since a column chunk in Parquet may consist of data coming from multiple chunks in a table column"
        },
        {
            "created_at": "2017-12-19T14:40:19.255Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-232?focusedCommentId=16296891) by Wes McKinney (wesm):*\nIssue resolved by pull request 1425\n<https://github.com/apache/arrow/pull/1425>"
        }
    ]
}