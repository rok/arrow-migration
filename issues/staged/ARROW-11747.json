{
    "issue": {
        "title": "[Python] spark.createDataFrame does not support Pandas StringDtype extension type.",
        "body": "***Note**: This issue was originally created as [ARROW-11747](https://issues.apache.org/jira/browse/ARROW-11747). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe following test case demonstrates the problem:\r\n```java\n\r\nimport pandas as pd\r\nfrom pyspark.sql import SparkSession, types\r\n\r\nspark = SparkSession.builder.appName(__file__)\\\r\n    .config(\"spark.sql.execution.arrow.pyspark.enabled\",\"true\") \\\r\n    .getOrCreate()\r\n\r\ngood = pd.DataFrame([[\"abc\"]], columns=[\"col\"])\r\n\r\nschema = types.StructType([types.StructField(\"col\", types.StringType(), True)])\r\ndf = spark.createDataFrame(good, schema=schema)\r\n\r\ndf.show()\r\n\r\nbad = good.copy()\r\nbad[\"col\"]=bad[\"col\"].astype(\"string\")\r\n\r\nschema = types.StructType([types.StructField(\"col\", types.StringType(), True)])\r\ndf = spark.createDataFrame(bad, schema=schema)\r\n\r\ndf.show()\r\n```\r\nThe error:\r\n```java\n\r\nC:\\Python\\3.8.3\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:289: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\r\n  Cannot specify a mask or a size when passing an object that is converted with the __arrow_array__ protocol.\r\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\r\n  warnings.warn(msg)\r\n```",
        "created_at": "2021-02-23T18:16:15.000Z",
        "updated_at": "2021-05-05T07:24:31.000Z",
        "labels": [
            "Migrated from Jira",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-05-05T07:24:31.000Z"
    },
    "comments": [
        {
            "created_at": "2021-02-24T13:10:02.070Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11747?focusedCommentId=17289912) by Joris Van den Bossche (jorisvandenbossche):*\nIn pyarrow itself this works:\r\n\r\n```Java\n\r\nIn [7]: good = pd.DataFrame([[\"abc\"]], columns=[\"col\"])\r\n\r\nIn [8]: bad = good.copy()\r\n   ...: bad[\"col\"]=bad[\"col\"].astype(\"string\")\r\n\r\nIn [9]: pa.table(bad)\r\nOut[9]: \r\npyarrow.Table\r\ncol: string\r\n```\r\n\r\nso I think this is something you will need to bring up with Spark."
        },
        {
            "created_at": "2021-05-05T07:23:41.759Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11747?focusedCommentId=17339477) by Joris Van den Bossche (jorisvandenbossche):*\n`[~pganelin]` Since there is an equivalent SPARK issue, I am going to close it here. "
        }
    ]
}