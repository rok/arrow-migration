{
    "issue": {
        "title": "[C++][Python][Dataset] Detect (and warn?) when DirectoryPartitioning is parsing an actually hive-style file path?",
        "body": "***Note**: This issue was originally created as [ARROW-15310](https://issues.apache.org/jira/browse/ARROW-15310). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhen you have a hive-style partitioned dataset, with our current `dataset(..)` API, it's relatively easy to mess up the inferred partitioning and get confusing results. \r\n\r\nFor example, if you specify the partitioning field names with `partitioning=[...]` (which is not needed for hive style since those are inferred), we actually assume you want directory partitioning. This DirectoryPartitioning will then parse the hive-style file paths and take the full \"key=value\" as the data values for the field.  \r\nAnd then, doing a filter can result in a confusing empty result (because \"value\" doesn't match \"key=value\").\r\n\r\nI am wondering if we can't relatively cheaply detect this case, and eg give an informative warning about this to the user. \r\n\r\nBasically what happens is this:\r\n\r\n```python\n\r\n>>> part = ds.DirectoryPartitioning(pa.schema([(\"part\", \"string\")]))\r\n>>> part.parse(\"part=a\")\r\n<pyarrow.dataset.Expression (part == \"part=a\")>\r\n```\r\n\r\nIf the parsed value is a string that contains a \"=\" (and in this case also contains the field name), that is I think a clear sign that (in the large majority of cases) the user is doing something wrong.\r\n\r\nI am not fully sure where and at what stage the check could be done though. Doing it for every path in the dataset might be too costly.\r\n\r\n\r\n----\r\n\r\nIllustrative code example:\r\n\r\n```python\n\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport pyarrow.dataset as ds\r\n\r\nimport pathlib\r\n\r\n## constructing a small dataset with 1 hive-style partitioning level\r\n\r\nbasedir = pathlib.Path(\".\") / \"dataset_wrong_partitioning\"\r\nbasedir.mkdir(exist_ok=True)\r\n\r\n(basedir / \"part=a\").mkdir(exist_ok=True)\r\n(basedir / \"part=b\").mkdir(exist_ok=True)\r\n\r\ntable1 = pa.table({'a': [1, 2, 3], 'b': [1, 2, 3]})\r\npq.write_table(table1, basedir / \"part=a\" / \"data.parquet\")\r\n\r\ntable2 = pa.table({'a': [4, 5, 6], 'b': [1, 2, 3]})\r\npq.write_table(table2, basedir / \"part=b\" / \"data.parquet\")\r\n```\r\n\r\nReading as is (not specifying a partitioning, so default to no partitioning) will at least give an error about a missing field:\r\n\r\n```Java\n\r\n>>> dataset = ds.dataset(basedir)\r\n>>> dataset.to_table(filter=ds.field(\"part\") == \"a\")\r\n...\r\nArrowInvalid: No match for FieldRef.Name(part) in a: int64\r\n```\r\n\r\nBut specifying the partitioning field name (which currently gets (silently) interpreted as directory partitioning) gives a confusing empty result:\r\n\r\n```python\n\r\n>>> dataset = ds.dataset(basedir, partitioning=[\"part\"])\r\n>>> dataset.to_table(filter=ds.field(\"part\") == \"a\")\r\npyarrow.Table\r\na: int64\r\nb: int64\r\npart: string\r\n----\r\na: []\r\nb: []\r\npart: []\r\n```\r\n\r\nThis filter doesn't work because the values in the \"part\" column are not \"a\" but \"part=a\":\r\n\r\n```python\n\r\n>>> dataset.to_table().to_pandas()\r\n   a  b    part\r\n0  1  1  part=a\r\n1  2  2  part=a\r\n2  3  3  part=a\r\n3  4  1  part=b\r\n4  5  2  part=b\r\n5  6  3  part=b\r\n```",
        "created_at": "2022-01-12T11:21:01.000Z",
        "updated_at": "2022-07-04T17:41:29.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-01-12T16:46:02.691Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15310?focusedCommentId=17474693) by Joris Van den Bossche (jorisvandenbossche):*\nIt seems ARROW-10485 is discussing a very similar case on the R side"
        },
        {
            "created_at": "2022-01-12T19:37:03.335Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15310?focusedCommentId=17474912) by Weston Pace (westonpace):*\nSo I'd vote we do something similar to what I proposed in ARROW-10485.  In python this would mean adding a `partitioning_flavor` option to `pyarrow.dataset.dataset` and default it to `\"hive\"`.\r\n\r\nIf set to \"hive\" then the python code would supply a `HivePartitioningFactory` to the `FileSystemDatasetFactory`.  This would basically be the analogue of the `partitioning_flavor` option in `pyarrow.dataset.write_dataset`.\r\n\r\nIf both `partitioning` and `partitioning_flavor` are set then `partitioning` would take precedence (although an error would be acceptable).\r\n\r\nThis should make it clear to the user:\r\n\r\n \\* By default we will try and interpret directories as hive partitioned folders.\r\n \\* If you don't want that default there is an easy way to change it."
        }
    ]
}