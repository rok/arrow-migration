{
    "issue": {
        "title": "function read_parquet(*,as_data_frame=TRUE) fails when embedded nuls present. ",
        "body": "***Note**: This issue was originally created as [ARROW-10324](https://issues.apache.org/jira/browse/ARROW-10324). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nFor the following code snippet\r\n```java\n\r\n// code placeholder\r\nlibrary(arrow)\r\n\r\ndownload.file('https://github.com/akashshah59/embedded_nul_parquet/raw/main/CC-MAIN-20200702045758-20200702075758-00007.parquet','sample.parquet')\r\n\r\nread_parquet(file = 'sample.parquet',as_data_frame = TRUE)\r\n\r\n```\r\nI get -\r\n\r\n\u00a0\r\n```java\n\r\nError in Table__to_dataframe(x, use_threads = option_use_threads()) : embedded nul in string: '\\0 at \\0'\r\n```\r\n\u00a0\r\n\r\nSo, I thought, what if I could read the file as binaries and replace the embedded nul character \\0 myself.\r\n\r\n\u00a0\r\n```java\n\r\nparquet <- read_parquet(file = 'sample.parquet',as_data_frame = FALSE)\u00a0\r\nraw <- write_to_raw(parquet,format = \"file\")\r\nprint(raw)\n```\r\n\u00a0\r\n\r\nIn this case, I get an indecipherable stream of characters and nuls, which makes it very difficult to remove '00' characters that are problematic in the stream.\r\n\r\n\u00a0\r\n```java\n\r\n[1] 41 52 52 4f 57 31 00 00 ff ff ff ff d0 02 00 00 10 00 00 00 00 00 0a 00 0c 00 06 00\u00a0\r\n[29] 05 00 08 00 0a 00 00 00 00 01 04 00 0c 00 00 00 08 00 08 00 00 00 04 00 08 00 00 00\u00a0\r\n[57] 04 00 00 00 0d 00 00 00 70 02 00 00 38 02 00 00 10 02 00 00 d0 01 00 00 a4 01 00 00\u00a0\r\n[85] 74 01 00 00 34 01 00 00 04 01 00 00 cc 00 00 00 9c 00 00 00 64 00 00 00 34 00 00 00\u00a0\r\n[113] 04 00 00 00 d4 fd ff ff 00 00 01 05 14 00 00 00 0c 00 00 00 04 00 00 00 00 00 00 00\u00a0\r\n[141] c4 fd ff ff 0a 00 00 00 77 61 72 63 5f 6c 61 6e 67 73 00 00 00 fe ff ff 00 00 01 05\u00a0\r\n[169] 14 00 00 00 0c 00 00 00 04 00 00 00 00 00 00 00 f0 fd ff ff 0b 00 00 00 6c 61 6e 67\u00a0\r\n[197] 5f 64 65 74 65 63 74 00 2c fe ff ff 00 00 01 03 18 00 00 00 0c 00 00 00 04 00\r\n```\r\n\u00a0\r\nIs there a way to handle this while reading Apache parquet?",
        "created_at": "2020-10-16T06:19:56.000Z",
        "updated_at": "2020-10-16T15:10:29.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-10-16T15:10:29.000Z"
    },
    "comments": [
        {
            "created_at": "2020-10-16T15:10:00.847Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-10324?focusedCommentId=17215444) by Neal Richardson (npr):*\nThis is the same as ARROW-6582. We're working on a proper solution but don't have one yet. Two things to note:\r\n\r\n1. In the upcoming release, it won't error anymore, it will truncate the string at the nul. Arguably that's worse because you won't know you have a problem.\r\n2. I think you can work around this by reading with `as_data_frame = FALSE` as you have done, and then cast the offending column(s) to `binary()` before bringing the data into R. That will give you a list of raw vectors, and you should be able to filter out the `00`s and then call `rawToChar()` on them (assuming what you want is to drop the nuls). "
        }
    ]
}