{
    "issue": {
        "title": "[Java][Python] Schema Missing Exception in ArrowStreamReader",
        "body": "***Note**: This issue was originally created as [ARROW-6133](https://issues.apache.org/jira/browse/ARROW-6133). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHello\r\n\r\nMy colleague and I are trying to pass Arrow thru Kafka. He uses a PyArrow, I'm using Scala Java API.\r\n\r\nHere's the Transmitter code:\r\n```python\n\r\nimport pyarrow as pa\r\n def record_batch_to_bytes(df):\r\n \u00a0\u00a0\u00a0 batch = pa.RecordBatch.from_pandas(df)\r\n \u00a0\u00a0\u00a0 ser_ = pa.serialize(batch)\r\n \u00a0\u00a0\u00a0 return bytes(ser_.to_buffer())\r\n\r\n```\r\n\u00a0\r\n\r\nMy colleague is able to read this stream with the Python API:\r\n```python\n\r\ndef bytes_to_batch_record(bytes_):\r\n \u00a0\u00a0\u00a0 batch = pa.deserialize(bytes_)\r\n \u00a0\u00a0\u00a0 print(batch.schema)\r\n```\r\n\r\nOn the Receiver side, I use the following from Java API:\r\n\r\n```scala\n\r\ndef deserialize(din: Chunk[BArr]): Chunk[ArrowStreamReader] =\r\n for { \r\n    arr <- din \r\n    stream = new ByteArrayInputStream(arr) \r\n} yield new ArrowStreamReader(stream, allocator)\r\n \u00a0\r\n reader = deserialize(arr)\r\n schema = reader.map(r => r.getVectorSchemaRoot.getSchema)\r\n empty = reader.map(r => r.loadNextBatch)\r\n```\r\n\r\n\u00a0\r\n\r\nWhich fails with exception on both lines 2 and 3 in the last snippet:\r\n```bash\n\r\nFiber failed.\r\n An unchecked error was produced.\r\n java.io.IOException: Unexpected end of input. Missing schema.\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.arrow.vector.ipc.ArrowStreamReader.readSchema(ArrowStreamReader.java:135)\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.arrow.vector.ipc.ArrowReader.initialize(ArrowReader.java:178)\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.arrow.vector.ipc.ArrowReader.ensureInitialized(ArrowReader.java:169)\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.arrow.vector.ipc.ArrowReader.getVectorSchemaRoot(ArrowReader.java:62)\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at nettest.ArrowSpec.$anonfun$testConsumeArrow$7(Arrow.scala:96)\r\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at zio.Chunk$Arr.map(Chunk.scala:722)\r\n```\r\n\u00a0\r\n\r\nThe full Scala code is [here](https://github.com/Clover-Group/zio-tsp/blob/46e34c7c060bf4061067922077bbe05ea4b9f301/src/test/scala/Arrow.scala#L95)\r\n\r\n\u00a0\r\n\r\nHow do I resolve that ? We both are using Arrow 0.14.1 and my colleague has no issues with PyArrow API.\r\n\r\nThank you!",
        "created_at": "2019-08-05T09:01:14.000Z",
        "updated_at": "2019-08-05T21:25:10.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Java",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-08-05T21:25:10.000Z"
    },
    "comments": [
        {
            "created_at": "2019-08-05T21:24:38.791Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6133?focusedCommentId=16900419) by Wes McKinney (wesm):*\nThe output of `pyarrow.serialize` is not an IPC stream compatible with ArrowStreamReader. You need to use the Python stream writer class, see http://arrow.apache.org/docs/python/generated/pyarrow.RecordBatchStreamWriter.html#pyarrow.RecordBatchStreamWriter"
        }
    ]
}