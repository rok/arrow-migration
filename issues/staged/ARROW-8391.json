{
    "issue": {
        "title": "[C++] Implement row range read API for IPC file (and Feather)",
        "body": "***Note**: This issue was originally created as [ARROW-8391](https://issues.apache.org/jira/browse/ARROW-8391). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe objective would be able to read a range of rows from the middle of a file. It's not as easy as it might sound since all the record batch metadata must be examined to determine the start and end point of the row range",
        "created_at": "2020-04-10T01:35:05.000Z",
        "updated_at": "2020-04-10T16:03:29.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2020-04-10T15:00:39.744Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8391?focusedCommentId=17080545) by Radu Teodorescu (raduteodorescu):*\nWould you consider allowing for an indexing structure stored in a contiguous section that contains records like <record batch (id?), offset>?\r\n\r\nThis structure can itself be represented using arrow constructs (aka as an arrow table).\r\n\r\nIf we want to provision for having an overwhelmingly large number of record batches, to the point where the index itself can provide a significant communication overhead, I would suggest breaking the index in hierarchical structure, somewhat similar to a BTree:\r\n \\* Each Node, represents a fixed size, <batch id,offset> table and it is represented itself as a record batch in the index table.\r\n \\* Leaf nodes point to record batches in the original table\r\n \\* Internal nodes point to other index record batches\r\n\r\nThe first index table record batch represents the root of the hierarchy.\r\n\r\nThis way, getting the list of record batches involved in a row range, involves reading _log B(record batch count)_ index batches,\u00a0where B is the size of the index record batch.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2020-04-10T15:29:39.892Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8391?focusedCommentId=17080561) by Wes McKinney (wesm):*\nCurrently we just have the file format that's defined in \r\n\r\nhttps://github.com/apache/arrow/blob/master/docs/source/format/Columnar.rst#ipc-file-format\r\n\r\nand\r\n\r\nhttps://github.com/apache/arrow/blob/master/format/File.fbs\r\n\r\nIf you'd like to propose changes to the format we would need to have a mailing list discussion about it and then a PR with the proposed changes that can be formally adopted. That said it would still be nice to be able to do read-range with the existing file structure. "
        },
        {
            "created_at": "2020-04-10T16:03:29.154Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8391?focusedCommentId=17080601) by Radu Teodorescu (raduteodorescu):*\nFair point\r\n\r\nI guess I was doing two things at once:\r\n1. Trying to understand the scope of the ticket - based on your comments it sound like the preferred approach would be something along the lines of binary searching the\u00a0recordBatches from the file footer.\n1. Exploring the notion of adding broader support for efficiently identifying a row range within the arrow API in general (as in ChunkedArray and beyond) - this might fall out of the scope of this ticket but I am intrigued wrt the current state of the conversation on the topic.\u00a0"
        }
    ]
}