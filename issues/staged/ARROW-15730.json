{
    "issue": {
        "title": "[R] Memory usage in R blows up",
        "body": "***Note**: This issue was originally created as [ARROW-15730](https://issues.apache.org/jira/browse/ARROW-15730). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHi,\r\n\r\nI'm trying to load a ~10gb arrow file into R (under Windows)\r\n\r\n_(The file is generated in the 6.0.1 arrow version under Linux)._\r\n\r\nFor whatever reason the memory usage blows up to ~110-120gb (in a fresh and empty R instance).\r\n\r\nThe weird thing is that when deleting the object again and running a gc() the memory usage goes down to 90gb only. The delta of ~20-30gb is what I would have expected the dataframe to use up in memory (and that's also approx. what was used - in total during the load - when running the old arrow version of 0.15.1. And it is also what R shows me when just printing the object size.)\r\n\r\nThe commands I'm running are simply:\r\n\r\noptions(arrow.use_threads=FALSE);\r\n\r\narrow::set_cpu_count(1); # need this - otherwise it freezes under windows\r\n\r\narrow::read_arrow('file.arrow5')\r\n\r\nIs arrow reserving some resources in the background and not giving them up again? Are there some settings I need to change for this?\r\n\r\nIs this something that is known and fixed in a newer version?\r\n\r\n**Note** that this doesn't happen in Linux. There all the resources are freed up when calling the gc() function - not sure if it matters but there I also don't need to set the cpu count to 1.\r\n\r\nAny help would be appreciated.",
        "created_at": "2022-02-18T19:31:14.000Z",
        "updated_at": "2022-05-03T21:46:10.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: R",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2022-05-03T21:46:10.000Z"
    },
    "comments": [
        {
            "created_at": "2022-02-18T22:22:09.996Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17494830) by Will Jones (willjones127):*\nHi Christian,\r\n\r\nThat's very odd. Could you check these two things to help us identify the issue?\r\n1. Show us the output of\u00a0`{}arrow::arrow_info(){`}. I'm particularly interested check which allocator/memory pool is being used. You can change that with the `ARROW_DEFAULT_MEMORY_POOL` [environment variable ](https://arrow.apache.org/docs/cpp/memory.html?highlight=arrow_default_memory_pool#overriding-the-default-memory-pool).\u00a0\n1. Does this issue happen if you pass in `as_data_frame = FALSE` into `arrow::read_arrow()`? That could help us determine if it's due to the file read or the conversion to an R data frame."
        },
        {
            "created_at": "2022-02-19T14:06:39.668Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17494978) by Christian (Klar):*\nApologies for the late reply. I just checked it after a full computer restart and it is exactly the same problem. Interestingly this time the full memory usage went to 90gb and then after deleting+gc() it got stuck at 60gb. So same problem - just a little bit lower total numbers. It holds both in Rstudio and in a R terminal.\r\n\r\nBelow the requested outputs. I also added what it shows on a gc() and what windows shows as resource usage.\r\n\r\nThis happens with as_data_frame=T (default setting of read_arrow), given that I don't need to make any changes to the df when loading it in.\r\n\r\nAnd to reiterate - under Linux it frees up all resources after calling gc().\r\n\r\n> arrow::arrow_info()\r\nArrow package version: 6.0.1\r\n\r\nCapabilities:\r\n\r\ndataset \u00a0 \u00a0TRUE\r\nparquet \u00a0 \u00a0TRUE\r\njson \u00a0 \u00a0 \u00a0 TRUE\r\ns3 \u00a0 \u00a0 \u00a0 \u00a0 TRUE\r\nutf8proc \u00a0 TRUE\r\nre2 \u00a0 \u00a0 \u00a0 \u00a0TRUE\r\nsnappy \u00a0 \u00a0 TRUE\r\ngzip \u00a0 \u00a0 \u00a0 TRUE\r\nbrotli \u00a0 \u00a0FALSE\r\nzstd \u00a0 \u00a0 \u00a0 TRUE\r\nlz4 \u00a0 \u00a0 \u00a0 \u00a0TRUE\r\nlz4_frame \u00a0TRUE\r\nlzo \u00a0 \u00a0 \u00a0 FALSE\r\nbz2 \u00a0 \u00a0 \u00a0 FALSE\r\njemalloc \u00a0FALSE\r\nmimalloc \u00a0 TRUE\r\n\r\nArrow options():\r\n\r\narrow.use_threads FALSE\r\n\r\nMemory:\r\n\r\nAllocator mimalloc\r\nCurrent \u00a0 \u00a00 bytes\r\nMax \u00a0 \u00a0 \u00a0 34.31 Gb\r\n\r\nRuntime:\r\n\r\nSIMD Level \u00a0 \u00a0 \u00a0 \u00a0 \u00a0avx512\r\nDetected SIMD Level avx512\r\n\r\nBuild:\r\n\r\nC++ Library Version \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 6.0.1\r\nC++ Compiler \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0GNU\r\nC++ Compiler Version \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a08.3.0\r\nGit ID \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 d132a740e33ec18c07b8718e15f85b4080a292ff\r\n\r\n> gc()\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 used (Mb) gc trigger \u00a0 \u00a0(Mb) \u00a0 max used \u00a0 \u00a0(Mb)\r\nNcells 1792749 95.8 \u00a0 \u00a03428368 \u00a0 183.1 \u00a0 \u00a02914702 \u00a0 155.7\r\nVcells 4673226 35.7 2939373019 22425.7 3943230076 30084.5\r\n\r\n> ls()\r\ncharacter(0)\r\n\r\n\u00a0\r\n\r\n![image-2022-02-19-09-05-32-278.png](https://issues.apache.org/jira/secure/attachment/13040260/image-2022-02-19-09-05-32-278.png)\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-02-19T14:38:55.204Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17494982) by Christian (Klar):*\nAlso if you want me to test the problem with a specific arrow5 file I'm happy to do so."
        },
        {
            "created_at": "2022-02-22T14:44:28.131Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496143) by Christian (Klar):*\nI did some more testing (all the reading is done within R and Arrow 6.0.1). It looks like there's a few things here:\r\n\r\n1) I read a file that was written in Arrow 5 (the file is {}30{}gb and was written directly with the C#/C++ interface) - that one increases the memory usage to ~30-38. But then on gc() the memory usage goes down to 8gb and doesn't free up everything. I'm not sure why that is but that's acceptable. The file only has chr/Date/num/int. Calling arrow_info yields the following (same result after loading/deleting the df).\r\n\r\nAllocator mimalloc\r\nCurrent \u00a0 \u00a00 bytes\r\nMax \u00a0 \u00a0 \u00a0 \u00a00 bytes\r\n\r\n2) Reading the file from last week ({}10{}gb written in Arrow 6.0.1 from R) yields again the same result as last week. Note that here I have also the factor/logical types which arrow seems to store and read.\r\n\r\nAllocator mimalloc\r\nCurrent \u00a0 \u00a04.19 Kb\r\nMax \u00a0 \u00a0 \u00a0 34.31 Gb\r\n\r\n3) As a test I did a write_arrow on the file from 2), but I did an unfactor on all the factor columns. Same issue as in 2). So it doesn't look like it is the factor type that's the issue.\r\n\r\n4) As a final test I read the file from 1) and did a write_arrow on it from R. The issue comes up again after reading it back in.\r\n\r\nBefore deletion:\r\n\r\nAllocator mimalloc\r\nCurrent \u00a0 \u00a028.2 Gb\r\nMax \u00a0 \u00a0 \u00a0 \u00a028.2 Gb\r\n\r\nAfter deletion:\r\n\r\nAllocator mimalloc\r\nCurrent \u00a0 \u00a00 bytes\r\nMax \u00a0 \u00a0 \u00a0 \u00a028.2 Gb\r\n\r\n\u00a0\r\n\r\n###\r\n\r\nSo the issue seems to be with writing the arrow file from R. All I do is to call a write_arrow('file.arrow5'). Is there a problem with that?"
        },
        {
            "created_at": "2022-02-22T15:39:21.105Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496175) by Christian (Klar):*\nAs one final test I wrote the arrow file in 4 different ways:\r\n\r\nc(\"default\", \"lz4\", \"uncompressed\", \"zstd\") %>% walk(~{\r\n\u00a0 log_info(.x)\r\n\u00a0 write_feather(\r\n\u00a0 \u00a0 testdf,\r\n\u00a0 \u00a0 glue('C:/Temp/df_test_\\{.x}.arrow'),\r\n\u00a0 \u00a0 compression = .x\r\n\u00a0 )\r\n})\r\n\r\n\u00a0\r\n\r\nIt seems that only when writing it uncompressed it does not have the memory issue - then it behaves as expected:\r\n \\* the memory gets freed up after deletion\r\n \\* the max memory usage is never bigger than the file size (or object size in R)\r\n \\* the below holds as well.\r\n\r\nAllocator mimalloc\r\nCurrent \u00a0 \u00a00 bytes\r\nMax \u00a0 \u00a0 \u00a0 \u00a00\u00a0 bytes\r\n\r\n\u00a0\r\n\r\nDoes this make sense to anyone? Is this a bug or is this expected behavior in Windows?\r\n\r\nAs said in Linux I don't have that issue (even though the max memory usage jumps up to twice the object size during reading, it is being freed up again).\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-02-22T16:33:47.661Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496204) by Will Jones (willjones127):*\nHi Christian,\r\n\r\nDid you do any tests with as_data_frame = FALSE?\r\n\r\nThere are two separate stores of memory: R's memory and Arrow's memory pool (on Windows defaults to mimalloc). `arrow_info` prints out the stats for the Arrow memory pool; it looks like it's freeing things correctly, right? When you call `{}gc(){`}, that affects R's memory system. It sounds like R isn't freeing memory there correctly. Testing with `as_data_frame = FALSE` would help confirm this.\r\n\r\nIf what I've said above is correct, it seems like either there might be a bug in the R for Windows, or there is something wrong in Arrow. If you could describe the data a little more (or even share a sample), perhaps I could reproduce it?\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-02-22T18:39:19.090Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496269) by Christian (Klar):*\nI have not tried that yet but will do so soon.\r\n\r\nAs said reading a non-compressed version seems to have worked - not sure if that indicates what the issue might be.\r\n\r\nUnfortunately I can't share the data set but given that I was able to reproduce it with 2 different data sets I don't think it has something to do with the data itself. If you have a reference arrow file you want me to download and that we both can test I'm very happy to do so."
        },
        {
            "created_at": "2022-02-22T18:41:55.689Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496270) by Will Jones (willjones127):*\n`[~Klar]` to be more specific, could you share the output of the following:\r\n\r\n```R\n\r\noptions(arrow.use_threads=FALSE);\r\n\r\narrow::set_cpu_count(1); # need this - otherwise it freezes under windows\r\n\r\ntable <- arrow::read_arrow('file.arrow5', as_data_frame = FALSE)\r\n\r\narrow_info()$memory\r\ngc()\r\ntable$schema\r\n```\r\n\u00a0"
        },
        {
            "created_at": "2022-02-22T18:43:40.210Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496272) by Christian (Klar):*\nYes that should be fine."
        },
        {
            "created_at": "2022-02-22T18:50:36.959Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496274) by Christian (Klar):*\nNote that this is with a cut down version. Here the size of the file is ~1gb and is written with the \"default\" compression. It takes about 3-5gb when reading it into R. And the space that doesn't get freed up is ~7gb.\r\n\r\n(Deleting table and running another gc() keeps the 7gb allocated.)\r\n\r\n\u00a0\r\n\r\n> arrow_info()$memory\r\n$backend_name\r\n[1] \"mimalloc\"\r\n\r\n$bytes_allocated\r\n[1] 5379819648\r\n\r\n$max_memory\r\n[1] 5379819648\r\n\r\n$available_backends\r\n[1] \"mimalloc\" \"system\" \u00a0\r\n\r\n> gc()\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 used \u00a0(Mb) gc trigger \u00a0(Mb) max used \u00a0(Mb)\r\nNcells 2625778 140.3 \u00a0 \u00a04439937 237.2 \u00a04439937 237.2\r\nVcells 7082576 \u00a054.1 \u00a0 12255594 \u00a093.6 \u00a09236142 \u00a070.5\r\n> table$schema\r\nSchema\r\n: int32\r\n: date32[day]\r\n: string\r\n: string\r\nstring\r\ndate32[day]\r\nstring\r\nstring\r\ndouble\r\ndouble\r\ndouble\r\nint32\r\nint32\r\nstring\r\ndouble\r\nstring\r\ndouble\r\ndouble\r\nstring\r\ndouble\r\ndouble\r\nstring\r\nstring\r\ndouble\r\nstring\r\nbool\r\ndate32[day]\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nint32\r\nint32\r\nint32\r\nint32\r\nint32\r\nint32\r\nstring\r\nint32\r\nstring\r\nint32\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\nstring\r\ndouble\r\ndouble\r\nint32\r\ndouble\r\ndate32[day]\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>\r\ndictionary<values=string, indices=int8>"
        },
        {
            "created_at": "2022-02-22T19:53:49.512Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496291) by Will Jones (willjones127):*\nNot able to reproduce yet, but I am noticing the memory usage reporting is a little confusing in Rstudio. To make sure we are on the same page, my test code is below.\r\n\r\n1. Does this align with how you are measuring memory use? Or is there somewhere else?\n1. Does this example data show the memory leaking behavior you are seeing?\n   \u00a0\n   {code:r}\n   library(arrow)\n   \n   print_memory <- function() {\n     print(sprintf(\"Arrow: %s MB\", trunc(arrow_info()$memory$bytes_allocated / 1024 / 1024)))\n     print(sprintf(\"R: %s MB\", gc()[\"Vcells\", 2]))\n   }\n   \n1. Create example data\n   size <- 1E8\n   \n   my_table <- arrow_table(\n     x = Array$create(sample(letters, size, replace = TRUE)),\n     y = Array$create(as.factor(sample(letters, size, replace = TRUE))),\n     z = Array$create(as.Date(1:size, as.Date(\"2020-01-01\"))),\n     a = Array$create(1:size, type=int32())\n   )\n   \n   arrow::write_arrow(my_table, \"file.arrow5\")\n   remove(my_table)\n   \n1. Note: you may need to wait a few seconds for Arrow memory pool to free memory\n   print_memory()\n1. [1] \"Arrow: 0 MB\"\n1. [1] \"R: 14.1 MB\"\n   \n   options(arrow.use_threads=FALSE);\n   \n   arrow::set_cpu_count(1); # need this - otherwise it freezes under windows\n   \n   table <- arrow::read_arrow('file.arrow5')\n   print_memory()\n1. [1] \"Arrow: 1335 MB\"\n1. [1] \"R: 1158.5 MB\"\n   \n   remove(table)\n   print_memory()\n1. [1] \"Arrow: 0 MB\"\n1. [1] \"R: 14.1 MB\"{code}"
        },
        {
            "created_at": "2022-02-22T21:06:34.282Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496319) by Christian (Klar):*\nYes this is enough to reproduce the issue. I ran it.\r\n \\* Note that I restarted the R session before reading in the arrow file to have a clean view of how much memory is being used up.\r\n \\* When reading in the arrow file I'm getting a max memory usage of ~7gb (as per Windows process explorer)\r\n \\* When deleting the table object the stub memory usage is ~2.5gb - I can't get it back no matter how many gc()'s I do - but I can get it back when either reading it in on a Linux machine or reading an uncompressed arrow file.\r\n\r\nI'm generally measuring memory usage ballpark when looking at the process explorer. It's not exact but still gives a good view if something isn't being freed up."
        },
        {
            "created_at": "2022-02-22T21:46:45.252Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496336) by Jameel Alsalam (jalsalam):*\nHello, I think I have reproduced the issue here. About 1.5 GB appears to still be in use after the remove statement. I am on CRAN arrow 7.0.0. I was interested in this issue because I have tried to diagnose a different arrow memory issue involving write_dataset. In my investigations, the memory reported internally by gc() or arrow is quite different than what is reported by Windows via e.g., task manager. I have found a way to get the system task manager-like memory by running: `system2(\"tasklist\", stdout=TRUE)` and then filtering for the right process. Pasted below I ran your script with the additional memory info.\r\n\r\n\u00a0\r\n\r\n``` r\r\nlibrary(arrow)\r\n#>\u00a0\r\n#> Attaching package: 'arrow'\r\n#> The following object is masked from 'package:utils':\r\n#>\u00a0\r\n#> \u00a0 \u00a0 timestamp\r\n\r\nprint_memory <- function() {\r\n\u00a0 print(sprintf(\"Arrow: %s MB\", trunc(arrow_info()$memory$bytes_allocated / 1024 / 1024)))\r\n\u00a0 print(sprintf(\"R: %s MB\", gc()[\"Vcells\", 2]))\r\n\u00a0 print((function(t) t[grep(Sys.getpid(), t)])(system2(\"tasklist\", stdout = TRUE)))\r\n}\r\n\r\n1. Create example data\n   size <- 1E8\n   \n   print_memory()\n#> [1] \"Arrow: 0 MB\"\r\n#> [1] \"R: 9.8 MB\"\r\n#> [1] \"Rterm.exe \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a019096 Console \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02 \u00a0 \u00a0125,672 K\"\r\n\r\nmy_table <- arrow_table(\r\n\u00a0 x = Array$create(sample(letters, size, replace = TRUE)),\r\n\u00a0 y = Array$create(as.factor(sample(letters, size, replace = TRUE))),\r\n\u00a0 z = Array$create(as.Date(1:size, as.Date(\"2020-01-01\"))),\r\n\u00a0 a = Array$create(1:size, type=int32())\r\n)\r\n\r\narrow::write_arrow(my_table, \"file.arrow5\")\r\n#> Warning: Use 'write_ipc_stream' or 'write_feather' instead.\r\nremove(my_table)\r\n\r\n1. Note: you may need to wait a few seconds for Arrow memory pool to free memory\n   Sys.sleep(5)\n   print_memory()\n#> [1] \"Arrow: 953 MB\"\r\n#> [1] \"R: 392.6 MB\"\r\n#> [1] \"Rterm.exe \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a019096 Console \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02 \u00a0 \u00a0563,344 K\"\r\n\r\n\r\noptions(arrow.use_threads=FALSE);\r\n\r\narrow::set_cpu_count(1); # need this - otherwise it freezes under windows\r\n\r\ntable <- arrow::read_arrow('file.arrow5')\r\n#> Warning: Use 'read_ipc_stream' or 'read_feather' instead.\r\nprint_memory()\r\n#> [1] \"Arrow: 1335 MB\"\r\n#> [1] \"R: 1156.2 MB\"\r\n#> [1] \"Rterm.exe \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a019096 Console \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02 \u00a02,709,252 K\"\r\n\r\nremove(table)\r\nSys.sleep(5)\r\nprint_memory()\r\n#> [1] \"Arrow: 858 MB\"\r\n#> [1] \"R: 11.8 MB\"\r\n#> [1] \"Rterm.exe \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a019096 Console \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02 \u00a01,534,436 K\"\r\n```\r\n\r\n<sup>Created on 2022-02-22 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>\r\n\r\n<details style=\"margin-bottom:10px;\">\r\n<summary>\r\nSession info\r\n</summary>\r\n\r\n``` r\r\nsessioninfo::session_info()\r\n#> - Session info ---------------------------------------------------------------\r\n#> \u00a0setting \u00a0value\r\n#> \u00a0version \u00a0R version 4.0.5 (2021-03-31)\r\n#> \u00a0os \u00a0 \u00a0 \u00a0 Windows 10 x64 (build 19042)\r\n#> \u00a0system \u00a0 x86_64, mingw32\r\n#> \u00a0ui \u00a0 \u00a0 \u00a0 RTerm\r\n#> \u00a0language (EN)\r\n#> \u00a0collate \u00a0English_United States.1252\r\n#> \u00a0ctype \u00a0 \u00a0English_United States.1252\r\n#> \u00a0tz \u00a0 \u00a0 \u00a0 America/New_York\r\n#> \u00a0date \u00a0 \u00a0 2022-02-22\r\n#> \u00a0pandoc \u00a0 2.11.4 @ C:/Program Files/RStudio/bin/pandoc/ (via rmarkdown)\r\n#>\u00a0\r\n#> - Packages -------------------------------------------------------------------\r\n#> \u00a0! package \u00a0 \u00a0 \\* version date (UTC) lib source\r\n#> \u00a0 \u00a0arrow \u00a0 \u00a0 \u00a0 \\* 7.0.0 \u00a0 2022-02-10 [1] CRAN (R 4.0.5)\r\n#> \u00a0P assertthat \u00a0 \u00a00.2.1 \u00a0 2019-03-21 [?] CRAN (R 4.0.5)\r\n#> \u00a0P backports \u00a0 \u00a0 1.4.1 \u00a0 2021-12-13 [?] CRAN (R 4.0.5)\r\n#> \u00a0P bit \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 4.0.4 \u00a0 2020-08-04 [?] CRAN (R 4.0.5)\r\n#> \u00a0P bit64 \u00a0 \u00a0 \u00a0 \u00a0 4.0.5 \u00a0 2020-08-30 [?] CRAN (R 4.0.5)\r\n#> \u00a0P cli \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 3.2.0 \u00a0 2022-02-14 [?] CRAN (R 4.0.5)\r\n#> \u00a0P crayon \u00a0 \u00a0 \u00a0 \u00a01.5.0 \u00a0 2022-02-14 [?] CRAN (R 4.0.5)\r\n#> \u00a0P digest \u00a0 \u00a0 \u00a0 \u00a00.6.29 \u00a02021-12-01 [?] CRAN (R 4.0.5)\r\n#> \u00a0P ellipsis \u00a0 \u00a0 \u00a00.3.2 \u00a0 2021-04-29 [?] CRAN (R 4.0.5)\r\n#> \u00a0P evaluate \u00a0 \u00a0 \u00a00.14 \u00a0 \u00a02019-05-28 [?] CRAN (R 4.0.5)\r\n#> \u00a0P fansi \u00a0 \u00a0 \u00a0 \u00a0 1.0.2 \u00a0 2022-01-14 [?] CRAN (R 4.0.5)\r\n#> \u00a0P fastmap \u00a0 \u00a0 \u00a0 1.1.0 \u00a0 2021-01-25 [?] CRAN (R 4.0.5)\r\n#> \u00a0P fs \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a01.5.2 \u00a0 2021-12-08 [?] CRAN (R 4.0.5)\r\n#> \u00a0P glue \u00a0 \u00a0 \u00a0 \u00a0 \u00a01.6.1 \u00a0 2022-01-22 [?] CRAN (R 4.0.5)\r\n#> \u00a0P highr \u00a0 \u00a0 \u00a0 \u00a0 0.9 \u00a0 \u00a0 2021-04-16 [?] CRAN (R 4.0.5)\r\n#> \u00a0P htmltools \u00a0 \u00a0 0.5.2 \u00a0 2021-08-25 [?] CRAN (R 4.0.5)\r\n#> \u00a0P knitr \u00a0 \u00a0 \u00a0 \u00a0 1.37 \u00a0 \u00a02021-12-16 [?] CRAN (R 4.0.5)\r\n#> \u00a0P lifecycle \u00a0 \u00a0 1.0.1 \u00a0 2021-09-24 [?] CRAN (R 4.0.5)\r\n#> \u00a0P magrittr \u00a0 \u00a0 \u00a02.0.2 \u00a0 2022-01-26 [?] CRAN (R 4.0.5)\r\n#> \u00a0P pillar \u00a0 \u00a0 \u00a0 \u00a01.7.0 \u00a0 2022-02-01 [?] CRAN (R 4.0.5)\r\n#> \u00a0P pkgconfig \u00a0 \u00a0 2.0.3 \u00a0 2019-09-22 [?] CRAN (R 4.0.5)\r\n#> \u00a0P purrr \u00a0 \u00a0 \u00a0 \u00a0 0.3.4 \u00a0 2020-04-17 [?] CRAN (R 4.0.5)\r\n#> \u00a0 \u00a0R.cache \u00a0 \u00a0 \u00a0 0.15.0 \u00a02021-04-30 [2] CRAN (R 4.0.5)\r\n#> \u00a0 \u00a0R.methodsS3 \u00a0 1.8.1 \u00a0 2020-08-26 [2] CRAN (R 4.0.3)\r\n#> \u00a0 \u00a0R.oo \u00a0 \u00a0 \u00a0 \u00a0 \u00a01.24.0 \u00a02020-08-26 [2] CRAN (R 4.0.3)\r\n#> \u00a0 \u00a0R.utils \u00a0 \u00a0 \u00a0 2.11.0 \u00a02021-09-26 [2] CRAN (R 4.0.5)\r\n#> \u00a0P R6 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02.5.1 \u00a0 2021-08-19 [?] CRAN (R 4.0.5)\r\n#> \u00a0P reprex \u00a0 \u00a0 \u00a0 \u00a02.0.1 \u00a0 2021-08-05 [?] CRAN (R 4.0.5)\r\n#> \u00a0P rlang \u00a0 \u00a0 \u00a0 \u00a0 1.0.1 \u00a0 2022-02-03 [?] CRAN (R 4.0.5)\r\n#> \u00a0P rmarkdown \u00a0 \u00a0 2.11 \u00a0 \u00a02021-09-14 [?] CRAN (R 4.0.5)\r\n#> \u00a0P rstudioapi \u00a0 \u00a00.13 \u00a0 \u00a02020-11-12 [?] CRAN (R 4.0.5)\r\n#> \u00a0P sessioninfo \u00a0 1.2.2 \u00a0 2021-12-06 [?] CRAN (R 4.0.5)\r\n#> \u00a0P stringi \u00a0 \u00a0 \u00a0 1.7.6 \u00a0 2021-11-29 [?] CRAN (R 4.0.5)\r\n#> \u00a0P stringr \u00a0 \u00a0 \u00a0 1.4.0 \u00a0 2019-02-10 [?] CRAN (R 4.0.5)\r\n#> \u00a0 \u00a0styler \u00a0 \u00a0 \u00a0 \u00a01.6.2 \u00a0 2021-09-23 [2] CRAN (R 4.0.5)\r\n#> \u00a0P tibble \u00a0 \u00a0 \u00a0 \u00a03.1.6 \u00a0 2021-11-07 [?] CRAN (R 4.0.5)\r\n#> \u00a0P tidyselect \u00a0 \u00a01.1.2 \u00a0 2022-02-21 [?] CRAN (R 4.0.5)\r\n#> \u00a0P utf8 \u00a0 \u00a0 \u00a0 \u00a0 \u00a01.2.2 \u00a0 2021-07-24 [?] CRAN (R 4.0.5)\r\n#> \u00a0P vctrs \u00a0 \u00a0 \u00a0 \u00a0 0.3.8 \u00a0 2021-04-29 [?] CRAN (R 4.0.5)\r\n#> \u00a0P withr \u00a0 \u00a0 \u00a0 \u00a0 2.4.3 \u00a0 2021-11-30 [?] CRAN (R 4.0.5)\r\n#> \u00a0P xfun \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.29 \u00a0 \u00a02021-12-14 [?] CRAN (R 4.0.5)\r\n#> \u00a0P yaml \u00a0 \u00a0 \u00a0 \u00a0 \u00a02.3.5 \u00a0 2022-02-21 [?] CRAN (R 4.0.5)\r\n#>\u00a0\r\n#> \u00a0[1] C:/Users/jalsal02/R/renv/library/arrow-nightly-d7265b80/R-4.0/x86_64-w64-mingw32\r\n#> \u00a0[2] C:/Users/jalsal02/R/dev-library/4.0\r\n#> \u00a0[3] C:/Program Files/R/R-4.0.5/library\r\n#>\u00a0\r\n#> \u00a0P \u2013 Loaded and on-disk path mismatch.\r\n#>\u00a0\r\n#> ------------------------------------------------------------------------------\r\n```\r\n\r\n</details>"
        },
        {
            "created_at": "2022-02-22T21:54:55.615Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496340) by Jameel Alsalam (jalsalam):*\nI'm sorry for the garbled output. I am rendering using the reprex package, but I can't figure out how to make it look nice in JIRA."
        },
        {
            "created_at": "2022-02-22T22:22:28.097Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496358) by Will Jones (willjones127):*\nYes I think I can reproduce this. Essentially, R and Arrow report freeing that memory, but the OS is reporting that memory as still used. I think this is actually expected behavior for the underlying memory pools; they tend to not release memory very aggressively with the expectation that it will reuse it.\r\n\r\nIf you instead use the system allocator, you should see this issue go away (I did when I tested on my local):\r\n\r\n```R\n\r\nSys.setenv(ARROW_DEFAULT_MEMORY_POOL=\"system\") # You must run this before library(arrow)\r\nlibrary(arrow)\r\narrow_info()$memory$backend_name\r\n# [1] \"system\"\r\n```\r\n\r\nHowever, depending on your application you probably don't want to do this. While it may appear to use more memory, it's not necessarily the case that the way the allocator is handling memory is worse. See these discussions:\r\n\r\n \\* <https://github.com/microsoft/mimalloc/issues/393#issuecomment-828707830>\r\n \\* https://issues.apache.org/jira/browse/ARROW-14790?focusedCommentId=17447365\r\n\r\nTo pull out one quote from one of the maintainers of mimalloc:\r\n\r\n> However, generally mimalloc will only hold on to virtual memory and will return physical memory to the OS. Now, generally mimalloc flags unused memory as available to the OS and the OS will use that memory when there is memory pressure (MEM_RESET on windows, MADV_FREE on Linux) \u2013 however, the OS does not always show that memory as available (even though it is) as it is only reclaimed under memory pressure.\r\n\r\nThere is some possibility that there is a bug in the mimalloc version we are using (1.7.3), but the next release (2.0.x) is still in alpha: <https://github.com/microsoft/mimalloc/issues/383>"
        },
        {
            "created_at": "2022-02-22T22:30:14.455Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496359) by Christian (Klar):*\nGot it - thank you. I will try it with \"system\"."
        },
        {
            "created_at": "2022-02-22T23:32:42.372Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496382) by Christian (Klar):*\nI have a conceptual question though: Does the current setup create a \"copy\" of the file within the arrow memory (meaning does it read the entire file into arrow, and then loads it into R)? Because for large data.frames the double counting would be an issue?\r\n\r\n\u00a0\r\n\r\nAnd additionally even if isn't fully a memory leak it seems that once I delete the object, and then load another one, the space isn't used at all - Arrow is reserving more/incremental memory. So the system just starts running out of space."
        },
        {
            "created_at": "2022-02-22T23:51:40.610Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496391) by Will Jones (willjones127):*\n> I have a conceptual question though: Does the current setup create a \"copy\" of the file within the arrow memory (meaning does it read the entire file into arrow, and then loads it into R)? Because for large data.frames the double counting would be an issue?\r\nYes that's right. Basically all the Arrow readers will first read the data into Arrow format, and then if you asked for it as an R dataframe, will \"convert\" to a data frame. Now some of the conversion is really cheap; I think simple vectors like integer and numeric are essentially zero copy. IIRC there are some like structs that require more transformation to become their R analogue."
        },
        {
            "created_at": "2022-02-23T00:00:52.197Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496400) by Will Jones (willjones127):*\n> And additionally even if isn't fully a memory leak it seems that once I delete the object, and then load another one, the space isn't used at all - Arrow is reserving more/incremental memory. So the system just starts running out of space.\r\nThen that sounds like you might be encountering the bug from mimalloc I mentioned, which out of scope for this Arrow unfortunately. I think I'll create a new issue to look at mimalloc V2 which supposedly doesn't have this problem; according to the author the only reason not to use it is that is that some users report performance regressions in moving from v1 to v2."
        },
        {
            "created_at": "2022-02-23T00:09:33.229Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496403) by Christian (Klar):*\nOkay thanks. As said I will try it with \"system\" and see if it goes better. I'm not sure if I will be able to test it before Sunday but it would be great if you could leave this issue open for the case that I find some other problems."
        },
        {
            "created_at": "2022-02-23T00:46:39.684Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496413) by Christian (Klar):*\nThree additional questions:\r\n \\* Did the memory model (i.e. keeping a copy within arrow) change after 0.15 or was it introduced afterwards? That was the previous version I was\u00a0 using and I never had these kind of memory \"issues\" with it (understood that issues is not necessarily the right word). The double counting just seems very punitive.\r\nI just tried \"system\" and it does free it up (as you said) but for a while R is using about 70gb when the actual object size within R is just 30gb.\r\n\r\n \\* Do you know if R Factors (show up as dictionary in the table schema) are especially punitive compared to strings?\r\n\r\n \\* Were you able to set Sys.setenv(ARROW_DEFAULT_MEMORY_POOL=\"system\") within Rstudio? I tried a few different ways and it always just shows me mimalloc. It does work in a R console window (which is where I did the above test).\r\nI even completely restarted Rstudio - whatever I do it stays at mimalloc.\r\n\r\n\u00a0\r\n\r\nFor the last point see below:\r\n\r\n> Sys.setenv(ARROW_DEFAULT_MEMORY_POOL=\"system\")\r\n> Sys.getenv('ARROW_DEFAULT_MEMORY_POOL')\r\n[1] \"system\"\r\n> library(arrow)\r\n\r\nAttaching package: \u2018arrow\u2019\r\n\r\nThe following object is masked from \u2018package:utils\u2019:\r\n\r\n\u00a0 \u00a0 timestamp\r\n\r\n> arrow_info()$memory$backend_name\r\n[1] \"mimalloc\"\r\n\r\n\u00a0\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-02-23T01:56:23.791Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17496426) by Will Jones (willjones127):*\n> Did the memory model (i.e. keeping a copy within arrow) change after 0.15 or was it introduced afterwards? That was the previous version I was\u00a0 using and I never had these kind of memory \"issues\" with it (understood that issues is not necessarily the right word). The double counting just seems very punitive.\r\nNo, as far as I know it should have gotten better since then, with fewer copies made. This has been done by implementing \"altrep\" conversions to R vectors, which allows R to use the existing Arrow array memory instead of copying data. For each new version we've implemented this for additional data types. For example, here's the PR for integers and numerics vectors: <https://github.com/apache/arrow/pull/10445>.\r\n\r\nHowever, I just noticed that altrep was just implemented for ChunkedArray in 7.0.0, so you might not be getting the full benefit in 6.0.1 (since your 30GB file is most likely made up of multiple chunks). So it is likely worth retrying in 7.0.0.\r\n> I just tried \"system\" and it does free it up (as you said) but for a while R is using about 70gb when the actual object size within R is just 30gb.\r\nIt's hard to do any computation (read, aggregate, write, whatever) without creating some sort of intermediate result. For a 30GB file, that sounds pretty normal. You saying you can measure lower peak memory use in Arrow 0.15?\r\n> Do you know if R Factors (show up as dictionary in the table schema) are especially punitive compared to strings?\r\nIt's hard to say, and I think depends on your R version. But in 6.0.1 altrep was implemented for strings, and it won't be implemented for factors until 8.0.0. I think the best thing to do would be to save a file with just a string or just a factor and then test the peak vs result memory of each.\r\n> Were you able to set Sys.setenv(ARROW_DEFAULT_MEMORY_POOL=\"system\") within Rstudio? I tried a few different ways and it always just shows me mimalloc. It does work in a R console window (which is where I did the above test).\n> I even completely restarted Rstudio - whatever I do it stays at mimalloc.\r\n\u00a0\r\n\r\nYes I tested in Rstudio. Make sure to do Session > Restart R before you do this.\r\n\r\n\u00a0"
        },
        {
            "created_at": "2022-02-28T15:53:18.870Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-15730?focusedCommentId=17498979) by Christian (Klar):*\n**Please ignore below - It still isn't working but I just put it into the Rprofile for now and that actually seems to set it correctly.**\r\n\r\n\u00a0\r\n\r\nThanks.\r\n\r\nSo I tried pretty much everything in Rstudio but no dice. I'm literally running the following commands right away when starting RStudio - but it always comes back with mimalloc.\r\n\r\nSys.setenv(ARROW_DEFAULT_MEMORY_POOL=\"system\")\r\nSys.getenv('ARROW_DEFAULT_MEMORY_POOL')\r\nlibrary(arrow)\r\narrow_info()$memory$backend_name\r\n\r\n\u00a0\r\n\r\nWithin a normal R console it works fine."
        }
    ]
}