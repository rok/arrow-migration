{
    "issue": {
        "title": "[C++][Dataset] Ability to specify granularity of ParquetFileFragment (support row groups)",
        "body": "***Note**: This issue was originally created as [ARROW-8061](https://issues.apache.org/jira/browse/ARROW-8061). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nSpecifically for parquet (not sure if it will be relevant for other file formats as well, for IPC/feather potentially ther record batch), it would be useful to target row groups instead of files as fragments.\r\n\r\nQuoting the original design documents: _\"In datasets consisting of many fragments, the dataset API must expose the granularity of fragments in a public way to enable parallel processing, if desired. \"._   \r\nAnd a comment from Wes on that: _\"a single Parquet file can \"export\" one or more fragments based on settings. The default might be to split fragments based on row group\"_\r\n\r\nCurrently, the level on which fragments are defined (at least in the typical partitioned parquet dataset) is \"1 file == 1 fragment\".\r\n\r\nWould it be possible or desirable to make this more fine grained, where you could also opt to have a fragment per row group?   \r\nWe could have a ParquetFragment that has this option, and a ParquetFileFormat specific option to say what the granularity of a fragment is (file vs row group)?\r\n\r\ncc `[~fsaintjacques]` `[~bkietz]`",
        "created_at": "2020-03-10T18:00:31.000Z",
        "updated_at": "2020-04-10T15:31:39.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-03-27T16:52:44.000Z"
    },
    "comments": [
        {
            "created_at": "2020-03-10T18:01:14.742Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8061?focusedCommentId=17056201) by Joris Van den Bossche (jorisvandenbossche):*\nExample usecase for this: for Dask, wich wants to do it's own parallel scheduling, being able to map one task to one row group instead of one file would be useful. It is possible right now with the pyarrow.parquet ParquetDataset API, and dask also uses this API to map tasks to row groups by default (there is a `split_row_groups` keyword in dask's `read_parquet`, see https://docs.dask.org/en/latest/dataframe-api.html#dask.dataframe.read_parquet). "
        },
        {
            "created_at": "2020-03-10T18:15:07.846Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8061?focusedCommentId=17056211) by Francois Saint-Jacques (fsaintjacques):*\nYes, this is possible, a ParquetFragment could have a FileSource and a list of RowGroup identifier. Note that parallelism of RowGroup is already achieved since we return \"1 row group == 1 scantask\". I believe this would be the job of the DatasetFactory to do such partitioning, e.g. do you want 1-1, 1-n, how to configure said threshold.\r\n\r\nAlso think about formats where we don't know the granularity ahead, e.g. gzipped CSV.\u00a0"
        },
        {
            "created_at": "2020-03-10T18:33:15.767Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8061?focusedCommentId=17056248) by Joris Van den Bossche (jorisvandenbossche):*\n> Note that parallelism of RowGroup is already achieved since we return \"1 row group == 1 scantask\"\r\n\r\nYes, but for external users, it might be better to work on the level of fragments, rather than scan tasks? (eg, from the discussions, I had understood that serializing/reconstructing a scantask won't be possible. While for a fragment (or single-fragment dataset), this is posstible)"
        },
        {
            "created_at": "2020-03-27T16:52:44.241Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-8061?focusedCommentId=17068874) by Francois Saint-Jacques (fsaintjacques):*\nIssue resolved by pull request 6670\n<https://github.com/apache/arrow/pull/6670>"
        }
    ]
}