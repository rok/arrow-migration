{
    "issue": {
        "title": "[Python] Reading small amount of files from a partitioned dataset is unexpectedly slow",
        "body": "***Note**: This issue was originally created as [ARROW-11781](https://issues.apache.org/jira/browse/ARROW-11781). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nI posted this on StackOverflow and was told I should probably create an issue here.\r\n\r\nI managed to create a relative minimal example:\r\n```java\n\r\n    df = spark.createDataFrame(\r\n        [\r\n            (str(a), b, c, random.randint(0, 1000))\r\n            for a in range(100)\r\n            for b in range(10)\r\n            for c in range(10000)\r\n        ],\r\n        ['a', 'b', 'c', 'd']\r\n    )    \r\n\r\nprint(\"Writing the spark dataframe to the file system in partitioned folders.\")\r\n    df.repartition('a').write.partitionBy('a', 'b').parquet(str(data_dir), compression='snappy', mode='overwrite')    \r\n\r\ndef time_it(func, repetition=10):\r\n        start = time.time()\r\n        for _ in range(repetition):\r\n            func()\r\n        return (time.time() - start) / repetition    \r\n\r\nprint(\"Loading the entire dataset\")\r\nprint(time_it(lambda: pd.read_parquet(data_dir, engine='pyarrow')))    \r\n\r\nprint(\"Loading a single file using filters\")\r\nprint(time_it(lambda: pd.read_parquet(data_dir, engine='pyarrow', filters=[[('a', '=', '0'), ('b', '=', '0')]])))    \r\n\r\nprint(\"Loading a single file using filters and a specified partitioning\")\r\n    partitioning = pa.dataset.HivePartitioning(\r\n        pa.schema([\r\n            pa.field('a', pa.string()),\r\n            pa.field('b', pa.string())\r\n        ])\r\n    )\r\nprint(time_it(lambda: pd.read_parquet(data_dir, engine='pyarrow', filters=[[('a', '=', '0'), ('b', '=', '0')]], partitioning=partitioning)))    \r\n\r\nprint(\"Loading a single file by specifying the path\")\r\nprint(time_it(lambda: pd.read_parquet(data_dir / 'a=0' / 'b=0', engine='pyarrow')))\r\n```\r\nWhich gives me the following output:\r\n```java\n\r\nWriting the spark dataframe to the file system in partitioned folders.\r\nLoading the entire dataset\r\n0.23926825523376466\r\nLoading a single file using filters\r\n0.04788286685943603\r\nLoading a single file using filters and a specified partitioning\r\n0.0323061466217041\r\nLoading a single file by specifying the path\r\n0.0017130613327026368\r\n```\r\n\u00a0\r\n\r\nLoading the small amount of files is about 20 times faster if you address the paths directly, compared to the pyarrow filters.\r\n\r\n\u00a0\r\n\r\nThe question as I posted it on StackOverflow:\r\n\r\nI am having some problems with the speed of loading `.parquet` files. However, I don't know what I am doing wrong.\r\n\r\n**Problem**\r\n\r\nI am trying to read a single `.parquet` file from from my local filesystem which is the partitioned output from a spark job. Such that there are `.parquet` files in hierarchical directories named `a=x` and `b=y`.\r\n\r\nTo achieve this, I am using `pandas.read_parquet` (which uses `pyarrow.parquet.read_table`) for which I include the `filters` kwarg. The run time of using the `filters` is way longer than I would expect.\r\n```java\n\r\n# The following runs for about 55 seconds\r\npd.read_parquet(<path_to_entire_dataset>, filters=[[('a', '=', 'x'), ('b', '=', 'y')]])\r\n# The following runs for about 0.04 seconds\r\npd.read_parquet(<path_to_entire_dataset>/a=x/b=y/)\r\n# The following runs for about 70 seconds\r\npd.read_parquet(<path_to_entire_dataset>)\n```\r\nReading a single parquet file by specifying filters is only slightly faster than loading the entire dataset, where I would expect a run time approximately linear in the amount of files.\r\n\r\n**What mistake do I make here?**\r\n\r\nI realize that simply putting the filters in the path would work, however this will quickly become complex as what I want to filter on will / can change. Besides, I think `read_table` should be able to load this data efficiently.\r\n\r\nPS: The entire dataset contains many millions of rows, the data I want to load is only a few thousand rows.\r\n\r\n**Edit 1:**\r\n As suggested by 0x26res I manually defined the partitioning, this lead to a significant speed up, but still not as much as I would have expected. In this situation the run time was about 5 seconds.\r\n```java\n\r\npartitioning = HivePartitioning(\r\n pa.schema([\r\n pa.field('a', pa.string()),\r\n pa.field('b', pa.int32()),\r\n ])\r\n)\r\npd.read_parquet(\r\n <path_to_entire_dataset>,\r\n engine='pyarrow',\r\n filters=[\r\n [\r\n ('a', '=', x),\r\n ('b', '=', y),\r\n ]\r\n ],\r\n partitioning=partitioning\r\n)\r\n```",
        "created_at": "2021-02-25T13:41:50.000Z",
        "updated_at": "2021-07-05T12:46:20.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-07-05T12:41:19.000Z"
    },
    "comments": [
        {
            "created_at": "2021-02-25T18:24:49.122Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17291127) by Weston Pace (westonpace):*\nThank you for filing this here.\u00a0 This is a good case to look into.\u00a0 Loading a single file from a dataset using partitionable filters will probably always be a little slower than reading the file directly (need to at least scan the directories to find which files to load) but I don't think it should be 5 seconds slower even with 100,000 files.\r\n\r\nFor future viewers, here is a script to generate test data without using spark.\u00a0 I get similar timings.\r\n```java\n\r\nimport numpy as np\r\nimport pyarrow as pa\r\nimport pyarrow.dataset as pads\r\nimport pyarrow.parquet as pq\r\nrbs = []\r\nfor a_idx in range(100):\r\n    a = str(a_idx)\r\n    for b in range(10):\r\n        c = np.arange(10000)\r\n        d = np.random.randint(0, 1000, 10000)\r\n        rbs.append(pa.record_batch([np.repeat(a, 10000), np.repeat(b, 10000), c, d], ['a', 'b', 'c', 'd']))\r\ntable = pa.Table.from_batches(rbs)\r\npq.write_to_dataset(table, 'data', partition_cols=['a', 'b'])\r\n\r\n```"
        },
        {
            "created_at": "2021-03-04T19:10:02.264Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17295532) by David Li (lidavidm):*\nI took a flamegraph with py-spy. The stack traces look a little\u2026odd (some things appear to have been incorrectly? attributed to a destructor), but it looks like a good portion of the time is spent just evaluating and simplifying expressions.\r\n\r\n[spy.svg](spy.svg)"
        },
        {
            "created_at": "2021-03-05T18:45:01.921Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17296277) by David Li (lidavidm):*\nUsing Weston's reproduction and looking at flamegraphs, the overheads are as follows:\r\n1. Time spent scanning the filesystem,\n1. Time spent parsing paths into partition expressions,\n1. Time spent evaluating the filter against the partition expressions,\n1. Time spent calling C++ destructors for objects that aren't created when you directly specify the file.\u00a0\n   \n   By default, Arrow infers the partition schema, and infers one that dictionary-encodes the values. However, in this case, this makes #2 and #3 significantly more expensive. When you manually specify the partitioning, you don't use dictionary encoding, and this is much cheaper in #2 and #3.\n   \n   Also, depending on what types you manually specify, there may or may not be casts inserted in the filter - this has a smaller effect but also makes #3 more expensive.\n   \n   These overheads won't completely go away, but can get better, and as you've already found, #2 and #3 are in your control. Here's the flamegraph with a fully specified partition schema that does not require casting or dictionaries:\u00a0[spy3.svg](spy3.svg)\u00a0As you can see, now most of the overhead is #1 and #3.\n   \n   Here's the flamegraph for when you directly specify the file path:\u00a0[spy2.svg](spy2.svg)\n   \n   Note I benchmarked using Weston's repro, which uses all integer types for the partitions - string types may throw in additional wreches."
        },
        {
            "created_at": "2021-03-08T17:15:49.934Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17297540) by Micah Kornfield (emkornfield):*\nI think\u00a0ARROW-7224 could also help here (limiting the scan via filesystem filtering)"
        },
        {
            "created_at": "2021-03-08T18:04:01.762Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17297607) by Ben Kietzman (bkietz):*\nARROW-8658 would also help in this case"
        },
        {
            "created_at": "2021-03-15T19:37:16.554Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17301918) by Ben Kietzman (bkietz):*\n`[~JeroenBos]` ARROW-8658 has been merged, which should mitigate this slowness significantly"
        },
        {
            "created_at": "2021-05-11T12:13:56.524Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17342515) by David Li (lidavidm):*\nJust to follow up: Arrow 4.0.0 was released with the optimization in ARROW-8658, are you able to see if that improves your use case?"
        },
        {
            "created_at": "2021-07-05T12:23:57.934Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17374792) by Joris Van den Bossche (jorisvandenbossche):*\nCan this be closed, or are there additional options to improve the performance under consideration?"
        },
        {
            "created_at": "2021-07-05T12:40:17.904Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-11781?focusedCommentId=17374798) by David Li (lidavidm):*\nI think we can close it for now, as it's tracked in benchmarks and had some improvements in 4.0.0. There's also some more potential improvements linked. If there's still issues we can reopen or open a new issue."
        }
    ]
}