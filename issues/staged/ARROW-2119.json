{
    "issue": {
        "title": "[C++][Java] Handle Arrow stream with zero record batch",
        "body": "***Note**: This issue was originally created as [ARROW-2119](https://issues.apache.org/jira/browse/ARROW-2119). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIt looks like currently many places of the code assume that there needs to\u00a0be at least one record batch for streaming format. Is zero-recordbatch not supported by design?\r\n\r\ne.g. <https://github.com/apache/arrow/blob/master/java/tools/src/main/java/org/apache/arrow/tools/StreamToFile.java#L45>\r\n```none\n\r\n  public static void convert(InputStream in, OutputStream out) throws IOException {\r\n    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\r\n    try (ArrowStreamReader reader = new ArrowStreamReader(in, allocator)) {\r\n      VectorSchemaRoot root = reader.getVectorSchemaRoot();\r\n      // load the first batch before instantiating the writer so that we have any dictionaries\r\n      if (!reader.loadNextBatch()) {\r\n        throw new IOException(\"Unable to read first record batch\");\r\n      }\r\n      ...\r\n```\r\nPyarrow-0.8.0 does not load 0-recordbatch stream either. It would throw an exception originated from <https://github.com/apache/arrow/blob/a95465b8ce7a32feeaae3e13d0a64102ffa590d9/cpp/src/arrow/table.cc#L309:>\r\n```none\n\r\nStatus Table::FromRecordBatches(const std::vector<std::shared_ptr<RecordBatch>>& batches,\r\n                                std::shared_ptr<Table>* table) {\r\n  if (batches.size() == 0) {\r\n    return Status::Invalid(\"Must pass at least one record batch\");\r\n  }\r\n  ...\n```",
        "created_at": "2018-02-08T23:18:28.000Z",
        "updated_at": "2019-05-23T15:46:48.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Java",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-05-23T15:46:35.000Z"
    },
    "comments": [
        {
            "created_at": "2018-02-09T21:32:13.417Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2119?focusedCommentId=16358997) by Wes McKinney (wesm):*\nI believe we should make some changes to support streams having a schema but no record batches. In C++ / Python, if there are none, then `Table::FromRecordBatches` should not be called"
        },
        {
            "created_at": "2019-02-06T04:24:35.414Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2119?focusedCommentId=16761458) by Wes McKinney (wesm):*\nI think this might be fixed. I added it to 0.13 to check C++ at least"
        },
        {
            "created_at": "2019-02-27T17:43:11.120Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2119?focusedCommentId=16779569) by Wes McKinney (wesm):*\nThis can be resolved by adding a zero-record-batch stream to the integration tests"
        },
        {
            "created_at": "2019-03-12T20:59:52.070Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2119?focusedCommentId=16790999) by Wes McKinney (wesm):*\nThe patch I put up is full of failures. I'm doubtful this can be resolved in time for 0.13"
        },
        {
            "created_at": "2019-05-23T15:46:35.407Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-2119?focusedCommentId=16846810) by Wes McKinney (wesm):*\nIssue resolved by pull request 3871\n<https://github.com/apache/arrow/pull/3871>"
        }
    ]
}