{
    "issue": {
        "title": "[Python] read_row_group fails with Nested data conversions not implemented for chunked array outputs",
        "body": "***Note**: This issue was originally created as [ARROW-5030](https://issues.apache.org/jira/browse/ARROW-5030). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nHey, I'm trying to concatenate two files and to avoid reading everything to memory at once, I wanted to use `read_row_group` for my solution, but it fails.\r\n\r\n\u00a0\r\n\r\nI think it's due to fields like these:\r\n\r\n`pyarrow.Field<to: list<item: string>>`\r\n\r\n\u00a0\r\n\r\nBut I'm not sure. Is this a duplicate? The issue linked in the code is resolved https://github.com/apache/arrow/blob/fd0b90a7f7e65fde32af04c4746004a1240914cf/cpp/src/parquet/arrow/reader.cc#L915\r\n\r\n\u00a0\r\n\r\nStacktrace is\r\n\r\n\u00a0\r\n\r\n`\u00a0 File \"/data/teftel/teftel-data/teftel_data/parquet_stream.py\", line 163, in read_batches`\r\n`\u00a0\u00a0\u00a0 table = pf.read_row_group(ix, columns=self._columns)`\r\n`\u00a0 File \"/home/kuba/.local/share/virtualenvs/teftel-o6G5iH_l/lib/python3.6/site-packages/pyarrow/parquet.py\", line 186, in read_row_group`\r\n`\u00a0\u00a0\u00a0 use_threads=use_threads)`\r\n`\u00a0 File \"pyarrow/_parquet.pyx\", line 695, in pyarrow._parquet.ParquetReader.read_row_group`\r\n`\u00a0 File \"pyarrow/error.pxi\", line 89, in pyarrow.lib.check_status`\r\n`pyarrow.lib.ArrowNotImplementedError: Nested data conversions not implemented for chunked array outputs`",
        "created_at": "2019-03-27T14:34:17.000Z",
        "updated_at": "2022-08-18T19:24:05.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2019-03-28T22:15:35.220Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5030?focusedCommentId=16804353) by Wes McKinney (wesm):*\nI fixed some cases where this occurs in ARROW-4688, but it is still possible to hit this error for very large row groups (> 2GB of string data in a row group). I didn't see a follow up JIRA to this or ARROW-3762 so we can use this one for the issue\r\n\r\nhttps://github.com/apache/arrow/blob/master/cpp/src/parquet/arrow/reader.cc#L915"
        },
        {
            "created_at": "2022-04-27T16:50:24.212Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-5030?focusedCommentId=17528890) by Judah (judah.rand):*\n[~wesm_impala_7e40] I'm also running into this issue. Is this likely to be fixed / easy to fix? I'd be happy to give it a go but not really sure where to start."
        }
    ]
}