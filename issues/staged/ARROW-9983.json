{
    "issue": {
        "title": "[C++][Dataset][Python] Use larger default batch size than 32K for Datasets API",
        "body": "***Note**: This issue was originally created as [ARROW-9983](https://issues.apache.org/jira/browse/ARROW-9983). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nDremio uses 64K batch sizes. We could probably get away with even larger batch sizes (e.g. 256K or 1M) and allow memory-constrained users to elect a smaller batch size. \r\n\r\nSee example of some performance issues related to this in ARROW-9924",
        "created_at": "2020-09-12T20:01:58.000Z",
        "updated_at": "2020-09-28T17:14:09.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: C++",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2020-09-28T17:14:09.000Z"
    },
    "comments": [
        {
            "created_at": "2020-09-23T15:29:25.632Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-9983?focusedCommentId=17200898) by Antoine Pitrou (apitrou):*\n`[~bkietz]`"
        }
    ]
}