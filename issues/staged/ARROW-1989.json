{
    "issue": {
        "title": "[Python] Better UX on timestamp conversion to Pandas",
        "body": "***Note**: This issue was originally created as [ARROW-1989](https://issues.apache.org/jira/browse/ARROW-1989). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nConverting timestamp columns to Pandas, users often have the problem that they have dates that are larger than Pandas can represent with their nanosecond representation. Currently they simply see an Arrow exception and think that this problem is caused by Arrow. We should try to change the error from\r\n\r\n```Java\n\r\nArrowInvalid: Casting from timestamp[ns] to timestamp[us] would lose data: XX\r\n```\r\n\r\nto something along the lines of \r\n\r\n```Java\n\r\nArrowInvalid: Casting from timestamp[ns] to timestamp[us] would lose data: XX. This conversion is needed as Pandas does only support nanosecond timestamps. Your data is likely out of the range that can be represented with nanosecond resolution.\r\n```",
        "created_at": "2018-01-11T08:24:14.000Z",
        "updated_at": "2021-08-04T08:57:18.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: enhancement"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2018-09-09T13:25:11.595Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1989?focusedCommentId=16608447) by Krisztian Szucs (kszucs):*\n```python\n\r\nIn [45]: pa.array([datetime.date(2018, 12, 12)], type=pa.timestamp('s'))\r\n---------------------------------------------------------------------------\r\nArrowTypeError                            Traceback (most recent call last)\r\n<ipython-input-45-f6eb2418d6b7> in <module>()\r\n----> 1 pa.array([datetime.date(2018, 12, 12)], type=pa.timestamp('s'))\r\n\r\n~/Workspace/arrow/python/pyarrow/array.pxi in pyarrow.lib.array()\r\n    169     else:\r\n    170         # ConvertPySequence does strict conversion if type is explicitly passed\r\n--> 171         return _sequence_to_array(obj, mask, size, type, pool, from_pandas)\r\n    172\r\n    173\r\n\r\n~/Workspace/arrow/python/pyarrow/array.pxi in pyarrow.lib._sequence_to_array()\r\n     33     cdef shared_ptr[CChunkedArray] out\r\n     34     with nogil:\r\n---> 35         check_status(ConvertPySequence(sequence, mask, options, &out))\r\n     36\r\n     37     if out.get().num_chunks() == 1:\r\n\r\n~/Workspace/arrow/python/pyarrow/error.pxi in pyarrow.lib.check_status()\r\n     89             raise ArrowNotImplementedError(message)\r\n     90         elif status.IsTypeError():\r\n---> 91             raise ArrowTypeError(message)\r\n     92         elif status.IsCapacityError():\r\n     93             raise ArrowCapacityError(message)\r\n\r\nArrowTypeError: an integer is required (got type datetime.date)\r\n\u00a0\n```\r\n\r\nhowever with datetime it works, so the error message could be better\r\n\r\n```python\n\r\nIn [46]: pa.array([datetime.datetime(2018, 12, 12)], type=pa.timestamp('s'))\r\nOut[46]:\r\n<pyarrow.lib.TimestampArray object at 0x11d243638>\r\n[\r\n  1544572800\r\n]\r\n```\r\n\r\nI think We should have a general solution to extend the low level errors with extra, python related context. \r\nThe current error handling in cython seems really lightweight https://github.com/apache/arrow/blob/master/python/pyarrow/error.pxi#L71\r\n\r\nWould it be OK to extend it with an error rewriting logic?"
        },
        {
            "created_at": "2019-01-01T00:21:59.072Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1989?focusedCommentId=16731491) by Matthew Rocklin (mrocklin):*\nI would find this fix useful.\u00a0 \r\n\r\nIn particular I think that it might be useful to point users towards possible solutions, like the `allow_truncated_timestamps=True` option."
        },
        {
            "created_at": "2019-04-05T19:01:55.630Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1989?focusedCommentId=16811172) by Nick Throckmorton (nthrockmorton):*\nAgreed. I would propose this message to point users to a potential solution.\r\nArrowInvalid: Casting from timestamp[ns] to timestamp[us] would lose data: XX\r\nTo accept this, use `allow_truncated_timestamps=True`. \r\n\u00a0"
        },
        {
            "created_at": "2019-05-31T00:37:30.408Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1989?focusedCommentId=16852495) by Wes McKinney (wesm):*\n`[~jorisvandenbossche]` potentially of interest?"
        },
        {
            "created_at": "2019-06-07T14:59:59.132Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1989?focusedCommentId=16858724) by Joris Van den Bossche (jorisvandenbossche):*\nLooking into this. But, I can't find a reproducible example which gives a similar error to what is reported above. Does somebody have a concrete example?\r\n\r\nWith latest pandas and pyarrow (and the same with pd 0.24.2 / pyarrow 0.12), I can get to something like this (having an timestamp with lower resolution that is out of bounds for pandas):\r\n\r\n```python\n\r\nIn [63]: a = pa.array([datetime.datetime(1018, 12, 12)], type=pa.timestamp('s'))\r\n\r\nIn [64]: a.to_pandas()\r\nOut[64]: array(['1018-12-12T00:00:00'], dtype='datetime64[s]')\r\n\r\nIn [65]: table = pa.Table.from_pydict({'a': a})\r\n\r\nIn [66]: table\r\nOut[66]: \r\npyarrow.Table\r\na: timestamp[s]\r\n\r\nIn [67]: table.to_pandas()\r\nOut[67]: \r\n                              a\r\n0 2188-01-19 23:09:07.419103232\r\n```\r\n\r\nThis is a wrong result, however, and silently. This is a bug in pandas, and described in ARROW-3176"
        },
        {
            "created_at": "2019-06-07T15:26:08.096Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1989?focusedCommentId=16858736) by Joris Van den Bossche (jorisvandenbossche):*\nThe mention of `allow_truncated_timestamps=True` led me to towards parquet, and with that I can indeed reproduce it (although for the case I reproduced below, it is about converting _from_ pandas  and not _to_ pandas):\r\n\r\n```python\n\r\nIn [85]: df = pd.DataFrame({'a': [pd.Timestamp(\"2019-01-01 09:10:15.123456789\")]})\r\n\r\nIn [86]: table = pa.Table.from_pandas(df)\r\n\r\nIn [88]: pq.write_table(table, '__test_datetime_highprecision.parquet')\r\n...\r\nArrowInvalid: Casting from timestamp[ns] to timestamp[us] would lose data: 1546333815123456789\r\n\r\nIn [89]: pq.write_table(table, '__test_datetime_highprecision.parquet', allow_truncated_timestamps=True)\r\n\r\nIn [91]: pq.read_table('__test_datetime_highprecision.parquet').to_pandas()\r\nOut[91]: \r\n                           a\r\n0 2019-01-01 09:10:15.123456\r\n```\r\n\r\nSo indeed, in this case it would be nice to have a better error message that also points to this option.\r\n\r\nHowever, for this specific case: shouldn't we be able to solve it now we have NANOS support in Parquet writing? (see https://issues.apache.org/jira/browse/ARROW-1957, which should be possible now the LogicalTypes PR is merged: PARQUET-1411)\r\n\r\nIn general though, there will be other cases where it could be useful to augment the arrow error message in Python. "
        },
        {
            "created_at": "2019-06-13T19:42:47.016Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1989?focusedCommentId=16863399) by Wes McKinney (wesm):*\nI'm moving out of the release scope for now"
        },
        {
            "created_at": "2021-08-04T08:57:18.421Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-1989?focusedCommentId=17392883) by Antoine Pitrou (apitrou):*\n`[~jorisvandenbossche]` Do we want to close this?"
        }
    ]
}