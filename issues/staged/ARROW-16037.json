{
    "issue": {
        "title": "[Python] Possible memory leak in compute.take",
        "body": "***Note**: This issue was originally created as [ARROW-16037](https://issues.apache.org/jira/browse/ARROW-16037). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nIf you run the following code, the memory usage of the process goes up to 1GB even though the pyarrow allocated bytes is always at ~80MB. The process memory comes down after a while to 800 MB, but is still way more than what is necessary.\r\n\r\n'''\r\n\r\nimport pyarrow as pa\r\nimport numpy as np\r\nimport pandas as pd\r\nimport os, psutil\r\nimport pyarrow.compute as compute\r\nimport gc\r\nmy_table = pa.Table.from_pandas(pd.DataFrame(np.random.normal(size=(10000,1000))))\r\n\r\nprocess = psutil.Process(os.getpid())\r\nprint(\"mem usage\", process.memory_info().rss, pa.total_allocated_bytes())\r\n\r\nfor i in range(100):\r\n\u00a0 \u00a0 print(\"mem usage\", process.memory_info().rss, pa.total_allocated_bytes())\r\n\u00a0 \u00a0 temp = compute.sort_indices(my_table['0'], sort_keys = [('0','ascending')])\r\n\u00a0 \u00a0 my_table = my_table.take(temp)\r\n\u00a0 \u00a0 gc.collect()\r\n\r\n'''",
        "created_at": "2022-03-27T03:32:10.000Z",
        "updated_at": "2022-06-29T16:25:54.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Python",
            "Type: bug"
        ],
        "closed": false
    },
    "comments": [
        {
            "created_at": "2022-03-28T16:05:32.082Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16037?focusedCommentId=17513470) by Will Jones (willjones127):*\nMost likely, what you are seeing is memory being held onto by the memory pool for future re-use. Arrow uses Jemalloc by default on Linux. You can check this by running\u00a0`os.environ['ARROW_DEFAULT_MEMORY_POOL'] = 'system'` prior to your code snippet, which should result in more consistent memory usage.\r\n\r\nCould you try that? And if you still think you see a memory leak, could you share the output you are seeing from the above snippet?"
        },
        {
            "created_at": "2022-03-28T18:48:07.776Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16037?focusedCommentId=17513573) by Ziheng Wang (marsupialtail):*\nDoes not help.\r\n\r\nmem usage 179580928 80000000\r\nmem usage 179580928 80000000\r\nmem usage 263417856 81280000\r\nmem usage 330989568 81280000\r\nmem usage 414253056 81280000\r\nmem usage 476971008 81280000\r\nmem usage 553205760 81280000\r\nmem usage 599236608 81280000\r\nmem usage 674279424 81280000\r\nmem usage 709419008 81280000\r\nmem usage 764780544 81280000\r\nmem usage 795869184 81280000\r\nmem usage 755544064 81280000\r\nmem usage 817991680 81280000\r\nmem usage 803844096 81280000\r\nmem usage 751759360 81280000\r\nmem usage 833671168 81280000\r\nmem usage 780136448 81280000\r\nmem usage 780677120 81280000\r\nmem usage 812576768 81280000\r\nmem usage 814198784 81280000\r\nmem usage 794263552 81280000\r\nmem usage 796155904 81280000\r\nmem usage 797507584 81280000\r\nmem usage 798318592 81280000\r\nmem usage 799399936 81280000\r\nmem usage 800481280 81280000\r\nmem usage 801832960 81280000\r\nmem usage 801832960 81280000\r\nmem usage 814268416 81280000\r\nmem usage 737091584 81280000\r\nmem usage 781156352 81280000\r\nmem usage 854958080 81280000\r\nmem usage 825163776 81280000\r\nmem usage 853274624 81280000\r\nmem usage 737460224 81280000\r\nmem usage 801800192 81280000\r\nmem usage 810450944 81280000\r\nmem usage 558161920 81280000\r\nmem usage 620609536 81280000\r\nmem usage 670892032 81280000\r\nmem usage 733609984 81280000\r\nmem usage 733609984 81280000\r\nmem usage 734961664 81280000\r\nmem usage 735502336 81280000\r\nmem usage 623452160 81280000\r\nmem usage 609259520 81280000\r\nmem usage 671707136 81280000\r\nmem usage 707751936 81280000\r\nmem usage 707751936 81280000\r\nmem usage 743706624 81280000\r\nmem usage 743706624 81280000\r\nmem usage 562147328 81280000\r\nmem usage 624594944 81280000\r\nmem usage 637956096 81280000\r\nmem usage 700403712 81280000\r\nmem usage 680206336 81280000\r\nmem usage 725622784 81280000\r\nmem usage 706813952 81280000\r\nmem usage 708165632 81280000\r\nmem usage 728440832 81280000\r\nmem usage 789536768 81280000\r\nmem usage 541188096 81280000\r\nmem usage 602284032 81280000\r\nmem usage 639320064 81280000\r\nmem usage 670679040 81280000\r\nmem usage 746643456 81280000\r\nmem usage 719314944 81280000\r\nmem usage 495579136 81280000\r\nmem usage 567218176 81280000\r\nmem usage 612093952 81280000\r\nmem usage 679677952 81280000\r\nmem usage 661270528 81280000\r\nmem usage 712622080 81280000\r\nmem usage 714514432 81280000\r\nmem usage 716136448 81280000\r\nmem usage 717217792 81280000\r\nmem usage 771825664 81280000\r\nmem usage 784801792 81280000\r\nmem usage 822665216 81280000\r\nmem usage 823205888 81280000\r\nmem usage 823205888 81280000\r\nmem usage 823476224 81280000\r\nmem usage 829153280 81280000\r\nmem usage 836722688 81280000\r\nmem usage 471212032 81280000\r\nmem usage 552583168 81280000\r\nmem usage 622600192 81280000\r\nmem usage 659906560 81280000\r\nmem usage 730193920 81280000\r\nmem usage 730193920 81280000\r\nmem usage 753713152 81280000\r\nmem usage 753983488 81280000\r\nmem usage 727797760 81280000\r\nmem usage 727797760 81280000\r\nmem usage 729419776 81280000\r\nmem usage 731041792 81280000\r\nmem usage 732663808 81280000\r\nmem usage 733745152 81280000\r\nmem usage 733745152 81280000\r\nmem usage 735367168 81280000"
        },
        {
            "created_at": "2022-03-28T19:37:09.709Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16037?focusedCommentId=17513589) by Will Jones (willjones127):*\nOkay interesting. So you don't see memory monotonically increasing, it seems to level out at about 800MB. I am unable to reproduce, at least with pyarrow 6.0.1 on MacOS. What version of numpy and pandas are you using? And maybe worth trying setting the environment variable outside of Arrow (I forgot on some platforms you can't set to os.environ)\r\n\r\n\u00a0\r\n```bash\n\r\n# Before launching python\r\nexport ARROW_DEFAULT_MEMORY_POOL=system\r\n```\r\n\u00a0\r\n```python\n\r\nimport pyarrow as pa\r\nimport numpy as np\r\nimport pandas as pd\r\nimport os, psutil\r\nimport pyarrow.compute as compute\r\nimport gc\r\nmy_table = pa.Table.from_pandas(pd.DataFrame(np.random.normal(size=(10000,1000))))\r\n\r\nprint(\"using backend: {}\".format(pa.default_memory_pool().backend_name))\r\n\r\nprocess = psutil.Process(os.getpid())\r\nprint(\"mem usage {:,} {:,}\".format(process.memory_info().rss, pa.total_allocated_bytes()))\r\n\r\nfor i in range(100):\r\n    print(\"mem usage {:,} {:,}\".format(process.memory_info().rss, pa.total_allocated_bytes()))\r\n    temp = compute.sort_indices(my_table['0'], sort_keys = [('0','ascending')])\r\n    my_table = my_table.take(temp)\r\n    gc.collect()\r\n```\r\nHere is the output I get, (truncated, but very consistent throughout)\r\n```Java\n\r\nusing backend: system\r\nmem usage 256,311,296 80,080,000\r\nmem usage 256,098,304 80,080,000\r\n0\r\nmem usage 256,819,200 81,360,000\r\n0\r\nmem usage 256,851,968 81,360,000\r\n0\r\nmem usage 256,917,504 81,360,000\r\n0\r\nmem usage 256,884,736 81,360,000\r\n0\r\nmem usage 256,950,272 81,360,000\r\n0\r\nmem usage 257,081,344 81,360,000\r\n0\r\nmem usage 256,704,512 81,360,000\r\n0\r\nmem usage 257,081,344 81,360,000\r\n0\r\nmem usage 257,212,416 81,360,000\r\n```"
        },
        {
            "created_at": "2022-03-28T20:01:02.863Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16037?focusedCommentId=17513609) by Ziheng Wang (marsupialtail):*\nI am on ubuntu\r\npa.default_memory_pool().backend_name\r\nDoesn't work for me? I'm running Pyarrow 6.0.1"
        },
        {
            "created_at": "2022-03-29T20:48:23.214Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16037?focusedCommentId=17514324) by Will Jones (willjones127):*\nIf that doesn't work, then that suggests you are actually running PyArrow < 3.0.0. I recomend double checking with `pa.\\_\\_version\\_\\_`. See: https://arrow.apache.org/docs/3.0/python/generated/pyarrow.MemoryPool.html"
        },
        {
            "created_at": "2022-04-08T12:12:33.370Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16037?focusedCommentId=17519539) by Jacob Wujciak-Jens (assignUser):*\n`[~marsupialtail]` is this still an issue for you or was it fixed by updating pyarrow?"
        },
        {
            "created_at": "2022-06-29T16:25:54.885Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-16037?focusedCommentId=17560356) by Jonathan Keane (jonkeane):*\nA bump on this: Have you had a chance to check your pyarrow version? Does this still replicate with newer versions? "
        }
    ]
}