{
    "issue": {
        "title": "[FlightRPC][Java] Implement Flight SQL JDBC Driver",
        "body": "***Note**: This issue was originally created as [ARROW-7744](https://issues.apache.org/jira/browse/ARROW-7744). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAs a Java developer, I would like the ability to use JDBC to interact with Flight servers. For example, there is now an example in the Arrow repo to run a Flight server wrapping DataFusion and it supports executing SQL against CSV and Parquet files. I would like to be able to call this from Java.\r\n\r\nA flight Arrow JDBC driver would also then simplify developing integrations with other Apache projects, such as building a Spark V2 Data Source or a Drill storage plugin. It would also be directly usable from many BI tools.\r\n\r\nI propose that the class name of the driver should be \"org.apache.arrow.jdbc.Driver\" and the connection string should be \"jdbc:arrow://host:port?[properties]\". I'm purposely leaving \"flight\" out of these because I don't think it makes sense to support multiple protocols now that we have flight and it is easier for users to remember \"arrow\" rather than needing to know about the protocol. This is easy to change if there are objections.\r\n\r\nJDBC is designed around sending queries as strings and then receiving results. These strings could be SQL queries, JSON-encoded query plans, or something else. The JDBC driver will not make any assumptions about the format or dialect of these strings. Queries would be executed using the \"DoGet\" method.\r\n\r\nThe JDBC metadata functionality for reading schema information could possibly use ListFlights but I haven't looked into this part yet.\r\n\r\nI do expect that this JDBC driver will serve as a base that could be extended to add specific functionality for different Flight servers rather than attempt to support them all.\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0",
        "created_at": "2020-02-02T15:09:33.000Z",
        "updated_at": "2022-09-30T12:26:07.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: FlightRPC",
            "Component: Java",
            "Type: enhancement"
        ],
        "closed": true,
        "closed_at": "2022-09-14T18:38:43.000Z"
    },
    "comments": [
        {
            "created_at": "2020-02-03T21:57:15.583Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7744?focusedCommentId=17029327) by Jacques Nadeau (jnadeau):*\nGiven my previous experience with these APIs, I suggest you use Avatica as the basis for this rather than implementing by hand. I noticed you haven't done that in your WIP. Was it something you considered?"
        },
        {
            "created_at": "2020-02-03T22:29:00.064Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7744?focusedCommentId=17029344) by Andy Grove (andygrove):*\nHi Jacques,\n\nI was wary of adding more dependencies unless/until they are really needed.\nI've implemented production JDBC drivers before, and there is definitely a\nbit of tedious work involved in implementing the result set type conversion\ncode and some of the associated metadata functionality but my gut feeling\nso far is that the long term burden would be less than designing around\nAvatica. Avatica seems to provide much more than we need with a server\nprocess, wire protocol, etc. It also has its own type system so we would\nhave to convert between Avatica and Arrow types. It seems preferable to\ndesign this from the ground up based on Arrow types? I also was not able to\nfind comprehensive documentation for building a JDBC driver like this with\nAvatica, which concerned me.\n\nI guess I could try and do a mini bake-off here and create a PR based on\nAvatica as well so we can compare the approaches. I can also ask some\nquestions on the appropriate mailing list about Avatica's suitability for\nthis use case.\n\nThanks,\n\nAndy.\n\n\n\n\n\n\n\nOn Mon, Feb 3, 2020 at 2:58 PM Jacques Nadeau (Jira) <jira@apache.org>\n\n"
        },
        {
            "created_at": "2020-06-08T16:54:12.961Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7744?focusedCommentId=17128444) by Wes McKinney (wesm):*\nI haven't seen activity on this so removing from the 1.0.0 milestone for now"
        },
        {
            "created_at": "2020-08-11T20:16:07.377Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7744?focusedCommentId=17175819) by John Kew (jkew):*\nGiven my experience as well; I think a pure java/flight/arrow version would be preferred, if only to reduce the number of dependencies. Primarily the\u00a0 advantage here of a JDBC driver is to explore lots of integration scenarios; so I suspect a light-weight approach would be ideal. While I really like calcite, for the purposes of flight I may explore Andy's original CL here as a start within Tableau as a wrapped up connector plugin to see what can be made of it."
        },
        {
            "created_at": "2020-08-20T15:35:17.914Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7744?focusedCommentId=17181285) by Andy Grove (andygrove):*\nI am still interested in exploring this but have unassigned myself for now because it will be a long time before I can get to this."
        },
        {
            "created_at": "2022-09-14T18:38:43.090Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-7744?focusedCommentId=17604914) by David Li (lidavidm):*\nIssue resolved by pull request 13800\n<https://github.com/apache/arrow/pull/13800>"
        }
    ]
}