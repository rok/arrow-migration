{
    "issue": {
        "title": "[Python] unexpected content after groupby on a dataframe restored from partitioned parquet with filters",
        "body": "***Note**: This issue was originally created as [ARROW-14772](https://issues.apache.org/jira/browse/ARROW-14772). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nWhile experimenting with the partitioned dataset persistence in parquet, I stumbled upon an interesting feature (or bug?) where after restoring only a certain partition and applying groupby I suddenly get all the filtered rows in the dataframe.\u00a0\r\n\r\nFollowing code demonstrates the issue:\r\n```java\n\r\nimport numpy as np\r\nimport os\r\nimport pandas as pd \u00a0# 1.3.4\r\nimport pyarrow as pa \u00a0# 6.0.1\r\nimport random\r\nimport shutil\r\nimport string\r\nimport tempfile\r\n\r\nfrom datetime import datetime, timedelta\r\n\r\nif __name__ == '__main__':\r\n# 1. generate random data frame\r\n\u00a0 \u00a0 day_count = 5\r\n\u00a0 \u00a0 data_length = 10\r\n\r\n\u00a0 \u00a0 numpy_random_gen = np.random.default_rng()\r\n\u00a0 \u00a0 label_choices = [''.join(random.choices(string.ascii_uppercase + string.digits, k=8)) for _ in range(5)]\r\n\u00a0 \u00a0 partial_dfs = []\r\n\r\n\u00a0 \u00a0 start_date = datetime.today().date() - timedelta(days=day_count)\r\n\u00a0 \u00a0 for date in (start_date + timedelta(n) for n in range(day_count)):\r\n\u00a0 \u00a0 \u00a0 \u00a0 date_array = pd.to_datetime(np.full(data_length, date)).date\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 label_array = np.full(data_length, [random.choice(label_choices) for _ in range(data_length)])\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 value_array = numpy_random_gen.integers(low=1, high=500, size=data_length)\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 partial_dfs.append(pd.DataFrame(data={'date': date_array, 'label': label_array, 'value': value_array}))\r\n\r\n\u00a0 \u00a0 df = pd.concat(partial_dfs, ignore_index=True)\r\n\u00a0 \u00a0 print(f\"Unique dates before restore:\\n{df.drop_duplicates(subset='date')['date']}\")\r\n\r\n# 2. persist data frame partitioned by date\r\n\u00a0 \u00a0 dataset_dir = tempfile.mkdtemp()\r\n\r\n\u00a0 \u00a0 df.to_parquet(path=dataset_dir, engine='pyarrow', partition_cols=['date', 'label'])\r\n\r\n# 3. restore from parquet partitioned dataset\r\n\u00a0 \u00a0 restored_df = pd.read_parquet(dataset_dir, engine='pyarrow', filters=[\r\n\u00a0 \u00a0 \u00a0 \u00a0 ('date', '=', str(start_date))], use_legacy_dataset=False)\r\n\u00a0 \u00a0 print(f\"Unique dates after restore:\\n{restored_df.drop_duplicates(subset='date')['date']}\")\r\n\r\n\u00a0 \u00a0 group_by_df = restored_df.groupby(by=['date', 'label'])['value'].sum().reset_index(name='val_sum')\r\n\u00a0 \u00a0 print(group_by_df)\r\n\r\n\u00a0 \u00a0 shutil.rmtree(dataset_dir) \n```\r\nIt correctly reports five unique dates upon random df generation and correctly reports only one after reading back from parquet:\r\n```\n\r\nUnique dates after restore:\r\n0 \u00a0 \u00a02021-11-13\r\nName: date, dtype: category\r\nCategories (5, object): ['2021-11-13', '2021-11-14', '2021-11-15', '2021-11-16', '2021-11-17']\n```\r\nAlbeit it adds that there are 5 categories. When subsequently I perform a groupby, all dates that were filtered out at read miracolously appear:\r\n```java\n\r\n\u00a0 \u00a0 group_by_df = restored_df.groupby(by=['date', 'label'])['value'].sum().reset_index(name='val_sum')\r\n\u00a0 \u00a0 print(group_by_df)\r\n```\r\nWith the following output:\r\n```\n\r\n  \u00a0 \u00a0 \u00a0 \u00a0 date \u00a0 \u00a0 label \u00a0val_sum\r\n0 \u00a0 2021-11-13 \u00a004LOXJCH \u00a0 \u00a0 \u00a0494\r\n1 \u00a0 2021-11-13 \u00a04QOZ321D \u00a0 \u00a0 \u00a0819\r\n2 \u00a0 2021-11-13 \u00a0GG6YO5FS \u00a0 \u00a0 \u00a0394\r\n3 \u00a0 2021-11-13 \u00a0J7ZD3LDS \u00a0 \u00a0 \u00a0203\r\n4 \u00a0 2021-11-13 \u00a0TFVIXE6L \u00a0 \u00a0 \u00a0164\r\n5 \u00a0 2021-11-14 \u00a004LOXJCH \u00a0 \u00a0 \u00a0 \u00a00\r\n6 \u00a0 2021-11-14 \u00a04QOZ321D \u00a0 \u00a0 \u00a0 \u00a00\r\n7 \u00a0 2021-11-14 \u00a0GG6YO5FS \u00a0 \u00a0 \u00a0 \u00a00\r\n8 \u00a0 2021-11-14 \u00a0J7ZD3LDS \u00a0 \u00a0 \u00a0 \u00a00\r\n9 \u00a0 2021-11-14 \u00a0TFVIXE6L \u00a0 \u00a0 \u00a0 \u00a00\r\n10 \u00a02021-11-15 \u00a004LOXJCH \u00a0 \u00a0 \u00a0 \u00a00\r\n11 \u00a02021-11-15 \u00a04QOZ321D \u00a0 \u00a0 \u00a0 \u00a00\r\n12 \u00a02021-11-15 \u00a0GG6YO5FS \u00a0 \u00a0 \u00a0 \u00a00\r\n13 \u00a02021-11-15 \u00a0J7ZD3LDS \u00a0 \u00a0 \u00a0 \u00a00\r\n14 \u00a02021-11-15 \u00a0TFVIXE6L \u00a0 \u00a0 \u00a0 \u00a00\r\n15 \u00a02021-11-16 \u00a004LOXJCH \u00a0 \u00a0 \u00a0 \u00a00\r\n16 \u00a02021-11-16 \u00a04QOZ321D \u00a0 \u00a0 \u00a0 \u00a00\r\n17 \u00a02021-11-16 \u00a0GG6YO5FS \u00a0 \u00a0 \u00a0 \u00a00\r\n18 \u00a02021-11-16 \u00a0J7ZD3LDS \u00a0 \u00a0 \u00a0 \u00a00\r\n19 \u00a02021-11-16 \u00a0TFVIXE6L \u00a0 \u00a0 \u00a0 \u00a00\r\n20 \u00a02021-11-17 \u00a004LOXJCH \u00a0 \u00a0 \u00a0 \u00a00\r\n21 \u00a02021-11-17 \u00a04QOZ321D \u00a0 \u00a0 \u00a0 \u00a00\r\n22 \u00a02021-11-17 \u00a0GG6YO5FS \u00a0 \u00a0 \u00a0 \u00a00\r\n23 \u00a02021-11-17 \u00a0J7ZD3LDS \u00a0 \u00a0 \u00a0 \u00a00\r\n24 \u00a02021-11-17 \u00a0TFVIXE6L \u00a0 \u00a0 \u00a0 \u00a00\n```\r\nPerhaps I am doing something incorrectly within read_parquet call or something, but my expectation would be for filtered data just be gone after the read operation.",
        "created_at": "2021-11-18T21:12:26.000Z",
        "updated_at": "2022-08-27T14:41:45.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Parquet",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-11-20T09:13:03.000Z"
    },
    "comments": [
        {
            "created_at": "2021-11-18T22:18:09.190Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17446169) by Weston Pace (westonpace):*\nI'm not really sure what the correct behavior should be.\u00a0 Maybe `[~cpcloud]` `[~icook]` have an opinion?"
        },
        {
            "created_at": "2021-11-19T01:58:06.687Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17446240) by Ian Cook (icook):*\n`[~jorisvandenbossche]` \u00a0do you know what might explain this behavior?"
        },
        {
            "created_at": "2021-11-19T18:28:13.786Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17446622) by Weston Pace (westonpace):*\nOh, I can probably explain it.\u00a0 The partition column is returned as a dictionary encoded string (in pandas this is converted to a category).\u00a0 There is only one value but the \"dictionary\" part has all the possibilities.\u00a0 You can see this above here:\r\n```\n\r\nUnique dates after restore:\r\n0 \u00a0 \u00a02021-11-13\r\nName: date, dtype: category\r\nCategories (5, object): ['2021-11-13', '2021-11-14', '2021-11-15', '2021-11-16', '2021-11-17'] \n```\r\nEven though there is only one unique value in the array (2021-11-13) there are five different values in the dictionary part (five categories in pandas).\r\n\r\nSo my question isn't \"how is this happening\" but \"what behavior do we want?\"\u00a0 For futher, example, note that we get the exact same result if we read in the entire dataset and do the filtering in Pandas.\r\n```\n\r\nrestored_df = pd.read_parquet(dataset_dir, engine='pyarrow', use_legacy_dataset=False)\r\nrestored_df[restored_df['date'] == str(start_date)]\n```\r\nI can see arguments for both sides.\u00a0 On the one hand there is a bunch of unexpected and often useless info.\u00a0 On the other hand there may be rare cases where it would be handy to know what the full range of possible values was."
        },
        {
            "created_at": "2021-11-19T22:11:53.454Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17446679) by Vadim Mironov (vadik_mironov):*\nThanks a lot Weston. I see. It restores the date column as a categorical type with all possible values in the dictionary. On your point regarding API expectations - it's a fair point. Although as you can see from my initial confusion, I expected the filter parameter to act as a true filter and have no other data in the data frame other than what I specified. I am not sure whether this would be an expectation of majority of API users for partitioned datasets, but if so then perhaps the behavior where all categories are restored should be available only via a dedicated argument.\r\n\r\nIn terms of practicality of current behaviour, it would be a bit cumbersome to pepper the code working with these filtered dataframes with all sorts of safeguards to catch zeroes or NaNs against the rows that were supposed to be filtered out. Besides, if I would to use multiple filters with 'greather than' or 'in' operators, post processing of the dataframe would be complex and I essentially would need to redo the filter rule logic.\r\n\r\nAnother point which is rather minor compared to the considerations outlined above is the conversion of data column to categorical type upon recovery. Is my assumption correct that this would be true for any column that was used to partition dataset? If so I am not sure what practical implications it may have beyond the need to format dates to strings, but it may also be a source of few surprizes."
        },
        {
            "created_at": "2021-11-19T23:27:48.004Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17446720) by Weston Pace (westonpace):*\nIt seems that pandas [groupby function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) has an \"observed\" parameter:\r\n\r\n```\n\r\nobserved : bool, default False\r\n\r\nThis only applies if any of the groupers are Categoricals.\r\nIf True: only show observed values for categorical groupers.\r\nIf False: show all values for categorical groupers.\r\n```\r\n\r\nDoes this help?\r\n\r\n> Another point which is rather minor compared to the considerations outlined above is the conversion of data column to categorical type upon recovery. Is my assumption correct that this would be true for any column that was used to partition dataset?\r\n\r\nYes and no (note, panda's \"categorical\" is the same as arrow's \"dictionary\" so when I say \"dictionary\" here I am referring to the same concept).  Pyarrow exposes this as an option in the newer dataset API and it actually defaults to **not** dictionary encoded so you have to go out of your way a little to get this behavior.\r\n\r\nHowever, the legacy dataset API (passing a directory name to pq.read_table) always sets \"infer_dictionary\" to true.  This is the API that is used by the pandas' pyarrow engine.  So, as a workaround, you could do something like...\r\n\r\n```\n\r\nimport pyarrow.dataset as ds\r\nrestored_df = ds.dataset(dataset_dir, partitioning='hive').to_table(filter=ds.field('date') == str(start_date)).to_pandas()\r\n```"
        },
        {
            "created_at": "2021-11-20T09:12:49.765Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17446771) by Vadim Mironov (vadik_mironov):*\nI see. Thanks Weston and I confirm that either of the two ways gives exactly what I would expect to see as a result of a groupby. Certainly, the suggestion to use a\u00a0 pyarrow.dataset API directly is the most appealing one as I am quite hesitant to retrofit all the pandas groupby calls with observed=True.\u00a0\r\n\r\nI will close this issue, but perhaps one last question - I could not find in pandas git tracker any open issues for dataset pyarrow API transition. Would you happen to know if this is something on their 1.4 roadmap or maybe it would be worth for me go there and raise something on the back of this curious find?\r\n\r\nDefinitely want to leave some trace for others who might stumble on the same issue and it feels like it belongs more to pandas tracker if anything.\u00a0"
        },
        {
            "created_at": "2021-11-22T13:28:48.173Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17447399) by Joris Van den Bossche (jorisvandenbossche):*\nSorry for the late response here, this was indeed a classical case of \"all _known_ categories versus all _present_ categories\" confusion in pandas, for which the `observed` keyword was added, as mentioned above. \r\n\r\n> I could not find in pandas git tracker any open issues for dataset pyarrow API transition. Would you happen to know if this is something on their 1.4 roadmap or maybe it would be worth for me go there and raise something on the back of this curious find?\r\n\r\nPandas is actually already using the datasets code under the hood, but just through the `pq.read_table` interface instead of through the `ds.dataset` interface (since the default for `pq.read_table` is to already use datasets under the hood). So I am not sure it is necessary for pandas to explicitly transition to the datasets interface (`pq.read_table` has some useful boilerplate around `ds.datasets` that otherwise would need to be replicated in pandas).  \r\nBut it would certainly be useful to consider the few behavioural differences, such as the dictionary encoding for the partition columns.\r\n\r\nFor example, something pandas could add (or pyarrow in `pq.read_table`) is a keyword to disable reading partition columns as dictionary/categorical data type. "
        },
        {
            "created_at": "2021-11-22T14:57:54.266Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17447456) by Vadim Mironov (vadik_mironov):*\nThanks Joris. Perhaps my understanding is wrong, but with the state as you describe it by enabling partitioning I suddenly get a change in behavior of pandas groupby and then has to go through all the models doing this type of aggregation to add the additional parameter. That is if I know that the issue is caused by partitioning columns turning into categoricals. Sound to me a bit too harsh for the users unless the observed parameter is widely used by everyone (which is unlikely as it would be enabled by default then).\u00a0"
        },
        {
            "created_at": "2022-08-27T14:41:45.116Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-14772?focusedCommentId=17585824) by @toddfarmer:*\nTransitioning issue from Resolved to Closed to based on resolution field value."
        }
    ]
}