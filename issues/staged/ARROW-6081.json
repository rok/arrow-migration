{
    "issue": {
        "title": "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmptb2ao6te_job_6e0a8ca1.parquet'",
        "body": "***Note**: This issue was originally created as [ARROW-6081](https://issues.apache.org/jira/browse/ARROW-6081). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nAny idea on how to fix this error?\u00a0\r\n\r\n\u00a0\r\n\r\nTraceback (most recent call last):\r\n File \"/usr/local/lib/python3.6/site-packages/google/cloud/bigquery/client.py\", line 1530, in load_table_from_dataframe\r\n dataframe.to_parquet(tmppath)\r\n File \"/usr/local/lib64/python3.6/site-packages/pandas/core/frame.py\", line 2203, in to_parquet\r\n partition_cols=partition_cols, \\*\\*kwargs)\r\n File \"/usr/local/lib64/python3.6/site-packages/pandas/io/parquet.py\", line 252, in to_parquet\r\n partition_cols=partition_cols, \\*\\*kwargs)\r\n File \"/usr/local/lib64/python3.6/site-packages/pandas/io/parquet.py\", line 122, in write\r\n coerce_timestamps=coerce_timestamps, \\*\\*kwargs)\r\n File \"/usr/local/lib64/python3.6/site-packages/pyarrow/parquet.py\", line 1270, in write_table\r\n writer.write_table(table, row_group_size=row_group_size)\r\n File \"/usr/local/lib64/python3.6/site-packages/pyarrow/parquet.py\", line 426, in write_table\r\n self.writer.write_table(table, row_group_size=row_group_size)\r\n File \"pyarrow/_parquet.pyx\", line 1311, in pyarrow._parquet.ParquetWriter.write_table\r\n File \"pyarrow/error.pxi\", line 85, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowInvalid: Nested column branch had multiple children\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n File \"/var/cache/tomcat/temp/interpreter-2169813765840716657.tmp\", line 84, in <module>\r\n client.load_table_from_dataframe(appended_data, table_ref,job_config=job_config).result()\r\n File \"/usr/local/lib/python3.6/site-packages/google/cloud/bigquery/client.py\", line 1546, in load_table_from_dataframe\r\n os.remove(tmppath)\r\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmptb2ao6te_job_6e0a8ca1.parquet'",
        "created_at": "2019-07-31T11:59:04.000Z",
        "updated_at": "2019-07-31T21:40:00.000Z",
        "labels": [
            "Migrated from Jira",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2019-07-31T21:40:00.000Z"
    },
    "comments": [
        {
            "created_at": "2019-07-31T12:38:02.308Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6081?focusedCommentId=16897125) by Joris Van den Bossche (jorisvandenbossche):*\nThe final error comes from bigquery, so you might want to also report it to them that they should handle arrow errors in a clearer way. \r\n\r\nThe underlying error raised from arrow is \"pyarrow.lib.ArrowInvalid: Nested column branch had multiple children\". It is hard to say for sure without a reproducible example, but I suppose this is related to the current limitation of the arrow parquet reader regarding nested columns with multiple children. See eg ARROW-1644, ARROW-1599"
        },
        {
            "created_at": "2019-07-31T21:40:00.368Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-6081?focusedCommentId=16897557) by Wes McKinney (wesm):*\nClosing as duplicate of ARROW-1644. Nested data support in Parquet is not yet complete"
        }
    ]
}