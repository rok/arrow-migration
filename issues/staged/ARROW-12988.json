{
    "issue": {
        "title": "[CI] The kartothek nightly integration build is failing (test_update_dataset_from_ddf_empty)",
        "body": "***Note**: This issue was originally created as [ARROW-12988](https://issues.apache.org/jira/browse/ARROW-12988). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n\n### Original Issue Description:\nThe nightly \"kartothek\" integration builds are failing.\r\n\r\nMore specifically, the `test_update_dataset_from_ddf_empty` is failing with:\r\n\r\n```Java\n\r\n=================================== FAILURES ===================================\r\n___________________ test_update_dataset_from_ddf_empty[True] ___________________\r\n\r\nstore_factory = functools.partial(<function get_store_from_url at 0x7f1434733050>, 'hfs:///tmp/pytest-of-root/pytest-0/test_update_dataset_from_ddf_e0/store')\r\nshuffle = True\r\n\r\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\r\n    def test_update_dataset_from_ddf_empty(store_factory, shuffle):\r\n        with pytest.raises(ValueError, match=\"Cannot store empty datasets\"):\r\n            update_dataset_from_ddf(\r\n>               dask.dataframe.from_delayed([], meta=((\"a\", int),)),\r\n                store_factory,\r\n                dataset_uuid=\"output_dataset_uuid\",\r\n                table=\"core\",\r\n                shuffle=shuffle,\r\n                partition_on=[\"a\"],\r\n            ).compute()\r\n\r\ntests/io/dask/dataframe/test_update.py:57: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\ndfs = [], meta = (('a', <class 'int'>),), divisions = None\r\nprefix = 'from-delayed', verify_meta = True\r\n\r\n    @insert_meta_param_description\r\n    def from_delayed(\r\n        dfs, meta=None, divisions=None, prefix=\"from-delayed\", verify_meta=True\r\n    ):\r\n        \"\"\"Create Dask DataFrame from many Dask Delayed objects\r\n    \r\n        Parameters\r\n        ----------\r\n        dfs : list of Delayed\r\n            An iterable of ``dask.delayed.Delayed`` objects, such as come from\r\n            ``dask.delayed`` These comprise the individual partitions of the\r\n            resulting dataframe.\r\n        $META\r\n        divisions : tuple, str, optional\r\n            Partition boundaries along the index.\r\n            For tuple, see https://docs.dask.org/en/latest/dataframe-design.html#partitions\r\n            For string 'sorted' will compute the delayed values to find index\r\n            values.  Assumes that the indexes are mutually sorted.\r\n            If None, then won't use index information\r\n        prefix : str, optional\r\n            Prefix to prepend to the keys.\r\n        verify_meta : bool, optional\r\n            If True check that the partitions have consistent metadata, defaults to True.\r\n        \"\"\"\r\n        from dask.delayed import Delayed\r\n    \r\n        if isinstance(dfs, Delayed):\r\n            dfs = [dfs]\r\n        dfs = [\r\n            delayed(df) if not isinstance(df, Delayed) and hasattr(df, \"key\") else df\r\n            for df in dfs\r\n        ]\r\n        for df in dfs:\r\n            if not isinstance(df, Delayed):\r\n                raise TypeError(\"Expected Delayed object, got %s\" % type(df).__name__)\r\n    \r\n>       parent_meta = delayed(make_meta)(dfs[0]).compute()\r\nE       IndexError: list index out of range\r\n\r\n/opt/conda/envs/arrow/lib/python3.7/site-packages/dask/dataframe/io/io.py:591: IndexError\r\n```\r\n\r\n(from https://github.com/ursacomputing/crossbow/runs/2756067090)\r\n\r\nNot directly sure if this is a kartothek issue or a pyarrow issue. But also created an issue on their side: https://github.com/JDASoftwareGroup/kartothek/issues/475",
        "created_at": "2021-06-07T13:29:58.000Z",
        "updated_at": "2021-07-06T11:10:13.000Z",
        "labels": [
            "Migrated from Jira",
            "Component: Continuous Integration",
            "Component: Python",
            "Type: bug"
        ],
        "closed": true,
        "closed_at": "2021-07-05T13:15:03.000Z"
    },
    "comments": [
        {
            "created_at": "2021-06-07T13:36:12.040Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12988?focusedCommentId=17358602) by Joris Van den Bossche (jorisvandenbossche):*\nThe last working build: https://github.com/ursacomputing/crossbow/runs/2691739138  (on 2021-05-28)\r\nThe first failing build: https://github.com/ursacomputing/crossbow/runs/2699726233\r\n\r\nThere is one change in the environment: dask updated from 2021.5.0 to 2021.5.1. So that might be the culprit."
        },
        {
            "created_at": "2021-06-07T16:00:46.777Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12988?focusedCommentId=17358686) by Joris Van den Bossche (jorisvandenbossche):*\nIssue resolved by pull request 10466\n<https://github.com/apache/arrow/pull/10466>"
        },
        {
            "created_at": "2021-06-07T16:02:29.916Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12988?focusedCommentId=17358687) by Joris Van den Bossche (jorisvandenbossche):*\nWill leave this open as a reminder for myself to revert this fix before 5.0.0 (can be done once the next dask is released with the bugfix: https://github.com/dask/dask/pull/7769)"
        },
        {
            "created_at": "2021-07-05T13:15:04.014Z",
            "body": "***Note**: [Comment](https://issues.apache.org/jira/browse/ARROW-12988?focusedCommentId=17374820) by Joris Van den Bossche (jorisvandenbossche):*\nIssue resolved by pull request 10655\n<https://github.com/apache/arrow/pull/10655>"
        }
    ]
}